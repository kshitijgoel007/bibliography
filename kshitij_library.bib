@book{_gnss_2008,
  title = {{{GNSS}} --- {{Global Navigation Satellite Systems}}},
  year = {2008},
  publisher = {Springer},
  address = {Vienna},
  doi = {10.1007/978-3-211-73017-1},
  url = {http://link.springer.com/10.1007/978-3-211-73017-1},
  urldate = {2025-03-13},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-211-73012-6 978-3-211-73017-1},
  langid = {english},
  keywords = {altitude determination,cartography,Galileo,geodesy,GLONASS,GNSS,GPS (Satellitengeodasie),Hohenstimmung,Kartographie,Koordinatenberechnung,Navigation,satellite,Vermessung},
  file = {/Users/kshitijgoel/Zotero/storage/8T7SC9QX/2008 - GNSS — Global Navigation Satellite Systems.pdf}
}

@inproceedings{abd-almageed_density_2006,
  title = {Density {{Estimation Using Mixtures}} of {{Mixtures}} of {{Gaussians}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2006},
  author = {{Abd-Almageed}, Wael and Davis, Larry S.},
  editor = {Leonardis, Ale{\v s} and Bischof, Horst and Pinz, Axel},
  year = {2006},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {410--422},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11744085_32},
  abstract = {In this paper we present a new density estimation algorithm using mixtures of mixtures of Gaussians. The new algorithm overcomes the limitations of the popular Expectation Maximization algorithm. The paper first introduces a new model selection criterion called the Penalty-less Information Criterion, which is based on the Jensen-Shannon divergence. Mean-shift is used to automatically initialize the means and covariances of the Expectation Maximization in order to obtain better structure inference. Finally, a locally linear search is performed using the Penalty-less Information Criterion in order to infer the underlying density of the data. The validity of the algorithm is verified using real color images.},
  isbn = {978-3-540-33839-0},
  langid = {english},
  keywords = {Bayesian Information Criterion,Expectation Maximization,Mixture Component,Segmentation Result,Segmented Image},
  file = {/Users/kshitijgoel/Zotero/storage/9PJXD2AQ/Abd-Almageed and Davis - 2006 - Density Estimation Using Mixtures of Mixtures of G.pdf}
}

@inproceedings{abdal_gaussian_2024,
  title = {Gaussian {{Shell Maps}} for {{Efficient 3D Human Generation}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Abdal, Rameen and Yifan, Wang and Shi, Zifan and Xu, Yinghao and Po, Ryan and Kuang, Zhengfei and Chen, Qifeng and Yeung, Dit-Yan and Wetzstein, Gordon},
  year = {2024},
  pages = {9441--9451},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Abdal_Gaussian_Shell_Maps_for_Efficient_3D_Human_Generation_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GJULDEVK/Abdal et al. - 2024 - Gaussian Shell Maps for Efficient 3D Human Generation.pdf}
}

@article{abdessameud_imagebased_2015,
  title = {Image-Based Tracking Control of {{VTOL}} Unmanned Aerial Vehicles},
  author = {Abdessameud, Abdelkader and {Janabi-Sharifi}, Farrokh},
  year = {2015},
  month = mar,
  journal = {Automatica},
  volume = {53},
  pages = {111--119},
  issn = {00051098},
  doi = {10.1016/j.automatica.2014.12.032},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0005109814006116},
  urldate = {2025-05-13},
  abstract = {This paper addresses the image-based control problem of vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs). Specifically, we propose a control scheme allowing the aircraft to track a moving target captured by an onboard camera where the orientation and angular velocity of the vehicle are assumed available for feedback. The proposed approach relies on appropriate image features, defined based on perspective image moments along with a useful projection, and the design of a bounded adaptive translational controller without linear velocity measurements in the presence of external disturbances. Estimates of the target's acceleration and the disturbances as well as some auxiliary variables are used to simplify the control design and guarantee the stability of the overall closed loop system. Simulation examples are provided to show the effectiveness of the proposed theoretical results.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AFM4MVCD/Abdessameud and Janabi-Sharifi - 2015 - Image-based tracking control of VTOL unmanned aerial vehicles.pdf}
}

@article{achanta_scaleadaptive_2018,
  title = {Scale-{{Adaptive Superpixels}}},
  editor = {Achanta, Radhakrishna and Marquez Neila, Pablo and Fua, Pascal and S{\"u}sstrunk, Sabine},
  year = {2018},
  journal = {26th Color and Imaging Conference Final Program and Proceedings},
  publisher = {{Society for Imaging Science and Technology}},
  doi = {10.2352},
  abstract = {Size uniformity is one of the prominent features of superpixels. However, size uniformity rarely conforms to the varying content of an image. The chosen size of the superpixels therefore represents a compromise - how to obtain the fewest superpixels without losing too much important detail. We present an image segmentation technique that generates compact clusters of pixels grown sequentially, which automatically adapt to the local texture and scale of an image. Our algorithm liberates the user from the need to choose of the right superpixel size or number. The algorithm is simple and requires just one input parameter. In addition, it is computationally very efficient, approaching real-time performance, and is easily extensible to three-dimensional image stacks and video volumes. We demonstrate that our superpixels superior to the respective state-of-the-art algorithms on quantitative benchmarks},
  file = {/Users/kshitijgoel/Zotero/storage/47PYVN5R/Achanta et al. - 2018 - Scale-Adaptive Superpixels.pdf}
}

@article{achanta_slic_2012,
  title = {{{SLIC Superpixels Compared}} to {{State-of-the-Art Superpixel Methods}}},
  author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and S{\"u}sstrunk, Sabine},
  year = {2012},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {34},
  number = {11},
  pages = {2274--2282},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2012.120},
  url = {https://ieeexplore.ieee.org/document/6205760},
  urldate = {2024-07-21},
  abstract = {Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.},
  keywords = {Approximation algorithms,clustering,Clustering algorithms,Complexity theory,Image color analysis,Image edge detection,Image segmentation,k-means,Measurement uncertainty,segmentation,Superpixels},
  file = {/Users/kshitijgoel/Zotero/storage/JCIV9GVX/Achanta et al. - 2012 - SLIC Superpixels Compared to State-of-the-Art Superpixel Methods.pdf;/Users/kshitijgoel/Zotero/storage/2X4B5C6C/6205760.html}
}

@inproceedings{achanta_superpixels_2017,
  title = {Superpixels and {{Polygons Using Simple Non-iterative Clustering}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Achanta, Radhakrishna and S{\"u}sstrunk, Sabine},
  year = {2017},
  month = jul,
  pages = {4895--4904},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2017.520},
  url = {https://ieeexplore.ieee.org/document/8100003},
  urldate = {2024-07-21},
  abstract = {We present an improved version of the Simple Linear Iterative Clustering (SLIC) superpixel segmentation. Unlike SLIC, our algorithm is non-iterative, enforces connectivity from the start, requires lesser memory, and is faster. Relying on the superpixel boundaries obtained using our algorithm, we also present a polygonal partitioning algorithm. We demonstrate that our superpixels as well as the polygonal partitioning are superior to the respective state-of-the-art algorithms on quantitative benchmarks.},
  keywords = {Clustering algorithms,Estimation,Image color analysis,Image segmentation,Iterative algorithms,Memory management,Partitioning algorithms},
  file = {/Users/kshitijgoel/Zotero/storage/GFYCDIXP/Achanta and Süsstrunk - 2017 - Superpixels and Polygons Using Simple Non-iterative Clustering.pdf;/Users/kshitijgoel/Zotero/storage/KVGFCFWL/Achanta and Süsstrunk - 2017 - Superpixels and Polygons Using Simple Non-iterative Clustering.pdf}
}

@inproceedings{achlioptas_learning_2018,
  title = {Learning {{Representations}} and {{Generative Models}} for {{3D Point Clouds}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Achlioptas, Panos and Diamanti, Olga and Mitliagkas, Ioannis and Guibas, Leonidas},
  year = {2018},
  month = jul,
  pages = {40--49},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/achlioptas18a.html},
  urldate = {2023-03-17},
  abstract = {Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SRGA6YWE/Achlioptas et al. - 2018 - Learning Representations and Generative Models for.pdf;/Users/kshitijgoel/Zotero/storage/VCNLJHLB/Achlioptas et al. - 2018 - Learning Representations and Generative Models for.pdf}
}

@article{adamkiewicz_visiononly_2022,
  title = {Vision-{{Only Robot Navigation}} in a {{Neural Radiance World}}},
  author = {Adamkiewicz, Michal and Chen, Timothy and Caccavale, Adam and Gardner, Rachel and Culbertson, Preston and Bohg, Jeannette and Schwager, Mac},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {4606--4613},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3150497},
  abstract = {Neural Radiance Fields (NeRFs) have recently emerged as a powerful paradigm for the representation of natural, complex 3D scenes. Neural Radiance Fields (NeRFs) represent continuous volumetric density and RGB values in a neural network, and generate photo-realistic images from unseen camera viewpoints through ray tracing. We propose an algorithm for navigating a robot through a 3D environment represented as a NeRF using only an onboard RGB camera for localization. We assume the NeRF for the scene has been pre-trained offline, and the robot's objective is to navigate through unoccupied space in the NeRF to reach a goal pose. We introduce a trajectory optimization algorithm that avoids collisions with high-density regions in the NeRF based on a discrete time version of differential flatness that is amenable to constraining the robot's full pose and control inputs. We also introduce an optimization based filtering method to estimate 6DoF pose and velocities for the robot in the NeRF given only an onboard RGB camera. We combine the trajectory planner with the pose filter in an online replanning loop to give a vision-based robot navigation pipeline. We present simulation results with a quadrotor robot navigating through a jungle gym environment, the inside of a church, and Stonehenge using only an RGB camera. We also demonstrate an omnidirectional ground robot navigating through the church, requiring it to reorient to fit through a narrow gap.},
  keywords = {Cameras,Collision avoidance,localization,motion and path planning,Navigation,neural radiance fields,Pipelines,Planning,Robot vision systems,Robots,vision-based navigation},
  file = {/Users/kshitijgoel/Zotero/storage/Y3J5VK4Y/Adamkiewicz et al. - 2022 - Vision-Only Robot Navigation in a Neural Radiance .pdf;/Users/kshitijgoel/Zotero/storage/E3N3INVY/9712211.html}
}

@incollection{adelson_plenoptic_1991,
  title = {The {{Plenoptic Function}} and the {{Elements}} of {{Early Vision}}},
  booktitle = {Computational {{Models}} of {{Visual Processing}}},
  author = {Adelson, Edward H. and Bergen, James R.},
  editor = {Landy, Michael and Movshon, J. Anthony},
  year = {1991},
  month = oct,
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/2002.003.0004},
  url = {https://direct.mit.edu/books/book/4264/chapter/179288/The-Plenoptic-Function-and-the-Elements-of-Early},
  urldate = {2024-02-21},
  isbn = {978-0-262-29089-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DFUDHALD/Adelson and Bergen - 1991 - The Plenoptic Function and the Elements of Early V.pdf}
}

@misc{agarwal_scenecomplete_2024,
  title = {{{SceneComplete}}: {{Open-World 3D Scene Completion}} in {{Complex Real World Environments}} for {{Robot Manipulation}}},
  shorttitle = {{{SceneComplete}}},
  author = {Agarwal, Aditya and Singh, Gaurav and Sen, Bipasha and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2024},
  month = oct,
  number = {arXiv:2410.23643},
  eprint = {2410.23643},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.23643},
  urldate = {2024-11-01},
  abstract = {Careful robot manipulation in every-day cluttered environments requires an accurate understanding of the 3D scene, in order to grasp and place objects stably and reliably and to avoid mistakenly colliding with other objects. In general, we must construct such a 3D interpretation of a complex scene based on limited input, such as a single RGB-D image. We describe SceneComplete, a system for constructing a complete, segmented, 3D model of a scene from a single view. It provides a novel pipeline for composing general-purpose pretrained perception modules (vision-language, segmentation, image-inpainting, image-to-3D, and pose-estimation) to obtain high-accuracy results. We demonstrate its accuracy and effectiveness with respect to ground-truth models in a large benchmark dataset and show that its accurate whole-object reconstruction enables robust grasp proposal generation, including for a dexterous hand.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/I627R4NZ/Agarwal et al. - 2024 - SceneComplete Open-World 3D Scene Completion in Complex Real World Environments for Robot Manipulat.pdf;/Users/kshitijgoel/Zotero/storage/UASELCYP/2410.html}
}

@article{aggravi_decentralized_2021,
  title = {Decentralized {{Control}} of a {{Heterogeneous Human-Robot Team}} for {{Exploration}} and {{Patrolling}}},
  author = {Aggravi, Marco and Sirignano, Giuseppe and Giordano, Paolo Robuffo and Pacchierotti, Claudio},
  year = {2021},
  journal = {IEEE Transactions on Automation Science and Engineering},
  pages = {1--17},
  issn = {1558-3783},
  doi = {10.1109/TASE.2021.3106386},
  abstract = {We present a decentralized connectivity-maintenance control framework for a heterogeneous human-robot team. The algorithm is able to manage a team composed of an arbitrary number of mobile robots (drones and ground robots in our case) and humans, for collaboratively achieving exploration and patrolling tasks. Differently from other works on the subject, here the human user physically becomes part of the team, moving in the same environment of the robots and receiving information about the team connectivity through wearable haptics or audio feedback. Although human explores the environment, robots move so as to keep the team connected via a connectivity-maintenance algorithm; at the same time, each robot can also be assigned with a specific target to visit. We carried out three human subject experiments, both in virtual and real environments. Results show that the proposed approach is effective in a wide range of scenarios. Moreover, providing either haptic or audio feedback for conveying information about the team connectivity significantly improves the performance of the considered tasks, although users significantly preferred receiving haptic stimuli w.r.t. the audio ones.},
  keywords = {Haptic interfaces,heterogeneous human-robot teams,human-centered robotics,Mobile robots,multirobot systems.,Robot kinematics,Robot sensing systems,Robots,Surveillance,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/LJMV7S5M/Aggravi et al. - 2021 - Decentralized Control of a Heterogeneous Human-Rob.pdf;/Users/kshitijgoel/Zotero/storage/JS8UH9YM/9528889.html}
}

@article{agha_nebula_2022,
  title = {{{NeBula}}: {{TEAM CoSTAR}}'s {{Robotic Autonomy Solution}} That {{Won Phase II}} of {{DARPA Subterranean Challenge}}},
  shorttitle = {{{NeBula}}},
  author = {Agha, Ali and Otsu, Kyohei and Morrell, Benjamin and Fan, David and Thakker, Rohan and {Santamaria-Navarro}, Angel and Kim, Sung-Kyun and Bouman, Amanda and Lei, Xianmei and Edlund, Jeffrey and Ginting, Muhammad and Ebadi, Kamak and Anderson, Matthew and Pailevanian, Torkom and Terry, Edward and Wolf, Michael and Tagliabue, Andrea and Vaquero, Tiago and Palieri, Matteo and Tepsuporn, Scott and Chang, Yun and Kalantari, Arash and Chavez, Fernando and Lopez, Brett and Funabiki, Nobuhiro and Miles, Gregory and Touma, Thomas and Buscicchio, Alessandro and Tordesillas, Jesus and Alatur, Nikhilesh and Nash, Jeremy and Walsh, William and Jung, Sunggoo and Lee, Hanseob and Kanellakis, Christoforos and Mayo, John and Harper, Scott and Kaufmann, Marcel and Dixit, Anushri and Correa, Gustavo and Lee, Carlyn and Gao, Jay and Merewether, Gene and {Maldonado-Contreras}, Jairo and Salhotra, Gautam and Saboia Da Silva, Maira and Ramtoula, Benjamin and Fakoorian, Seyed and Hatteland, Alexander and Kim, Taeyeon and Bartlett, Tara and Stephens, Alex and Kim, Leon and Bergh, Chuck and Heiden, Eric and Lew, Thomas and Cauligi, Abhishek and Heywood, Tristan and Kramer, Andrew and Leopold, Henry and Melikyan, Hov and Choi, Hyungho and Daftry, Shreyansh and Toupet, Olivier and Wee, Inhwan and Thakur, Abhishek and Feras, Micah and Beltrame, Giovanni and Nikolakopoulos, George and Shim, David and Carlone, Luca and Burdick, Joel},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {1432--1506},
  issn = {27713989},
  doi = {10.55417/fr.2022047},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_47.pdf},
  urldate = {2023-01-26},
  abstract = {This paper presents and discusses algorithms, hardware, and software architecture developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), competing in the DARPA Subterranean Challenge. Specifically, it presents the techniques utilized within the Tunnel (2019) and Urban (2020) competitions, where CoSTAR achieved second and first place, respectively. We also discuss CoSTAR's demonstrations in Martian-analog surface and subsurface (lava tubes) exploration. The paper introduces our autonomy solution, referred to as NeBula (Networked Belief-aware Perceptual Autonomy). NeBula is an uncertainty-aware framework that aims at enabling resilient and modular autonomy solutions by performing reasoning and decision making in the belief space (space of probability distributions over the robot and world states). We discuss various components of the NeBula framework, including (i) geometric and semantic environment mapping, (ii) a multi-modal positioning system, (iii) traversability analysis and local planning, (iv) global motion planning and exploration behavior, (v) risk-aware mission planning, (vi) networking and decentralized reasoning, and (vii) learning-enabled adaptation. We discuss the performance of NeBula on several robot types (e.g., wheeled, legged, flying), in various environments. We discuss the specific results and lessons learned from fielding this solution in the challenging courses of the DARPA Subterranean Challenge competition.}
}

@article{agha-mohammadi_confidencerich_2019,
  title = {Confidence-Rich Grid Mapping},
  author = {{Agha-mohammadi}, Ali-akbar and Heiden, Eric and Hausman, Karol and Sukhatme, Gaurav},
  year = {2019},
  month = oct,
  journal = {The International Journal of Robotics Research},
  volume = {38},
  number = {12-13},
  pages = {1352--1374},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364919839762},
  url = {https://doi.org/10.1177/0278364919839762},
  urldate = {2024-01-24},
  abstract = {Representing the environment is a fundamental task in enabling robots to act autonomously in unknown environments. In this work, we present confidence-rich mapping (CRM), a new algorithm for spatial grid-based mapping of the 3D environment. CRM augments the occupancy level at each voxel by its confidence value. By explicitly storing and evolving confidence values using the CRM filter, CRM extends traditional grid mapping in three ways: first, it partially maintains the probabilistic dependence among voxels; second, it relaxes the need for hand-engineering an inverse sensor model and proposes the concept of sensor cause model that can be derived in a principled manner from the forward sensor model; third, and most importantly, it provides consistent confidence values over the occupancy estimation that can be reliably used in collision risk evaluation and motion planning. CRM runs online and enables mapping environments where voxels might be partially occupied. We demonstrate the performance of the method on various datasets and environments in simulation and on physical systems. We show in real-world experiments that, in addition to achieving maps that are more accurate than traditional methods, the proposed filtering scheme demonstrates a much higher level of consistency between its error and the reported confidence, hence, enabling a more reliable collision risk evaluation for motion planning.},
  file = {/Users/kshitijgoel/Zotero/storage/ABMFTZKT/Agha-mohammadi et al. - 2019 - Confidence-rich grid mapping.pdf}
}

@inproceedings{agrawal_next_2020,
  title = {The {{Next Generation}} of {{Human-Drone Partnerships}}: {{Co-Designing}} an {{Emergency Response System}}},
  shorttitle = {The {{Next Generation}} of {{Human-Drone Partnerships}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Agrawal, Ankit and Abraham, Sophia J. and Burger, Benjamin and Christine, Chichi and Fraser, Luke and Hoeksema, John M. and Hwang, Sarah and Travnik, Elizabeth and Kumar, Shreya and Scheirer, Walter and {Cleland-Huang}, Jane and Vierhauser, Michael and Bauer, Ryan and Cox, Steve},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376825},
  url = {https://dl.acm.org/doi/10.1145/3313831.3376825},
  urldate = {2025-06-01},
  abstract = {The use of semi-autonomous Unmanned Aerial Vehicles (UAV) to support emergency response scenarios, such as fire surveillance and search and rescue, offers the potential for huge societal benefits. However, designing an effective solution in this complex domain represents a "wicked design" problem, requiring a careful balance between trade-offs associated with drone autonomy versus human control, mission functionality versus safety, and the diverse needs of different stakeholders. This paper focuses on designing for situational awareness (SA) using a scenario-driven, participatory design process. We developed SA cards describing six common design-problems, known as SA demons, and three new demons of importance to our domain. We then used these SA cards to equip domain experts with SA knowledge so that they could more fully engage in the design process. We designed a potentially reusable solution for achieving SA in multi-stakeholder, multi-UAV, emergency response applications.},
  isbn = {978-1-4503-6708-0},
  file = {/Users/kshitijgoel/Zotero/storage/WUP4RDS6/Agrawal et al. - 2020 - The Next Generation of Human-Drone Partnerships Co-Designing an Emergency Response System.pdf}
}

@inproceedings{agusta_unsupervised_2003,
  title = {Unsupervised {{Learning}} of {{Correlated Multivariate Gaussian Mixture Models Using MML}}},
  booktitle = {{{AI}} 2003: {{Advances}} in {{Artificial Intelligence}}},
  author = {Agusta, Yudi and Dowe, David L.},
  editor = {Gedeon, Tam{\'a}s (Tom) Domonkos and Fung, Lance Chun Che},
  year = {2003},
  pages = {477--489},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-24581-0_40},
  abstract = {Mixture modelling or unsupervised classification is the problem of identifying and modelling components (or clusters, or classes) in a body of data. We consider here the application of the Minimum Message Length (MML) principle to a mixture modelling problem of multivariate Gaussian distributions. Earlier work in MML mixture modelling includes the multinomial, Gaussian, Poisson, von Mises circular, and Student t distributions and in these applications all variables in a component are assumed to be uncorrelated with each other. In this paper, we propose a more general type of MML mixture modelling which allows the variables within a component to be correlated. Two MML approximations are used. These are the Wallace and Freeman (1987) approximation and Dowe's MMLD approximation (2002). The former is used for calculating the relative abundances (mixing proportions) of each component and the latter is used for estimating the distribution parameters involved in the components of the mixture model. The proposed method is applied to the analysis of two real-world datasets -- the well-known (Fisher) Iris and diabetes datasets. The modelling results are then compared with those obtained using two other modelling criteria, AIC and BIC (which is identical to Rissanen's 1978 MDL), in terms of their probability bit-costings, and show that the proposed MML method performs better than both these criteria. Furthermore, the MML method also infers more closely the three underlying Iris species than both AIC and BIC.},
  isbn = {978-3-540-24581-0},
  langid = {english},
  keywords = {Classification,Clustering,Information Theory,Intrinsic Classification,Knowledge Discovery and Data Mining,Machine Learning,Minimum Message Length,Mixture Modelling,MML,Numerical Taxonomy,Statistical Inference,Unsupervised Classification},
  file = {/Users/kshitijgoel/Zotero/storage/KJ2WRPJ8/Agusta and Dowe - 2003 - Unsupervised Learning of Correlated Multivariate Gaussian Mixture Models Using MML.pdf}
}

@article{ahmed_active_2023,
  title = {Active {{SLAM}}: {{A Review}} on {{Last Decade}}},
  shorttitle = {Active {{SLAM}}},
  author = {Ahmed, Muhammad Farhan and Masood, Khayyam and Fremont, Vincent and Fantoni, Isabelle},
  year = {2023},
  month = jan,
  journal = {Sensors},
  volume = {23},
  number = {19},
  pages = {8097},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23198097},
  url = {https://www.mdpi.com/1424-8220/23/19/8097},
  urldate = {2023-10-25},
  abstract = {This article presents a comprehensive review of the Active Simultaneous Localization and Mapping (A-SLAM) research conducted over the past decade. It explores the formulation, applications, and methodologies employed in A-SLAM, particularly in trajectory generation and control-action selection, drawing on concepts from Information Theory (IT) and the Theory of Optimal Experimental Design (TOED). This review includes both qualitative and quantitative analyses of various approaches, deployment scenarios, configurations, path-planning methods, and utility functions within A-SLAM research. Furthermore, this article introduces a novel analysis of Active Collaborative SLAM (AC-SLAM), focusing on collaborative aspects within SLAM systems. It includes a thorough examination of collaborative parameters and approaches, supported by both qualitative and statistical assessments. This study also identifies limitations in the existing literature and suggests potential avenues for future research. This survey serves as a valuable resource for researchers seeking insights into A-SLAM methods and techniques, offering a current overview of A-SLAM formulation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {active SLAM,control theory,information theory,path planning,SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/2FD8LI3K/Ahmed et al. - 2023 - Active SLAM A Review on Last Decade.pdf}
}

@inproceedings{ahn_analysis_2019,
  title = {Analysis and {{Noise Modeling}} of the {{Intel RealSense D435}} for {{Mobile Robots}}},
  booktitle = {2019 16th {{International Conference}} on {{Ubiquitous Robots}} ({{UR}})},
  author = {Ahn, Min Sung and Chae, Hosik and Noh, Donghun and Nam, Hyunwoo and Hong, Dennis},
  year = {2019},
  month = jun,
  pages = {707--711},
  issn = {2325-033X},
  doi = {10.1109/URAI.2019.8768489},
  abstract = {Cameras that provide distance measurement along with RGB data have increasingly been appearing in the market as alternatives to the more expensive setup of LIDARs and webcams. While products such as the Kinect have existed in the past, its weight and form factor have been demanding constraints for mobile robots, specifically legged robots that are sensitive to payload. Recently Intel released a new lineup of Intel RealSense RGB-D cameras that have favorable characteristics for legged robots, specifically in terms of resolution, frames per second, form factor, weight, and price range. However, because these active stereo sensors are noisy for reasons such as non-overlapping image regions or lack of texture, it is beneficial to empirically model the noise. Systematic errors, specifically the distance inhomogeneity and depth bias, are observed to recognize and verify the limitations of the camera. We also analyze the non-systematic error by modeling both the axial and lateral noise as a function of distance and angle of incidence using a Gaussian distribution for its versatile applicability for mobile robots in mapping.},
  keywords = {Cameras,Image edge detection,Mobile robots,Robot vision systems,Sensor phenomena and characterization},
  file = {/Users/kshitijgoel/Zotero/storage/HH3E6A68/Ahn et al. - 2019 - Analysis and Noise Modeling of the Intel RealSense.pdf;/Users/kshitijgoel/Zotero/storage/6ZS6WS9N/stamp.html}
}

@article{akaike_new_1974,
  title = {A New Look at the Statistical Model Identification},
  author = {Akaike, H.},
  year = {1974},
  month = dec,
  journal = {IEEE Transactions on Automatic Control},
  volume = {19},
  number = {6},
  pages = {716--723},
  issn = {1558-2523},
  doi = {10.1109/TAC.1974.1100705},
  url = {https://ieeexplore.ieee.org/document/1100705},
  urldate = {2024-11-15},
  abstract = {The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples.},
  keywords = {Art,Estimation theory,History,Linear systems,Maximum likelihood estimation,Roundoff errors,Sampling methods,Stochastic processes,Testing,Time series analysis},
  file = {/Users/kshitijgoel/Zotero/storage/74QU3XAX/Akaike - 1974 - A new look at the statistical model identification.pdf;/Users/kshitijgoel/Zotero/storage/M5CYR82E/1100705.html}
}

@phdthesis{albaugh_soft_2024,
  type = {Thesis},
  title = {Soft {{Technologies}}},
  author = {Albaugh, Lea},
  year = {2024},
  month = dec,
  doi = {10.1184/R1/27902280.v1},
  url = {https://kilthub.cmu.edu/articles/thesis/Soft_Technologies/27902280/1},
  urldate = {2025-01-03},
  abstract = {This work explores soft technologies in computational fabrication: ways of creating with materials that are flexible, dynamic, and/or uncertain. Soft fabrication systems can be built to work with unusual materials, and to adapt to current and futures needs; they can be appropriate to a wide variety of contexts, including those outside of industrial and production work such as materials research labs or personal creative practice. I develop the lens of ``softness'' through a combination of technical systems development and design inquiry, resulting in computational fabrication systems which explore softness at the levels of physical materials, contexts of use, and the workflows that bridge between them. In documenting the individual systems, I provide a number of supporting contributions, including techniques for producing complex mechanisms with machine knitting, demonstrations of inexpensive and easily deployable camera-based sensing for fabrication tasks, and insights from creative practitioners. Uniting the findings from these, I construct a conceptual frame and a set of system-building tactics that can be used to create flexible and adaptable computational fabrication systems, with implications for how complex materials can be used, by whom, and in what contexts},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/ZF6DBNBM/Albaugh - 2024 - Soft Technologies.pdf}
}

@inproceedings{alenezi_stealthy_2022,
  title = {Stealthy Path Planning against Dynamic Observers},
  booktitle = {Proceedings of the 15th {{ACM SIGGRAPH Conference}} on {{Motion}}, {{Interaction}} and {{Games}}},
  author = {Al Enezi, Wael and Verbrugge, Clark},
  year = {2022},
  month = nov,
  series = {{{MIG}} '22},
  pages = {1--9},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3561975.3562948},
  url = {https://dl.acm.org/doi/10.1145/3561975.3562948},
  urldate = {2025-01-03},
  abstract = {In virtual environments, research into the problem of stealthy or covert path planning has either assumed fixed and static motion of observers or has used relatively simple probabilistic models that statically summarize potential behavior. In this paper, we introduce a method that dynamically estimates enemy motion in order to plan covert paths in a prototype game environment. We compare our results to other baseline pathfinding methods and conduct an extensive exploration of the many parameters and design choices involved to better understand the impact of different settings on the success of covert path planning in virtual environments. Our design provides a more flexible approach to covert pathfinding problems, and our analysis provides useful insights into the relative weighting of the different factors that can improve design choices in building stealth scenarios.},
  isbn = {978-1-4503-9888-6},
  file = {/Users/kshitijgoel/Zotero/storage/EZENNQMW/Al Enezi and Verbrugge - 2022 - Stealthy path planning against dynamic observers.pdf}
}

@inproceedings{ali_autonomous_2023,
  title = {Autonomous {{Navigation}}, {{Mapping}} and {{Exploration}} with {{Gaussian Processes}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Ali, Mahmoud and Jardali, Hassan and Roy, Nicholas and Liu, Lantao},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p104.html},
  urldate = {2023-07-03},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/FNHJJREX/Ali et al. - 2023 - Autonomous Navigation, Mapping and Exploration wit.pdf}
}

@inproceedings{ali_enabling_2025,
  title = {Enabling {{Safe}}, {{Active}} and {{Interactive Human-Robot Collaboration}} via {{Smooth Distance Fields}}},
  booktitle = {2025 20th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}} ({{HRI}})},
  author = {Ali, Usama and Sukkar, Fouad and Mueller, Adrian and Wu, Lan and Gentil, Cedric Le and Kaupp, Tobias and Calleja, Teresa Vidal},
  year = {2025},
  month = mar,
  pages = {439--446},
  doi = {10.1109/HRI61500.2025.10974001},
  url = {https://ieeexplore.ieee.org/document/10974001/},
  urldate = {2025-06-01},
  abstract = {Human-Robot Collaboration (HRC) scenarios demand computationally efficient frameworks that enable natural and safe actions and interactions in shared workspaces. To address this, we propose a novel framework that utilises interactive Gaussian Process (GP) distance fields applying Riemannian Motion Policies (RMP) for key HRC functionality. Unlike traditional Euclidean distance field methods, our framework provides continuous and differentiable distance fields resulting in smooth collision avoidance, efficient updates in dynamic scenes and readily available surface information such as normal vectors and curvature. By leveraging RMPs, our framework supports fast, reactive motion generation, utilising both the distance and gradient fields generated by the GP model. In addition, we propose a Hessian-based normal vector estimation technique that elegantly leverages the GP's second-order derivative information which we utilise for object manipulation. We demonstrate the versatility of our CPU-only system in common HRC scenarios where a collaborative robot (cobot) interacts safely and naturally with a human and performs grasping actions in a dynamic environment. Our framework offers an open-source11https://uts-ri.github.io/IDMP-RMP/, comprehensive and low-computational resource solution for HRC, making it an ideal tool for conducting a wide range of user studies. By providing a continuous and differentiable distance field and combining motion generation, obstacle avoidance, and object manipulation within a single system, we aim to broaden the scope and accessibility of HRC research in real dynamic environments.},
  keywords = {Collaborative robots,Collision avoidance,Collision Avoidance,Distance Fields,Dynamics,Gaussian processes,Gaussian Processes,Grasping,Human Robot Interaction,Human-robot interaction,Planning,Reactive Planning,Robustness,Surface treatment,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/I9ZZ5WWK/Ali et al. - 2025 - Enabling Safe, Active and Interactive Human-Robot Collaboration via Smooth Distance Fields.pdf}
}

@inproceedings{ali_lightweight_2023,
  title = {Light-{{Weight Pointcloud Representation}} with {{Sparse Gaussian Process}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ali, Mahmoud and Liu, Lantao},
  year = {2023},
  month = may,
  pages = {4931--4937},
  doi = {10.1109/ICRA48891.2023.10161111},
  abstract = {This paper presents a framework to represent high-fidelity pointcloud sensor observations for efficient communication and storage. The proposed approach exploits Sparse Gaussian Process to encode pointcloud into a compact form. Our approach represents both the free space and the occupied space using only one model (one 2D Sparse Gaussian Process) instead of the existing two-model framework (two 3D Gaussian Mixture Models). We achieve this by proposing a variance-based sampling technique that effectively discriminates between the free and occupied space. The new representation requires less memory footprint and can be transmitted across limited-bandwidth communication channels. The framework is extensively evaluated in simulation and it is also demonstrated using a real mobile robot equipped with a 3D LiDAR. Our method results in a 70 100 times reduction in the communication rate compared to sending the raw pointcloud. We have provided a demonstration video11Video: https://youtu.be/BQZzXiCFGrM and open-sourced our code 22Code: https://github.com/mahmoud-a-ali/vsgp\_pcl.},
  keywords = {Collaboration,Communication channels,Laser radar,Memory management,Robot sensing systems,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/VPQFR4VP/Ali and Liu - 2023 - Light-Weight Pointcloud Representation with Sparse.pdf;/Users/kshitijgoel/Zotero/storage/AR87Z2E9/10161111.html}
}

@inproceedings{almuzaddid_variable_2022,
  title = {Variable {{Rate Compression}} for {{Raw 3D Point Clouds}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Al Muzaddid, Md Ahmed and Beksi, William J.},
  year = {2022},
  month = may,
  pages = {8748--8755},
  doi = {10.1109/ICRA46639.2022.9812239},
  abstract = {In this paper, we propose a novel variable rate deep compression architecture that operates on raw 3D point cloud data. The majority of learning-based point cloud compression methods work on a downsampled representation of the data. Moreover, many existing techniques require training multiple networks for different compression rates to generate consolidated point clouds of varying quality. In contrast, our network is capable of explicitly processing point clouds and generating a compressed description at a comprehensive range of bitrates. Furthermore, our approach ensures that there is no loss of information as a result of the voxelization process and the density of the point cloud does not affect the encoder/decoder performance. An extensive experimental evaluation shows that our model obtains state-of-the-art results, it is computationally efficient, and it can work directly with point cloud data thus avoiding an expensive voxelized representation.},
  keywords = {Automation,Big Data in Robotics and Automation,Bit rate,Computational modeling,Deep Learning for Visual Perception,Point cloud compression,RGB-D Perception,Three-dimensional displays,Training,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/UZAFYUBP/Al Muzaddid and Beksi - 2022 - Variable Rate Compression for Raw 3D Point Clouds.pdf;/Users/kshitijgoel/Zotero/storage/HZJBSF9D/9812239.html}
}

@article{alspach_nonlinear_1972,
  title = {Nonlinear {{Bayesian}} Estimation Using {{Gaussian}} Sum Approximations},
  author = {Alspach, D. and Sorenson, H.},
  year = {1972},
  month = aug,
  journal = {IEEE Transactions on Automatic Control},
  volume = {17},
  number = {4},
  pages = {439--448},
  issn = {1558-2523},
  doi = {10.1109/TAC.1972.1100034},
  url = {https://ieeexplore.ieee.org/document/1100034/?arnumber=1100034},
  urldate = {2025-03-24},
  abstract = {Knowledge of the probability density function of the state conditioned on all available measurement data provides the most complete possible description of the state, and from this density any of the common types of estimates (e.g., minimum variance or maximum a posteriori) can be determined. Except in the linear Gaussian case, it is extremely difficult to determine this density function. In this paper an approximation that permits the explicit calculation of the a posteriori density from the Bayesian recursion relations is discussed and applied to the solution of the nonlinear filtering problem. In particular, it is noted that a weighted sum of Gaussian probability density functions can be used to approximate arbitrarily closely another density function. This representation provides the basis for procedure that is developed and discussed.},
  keywords = {Bayesian methods,Density functional theory,Density measurement,Difference equations,Filtering,Gaussian noise,Nonlinear equations,Nonlinear filters,Probability density function,State estimation},
  file = {/Users/kshitijgoel/Zotero/storage/PRIEENCD/Alspach and Sorenson - 1972 - Nonlinear Bayesian estimation using Gaussian sum approximations.pdf;/Users/kshitijgoel/Zotero/storage/X67EGKDN/Alspach and Sorenson - 1972 - Nonlinear Bayesian estimation using Gaussian sum approximations.pdf;/Users/kshitijgoel/Zotero/storage/6QZ6Q2W4/1100034.html}
}

@incollection{alvarez_collision_2016,
  title = {Collision {{Avoidance}} for {{Quadrotors}} with a {{Monocular Camera}}},
  booktitle = {Experimental {{Robotics}}: {{The}} 14th {{International Symposium}} on {{Experimental Robotics}}},
  author = {Alvarez, H. and Paz, L. M. and Sturm, J. and Cremers, D.},
  editor = {Hsieh, M. Ani and Khatib, Oussama and Kumar, Vijay},
  year = {2016},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {195--209},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-23778-7_14},
  url = {https://doi.org/10.1007/978-3-319-23778-7_14},
  urldate = {2024-02-13},
  abstract = {Automatic obstacle detection and avoidance is a key component for the success of micro-aerial vehicles (MAVs) in the future. As the payload of MAVs is highly constrained, cameras are attractive sensors because they are both lightweight and provide rich information about the environment. In this paper, we present an approach that allows a quadrotor with a single monocular camera to locally generate collision-free waypoints. We acquire a small set of images while the quadrotor is hovering from which we compute a dense depth map. Based on this depth map, we render a 2D scan and generate a suitable waypoint for navigation. In our experiments, we found that the pose variation during hovering is already sufficient to obtain suitable depth maps. The computation takes less than one second which renders our approach applicable for obstacle avoidance in real-time. We demonstrate the validity of our approach in challenging environments where we navigate a Parrot Ardrone quadrotor successfully through narrow passages including doors, boxes, and people.},
  isbn = {978-3-319-23778-7},
  langid = {english},
  keywords = {Collision avoidance,Micro-aerial vehicles,Monocular depth-maps},
  file = {/Users/kshitijgoel/Zotero/storage/4EUWGEZ2/Alvarez et al. - 2016 - Collision Avoidance for Quadrotors with a Monocula.pdf}
}

@inproceedings{amanatides_fast_1987,
  title = {A {{Fast Voxel Traversal Algorithm}} for {{Ray Tracing}}},
  booktitle = {{{EG}} 1987-{{Technical Papers}}},
  author = {Amanatides, John and Woo, Andrew},
  year = {1987},
  publisher = {Eurographics Association},
  doi = {10.2312/egtp.19871000},
  url = {https://doi.org/10.2312/egtp.19871000},
  urldate = {2024-11-16},
  abstract = {A fast and simple voxel traversal algorithm through a 3D space partition is introduced. Going from one voxel to its neighbour requires only two floating point comparisons and one floating point addition. Also, multiple ray intersections with objects that are in more than one voxel are eliminated.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GHGK9LLF/60c72224-00f3-416d-9952-ee41e8c408da.html}
}

@article{amari_information_2001,
  title = {Information Geometry on Hierarchy of Probability Distributions},
  author = {Amari, S.-I.},
  year = {2001},
  month = jul,
  journal = {IEEE Transactions on Information Theory},
  volume = {47},
  number = {5},
  pages = {1701--1711},
  issn = {1557-9654},
  doi = {10.1109/18.930911},
  abstract = {An exponential family or mixture family of probability distributions has a natural hierarchical structure. This paper gives an "orthogonal" decomposition of such a system based on information geometry. A typical example is the decomposition of stochastic dependency among a number of random variables. In general, they have a complex structure of dependencies. Pairwise dependency is easily represented by correlation, but it is more difficult to measure effects of pure triplewise or higher order interactions (dependencies) among these variables. Stochastic dependency is decomposed quantitatively into an "orthogonal" sum of pairwise, triplewise, and further higher order dependencies. This gives a new invariant decomposition of joint entropy. This problem is important for extracting intrinsic interactions in firing patterns of an ensemble of neurons and for estimating its functional connections. The orthogonal decomposition is given in a wide class of hierarchical structures including both exponential and mixture families. As an example, we decompose the dependency in a higher order Markov chain into a sum of those in various lower order Markov chains.},
  keywords = {Probability},
  file = {/Users/kshitijgoel/Zotero/storage/AGPX8AI6/Amari - 2001 - Information geometry on hierarchy of probability d.pdf;/Users/kshitijgoel/Zotero/storage/MFJHKHFC/stamp.html}
}

@inproceedings{ames_control_2019,
  title = {Control {{Barrier Functions}}: {{Theory}} and {{Applications}}},
  shorttitle = {Control {{Barrier Functions}}},
  booktitle = {2019 18th {{European Control Conference}} ({{ECC}})},
  author = {Ames, Aaron D. and Coogan, Samuel and Egerstedt, Magnus and Notomista, Gennaro and Sreenath, Koushil and Tabuada, Paulo},
  year = {2019},
  month = jun,
  pages = {3420--3431},
  doi = {10.23919/ECC.2019.8796030},
  url = {https://ieeexplore.ieee.org/document/8796030/?arnumber=8796030},
  urldate = {2024-12-09},
  abstract = {This paper provides an introduction and overview of recent work on control barrier functions and their use to verify and enforce safety properties in the context of (optimization based) safety-critical controllers. We survey the main technical results and discuss applications to several domains including robotic systems.},
  file = {/Users/kshitijgoel/Zotero/storage/DKHLP2Z3/Ames et al. - 2019 - Control Barrier Functions Theory and Applications.pdf;/Users/kshitijgoel/Zotero/storage/P3THYTIM/8796030.html}
}

@inproceedings{amice_finding_2023,
  title = {Finding and~{{Optimizing Certified}}, {{Collision-Free Regions}} in~{{Configuration Space}} for~{{Robot Manipulators}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XV}}},
  author = {Amice, Alexandre and Dai, Hongkai and Werner, Peter and Zhang, Annan and Tedrake, Russ},
  editor = {LaValle, Steven M. and O'Kane, Jason M. and Otte, Michael and Sadigh, Dorsa and Tokekar, Pratap},
  year = {2023},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {328--348},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-21090-7_20},
  abstract = {Configuration space (C-space) has played a central role in collision-free motion planning, particularly for robot manipulators. While it is possible to check for collisions at a point using standard algorithms, to date no practical method exists for computing collision-free C-space regions with rigorous certificates due to the complexities of mapping task-space obstacles through the kinematics. In this work, we present the first to our knowledge method for generating such regions and certificates through convex optimization. Our method, called C-Iris (C-space Iterative Regional Inflation by Semidefinite programming), generates large, convex polytopes in a rational parametrization of the configuration space which are guaranteed to be collision-free. Such regions have been shown to be useful for both optimization-based and randomized motion planning. Our regions are generated by alternating between two convex optimization problems: (1) a simultaneous search for a maximal-volume ellipse inscribed in a given polytope and a certificate that the polytope is collision-free and (2) a maximal expansion of the polytope away from the ellipse which does not violate the certificate. The volume of the ellipse and size of the polytope are allowed to grow over several iterations while being collision-free by construction. Our method works in arbitrary dimensions, only makes assumptions about the convexity of the obstacles in the task space, and scales to realistic problems in manipulation. We demonstrate our algorithm's ability to fill a non-trivial amount of collision-free C-space in a 3-DOF example where the C-space can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA iiwa and a 12-DOF bimanual manipulator.},
  isbn = {978-3-031-21090-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9NKVCNGT/Amice et al. - 2023 - Finding and Optimizing Certified, Collision-Free R.pdf}
}

@misc{anastasiou_automated_2024,
  title = {Automated {{Real-Time Inspection}} in {{Indoor}} and {{Outdoor 3D Environments}} with {{Cooperative Aerial Robots}}},
  author = {Anastasiou, Andreas and Zacharia, Angelos and Papaioannou, Savvas and Kolios, Panayiotis and Panayiotou, Christos G. and Polycarpou, Marios M.},
  year = {2024},
  month = apr,
  number = {arXiv:2404.12018},
  eprint = {2404.12018},
  primaryclass = {cs, eess},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2404.12018},
  urldate = {2024-06-07},
  abstract = {This work introduces a cooperative inspection system designed to efficiently control and coordinate a team of distributed heterogeneous UAV agents for the inspection of 3D structures in cluttered, unknown spaces. Our proposed approach employs a two-stage innovative methodology. Initially, it leverages the complementary sensing capabilities of the robots to cooperatively map the unknown environment. It then generates optimized, collision-free inspection paths, thereby ensuring comprehensive coverage of the structure's surface area. The effectiveness of our system is demonstrated through qualitative and quantitative results from extensive Gazebobased simulations that closely replicate real-world inspection scenarios, highlighting its ability to thoroughly inspect realworld-like 3D structures.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/VILBUJG6/Anastasiou et al. - 2024 - Automated Real-Time Inspection in Indoor and Outdoor 3D Environments with Cooperative Aerial Robots.pdf}
}

@inproceedings{apostolopoulos_robotic_2001,
  title = {Robotic {{Antarctic}} Meteorite Search: Outcomes},
  shorttitle = {Robotic {{Antarctic}} Meteorite Search},
  booktitle = {Proceedings 2001 {{ICRA}}. {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{01CH37164}})},
  author = {Apostolopoulos, D.S. and Pedersen, L. and Shamah, B.N. and Shillcutt, K. and Wagner, M.D. and Whittaker, W.L.},
  year = {2001},
  volume = {4},
  pages = {4174--4179},
  publisher = {IEEE},
  address = {Seoul, South Korea},
  doi = {10.1109/ROBOT.2001.933270},
  url = {http://ieeexplore.ieee.org/document/933270/},
  urldate = {2023-10-26},
  abstract = {Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to otherplanets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learnedfrom the first \$eld demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limitedperformance in the speed and coverage of autonomous search.},
  isbn = {978-0-7803-6576-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UF9VMUTA/Apostolopoulos et al. - 2001 - Robotic Antarctic meteorite search outcomes.pdf}
}

@misc{apostolopoulou_ratedistortion_2024,
  title = {A {{Rate-Distortion View}} of {{Uncertainty Quantification}}},
  author = {Apostolopoulou, Ifigeneia and Eysenbach, Benjamin and Nielsen, Frank and Dubrawski, Artur},
  year = {2024},
  month = jun,
  number = {arXiv:2406.10775},
  eprint = {2406.10775},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.10775},
  urldate = {2024-06-18},
  abstract = {In supervised learning, understanding an input's proximity to the training data can help a model decide whether it has sufficient evidence for reaching a reliable prediction. While powerful probabilistic models such as Gaussian Processes naturally have this property, deep neural networks often lack it. In this paper, we introduce Distance Aware Bottleneck (DAB), i.e., a new method for enriching deep neural networks with this property. Building on prior information bottleneck approaches, our method learns a codebook that stores a compressed representation of all inputs seen during training. The distance of a new example from this codebook can serve as an uncertainty estimate for the example. The resulting model is simple to train and provides deterministic uncertainty estimates by a single forward pass. Finally, our method achieves better out-ofdistribution (OOD) detection and misclassification prediction than prior methods, including expensive ensemble methods, deep kernel Gaussian Processes, and approaches based on the standard information bottleneck.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/FRVDFBPD/Apostolopoulou et al. - 2024 - A Rate-Distortion View of Uncertainty Quantification.pdf}
}

@inproceedings{araya-lopez_pomdp_2010,
  title = {A {{POMDP}} Extension with Belief-Dependent Rewards},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Neural Information Processing Systems}} - {{Volume}} 1},
  author = {{Araya-L{\'o}pez}, Mauricio and Buffet, Olivier and Thomas, Vincent and Charpillet, Fran{\c c}ois},
  year = {2010},
  month = dec,
  series = {{{NIPS}}'10},
  pages = {64--72},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2023-10-23},
  abstract = {Partially Observable Markov Decision Processes (POMDPs) model sequential decision-making problems under uncertainty and partial observability. Unfortunately, some problems cannot be modeled with state-dependent reward functions, e.g., problems whose objective explicitly implies reducing the uncertainty on the state. To that end, we introduce {$\rho$}POMDPs, an extension of POMDPs where the reward function {$\rho$} depends on the belief state. We show that, under the common assumption that {$\rho$} is convex, the value function is also convex, what makes it possible to (1) approximate {$\rho$} arbitrarily well with a piecewise linear and convex (PWLC) function, and (2) use state-of-the-art exact or approximate solving algorithms with limited changes.}
}

@inproceedings{arbas_polynomial_2023,
  title = {Polynomial {{Time}} and {{Private Learning}} of {{Unbounded Gaussian Mixture Models}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Arbas, Jamil and Ashtiani, Hassan and Liaw, Christopher},
  year = {2023},
  month = jul,
  pages = {1018--1040},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/arbas23a.html},
  urldate = {2023-11-06},
  abstract = {We study the problem of privately estimating the parameters of {$d$}dd-dimensional Gaussian Mixture Models (GMMs) with {$k$}kk components. For this, we develop a technique to reduce the problem to its non-private counterpart. This allows us to privatize existing non-private algorithms in a blackbox manner, while incurring only a small overhead in the sample complexity and running time. As the main application of our framework, we develop an ({$E$},{$\delta$})({$\varepsilon$},{$\delta$})({\textbackslash}varepsilon, {\textbackslash}delta)-differentially private algorithm to learn GMMs using the non-private algorithm of Moitra and Valiant (2010) as a blackbox. Consequently, this gives the first sample complexity upper bound and first polynomial time algorithm for privately learning GMMs without any boundedness assumptions on the parameters. As part of our analysis, we prove a tight (up to a constant factor) lower bound on the total variation distance of high-dimensional Gaussians which can be of independent interest.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YFQG8NGJ/Arbas et al. - 2023 - Polynomial Time and Private Learning of Unbounded .pdf}
}

@inproceedings{argyle_vertical_2013,
  title = {The {{Vertical Bat}} Tail-Sitter: {{Dynamic}} Model and Control Architecture},
  shorttitle = {The {{Vertical Bat}} Tail-Sitter},
  booktitle = {2013 {{American Control Conference}}},
  author = {Argyle, Matthew E. and Beard, Randal W. and Morris, Stephen},
  year = {2013},
  month = jun,
  pages = {806--811},
  issn = {2378-5861},
  doi = {10.1109/ACC.2013.6579935},
  abstract = {Over the years many aircraft designs have been developed that attempt to merge the endurance and speed of fixed wing aircraft with the flexibility and vertical takeoff and landing abilities of rotor craft. The tail-sitter is one such design. Unlike most other designs, a tail-sitter requires no additional moving parts. However, it trades this mechanical simplicity for increased control complexity. This paper presents the kinematic and dynamic model for the Vertical Bat, a tail-sitter that is currently being developed, as well as vector field based control schemes covering all the flight regimes. In addition, the level to hover transition controller presented is able to control the ending horizontal position of the aircraft.},
  keywords = {Aerodynamics,Aircraft,Atmospheric modeling,Blades,Ducts,Force,Propellers},
  file = {/Users/kshitijgoel/Zotero/storage/MFXT8UZ5/Argyle et al. - 2013 - The Vertical Bat tail-sitter Dynamic model and co.pdf}
}

@article{arm_scientific_2023,
  title = {Scientific {{Exploration}} of {{Challenging Planetary Analog Environments}} with a {{Team}} of {{Legged Robots}}},
  author = {Arm, Philip and Waibel, Gabriel and Preisig, Jan and Tuna, Turcan and Zhou, Ruyi and Bickel, Valentin and Ligeza, Gabriela and Miki, Takahiro and Kehl, Florian and Kolvenbach, Hendrik and Hutter, Marco},
  year = {2023},
  month = jul,
  journal = {Science Robotics},
  volume = {8},
  number = {80},
  eprint = {2307.10079},
  primaryclass = {cs, eess},
  pages = {eade9548},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.ade9548},
  url = {http://arxiv.org/abs/2307.10079},
  urldate = {2023-07-20},
  abstract = {The interest in exploring planetary bodies for scientific investigation and in-situ resource utilization is ever-rising. Yet, many sites of interest are inaccessible to state-of-the-art planetary exploration robots because of the robots' inability to traverse steep slopes, unstructured terrain, and loose soil. Additionally, current single-robot approaches only allow a limited exploration speed and a single set of skills. Here, we present a team of legged robots with complementary skills for exploration missions in challenging planetary analog environments. We equipped the robots with an efficient locomotion controller, a mapping pipeline for online and post-mission visualization, instance segmentation to highlight scientific targets, and scientific instruments for remote and in-situ investigation. Furthermore, we integrated a robotic arm on one of the robots to enable high-precision measurements. Legged robots can swiftly navigate representative terrains, such as granular slopes beyond 25 degrees, loose soil, and unstructured terrain, highlighting their advantages compared to wheeled rover systems. We successfully verified the approach in analog deployments at the BeyondGravity ExoMars rover testbed, in a quarry in Switzerland, and at the Space Resources Challenge in Luxembourg. Our results show that a team of legged robots with advanced locomotion, perception, and measurement skills, as well as task-level autonomy, can conduct successful, effective missions in a short time. Our approach enables the scientific exploration of planetary target sites that are currently out of human and robotic reach.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/6THXKTH6/Arm et al. - 2023 - Scientific Exploration of Challenging Planetary An.pdf;/Users/kshitijgoel/Zotero/storage/I444URD6/2307.html}
}

@article{arora_multimodal_2019,
  title = {Multi-Modal Active Perception for Information Gathering in Science Missions},
  author = {Arora, Akash and Furlong, P. Michael and Fitch, Robert and Sukkarieh, Salah and Fong, Terrence},
  year = {2019},
  month = oct,
  journal = {Autonomous Robots},
  volume = {43},
  number = {7},
  pages = {1827--1853},
  issn = {1573-7527},
  doi = {10.1007/s10514-019-09836-5},
  url = {https://doi.org/10.1007/s10514-019-09836-5},
  urldate = {2022-04-08},
  abstract = {Robotic science missions in remote environments, such as deep ocean and outer space, can involve studying phenomena that cannot directly be observed using on-board sensors but must be deduced by combining measurements of correlated variables with domain knowledge. Traditionally, in such missions, robots passively gather data along prescribed paths, while inference, path planning, and other high level decision making is largely performed by a supervisory science team located at a different location, often at a great distance. However, communication constraints hinder these processes, and hence the rate of scientific progress. This paper presents an active perception approach that aims to reduce robots' reliance on human supervision and improve science productivity by encoding scientists' domain knowledge and decision making process on-board. We present a Bayesian network architecture to compactly model critical aspects of scientific knowledge while remaining robust to observation and modeling uncertainty. We then formulate path planning and sensor scheduling as an information gain maximization problem, and propose a sampling-based solution based on Monte Carlo tree search to plan informative sensing actions which exploit the knowledge encoded in the network. The computational complexity of our framework does not grow with the number of observations taken and allows long horizon planning in an anytime manner, making it highly applicable to field robotics with constrained computing. Simulation results show statistically significant performance improvements over baseline methods, and we validate the practicality of our approach through both hardware experiments and simulated experiments with field data gathered during the NASA Mojave Volatiles Prospector science expedition.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/I5BK3NBG/Arora et al. - 2019 - Multi-modal active perception for information gath.pdf}
}

@misc{arrizabalaga_differentiable_2024,
  title = {Differentiable {{Collision-Free Parametric Corridors}}},
  author = {Arrizabalaga, Jon and Manchester, Zachary and Ryll, Markus},
  year = {2024},
  month = jul,
  number = {arXiv:2407.12283},
  eprint = {2407.12283},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.12283},
  urldate = {2024-07-21},
  abstract = {This paper presents a method to compute differentiable collision-free parametric corridors. In contrast to existing solutions that decompose the obstacle-free space into multiple convex sets, the continuous corridors computed by our method are smooth and differentiable, making them compatible with existing numerical techniques for learning and optimization. To achieve this, we represent the collision-free corridors as a path-parametric off-centered ellipse with a polynomial basis. We show that the problem of maximizing the volume of such corridors is convex, and can be efficiently solved. To assess the effectiveness of the proposed method, we examine its performance in a synthetic case study and subsequently evaluate its applicability in a real-world scenario from the KITTI dataset.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/454B8CSH/Arrizabalaga et al. - 2024 - Differentiable Collision-Free Parametric Corridors.pdf}
}

@inproceedings{arrizabalaga_timeoptimal_2022,
  title = {Towards {{Time-Optimal Tunnel-Following}} for {{Quadrotors}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Arrizabalaga, Jon and Ryll, Markus},
  year = {2022},
  month = may,
  pages = {4044--4050},
  doi = {10.1109/ICRA46639.2022.9811764},
  abstract = {Minimum-time navigation within constrained and dynamic environments is of special relevance in robotics. Seeking time-optimality, while guaranteeing the integrity of time-varying spatial bounds, is an appealing trade-off for agile vehicles, such as quadrotors. State-of-the-art approaches, either assume bounds to be static and generate time-optimal trajectories offline, or compromise time-optimality for constraint satisfaction. Leveraging nonlinear model predictive control and a path parametric reformulation of the quadrotor model, we present a real-time control that approximates time-optimal behavior and remains within dynamic corridors. The efficacy of the approach is evaluated by simulated results, showing itself capable of performing extremely aggressive maneuvers as well as stop-and-go and backward motions. Video: https://youtu.be/Apc8MCu7Yvo},
  keywords = {Dynamics,Navigation,Predictive models,Real-time systems,Shape,Streaming media,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/SJDBV44L/Arrizabalaga and Ryll - 2022 - Towards Time-Optimal Tunnel-Following for Quadroto.pdf;/Users/kshitijgoel/Zotero/storage/RSPSDXGC/9811764.html}
}

@inproceedings{arthur_kmeans_2007,
  title = {K-Means++: The Advantages of Careful Seeding},
  shorttitle = {K-Means++},
  booktitle = {Proceedings of the Eighteenth Annual {{ACM-SIAM}} Symposium on {{Discrete}} Algorithms},
  author = {Arthur, David and Vassilvitskii, Sergei},
  year = {2007},
  month = jan,
  series = {{{SODA}} '07},
  pages = {1027--1035},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {USA},
  url = {https://dl.acm.org/doi/pdf/10.5555/1283383.1283494},
  urldate = {2022-06-16},
  abstract = {The k-means method is a widely used clustering technique that seeks to minimize the average squared distance between points in the same cluster. Although it offers no accuracy guarantees, its simplicity and speed are very appealing in practice. By augmenting k-means with a very simple, randomized seeding technique, we obtain an algorithm that is {$\Theta$}(logk)-competitive with the optimal clustering. Preliminary experiments show that our augmentation improves both the speed and the accuracy of k-means, often quite dramatically.},
  isbn = {978-0-89871-624-5},
  file = {/Users/kshitijgoel/Zotero/storage/9S6N7F8T/Arthur and Vassilvitskii - 2007 - k-means++ the advantages of careful seeding.pdf}
}

@article{arun_leastsquares_1987,
  title = {Least-{{Squares Fitting}} of {{Two}} 3-{{D Point Sets}}},
  author = {Arun, K. S. and Huang, T. S. and Blostein, S. D.},
  year = {1987},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-9},
  number = {5},
  pages = {698--700},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.1987.4767965},
  abstract = {Two point sets pi and p'i; i = 1, 2,..., N are related by p'i = Rpi + T + Ni, where R is a rotation matrix, T a translation vector, and Ni a noise vector. Given pi and p'i, we present an algorithm for finding the least-squares solution of R and T, which is based on the singular value decomposition (SVD) of a 3 {\texttimes} 3 matrix. This new algorithm is compared to two earlier algorithms with respect to computer time requirements.},
  keywords = {Application software,Computer vision,Economic indicators,Iterative algorithms,least-squares,Matrix decomposition,motion estimation,Motion estimation,Parameter estimation,Position measurement,quaternion,Quaternions,singular value decomposition,Singular value decomposition},
  file = {/Users/kshitijgoel/Zotero/storage/GQR4HR5M/Arun et al. - 1987 - Least-Squares Fitting of Two 3-D Point Sets.pdf;/Users/kshitijgoel/Zotero/storage/ZSAKXDPR/4767965.html}
}

@inproceedings{arvanitidis_pulling_2022,
  title = {Pulling Back Information Geometry},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Arvanitidis, Georgios and {Gonz{\'a}lez-Duque}, Miguel and Pouplin, Alison and Kalatzis, Dimitrios and Hauberg, Soren},
  year = {2022},
  month = may,
  pages = {4872--4894},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v151/arvanitidis22b.html},
  urldate = {2024-09-20},
  abstract = {Latent space geometry has shown itself to provide a rich and rigorous framework for interacting with the latent variables of deep generative models. The existing theory, however, relies on the decoder being a Gaussian distribution as its simple reparametrization allows us to interpret the generating process as a random projection of a deterministic manifold. Consequently, this approach breaks down when applied to decoders that are not as easily reparametrized. We here propose to use the Fisher-Rao metric associated with the space of decoder distributions as a reference metric, which we pull back to the latent space. We show that we can achieve meaningful latent geometries for a wide range of decoder distributions for which the previous theory was not applicable, opening the door to 'black box' latent geometries.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CSJJHYN6/Arvanitidis et al. - 2022 - Pulling back information geometry.pdf}
}

@inproceedings{arzelier_polynomial_2021,
  title = {Polynomial Superlevel Set Approximation of Swept-Volume for Computing Collision Probability in Space Encounters},
  booktitle = {2021 60th {{IEEE Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Arzelier, D. and Br{\'e}hard, F. and Jolde{\c s}, M. and Lasserre, J.-B. and Laurens, S. and Rondepierre, A.},
  year = {2021},
  month = dec,
  pages = {6300--6305},
  issn = {2576-2370},
  doi = {10.1109/CDC45484.2021.9683445},
  url = {https://ieeexplore.ieee.org/document/9683445/?arnumber=9683445},
  urldate = {2024-10-26},
  abstract = {Computing long-term collision probability in space encounters is usually based on integration of a multivariate Gaussian distribution over the volume of initial conditions which generate collisions in the considered time interval. As this collision set is very difficult to determine analytically, for practical computation various simplifications are made in the literature. We present a new method for computing the collision probability based on two steps. Firstly, a higher-order outer-approximation of the swept-volume by a polynomial superlevel set is obtained as an optimal solution of a polynomial optimization problem. This has the advantage of providing approximate closed-form descriptions of the collision-prone states which can then be effectively used for long-term and repeated conjunctions analysis. Numerically, a hierarchy of linear matrix inequality problems is solved, which provide approximations (i) of increasing accuracy and (ii) convergent in volume to the original set. Secondly, once such a polynomial representation is computed, a high-order quadrature scheme for volumes implicitly defined by a polynomial superlevel sets is employed. Finally, the method is illustrated on a practical numerical example.},
  keywords = {Classification algorithms,Conferences,Extraterrestrial measurements,Gaussian distribution,Numerical analysis,Shape,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/I7ZR4MH4/Arzelier et al. - 2021 - Polynomial superlevel set approximation of swept-volume for computing collision probability in space.pdf;/Users/kshitijgoel/Zotero/storage/JVTJM2C6/9683445.html}
}

@inproceedings{asgharivaskasi_active_2021,
  title = {Active {{Bayesian Multi-class Mapping}} from {{Range}} and {{Semantic Segmentation Observations}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Asgharivaskasi, Arash and Atanasov, Nikolay},
  year = {2021},
  month = may,
  pages = {1--7},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561711},
  abstract = {Many robot applications call for autonomous exploration and mapping of unknown and unstructured environments. Information-based exploration techniques, such as Cauchy-Schwarz quadratic mutual information (CSQMI) and fast Shannon mutual information (FSMI), have successfully achieved active binary occupancy mapping with range measurements. However, as we envision robots performing complex tasks specified with semantically meaningful objects, it is necessary to capture semantic categories in the measurements, map representation, and exploration objective. This work develops a Bayesian multi-class mapping algorithm utilizing range-category measurements. We derive a closed-form efficiently computable lower bound for the Shannon mutual information between the multi-class map and the measurements. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against frontier-based and FSMI exploration and apply it in a 3-D photo-realistic simulation environment.},
  keywords = {Bayes methods,Probabilistic logic,Semantics,Solid modeling,Trajectory,Uncertainty,Velocity measurement},
  file = {/Users/kshitijgoel/Zotero/storage/RQ7YNGKP/Asgharivaskasi and Atanasov - 2021 - Active Bayesian Multi-class Mapping from Range and.pdf}
}

@phdthesis{asgharivaskasi_distributed_2024,
  title = {Distributed {{Multi-Robot Active OcTree Mapping}}},
  author = {Asgharivaskasi, Arash},
  year = {2024},
  address = {United States -- California},
  url = {https://www.proquest.com/docview/3117294831/abstract/ECAD4876D8C24BA6PQ/1},
  urldate = {2024-10-22},
  abstract = {Many real-world mobile robot applications, such as disaster response, military reconnaissance, and environmental monitoring, require operating in unknown and unstructured environments. This calls for algorithms that empower robots with active information gathering capabilities in order to autonomously and incrementally build a model of an environment. In this dissertation, we present a novel 3-D multi-class online mapping approach using a stream of range and semantic segmentation observations. Moreover, we derive a closed-form expression for the Semantic Shannon Mutual Information (SSMI) between our proposed map representation and a sequence of future sensor observations. Using an octree data structure, we reduce the memory footprint of the map storage for large-scale environments, while simultaneously accelerating the computation of mutual information. This allows real-time integration of new sensor measurements into the map, and rapid evaluation of candidate future sensor poses for exploration. Additionally, we introduce a differentiable approximation of the Shannon mutual information between grid maps and ray-based measurements, enabling gradient-based occlusion and collision-aware active mapping. The gradient-based active mapping in the continuous space of sensor poses reduces the optimization complexity from exponential in the number of robots to linear, paving the way for extension from a single agent to a team of robots. We formulate multi-robot exploration as a combination of multi-robot mapping and multi-robot planning, where both sub-problems are specified as an instance of multi-agent Riemannian optimization. We propose a general distributed Riemannian optimization algorithm that solves both mapping and planning in fully decentralized manner. Our method, named Riemannian Optimization for Active Mapping (ROAM), enables distributed collaborative multi-robot exploration, with only point-to-point communication and no central estimation and control unit. Lastly, we deploy our active mapping method on a team of ground wheeled robots in both simulation and real-world environments, and compare its performance with other autonomous exploration approaches.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798384494294},
  langid = {english},
  school = {University of California, San Diego},
  keywords = {Active mapping,Artificial intelligence,Computer engineering,Distributed optimization,Electrical engineering,Multi-robot systems,Riemannian manifolds,Robotics,Vision-based planning},
  file = {/Users/kshitijgoel/Zotero/storage/FFYRLLKG/Asgharivaskasi - 2024 - Distributed Multi-Robot Active OcTree Mapping.pdf}
}

@article{asgharivaskasi_riemannian_2025,
  title = {Riemannian {{Optimization}} for {{Active Mapping With Robot Teams}}},
  author = {Asgharivaskasi, Arash and Girke, Fritz and Atanasov, Nikolay},
  year = {2025},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2025.3526295},
  url = {https://ieeexplore.ieee.org/document/10829726},
  urldate = {2025-01-08},
  abstract = {Autonomous exploration of unknown environments using a team of mobile robots demands distributed perception and planning strategies to enable efficient and scalable performance. Ideally, each robot should update its map and plan its motion not only relying on its own observations, but also considering the observations of its peers. Centralized solutions to multi-robot coordination are susceptible to central node failure and require a sophisticated communication infrastructure for reliable operation. Current decentralized active mapping methods consider simplistic robot models with linear-Gaussian observations and Euclidean robot states. In this work, we present a distributed multi-robot mapping and planning method, called Riemannian Optimization for Active Mapping (ROAM). We formulate an optimization problem over a graph with node variables belonging to a Riemannian manifold and a consensus constraint requiring feasible solutions to agree on the node variables. We develop a distributed Riemannian optimization algorithm that relies only on one-hop communication to solve the problem with consensus and optimality guarantees. We show that multi-robot active mapping can be achieved via two applications of our distributed Riemannian optimization over different manifolds: distributed estimation of a 3-D semantic map and distributed planning of SE(3) trajectories that minimize map uncertainty. We demonstrate the performance of ROAM in simulation and real-world experiments using a team of robots with RGB-D cameras. Open-source software and videos supplementing this paper are available at https://existentialrobotics.org/ROAM/.},
  keywords = {Distributed riemannian optimization,distributed robot systems,Manifolds,mapping,Octrees,Optimization,Peer-to-peer computing,Planning,reactive and sensor-based planning,Robot kinematics,Robot sensing systems,Robots,Semantics,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/IFNFFE3V/Asgharivaskasi et al. - 2025 - Riemannian Optimization for Active Mapping With Robot Teams.pdf;/Users/kshitijgoel/Zotero/storage/ZJP9AF5Y/10829726.html}
}

@article{asgharivaskasi_semantic_2023,
  title = {Semantic {{OcTree Mapping}} and {{Shannon Mutual Information Computation}} for {{Robot Exploration}}},
  author = {Asgharivaskasi, Arash and Atanasov, Nikolay},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--19},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3245986},
  abstract = {Autonomous robot operation in unstructured and unknown environments requires efficient techniques for mapping and exploration using streaming range and visual observations. Information-based exploration techniques, such as Cauchy--Schwarz quadratic mutual information and fast Shannon mutual information, have successfully achieved active binary occupancy mapping with range measurements. However, as we envision robots performing complex tasks specified with semantically meaningful concepts, it is necessary to capture semantics in the measurements, map representation, and exploration objective. This work presents semantic octree mapping and Shannon mutual information computation for robot exploration. We develop a Bayesian multiclass mapping algorithm based on an octree data structure, where each voxel maintains a categorical distribution over semantic classes. We derive a closed-form efficiently computable lower bound of the Shannon mutual information between a multiclass octomap and a set of range-category measurements using semantic run-length encoding of the sensor rays. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against state-of-the-art exploration techniques and apply it in a variety of simulated and real-world experiments.},
  keywords = {Bayes methods,Measurement uncertainty,Mutual information,Reactive and sensor-based planning,Robot sensing systems,Robots,Semantics,Uncertainty,view plann-ing for simultaneous localization and mapping (SLAM),vision-based navigation},
  file = {/Users/kshitijgoel/Zotero/storage/AEIYIWYM/Asgharivaskasi and Atanasov - 2023 - Semantic OcTree Mapping and Shannon Mutual Informa.pdf}
}

@inproceedings{ashizawa_leastsquares_2017,
  title = {Least-{{Squares Log-Density Gradient Clustering}} for {{Riemannian Manifolds}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Ashizawa, Mina and Sasaki, Hiroaki and Sakai, Tomoya and Sugiyama, Masashi},
  year = {2017},
  month = apr,
  pages = {537--546},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v54/ashizawa17a.html},
  urldate = {2024-06-27},
  abstract = {Mean shift is a mode-seeking clustering algorithm that has been successfully used in a wide range of applications such as image segmentation and object tracking. To further improve the clustering performance, mean shift has been extended to various directions, including generalization to handle data on Riemannian manifolds and extension to directly estimating the density gradient without density estimation. In this paper, we combine these ideas and propose a novel mode-seeking algorithm for Riemannian manifolds with direct density-gradient estimation. Although the idea of combining the two extensions is rather straightforward, directly estimating the density gradient on Riemannian manifolds is mathematically challenging. We will provide a mathematically sound algorithm and demonstrate its usefulness through experiments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DQAFDPVA/Ashizawa et al. - 2017 - Least-Squares Log-Density Gradient Clustering for Riemannian Manifolds.pdf;/Users/kshitijgoel/Zotero/storage/XH62CJ3A/Ashizawa et al. - 2017 - Least-Squares Log-Density Gradient Clustering for Riemannian Manifolds.pdf}
}

@inproceedings{atanasov_decentralized_2015,
  title = {Decentralized Active Information Acquisition: {{Theory}} and Application to Multi-Robot {{SLAM}}},
  shorttitle = {Decentralized Active Information Acquisition},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Atanasov, Nikolay and Le Ny, Jerome and Daniilidis, Kostas and Pappas, George J.},
  year = {2015},
  month = may,
  pages = {4775--4782},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7139863},
  abstract = {This paper addresses the problem of controlling mobile sensing systems to improve the accuracy and efficiency of gathering information autonomously. It applies to scenarios such as environmental monitoring, search and rescue, surveillance and reconnaissance, and simultaneous localization and mapping (SLAM). A multi-sensor active information acquisition problem, capturing the common characteristics of these scenarios, is formulated. The goal is to design sensor control policies which minimize the entropy of the estimation task, conditioned on the future measurements. First, we provide a non-greedy centralized solution, which is computationally fast, since it exploits linearized sensing models, and memory efficient, since it exploits sparsity in the environment model. Next, we decentralize the control task to obtain linear complexity in the number of sensors and provide suboptimality guarantees. Finally, our algorithms are applied to the multi-robot active SLAM problem to enable a decentralized nonmyopic solution that exploits sparsity in the planning process.},
  keywords = {Complexity theory,Estimation,Planning,Simultaneous localization and mapping,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/STLHMSGE/Atanasov et al. - 2015 - Decentralized active information acquisition Theo.pdf;/Users/kshitijgoel/Zotero/storage/7A2S2GKX/7139863.html}
}

@article{athanassoulis_data_2023,
  title = {Data {{Structures}} for {{Data-Intensive Applications}}: {{Tradeoffs}} and {{Design Guidelines}}},
  shorttitle = {Data {{Structures}} for {{Data-Intensive Applications}}},
  author = {Athanassoulis, Manos and Idreos, Stratos and Shasha, Dennis},
  year = {2023},
  month = jul,
  journal = {Foundations and Trends{\textregistered} in Databases},
  volume = {13},
  number = {1-2},
  pages = {1--168},
  publisher = {Now Publishers, Inc.},
  issn = {1931-7883, 1931-7891},
  doi = {10.1561/1900000059},
  url = {https://www.nowpublishers.com/article/Details/DBS-059},
  urldate = {2024-02-10},
  abstract = {Data Structures for Data-Intensive Applications: Tradeoffs and Design Guidelines},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QDEZTXAU/Athanassoulis et al. - 2023 - Data Structures for Data-Intensive Applications T.pdf}
}

@misc{attias_information_2024,
  title = {Information {{Complexity}} of {{Stochastic Convex Optimization}}: {{Applications}} to {{Generalization}} and {{Memorization}}},
  shorttitle = {Information {{Complexity}} of {{Stochastic Convex Optimization}}},
  author = {Attias, Idan and Dziugaite, Gintare Karolina and Haghifam, Mahdi and Livni, Roi and Roy, Daniel M.},
  year = {2024},
  month = jul,
  number = {arXiv:2402.09327},
  eprint = {2402.09327},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2402.09327},
  urldate = {2024-07-23},
  abstract = {In this work, we investigate the interplay between memorization and learning in the context of stochastic convex optimization (SCO). We define memorization via the information a learning algorithm reveals about its training data points. We then quantify this information using the framework of conditional mutual information (CMI) proposed by Steinke and Zakynthinou [SZ20]. Our main result is a precise characterization of the tradeoff between the accuracy of a learning algorithm and its CMI, answering an open question posed by Livni [Liv23]. We show that, in the L2 Lipschitz--bounded setting and under strong convexity, every learner with an excess error {$\varepsilon$} has CMI bounded below by {\textohm}(1/{$\varepsilon$}2) and {\textohm}(1/{$\varepsilon$}), respectively. We further demonstrate the essential role of memorization in learning problems in SCO by designing an adversary capable of accurately identifying a significant fraction of the training samples in specific SCO problems. Finally, we enumerate several implications of our results, such as a limitation of generalization bounds based on CMI and the incompressibility of samples in SCO problems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/RAAAP3X9/Attias et al. - 2024 - Information Complexity of Stochastic Convex Optimization Applications to Generalization and Memoriz.pdf}
}

@inproceedings{attias_variational_1999,
  title = {A Variational {{Bayesian}} Framework for Graphical Models},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Attias, Hagai},
  year = {1999},
  month = nov,
  series = {{{NIPS}}'99},
  pages = {209--215},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  url = {https://www.gatsby.ucl.ac.uk/publications/papers/03-2000.pdf},
  urldate = {2024-11-15},
  abstract = {This paper presents a novel practical framework for Bayesian model averaging and model selection in probabilistic graphical models. Our approach approximates full posterior distributions over model parameters and structures, as well as latent variables, in an analytical manner. These posteriors fall out of a free-form optimization procedure, which naturally incorporates conjugate priors. Unlike in large sample approximations, the posteriors are generally non-Gaussian and no Hessian needs to be computed. Predictive quantities are obtained analytically. The resulting algorithm generalizes the standard Expectation Maximization algorithm, and its convergence is guaranteed. We demonstrate that this approach can be applied to a large class of models in several domains, including mixture models and source separation.},
  file = {/Users/kshitijgoel/Zotero/storage/NM4HA9EY/Attias - 1999 - A variational Bayesian framework for graphical models.pdf}
}

@article{azizyan_densitysensitive_2013,
  title = {Density-Sensitive Semisupervised Inference},
  author = {Azizyan, Martin and Singh, Aarti and Wasserman, Larry},
  year = {2013},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {41},
  number = {2},
  pages = {751--771},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/13-AOS1092},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-41/issue-2/Density-sensitive-semisupervised-inference/10.1214/13-AOS1092.full},
  urldate = {2024-05-29},
  abstract = {Semisupervised methods are techniques for using labeled data \$(X\_\{1\},Y\_\{1\}),{\textbackslash}ldots,(X\_\{n\},Y\_\{n\})\$ together with unlabeled data \$X\_\{n+1\},{\textbackslash}ldots,X\_\{N\}\$ to make predictions. These methods invoke some assumptions that link the marginal distribution \$P\_\{X\}\$ of \$X\$ to the regression function \$f(x)\$. For example, it is common to assume that \$f\$ is very smooth over high density regions of \$P\_\{X\}\$. Many of the methods are ad-hoc and have been shown to work in specific examples but are lacking a theoretical foundation. We provide a minimax framework for analyzing semisupervised methods. In particular, we study methods based on metrics that are sensitive to the distribution \$P\_\{X\}\$. Our model includes a parameter \${\textbackslash}alpha\$ that controls the strength of the semisupervised assumption. We then use the data to adapt to \${\textbackslash}alpha\$.},
  keywords = {62G07,62G15,efficiency,kernel density,nonparametric inference,semisupervised},
  file = {/Users/kshitijgoel/Zotero/storage/NKL9ADT6/Azizyan et al. - 2013 - Density-sensitive semisupervised inference.pdf}
}

@article{azzalini_statistical_1999,
  title = {Statistical Applications of the Multivariate Skew Normal Distribution},
  author = {Azzalini, A. and Capitanio, A.},
  year = {1999},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {61},
  number = {3},
  pages = {579--602},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00194},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00194},
  urldate = {2024-06-07},
  abstract = {Azzalini and Dalla Valle have recently discussed the multivariate skew normal distribution which extends the class of normal distributions by the addition of a shape parameter. The first part of the present paper examines further probabilistic properties of the distribution, with special emphasis on aspects of statistical relevance. Inferential and other statistical issues are discussed in the following part, with applications to some multivariate statistics problems, illustrated by numerical examples. Finally, a further extension is described which introduces a skewing factor of an elliptical density.},
  copyright = {1999 Royal Statistical Society},
  langid = {english},
  keywords = {Elliptical distributions,Multivariate normal distribution,Quadratic forms,Skew normal distribution,Skewness},
  file = {/Users/kshitijgoel/Zotero/storage/JASEDNUC/Azzalini and Capitanio - 1999 - Statistical applications of the multivariate skew normal distribution.pdf;/Users/kshitijgoel/Zotero/storage/735IG86P/1467-9868.html}
}

@misc{babu_consensusconstrained_2024,
  title = {A Consensus-Constrained Parsimonious {{Gaussian}} Mixture Model for Clustering Hyperspectral Images},
  author = {Babu, Ganesh and Gowen, Aoife and Fop, Michael and Gormley, Isobel Claire},
  year = {2024},
  month = dec,
  number = {arXiv:2403.03349},
  eprint = {2403.03349},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.03349},
  url = {http://arxiv.org/abs/2403.03349},
  urldate = {2024-12-19},
  abstract = {The use of hyperspectral imaging to investigate food samples has grown due to the improved performance and lower cost of instrumentation. Food engineers use hyperspectral images to classify the type and quality of a food sample, typically using classification methods. In order to train these methods, every pixel in each training image needs to be labelled. Typically, computationally cheap threshold-based approaches are used to label the pixels, and classification methods are trained based on those labels. However, threshold-based approaches are subjective and cannot be generalized across hyperspectral images taken in different conditions and of different foods. Here a consensus-constrained parsimonious Gaussian mixture model (ccPGMM) is proposed to label pixels in hyperspectral images using a model-based clustering approach. The ccPGMM utilizes information that is available on some pixels and specifies constraints on those pixels belonging to the same or different clusters while clustering the rest of the pixels in the image. A latent variable model is used to represent the high-dimensional data in terms of a small number of underlying latent factors. To ensure computational feasibility, a consensus clustering approach is employed, where the data are divided into multiple randomly selected subsets of variables and constrained clustering is applied to each data subset; the clustering results are then consolidated across all data subsets to provide a consensus clustering solution. The ccPGMM approach is applied to simulated datasets and real hyperspectral images of three types of puffed cereal, corn, rice, and wheat. Improved clustering performance and computational efficiency are demonstrated when compared to other current state-of-the-art approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Methodology},
  file = {/Users/kshitijgoel/Zotero/storage/NMH9B6DT/Babu et al. - 2024 - A consensus-constrained parsimonious Gaussian mixture model for clustering hyperspectral images.pdf;/Users/kshitijgoel/Zotero/storage/LVMUXL9Q/2403.html}
}

@book{bach_learning_2024,
  title = {Learning {{Theory}} from {{First Principles}}},
  author = {Bach, Francis},
  year = {2024},
  publisher = {The MIT Press},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8CAQRE9B/Bach - Learning Theory from First Principles.pdf}
}

@inproceedings{bae_estimating_2021,
  title = {Estimating and {{Exploiting}} the {{Aleatoric Uncertainty}} in {{Surface Normal Estimation}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Bae, Gwangbin and Budvytis, Ignas and Cipolla, Roberto},
  year = {2021},
  month = oct,
  pages = {13117--13126},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICCV48922.2021.01289},
  url = {https://ieeexplore.ieee.org/document/9710890/},
  urldate = {2024-07-24},
  abstract = {Surface normal estimation from a single image is an important task in 3D scene understanding. In this paper, we address two limitations shared by the existing methods: the inability to estimate the aleatoric uncertainty and lack of detail in the prediction. The proposed network estimates the per-pixel surface normal probability distribution. We introduce a new parameterization for the distribution, such that its negative log-likelihood is the angular loss with learned attenuation. The expected value of the angular error is then used as a measure of the aleatoric uncertainty. We also present a novel decoder framework where pixel-wise multi-layer perceptrons are trained on a subset of pixels sampled based on the estimated uncertainty. The proposed uncertainty-guided sampling prevents the bias in training towards large planar surfaces and improves the quality of prediction, especially near object boundaries and on small structures. Experimental results show that the proposed method outperforms the state-of-the-art in ScanNet [4] and NYUv2 [33], and that the estimated uncertainty correlates well with the prediction error. Code is available at https://github.com/baegwangbin/ surface\_normal\_uncertainty .},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-6654-2812-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/44EHGFDN/Bae et al. - 2021 - Estimating and Exploiting the Aleatoric Uncertainty in Surface Normal Estimation.pdf}
}

@inproceedings{bae_rethinking_2024,
  title = {Rethinking {{Inductive Biases}} for {{Surface Normal Estimation}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Bae, Gwangbin and Davison, Andrew J.},
  year = {2024},
  pages = {9535--9545},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Bae_Rethinking_Inductive_Biases_for_Surface_Normal_Estimation_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/977LX23B/Bae and Davison - 2024 - Rethinking Inductive Biases for Surface Normal Estimation.pdf}
}

@misc{bagdasarian_3dgszip_2024,
  title = {{{3DGS}}.Zip: {{A}} Survey on {{3D Gaussian Splatting Compression Methods}}},
  shorttitle = {{{3DGS}}.Zip},
  author = {Bagdasarian, Milena T. and Knoll, Paul and Barthel, Florian and Hilsmann, Anna and Eisert, Peter and Morgenstern, Wieland},
  year = {2024},
  month = jul,
  number = {arXiv:2407.09510},
  eprint = {2407.09510},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.09510},
  urldate = {2024-08-22},
  abstract = {We present a work-in-progress survey on 3D Gaussian Splatting [5] compression methods, focusing on their statistical performance across various benchmarks. This survey aims to facilitate comparability by summarizing key statistics of different compression approaches in a tabulated format. The datasets evaluated include TanksAndTemples [6], MipNeRF360 [1], DeepBlending [4], and SyntheticNeRF [8]. For each method, we report the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and the resultant size in megabytes (MB), as provided by the respective authors. This is an ongoing, open project, and we invite contributions from the research community as GitHub issues or pull requests. Please visit http://w-m.github.io/3dgs-compression-survey/ for more information and a sortable version of the table.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/RF2SN5YW/Bagdasarian et al. - 2024 - 3DGS.zip A survey on 3D Gaussian Splatting Compression Methods.pdf}
}

@article{bakshi_nearlinear_2023,
  title = {Near-{{Linear Time Algorithm}} for the {{Chamfer Distance}}},
  author = {Bakshi, Ainesh and Indyk, Piotr and Jayaram, Rajesh and Silwal, Sandeep and Waingarten, Erik},
  year = {2023},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {66833--66844},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/d2fe3a5711a6d488da9e9a78b84ee24c-Abstract-Conference.html},
  urldate = {2024-04-22},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2PWVV6BX/Bakshi et al. - 2023 - Near-Linear Time Algorithm for the Chamfer Distanc.pdf}
}

@inproceedings{bakshi_stealthy_2023,
  title = {Stealthy {{Terrain-Aware Multi-Agent Active Search}}},
  booktitle = {Proceedings of {{The}} 7th {{Conference}} on {{Robot Learning}}},
  author = {Bakshi, Nikhil Angad and Schneider, Jeff},
  year = {2023},
  month = dec,
  pages = {1782--1796},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v229/bakshi23a.html},
  urldate = {2025-01-03},
  abstract = {Stealthy multi-agent active search is the problem of making efficient sequential data-collection decisions to identify an unknown number of sparsely located targets while adapting to new sensing information and concealing the search agents' location from the targets. This problem is applicable to reconnaissance tasks wherein the safety of the search agents can be compromised as the targets may be adversarial. Prior work usually focuses either on adversarial search, where the risk of revealing the agents' location to the targets is ignored or evasion strategies where efficient search is ignored. We present the Stealthy Terrain-Aware Reconnaissance (STAR) algorithm, a multi-objective parallelized Thompson sampling-based algorithm that relies on a strong topographical prior to reason over changing visibility risk over the course of the search. The STAR algorithm outperforms existing state-of-the-art multi-agent active search methods on both rate of recovery of targets as well as minimising risk even when subject to noisy observations, communication failures and an unknown number of targets.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HSK73N2Y/Bakshi and Schneider - 2023 - Stealthy Terrain-Aware Multi-Agent Active Search.pdf}
}

@article{ban_superpixel_2018,
  title = {Superpixel {{Segmentation Using Gaussian Mixture Model}}},
  author = {Ban, Zhihua and Liu, Jianguo and Cao, Li},
  year = {2018},
  month = aug,
  journal = {IEEE Transactions on Image Processing},
  volume = {27},
  number = {8},
  pages = {4105--4117},
  issn = {1941-0042},
  doi = {10.1109/TIP.2018.2836306},
  url = {https://ieeexplore.ieee.org/document/8360143/?arnumber=8360143},
  urldate = {2025-01-09},
  abstract = {Superpixel segmentation partitions an image into perceptually coherent segments of similar size, namely, superpixels. It is becoming a fundamental preprocessing step for various computer vision tasks because superpixels significantly reduce the number of inputs and provide a meaningful representation for feature extraction. We present a pixel-related Gaussian mixture model (GMM) to segment images into superpixels. GMM is a weighted sum of Gaussian functions, each one corresponding to a superpixel, to describe the density of each pixel represented by a random variable. Different from previously proposed GMMs, our weights are constant, and Gaussian functions in the sums are subsets of all the Gaussian functions, resulting in segments of similar size and an algorithm of linear complexity with respect to the number of pixels. In addition to the linear complexity, our algorithm is inherently parallel and allows fast execution on multi-core systems. During the expectation-maximization iterations of estimating the unknown parameters in the Gaussian functions, we impose two lower bounds to truncate the eigenvalues of the covariance matrices, which enables the proposed algorithm to control the regularity of superpixels. Experiments on a well-known segmentation dataset show that our method can efficiently produce superpixels that adhere to object boundaries better than the current state-of-the-art methods.},
  keywords = {Computational complexity,Covariance matrices,Erbium,expectation-maximization,Feature extraction,Gaussian mixture model,Image color analysis,image segmentation,Image segmentation,parallel algorithms,Shape,Superpixel},
  file = {/Users/kshitijgoel/Zotero/storage/UU95F7DM/Ban et al. - 2018 - Superpixel Segmentation Using Gaussian Mixture Model.pdf;/Users/kshitijgoel/Zotero/storage/8R7Q658G/8360143.html}
}

@article{banerjee_clustering_2005,
  title = {Clustering on the {{Unit Hypersphere}} Using von {{Mises-Fisher Distributions}}},
  author = {Banerjee, Arindam and Dhillon, Inderjit S. and Ghosh, Joydeep and Sra, Suvrit},
  year = {2005},
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {46},
  pages = {1345--1382},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v6/banerjee05a.html},
  urldate = {2024-06-23},
  abstract = {Several large scale data mining applications, such as text categorization and gene expression analysis, involve high-dimensional data that is also inherently directional in nature.  Often such data is L2 normalized so that it lies on the surface of a unit hypersphere.  Popular models such as (mixtures of) multi-variate Gaussians are inadequate for characterizing such data. This paper proposes a generative mixture-model approach to clustering directional data based on the von Mises-Fisher (vMF) distribution, which arises naturally for data distributed on the unit hypersphere.  In particular, we derive and analyze two variants of the Expectation Maximization (EM) framework for estimating the mean and concentration parameters of this mixture.  Numerical estimation of the concentration parameters is non-trivial in high dimensions since it involves functional inversion of ratios of Bessel functions.  We also formulate two clustering algorithms corresponding to the variants of EM that we derive.  Our approach provides a theoretical basis for the use of cosine similarity that has been widely employed by the information retrieval community, and obtains the spherical kmeans algorithm (kmeans with cosine similarity) as a special case of both variants. Empirical results on clustering of high-dimensional text and gene-expression data based on a mixture of vMF distributions show that the ability to estimate the concentration parameter for each vMF component, which is not present in existing approaches, yields superior results, especially for difficult clustering tasks in high-dimensional spaces.},
  file = {/Users/kshitijgoel/Zotero/storage/7V2CW55M/Banerjee et al. - 2005 - Clustering on the Unit Hypersphere using von Mises-Fisher Distributions.pdf}
}

@article{banerjee_clustering_2005a,
  title = {Clustering with {{Bregman Divergences}}},
  author = {Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S. and Ghosh, Joydeep},
  year = {2005},
  journal = {Journal of Machine Learning Research},
  volume = {6},
  number = {58},
  pages = {1705--1749},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v6/banerjee05b.html},
  urldate = {2024-06-09},
  abstract = {A wide variety of distortion functions, such as squared Euclidean   distance, Mahalanobis distance, Itakura-Saito distance and relative   entropy, have been used for clustering. In this paper, we propose and   analyze parametric hard and soft clustering algorithms based on a   large class of distortion functions known as Bregman divergences. The   proposed algorithms unify centroid-based parametric clustering   approaches, such as classical kmeans, the Linde-Buzo-Gray (LBG)   algorithm and information-theoretic clustering, which arise by special   choices of the Bregman divergence. The algorithms maintain the   simplicity and scalability of the classical kmeans algorithm,   while generalizing the method to a large class of clustering loss   functions.  This is achieved by first posing the hard clustering   problem in terms of minimizing the loss in Bregman information, a   quantity motivated by rate distortion theory, and then deriving an   iterative algorithm that monotonically decreases this loss. In   addition,   we show that there is a bijection between regular exponential families   and a large class of Bregman divergences, that we call regular Bregman   divergences. This result enables the development of an alternative   interpretation of an efficient EM scheme for learning mixtures of   exponential family distributions, and leads to a simple soft   clustering algorithm for regular Bregman divergences. Finally, we   discuss the connection between rate distortion theory and Bregman   clustering and present an information theoretic analysis of Bregman   clustering algorithms in terms of a trade-off between compression and   loss in Bregman information.},
  file = {/Users/kshitijgoel/Zotero/storage/WERIN3R3/Banerjee et al. - 2005 - Clustering with Bregman Divergences.pdf}
}

@inproceedings{banfi_it_2022,
  title = {Is It {{Worth}} to {{Reason}} about {{Uncertainty}} in {{Occupancy Grid Maps}} during {{Path Planning}}?},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Banfi, Jacopo and Woo, Lindsey and Campbell, Mark},
  year = {2022},
  month = may,
  pages = {11102--11108},
  doi = {10.1109/ICRA46639.2022.9812431},
  abstract = {This paper investigates the usefulness of reasoning about the uncertain presence of obstacles during path planning, which typically stems from the usage of probabilistic occupancy grid maps for representing the environment when mapping via a noisy sensor like a stereo camera. The traditional planning paradigm prescribes using a hard threshold on the occupancy probability to declare that a cell is an obstacle, and to plan a single path accordingly while treating unknown space as free. We compare this approach against a new uncertainty-aware planner, which plans two different path hypotheses and then merges their initial trajectory segments into a single one ending in a ``next-best view'' pose. After this informative view is taken, the planner commits to one of the hypotheses, or to a completely new one if a collision is imminent. Simulations were conducted comparing the proposed and traditional planner. Results show the existence of planning scenarios -like when the environment contains a dead-end, or when the goal is placed close to an obstacle- in which reasoning about uncertainty can significantly decrease the robot's traveled distance and increase the chances of reaching the goal. The new planner was also validated on a real Clearpath Jackal robot equipped with a ZED 2 stereo camera.},
  keywords = {Automation,Cameras,Cognition,Planning,Probabilistic logic,Robot vision systems,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/RACFF5A8/Banfi et al. - 2022 - Is it Worth to Reason about Uncertainty in Occupan.pdf}
}

@inproceedings{banuls_object_2020,
  title = {Object {{Detection}} from {{Thermal Infrared}} and {{Visible Light Cameras}} in {{Search}} and {{Rescue Scenes}}},
  booktitle = {2020 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Ba{\~n}uls, Adri{\'a}n and Mandow, Anthony and {V{\'a}zquez-Mart{\'i}n}, Ricardo and Morales, Jes{\'u}s and {Garc{\'i}a-Cerezo}, Alfonso},
  year = {2020},
  month = nov,
  pages = {380--386},
  issn = {2475-8426},
  doi = {10.1109/SSRR50563.2020.9292593},
  abstract = {Visual object recognition is a fundamental challenge for reliable search and rescue (SAR) robots, where vision can be limited by lighting and other harsh environmental conditions in disaster sites. The goal of this paper is to explore the use of thermal and visible light images for automatic object detection in SAR scenes. With this purpose, we have used a new dataset consisting of pairs of thermal infrared (TIR) and visible (RGB) video sequences captured from an all-terrain vehicle moving through several realistic SAR exercises participated by actual first response organisations. Two instances of the open source YOLOv3 convolutional neural network (CNN) architecture are trained from annotated sets of RGB and TIR images, respectively. In particular, frames are labelled with four representative classes in SAR scenes comprising both persons (civilian and first-responder) and vehicles (Civilian-car and response-vehicle). Furthermore, we perform a comparative evaluation of these networks that can provide insight for future RGB/TIR fusion.},
  keywords = {Cameras,Object detection,Robot vision systems,Robots,Security,Training,Video sequences},
  file = {/Users/kshitijgoel/Zotero/storage/93BKHD3Q/Bañuls et al. - 2020 - Object Detection from Thermal Infrared and Visible.pdf;/Users/kshitijgoel/Zotero/storage/VMJ65DK3/9292593.html}
}

@misc{bao_3d_2024,
  title = {{{3D Gaussian Splatting}}: {{Survey}}, {{Technologies}}, {{Challenges}}, and {{Opportunities}}},
  shorttitle = {{{3D Gaussian Splatting}}},
  author = {Bao, Yanqi and Ding, Tianyu and Huo, Jing and Liu, Yaoli and Li, Yuxin and Li, Wenbin and Gao, Yang and Luo, Jiebo},
  year = {2024},
  month = jul,
  number = {arXiv:2407.17418},
  eprint = {2407.17418},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.17418},
  urldate = {2024-08-22},
  abstract = {3D Gaussian Splatting (3DGS) has emerged as a prominent technique with the potential to become a mainstream method for 3D representations. It can effectively transform multi-view images into explicit 3D Gaussian representations through efficient training, and achieve real-time rendering of novel views. This survey aims to analyze existing 3DGS-related works from multiple intersecting perspectives, including related tasks, technologies, challenges, and opportunities. The primary objective is to provide newcomers with a rapid understanding of the field and to assist researchers in methodically organizing existing technologies and challenges. Specifically, we delve into the optimization, application, and extension of 3DGS, categorizing them based on their focuses or motivations. Additionally, we summarize and classify nine types of technical modules and corresponding improvements identified in existing works. Based on these analyses, we further examine the common challenges and technologies across various tasks, proposing potential research opportunities.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/GLHZ98J2/Bao et al. - 2024 - 3D Gaussian Splatting Survey, Technologies, Challenges, and Opportunities.pdf}
}

@article{barcelos_comprehensive_2024,
  title = {A {{Comprehensive Review}} and {{New Taxonomy}} on {{Superpixel Segmentation}}},
  author = {Barcelos, Isabela Borlido and Bel{\'e}m, Felipe De Castro and Jo{\~a}o, Leonardo De Melo and Patroc{\'i}nio, Zenilton K. G. Do and Falc{\~a}o, Alexandre Xavier and Guimar{\~a}es, Silvio Jamil Ferzoli},
  year = {2024},
  month = apr,
  journal = {ACM Comput. Surv.},
  volume = {56},
  number = {8},
  pages = {200:1--200:39},
  issn = {0360-0300},
  doi = {10.1145/3652509},
  url = {https://dl.acm.org/doi/10.1145/3652509},
  urldate = {2025-01-09},
  abstract = {Superpixel segmentation consists of partitioning images into regions composed of similar and connected pixels. Its methods have been widely used in many computer vision applications, since it allows for reducing the workload, removing redundant information, and preserving regions with meaningful features. Due to the rapid progress in this area, the literature fails to catch up on more recent works among the compared ones and to categorize the methods according to all existing strategies. This work fills this gap by presenting a comprehensive review with a new taxonomy for superpixel segmentation, in which methods are classified according to their processing steps and processing levels of image features. We revisit the recent and popular literature according to our taxonomy and evaluate 23 strategies and a grid segmentation baseline based on nine criteria: connectivity, compactness, delineation, control over the number of superpixels, color homogeneity, robustness, running time, stability, and visual quality. Our experiments show the trends of each approach in superpixel segmentation and discuss individual trade-offs. Finally, we provide a new benchmark for superpixel assessment, available at .},
  file = {/Users/kshitijgoel/Zotero/storage/GW5YAVXQ/Barcelos et al. - 2024 - A Comprehensive Review and New Taxonomy on Superpixel Segmentation.pdf}
}

@article{barenboim_monte_2023,
  title = {Monte {{Carlo Planning}} in {{Hybrid Belief POMDPs}}},
  author = {Barenboim, Moran and Shienman, Moshe and Indelman, Vadim},
  year = {2023},
  month = aug,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {8},
  pages = {4410--4417},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3282773},
  url = {https://ieeexplore.ieee.org/document/10143637},
  urldate = {2024-01-31},
  abstract = {Real-world problems often require reasoning about hybrid beliefs, over both discrete and continuous random variables. Yet, such a setting has hardly been investigated in the context of planning. Moreover, existing online partially observable Markov decision processes (POMDPs) solvers do not support hybrid beliefs directly. In particular, these solvers do not address the added computational burden due to an increasing number of hypotheses with the planning horizon, which can grow exponentially. As part of this work, we present a novel algorithm, Hybrid Belief Monte Carlo Planning (HB-MCP) that utilizes the Monte Carlo Tree Search (MCTS) algorithm to solve a POMDP while maintaining a hybrid belief. We illustrate how the upper confidence bound (UCB) exploration bonus can be leveraged to guide the growth of hypotheses trees alongside the belief trees. We then evaluate our approach in highly aliased simulated environments where unresolved data association leads to multi-modal belief hypotheses.},
  keywords = {autonomous agents,Data models,History,Inference algorithms,Markov processes,Monte Carlo methods,Planning,Planning under uncertainty,Random variables},
  file = {/Users/kshitijgoel/Zotero/storage/GTMT2J8A/Barenboim et al. - 2023 - Monte Carlo Planning in Hybrid Belief POMDPs.pdf;/Users/kshitijgoel/Zotero/storage/Q3EZKXFF/10143637.html}
}

@article{bares_dante_1999,
  title = {Dante {{II}}: {{Technical Description}}, {{Results}}, and {{Lessons Learned}}},
  shorttitle = {Dante {{II}}},
  author = {Bares, John E. and Wettergreen, David S.},
  year = {1999},
  month = jul,
  journal = {The International Journal of Robotics Research},
  volume = {18},
  number = {7},
  pages = {621--649},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649922066475},
  url = {https://doi.org/10.1177/02783649922066475},
  urldate = {2023-10-25},
  abstract = {Dante II is a unique walking robot that provides important insight into high-mobility robotic locomotion and remote robotic exploration. Dante II's uniqueness stems from its combined legged and rappelling mobility system, its scanning-laser rangefinder, and its multilevel control scheme. In 1994 Dante II was deployed and successfully tested in a remote Alaskan volcano, as a demonstration of the fieldworthiness of these technologies. For more than five days the robot explored alone in the volcano crater using a combination of supervised autonomous control and teleoperated control. Human operators were located 120 km distant during the mission. This article first describes in detail the robot, support systems, control techniques, and user interfaces. We then describe results from the battery of field tests leading up to and including the volcanic mission. Finally, we put forth important lessons which comprise the legacy of this project. We show that framewalkers are appropriate for rappelling in severe terrain, though tether systems have limitations. We also discuss the importance of future ``autonomous'' systems to realize when they require human support rather than relying on humans for constant oversight.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9DDSDNUA/Bares and Wettergreen - 1999 - Dante II Technical Description, Results, and Less.pdf}
}

@book{barfoot_state_2017,
  title = {State {{Estimation}} for {{Robotics}}},
  author = {Barfoot, Timothy D.},
  year = {2017},
  month = jul,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781316671528},
  url = {https://www.cambridge.org/core/product/identifier/9781316671528/type/book},
  urldate = {2023-05-20},
  abstract = {A key aspect of robotics today is estimating the state, such as position and orientation, of a robot as it moves through the world. Most robots and autonomous vehicles depend on noisy data from sensors such as cameras or laser rangefinders to navigate in a three-dimensional world. This book presents common sensor models and practical advice on how to carry out state estimation for rotations and other state variables. It covers both classical state estimation methods such as the Kalman filter, as well as important modern topics such as batch estimation, the Bayes filter, sigmapoint and particle filters, robust estimation for outlier rejection, and continuous-time trajectory estimation and its connection to Gaussian-process regression. The methods are demonstrated in the context of important applications such as point-cloud alignment, pose-graph relaxation, bundle adjustment, and simultaneous localization and mapping. Students and practitioners of robotics alike will find this a valuable resource.},
  isbn = {978-1-107-15939-6 978-1-316-67152-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DYRPKNU5/Barfoot - 2017 - State Estimation for Robotics.pdf}
}

@article{barisic_brain_2022,
  title = {Brain over {{Brawn}}: {{Using}} a {{Stereo Camera}} to {{Detect}}, {{Track}}, and {{Intercept}} a {{Faster UAV}} by {{Reconstructing}} the {{Intruder}}'s {{Trajectory}}},
  shorttitle = {Brain over {{Brawn}}},
  author = {Bari{\v s}i{\'c}, Antonella and Petric, Frano and Bogdan, Stjepan},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  pages = {222--240},
  issn = {2771-3989},
  doi = {10.55417/fr.2022009},
  url = {https://ieeexplore.ieee.org/document/10876012/},
  urldate = {2025-06-27},
  abstract = {This paper presents our approach to intercepting a faster intruder UAV, inspired by the MBZIRC 2020 Challenge 1. By utilizing a priori knowledge of the shape of the intruder's trajectory, we can calculate an interception point. Target tracking is based on image processing by a YOLOv3 Tiny convolutional neural network, combined with depth calculation using a gimbal-mounted ZED Mini stereo camera. We use RGB and depth data from the camera, devising a noise-reducing histogram-filter to extract the target's 3D position. Obtained 3D measurements of target's position are used to calculate the position, orientation, and size of a figure-eight shaped trajectory, which we approximate using a Bernoulli lemniscate. Once the approximation is deemed sufficiently precise, as measured by the distance between observations and estimate, we calculate an interception point to position the interceptor UAV directly on the intruder's path. Our method, which we have significantly improved based on the experience gathered during the MBZIRC competition, has been validated in simulation and through field experiments. Our results confirm that we have developed an efficient, visual-perception module that can extract information describing the intruder UAV's motion with precision sufficient to support interception planning. In a majority of our simulated encounters, we can track and intercept a target that moves 30\% faster than the interceptor. Corresponding tests in an unstructured environment yielded 9 out of 12 successful results.},
  keywords = {aerial robotics,Autonomous aerial vehicles,Cameras,computer vision,Detectors,Estimation,Image reconstruction,perception,position estimation,Radar tracking,Robots,Target tracking,Three-dimensional displays,Trajectory,visual serving},
  file = {/Users/kshitijgoel/Zotero/storage/IJFBNKIZ/Barišić et al. - 2022 - Brain over Brawn Using a Stereo Camera to Detect, Track, and Intercept a Faster UAV by Reconstructi.pdf}
}

@article{barnes_geological_2018,
  title = {Geological {{Analysis}} of {{Martian Rover-Derived Digital Outcrop Models Using}} the 3-{{D Visualization Tool}}, {{Planetary Robotics}} 3-{{D Viewer}}---{{PRo3D}}},
  author = {Barnes, Robert and Gupta, Sanjeev and Traxler, Christoph and Ortner, Thomas and Bauer, Arnold and Hesina, Gerd and Paar, Gerhard and Huber, Ben and Juhart, Kathrin and Fritz, Laura and Nauschnegg, Bernhard and Muller, Jan-Peter and Tao, Yu},
  year = {2018},
  journal = {Earth and Space Science},
  volume = {5},
  number = {7},
  pages = {285--307},
  issn = {2333-5084},
  doi = {10.1002/2018EA000374},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/2018EA000374},
  urldate = {2024-11-27},
  abstract = {Panoramic camera systems on robots exploring the surface of Mars are used to collect images of terrain and rock outcrops which they encounter along their traverse. Image mosaics from these cameras are essential in mapping the surface geology and selecting locations for analysis by other instruments on the rover's payload. 2-D images do not truly portray the depth of field of features within an image, nor their 3-D geometry. This paper describes a new 3-D visualization software tool for geological analysis of Martian rover-derived Digital Outcrop Models created using photogrammetric processing of stereo-images using the Planetary Robotics Vision Processing tool developed for 3-D vision processing of ExoMars PanCam and Mars 2020 Mastcam-Z data. Digital Outcrop Models are rendered in real time in the Planetary Robotics 3-D Viewer PRo3D, allowing scientists to roam outcrops as in a terrestrial field campaign. Digitization of point, line, and polyline features is used for measuring the physical dimensions of geological features and communicating interpretations. Dip and strike of bedding and fractures is measured by digitizing a polyline along the contact or fracture trace, through which a best fit plane is plotted. The attitude of this plane is calculated in the software. Here we apply these tools to analysis of sedimentary rock outcrops and quantification of the geometry of fracture systems encountered by the science teams of NASA's Mars Exploration Rover Opportunity and Mars Science Laboratory rover Curiosity. We show the benefits PRo3D allows for visualization and collection of geological interpretations and analyses from rover-derived stereo-images.},
  copyright = {{\copyright}2018. The Authors.},
  langid = {english},
  keywords = {Digital Outcrop Models,Exomars 2020 Rover,Mars Exploration Rover,Mars Science Laboratory,sedimentology,veins},
  file = {/Users/kshitijgoel/Zotero/storage/XVVHVD2N/Barnes et al. - 2018 - Geological Analysis of Martian Rover-Derived Digital Outcrop Models Using the 3-D Visualization Tool.pdf;/Users/kshitijgoel/Zotero/storage/NBUAY2YZ/2018EA000374.html}
}

@inproceedings{barron_mipnerf_2021,
  title = {Mip-{{NeRF}}: {{A Multiscale Representation}} for {{Anti-Aliasing Neural Radiance Fields}}},
  shorttitle = {Mip-{{NeRF}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Barron, Jonathan T. and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and {Martin-Brualla}, Ricardo and Srinivasan, Pratul P.},
  year = {2021},
  pages = {5855--5864},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Barron_Mip-NeRF_A_Multiscale_Representation_for_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2021_paper.html},
  urldate = {2022-09-02},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GUSFTXUP/Barron et al. - 2021 - Mip-NeRF A Multiscale Representation for Anti-Ali.pdf}
}

@article{barry_highspeed_2018,
  title = {High-Speed Autonomous Obstacle Avoidance with Pushbroom Stereo},
  author = {Barry, Andrew J. and Florence, Peter R. and Tedrake, Russ},
  year = {2018},
  journal = {Journal of Field Robotics},
  volume = {35},
  number = {1},
  pages = {52--68},
  issn = {1556-4967},
  doi = {10.1002/rob.21741},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21741},
  urldate = {2024-03-07},
  abstract = {We present the design and implementation of a small autonomous unmanned aerial vehicle capable of high-speed flight through complex natural environments. Using only onboard GPS-denied sensing and computation, we perform obstacle detection, planning, and feedback control in real time. We present a novel integrated approach to perception and control using pushbroom stereo, which exploits forward motion to enable efficient obstacle detection and avoidance using lightweight processors on an unmanned aerial vehicle. Our use of model-based planning and control techniques allows us to track precise trajectories that avoid obstacles identified by the vision system. We demonstrate a complete working system detecting obstacles at 120 Hz and avoiding trees at up to 14 m/s (31 MPH). To the best of our knowledge, this is the fastest lightweight aerial vehicle to perform collision avoidance using three-dimensional geometric information.},
  copyright = {{\copyright} 2017 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SSSFDZ4U/Barry et al. - 2018 - High-speed autonomous obstacle avoidance with push.pdf}
}

@article{bartolomei_fast_2023,
  title = {Fast {{Multi-UAV Decentralized Exploration}} of {{Forests}}},
  author = {Bartolomei, Luca and Teixeira, Lucas and Chli, Margarita},
  year = {2023},
  month = sep,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {9},
  pages = {5576--5583},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3296037},
  url = {https://ieeexplore.ieee.org/document/10184313/},
  urldate = {2024-02-25},
  abstract = {Efficient exploration strategies are vital in tasks such as search-and-rescue missions and disaster surveying. Unmanned Aerial Vehicles (UAVs) have become particularly popular in such applications, promising to cover large areas at high speeds. Moreover, with the increasing maturity of onboard UAV perception, research focus has been shifting toward higher-level reasoning for multi-robot missions. However, autonomous navigation and exploration of previously unknown large spaces still constitute an open challenge, especially when the environment is cluttered and exhibits large and frequent occlusions due to high obstacle density, as is the case of forests. Moreover, the problem of long-distance wireless communication in such scenes can become a limiting factor, especially when automating the navigation of a UAV fleet. In this spirit, this work proposes an exploration strategy that enables multiple UAVs to quickly explore complex scenes in a decentralized fashion. By providing the decision-making capabilities to each UAV to switch between different execution modes, the proposed strategy is shown to strike a great balance between cautious exploration of yet completely unknown regions and more aggressive exploration of smaller areas of unknown space. This results in full coverage of forest areas in multi-UAV setups up to 30\% faster than the state of the art.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ID6R4EZV/Bartolomei et al. - 2023 - Fast Multi-UAV Decentralized Exploration of Forest.pdf}
}

@article{basri_lambertian_2003,
  title = {Lambertian Reflectance and Linear Subspaces},
  author = {Basri, R. and Jacobs, D.W.},
  year = {2003},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {25},
  number = {2},
  pages = {218--233},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2003.1177153},
  url = {http://ieeexplore.ieee.org/document/1177153/},
  urldate = {2024-03-17},
  abstract = {We prove that the set of all Lambertian reflectance functions (the mapping from surface normals to intensities) obtained with arbitrary distant light sources lies close to a 9D linear subspace. This implies that, in general, the set of images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately by a low-dimensional linear subspace, explaining prior empirical results. We also provide a simple analytic characterization of this linear space. We obtain these results by representing lighting using spherical harmonics and describing the effects of Lambertian materials as the analog of a convolution. These results allow us to construct algorithms for object recognition based on linear methods as well as algorithms that use convex optimization to enforce nonnegative lighting functions. We also show a simple way to enforce nonnegative lighting when the images of an object lie near a 4D linear space. We apply these algorithms to perform face recognition by finding the 3D model that best matches a 2D query image.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZS76JPFH/Basri and Jacobs - 2003 - Lambertian reflectance and linear subspaces.pdf}
}

@inproceedings{batra_decentralized_2022,
  title = {Decentralized {{Control}} of {{Quadrotor Swarms}} with {{End-to-end Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  author = {Batra, Sumeet and Huang, Zhehui and Petrenko, Aleksei and Kumar, Tushar and Molchanov, Artem and Sukhatme, Gaurav S.},
  year = {2022},
  month = jan,
  pages = {576--586},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v164/batra22a.html},
  urldate = {2025-08-08},
  abstract = {We demonstrate the possibility of learning drone swarm controllers that are zero-shot transferable to real quadrotors via large-scale multi-agent end-to-end reinforcement learning. We train policies parameterized by neural networks that are capable of controlling individual drones in a swarm in a fully decentralized manner. Our policies, trained in simulated environments with realistic quadrotor physics, demonstrate advanced flocking behaviors, perform aggressive maneuvers in tight formations while avoiding collisions with each other, break and re-establish formations to avoid collisions with moving obstacles, and efficiently coordinate in pursuit-evasion tasks. We analyze, in simulation, how different model architectures and parameters of the training regime influence the final performance of neural swarms. We demonstrate the successful deployment of the model learned in simulation to highly resource-constrained physical quadrotors performing station keeping and goal swapping behaviors. Video demonstrations and source code are available at the project website https://sites.google.com/view/swarm-rl.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CKKHKQ7I/Batra et al. - 2022 - Decentralized Control of Quadrotor Swarms with End-to-end Deep Reinforcement Learning.pdf}
}

@article{bauersfeld_range_2022,
  title = {Range, {{Endurance}}, and {{Optimal Speed Estimates}} for {{Multicopters}}},
  author = {Bauersfeld, Leonard and Scaramuzza, Davide},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {2953--2960},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3145063},
  url = {https://ieeexplore.ieee.org/abstract/document/9691840},
  urldate = {2023-11-14},
  abstract = {Multicopters are among the most versatile mobile robots. Their applications range from inspection and mapping tasks to providing vital reconnaissance in disaster zones and to package delivery. The range, endurance, and speed a multirotor vehicle can achieve while performing its task is a decisive factor not only for vehicle design and mission planning, but also for policy makers deciding on the rules and regulations for aerial robots. To the best of the authors' knowledge, this work proposes the first approach to estimate the range, endurance, and optimal flight speed for a wide variety of multicopters. This advance is made possible by combining a state-of-the-art first-principles aerodynamic multicopter model based on blade-element-momentum theory with an electric-motor model and a graybox battery model. This model predicts the cell voltage with only 1.3\% relative error (43.1{\textbackslash}, {\textbackslash}mathrm mV), even if the battery is subjected to non-constant discharge rates. Our approach is validated with real-world experiments on a test bench as well as with flights at speeds up to 65{\textbackslash}, {\textbackslash}mathrm km/{\textbackslash}mathrm h in one of the world's largest motion-capture systems. We also present an accurate pen-and-paper algorithm to estimate the range, endurance and optimal speed of multicopters to help future researchers build drones with maximal range and endurance, ensuring that future multirotor vehicles are even more versatile.},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/CERHVL3G/Bauersfeld and Scaramuzza - 2022 - Range, Endurance, and Optimal Speed Estimates for .pdf;/Users/kshitijgoel/Zotero/storage/LSA3DI38/Bauersfeld and Scaramuzza - 2022 - Range, Endurance, and Optimal Speed Estimates for .pdf;/Users/kshitijgoel/Zotero/storage/VGDU5JS3/2109.html}
}

@misc{bautista_fully_2024,
  title = {Fully Distributed and Resilient Source Seeking for Robot Swarms},
  author = {Bautista, Jes{\'u}s and Acuaviva, Antonio and Hinojosa, Jos{\'e} and Yao, Weijia and Jim{\'e}nez, Juan and de Marina, H{\'e}ctor Garc{\'i}a},
  year = {2024},
  month = oct,
  number = {arXiv:2410.15921},
  eprint = {2410.15921},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.15921},
  urldate = {2024-10-28},
  abstract = {We propose a self-contained, resilient and fully distributed solution for locating the maximum of an unknown 3D scalar field using a swarm of robots that travel at constant speeds. Unlike conventional reactive methods relying on gradient information, our methodology enables the swarm to determine an ascending direction so that it approaches the source with arbitrary precision. Our source-seeking solution consists of three algorithms. The first two algorithms run sequentially and distributively at a high frequency providing barycentric coordinates and the ascending direction respectively to the individual robots. The third algorithm is the individual control law for a robot to track the estimated ascending direction. We show that the two algorithms with higher frequency have an exponential convergence to their eventual values since they are based on the standard consensus protocol for first-order dynamical systems; their high frequency depends on how fast the robots travel through the scalar field. The robots are not constrained to any particular geometric formation, and we study both discrete and continuous distributions of robots within swarm shapes. The shape analysis reveals the resiliency of our approach as expected in robot swarms, i.e., by amassing robots we ensure the source-seeking functionality in the event of missing or misplaced individuals or even if the robot network splits into two or more disconnected subnetworks. In addition, we also enhance the robustness of the algorithm by presenting conditions for {\textbackslash}emph\{optimal\} swarm shapes, in the sense that the ascending directions can be closely parallel to the field's gradient. We exploit such an analysis so that the swarm can adapt to unknown environments by morphing its shape and maneuvering while still following an ascending direction.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/9VRDXPTE/Bautista et al. - 2024 - Fully distributed and resilient source seeking for robot swarms.pdf;/Users/kshitijgoel/Zotero/storage/QCP49SJC/2410.html}
}

@article{bayer_autonomous_2023,
  title = {Autonomous {{Multi-robot Exploration}} with {{Ground Vehicles}} in {{DARPA Subterranean Challenge Finals}}},
  author = {Bayer, Jan and C{\'i}{\v z}ek, Petr and Faigl, Jan},
  year = {2023},
  month = jan,
  journal = {Field Robotics},
  volume = {3},
  number = {1},
  pages = {266--300},
  issn = {27713989},
  doi = {10.55417/fr.2023008},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_3_files/Vol3_08.pdf},
  urldate = {2023-03-23},
  abstract = {Autonomous navigation and multi-robot exploration framework for ground robots are key parts of the robotic system deployed by the team CTU-CRAS-NORLAB in the final event of the Subterranean (SubT) Challenge organized by the Defense Advanced Research Projects Agency (DARPA) in 2021. The SubT Challenge aimed to advance technologies related to search-and-rescue missions with multi-robot systems in underground environments where communication is unavailable and global navigation satellite systems are denied. This field report describes the developed multirobot exploration framework focusing on planning, exploration, and traversability estimation for a heterogeneous team of ground vehicles in large-scale rough terrains and multi-robot coordination with limited communication. The developed method employs a dense local mapping for precise traversability estimation combined with a sparse topometrical map shareable between multiple robots and is thus used in the decision-making of the exploration strategy. The topometrical map is designed to support the decentralized coordination of heterogeneous teams of robots, which is demonstrated by deploying the developed framework in the SubT competitions. The framework has been employed in the Virtual track for the full autonomous control of the ground robots, where our team scored second. Besides, in the Systems track, a human supervisor exploited autonomous behaviors provided by the proposed framework to control a heterogeneous team of six ground robots. We report on real-world experimental results from the deployment of the SubT Challenge. Furthermore, we present results from the post-event testing of the SubT Challenge, where three quadruped robots controlled by the framework explored over five hundred meters fully autonomously.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3XSW8JV4/Bayer et al. - 2023 - Autonomous Multi-robot Exploration with Ground Veh.pdf}
}

@inproceedings{behley_efficient_2018,
  title = {Efficient {{Surfel-Based SLAM}} Using {{3D Laser Range Data}} in {{Urban Environments}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIV}}},
  author = {Behley, Jens and Stachniss, Cyrill},
  year = {2018},
  month = jun,
  volume = {14},
  url = {https://www.roboticsproceedings.org/rss14/p16.html},
  urldate = {2025-03-01},
  isbn = {978-0-9923747-4-7},
  file = {/Users/kshitijgoel/Zotero/storage/MXJCNSNT/Behley and Stachniss - 2018 - Efficient Surfel-Based SLAM using 3D Laser Range Data in Urban Environments.pdf}
}

@misc{bekris_state_2024,
  title = {The {{State}} of {{Robot Motion Generation}}},
  author = {Bekris, Kostas E. and Doerr, Joe and Meng, Patrick and Tangirala, Sumanth},
  year = {2024},
  month = oct,
  number = {arXiv:2410.12172},
  eprint = {2410.12172},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.12172},
  urldate = {2024-10-21},
  abstract = {This paper reviews the large spectrum of methods for generating robot motion proposed over the 50 years of robotics research culminating in recent developments. It crosses the boundaries of methodologies, typically not surveyed together, from those that operate over explicit models to those that learn implicit ones. The paper discusses the current state-of-the-art as well as properties of varying methodologies, highlighting opportunities for integration.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/KQMR693S/Bekris et al. - 2024 - The State of Robot Motion Generation.pdf}
}

@inproceedings{beksi_3d_2016,
  title = {{{3D}} Point Cloud Segmentation Using Topological Persistence},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Beksi, William J. and Papanikolopoulos, Nikolaos},
  year = {2016},
  month = may,
  pages = {5046--5051},
  doi = {10.1109/ICRA.2016.7487710},
  url = {https://ieeexplore.ieee.org/document/7487710/?arnumber=7487710},
  urldate = {2025-02-26},
  abstract = {In this paper, we present an approach to segment 3D point cloud data using ideas from persistent homology theory. The proposed algorithms first generate a simplicial complex representation of the point cloud dataset. Next, we compute the zeroth homology group of the complex which corresponds to the number of connected components. Finally, we extract the clusters of each connected component in the dataset. We show that this technique has several advantages over state of the art methods such as the ability to provide a stable segmentation of point cloud data under noisy or poor sampling conditions and its independence of a fixed distance metric.},
  keywords = {Clustering algorithms,Face,Image segmentation,Robots,Sensors,Three-dimensional displays,Topology},
  file = {/Users/kshitijgoel/Zotero/storage/J7N6KL69/Beksi and Papanikolopoulos - 2016 - 3D point cloud segmentation using topological persistence.pdf;/Users/kshitijgoel/Zotero/storage/N3D89ENT/7487710.html}
}

@article{ben-asher_time_2022,
  title = {Time {{Optimal Trajectories}} for a {{Car-Like Mobile Robot}}},
  author = {{Ben-Asher}, Joseph Z. and Rimon, Elon D.},
  year = {2022},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {1},
  pages = {421--432},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2021.3080656},
  url = {https://ieeexplore.ieee.org/document/9451188/},
  urldate = {2024-01-22},
  abstract = {This article studies the time optimal paths of a car-like mobile robot navigating in an obstacle-free planar environment. The robot, with forward and backward speeds, is controlled by bounded acceleration and limited front-wheels steering rate. The article extends previous results that solved this problem for a simplified car-robot model controlled by bounded speed and limited heading rate. The simplified car-robot model forms a unicycle with coupled bounds on the control inputs, while the full car-robot model has independent control inputs. The problem is analyzed as an optimal control problem by the minimum principle and by singular control theory. While the simplified car-robot model gives six time optimal path primitives, the optimality conditions for the full car-robot model yield twelve path primitives that form the time optimal paths. Three primitives involve singular controls of the steering front wheels that asymptotically align the robot along a straight line motion. All path primitives are analytically characterized and representative examples are studied in order to demonstrate how the path primitives combine to form the time optimal paths.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/WFPHKRCH/Ben-Asher and Rimon - 2022 - Time Optimal Trajectories for a Car-Like Mobile Ro.pdf}
}

@misc{benchetrit_anytime_2025,
  title = {Anytime {{Incremental}} \${$\rho\$$}{{POMDP Planning}} in {{Continuous Spaces}}},
  author = {Benchetrit, Ron and {Lev-Yehudi}, Idan and Zhitnikov, Andrey and Indelman, Vadim},
  year = {2025},
  month = feb,
  number = {arXiv:2502.02549},
  eprint = {2502.02549},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.02549},
  url = {http://arxiv.org/abs/2502.02549},
  urldate = {2025-02-06},
  abstract = {Partially Observable Markov Decision Processes (POMDPs) provide a robust framework for decision-making under uncertainty in applications such as autonomous driving and robotic exploration. Their extension, \${\textbackslash}rho\$POMDPs, introduces belief-dependent rewards, enabling explicit reasoning about uncertainty. Existing online \${\textbackslash}rho\$POMDP solvers for continuous spaces rely on fixed belief representations, limiting adaptability and refinement - critical for tasks such as information-gathering. We present \${\textbackslash}rho\$POMCPOW, an anytime solver that dynamically refines belief representations, with formal guarantees of improvement over time. To mitigate the high computational cost of updating belief-dependent rewards, we propose a novel incremental computation approach. We demonstrate its effectiveness for common entropy estimators, reducing computational cost by orders of magnitude. Experimental results show that \${\textbackslash}rho\$POMCPOW outperforms state-of-the-art solvers in both efficiency and solution quality.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/BNZKWHFM/Benchetrit et al. - 2025 - Anytime Incremental $ρ$POMDP Planning in Continuous Spaces.pdf;/Users/kshitijgoel/Zotero/storage/M584L5A5/2502.html}
}

@inproceedings{bender_continuously_2023,
  title = {Continuously {{Parameterized Mixture Models}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Bender, Christopher M. and Shi, Yifeng and Niethammer, Marc and Oliva, Junier},
  year = {2023},
  month = jul,
  pages = {2050--2062},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/bender23a.html},
  urldate = {2023-11-06},
  abstract = {Mixture models are universal approximators of smooth densities but are difficult to utilize in complicated datasets due to restrictions on typically available modes and challenges with initialiations. We show that by continuously parameterizing a mixture of factor analyzers using a learned ordinary differential equation, we can improve the fit of mixture models over direct methods. Once trained, the mixture components can be extracted and the neural ODE can be discarded, leaving us with an effective, but low-resource model. We additionally explore the use of a training curriculum from an easy-to-model latent space extracted from a normalizing flow to the more complex input space and show that the smooth curriculum helps to stabilize and improve results with and without the continuous parameterization. Finally, we introduce a hierarchical version of the model to enable more flexible, robust classification and clustering, and show substantial improvements against traditional parameterizations of GMMs.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/W6AQYETL/Bender et al. - 2023 - Continuously Parameterized Mixture Models.pdf}
}

@inproceedings{bengio_nonlocal_2005,
  title = {Non-{{Local Manifold Parzen Windows}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Bengio, Yoshua and Larochelle, Hugo and Vincent, Pascal},
  year = {2005},
  volume = {18},
  publisher = {MIT Press},
  url = {https://papers.nips.cc/paper_files/paper/2005/hash/17eb7ecc4c38e4705361cccd903ad8c6-Abstract.html},
  urldate = {2024-04-29},
  abstract = {To escape from the curse of dimensionality, we claim that one can learn non-local functions, in the sense that the value and shape of the learned function at x must be inferred using examples that may be far from x. With this objective, we present a non-local non-parametric density esti- mator. It builds upon previously proposed Gaussian mixture models with regularized covariance matrices to take into account the local shape of the manifold. It also builds upon recent work on non-local estimators of the tangent plane of a manifold, which are able to generalize in places with little training data, unlike traditional, local, non-parametric models.},
  file = {/Users/kshitijgoel/Zotero/storage/HGY7Q2YN/Bengio et al. - 2005 - Non-Local Manifold Parzen Windows.pdf}
}

@incollection{berger_rate_1975,
  title = {Rate {{Distortion Theory}} and {{Data Compression}}},
  booktitle = {Advances in {{Source Coding}}},
  author = {Berger, Toby},
  editor = {Berger, Toby and Davisson, Lee D.},
  year = {1975},
  pages = {1--39},
  publisher = {Springer},
  address = {Vienna},
  doi = {10.1007/978-3-7091-2928-9_1},
  url = {https://doi.org/10.1007/978-3-7091-2928-9_1},
  urldate = {2024-04-23},
  abstract = {In this introductory lecture we present the rudiments of rate distortion theory, the branch of information theory that treats data compression problems. The rate distortion function is defined and a powerful iterative algorithm for calculating it is described. Shannon's source coding theorems are stated and heuristically discussed.},
  isbn = {978-3-7091-2928-9},
  langid = {english},
  keywords = {Average Mutual Information,Code Word,Data Compression,Linear Code,Mean Square Error},
  file = {/Users/kshitijgoel/Zotero/storage/HUN4AJGF/Berger - 1975 - Rate Distortion Theory and Data Compression.pdf}
}

@incollection{berner_modern_2022,
  title = {The {{Modern Mathematics}} of {{Deep Learning}}},
  author = {Berner, Julius and Grohs, Philipp and Kutyniok, Gitta and Petersen, Philipp},
  year = {2022},
  month = dec,
  eprint = {2105.04026},
  primaryclass = {cs, stat},
  pages = {1--111},
  doi = {10.1017/9781009025096.002},
  url = {http://arxiv.org/abs/2105.04026},
  urldate = {2024-06-25},
  abstract = {We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/IQLVUYLK/Berner et al. - 2022 - The Modern Mathematics of Deep Learning.pdf}
}

@inproceedings{bernreiter_collaborative_2022,
  title = {Collaborative {{Robot Mapping}} Using {{Spectral Graph Analysis}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Bernreiter, Lukas and Khattak, Shehryar and Ott, Lionel and Siegwart, Roland and Hutter, Marco and Cadena, Cesar},
  year = {2022},
  month = may,
  pages = {3662--3668},
  doi = {10.1109/ICRA46639.2022.9812102},
  abstract = {In this paper, we deal with the problem of creating globally consistent pose graphs in a centralized multi-robot SLAM framework. For each robot to act autonomously, individual onboard pose estimates and maps are maintained, which are then communicated to a central server to build an optimized global map. However, inconsistencies between onboard and server estimates can occur due to onboard odometry drift or failure. Furthermore, robots do not benefit from the collaborative map if the server provides no feedback in a computationally tractable and bandwidth-efficient manner. Motivated by this challenge, this paper proposes a novel collaborative mapping framework to enable accurate global mapping among robots and server. In particular, structural differences between robot and server graphs are exploited at different spatial scales using graph spectral analysis to generate necessary constraints for the individual robot pose graphs. The proposed approach is thoroughly analyzed and validated using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90\%.},
  keywords = {Automation,Collaboration,Computational efficiency,Industries,Robots,Servers,Simultaneous localization and mapping},
  file = {/Users/kshitijgoel/Zotero/storage/VJDBCF52/Bernreiter et al. - 2022 - Collaborative Robot Mapping using Spectral Graph A.pdf;/Users/kshitijgoel/Zotero/storage/9HYTCNNA/9812102.html}
}

@article{bernreiter_framework_2024,
  title = {A Framework for Collaborative Multi-Robot Mapping Using Spectral Graph Wavelets},
  author = {Bernreiter, Lukas and Khattak, Shehryar and Ott, Lionel and Siegwart, Roland and Hutter, Marco and Cadena, Cesar},
  year = {2024},
  month = nov,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {13},
  pages = {2070--2088},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241246847},
  url = {https://doi.org/10.1177/02783649241246847},
  urldate = {2025-04-16},
  abstract = {The exploration of large-scale unknown environments can benefit from the deployment of multiple robots for collaborative mapping. Each robot explores a section of the environment and communicates onboard pose estimates and maps to a central server to build an optimized global multi-robot map. Naturally, inconsistencies can arise between onboard and server estimates due to onboard odometry drift, failures, or degeneracies. The mapping server can correct and overcome such failure cases using computationally expensive operations such as inter-robot loop closure detection and multi-modal mapping. However, the individual robots do not benefit from the collaborative map if the mapping server provides no feedback. Although server updates from the multi-robot map can greatly alleviate the robotic mission strategically, most existing work lacks them, due to their associated computational and bandwidth-related costs. Motivated by this challenge, this paper proposes a novel collaborative mapping framework that enables global mapping consistency among robots and the mapping server. In particular, we propose graph spectral analysis, at different spatial scales, to detect structural differences between robot and server graphs, and to generate necessary constraints for the individual robot pose graphs. Our approach specifically finds the nodes that correspond to the drift's origin rather than the nodes where the error becomes too large. We thoroughly analyze and validate our proposed framework using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90\% and can recover the onboard estimation from localization failures and even from the degeneracies within its estimation.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FNAVRUKI/Bernreiter et al. - 2024 - A framework for collaborative multi-robot mapping using spectral graph wavelets.pdf}
}

@book{bernstein_applied_1988,
  title = {Applied {{Multivariate Analysis}}},
  author = {Bernstein, Ira H. and Garbin, Calvin P. and Teng, Gary K.},
  year = {1988},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4613-8740-4},
  url = {http://link.springer.com/10.1007/978-1-4613-8740-4},
  urldate = {2023-08-15},
  isbn = {978-1-4613-8742-8 978-1-4613-8740-4},
  langid = {english},
  keywords = {algebra,analysis of variance,ANOVA,calculus,correlation,data analysis,Factor analysis,Multiple Regression,Regression analysis,STATISTICA,Statistical Control,Variance},
  file = {/Users/kshitijgoel/Zotero/storage/XNWXD22C/Bernstein et al. - 1988 - Applied Multivariate Analysis.pdf}
}

@inproceedings{berscheid_jerklimited_2021,
  title = {Jerk-Limited {{Real-time Trajectory Generation}} with {{Arbitrary Target States}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVII}}},
  author = {Berscheid, Lars and Kroeger, Torsten},
  year = {2021},
  month = jul,
  volume = {17},
  url = {https://www.roboticsproceedings.org/rss17/p015.html},
  urldate = {2025-06-18},
  isbn = {978-0-9923747-7-8},
  file = {/Users/kshitijgoel/Zotero/storage/XRFRYVFY/Berscheid and Kroeger - 2021 - Jerk-limited Real-time Trajectory Generation with Arbitrary Target States.pdf}
}

@article{besl_invariant_1986,
  title = {Invariant Surface Characteristics for {{3D}} Object Recognition in Range Images},
  author = {Besl, Paul J. and Jain, Ramesh C.},
  year = {1986},
  month = jan,
  journal = {Computer Vision, Graphics, and Image Processing},
  volume = {33},
  number = {1},
  pages = {33--80},
  issn = {0734-189X},
  doi = {10.1016/0734-189X(86)90220-3},
  url = {https://www.sciencedirect.com/science/article/pii/0734189X86902203},
  urldate = {2024-07-08},
  abstract = {In recent years there has been a tremendous increase in computer vision research using range images (or depth maps) as sensor input data. The most attractive feature of range images is the explicitness of the surface information. Many industrial and navigational robotic tasks will be more easily accomplished if such explicit depth information can be efficiently obtained and interpreted. Intensity image understanding research has shown that the early processing of sensor data should be data-driven. The goal of early processing is to generate a rich description for later processing. Classical differential geometry provides a complete local description of smooth surfaces. The first and second fundamental forms of surfaces provide a set of differential-geometric shape descriptors that capture domain-independent surface information. Mean curvature and Gaussian curvature are the fundamental second-order surface characteristics that possess desirable invariance properties and represent extrinsic and intrinsic surface geometry respectively. The signs of these surface curvatures are used to classify range image regions into one of eight basic viewpoint-independent surface types. Experimental results for real and synthetic range images show the properties, usefulness, and importance of differential-geometric surface characteristics.},
  file = {/Users/kshitijgoel/Zotero/storage/LGXVDYI5/Besl and Jain - 1986 - Invariant surface characteristics for 3D object recognition in range images.pdf;/Users/kshitijgoel/Zotero/storage/EBILMYDB/0734189X86902203.html}
}

@article{besl_method_1992,
  title = {A Method for Registration of 3-{{D}} Shapes},
  author = {Besl, P.J. and McKay, Neil D.},
  year = {1992},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {14},
  number = {2},
  pages = {239--256},
  issn = {1939-3539},
  doi = {10.1109/34.121791},
  abstract = {The authors describe a general-purpose, representation-independent method for the accurate and computationally efficient registration of 3-D shapes including free-form curves and surfaces. The method handles the full six degrees of freedom and is based on the iterative closest point (ICP) algorithm, which requires only a procedure to find the closest point on a geometric entity to a given point. The ICP algorithm always converges monotonically to the nearest local minimum of a mean-square distance metric, and the rate of convergence is rapid during the first few iterations. Therefore, given an adequate set of initial rotations and translations for a particular class of objects with a certain level of 'shape complexity', one can globally minimize the mean-square distance metric over all six degrees of freedom by testing each initial registration. One important application of this method is to register sensed data from unfixtured rigid objects with an ideal geometric model, prior to shape inspection. Experimental results show the capabilities of the registration algorithm on point sets, curves, and surfaces.{$<>$}},
  keywords = {Convergence,Inspection,Iterative algorithms,Iterative closest point algorithm,Iterative methods,Motion estimation,Quaternions,Shape measurement,Solid modeling,Testing},
  file = {/Users/kshitijgoel/Zotero/storage/XHEUQMJX/Besl and McKay - 1992 - A method for registration of 3-D shapes.pdf;/Users/kshitijgoel/Zotero/storage/U6J5GWM2/121791.html}
}

@inproceedings{besselmann_vdbmapping_2021,
  title = {{{VDB-Mapping}}: {{A High Resolution}} and {{Real-Time Capable 3D Mapping Framework}} for {{Versatile Mobile Robots}}},
  shorttitle = {{{VDB-Mapping}}},
  booktitle = {2021 {{IEEE}} 17th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Besselmann, M. Grosse and Puck, L. and Steffen, L. and Roennau, A. and Dillmann, R.},
  year = {2021},
  month = aug,
  pages = {448--454},
  issn = {2161-8089},
  doi = {10.1109/CASE49439.2021.9551430},
  abstract = {Recent developments of versatile mobile robots demand a precise and complete volumetric representation of space for path and mission planning. However, the immense amount of accumulated raw data points from 3D sensors quickly becomes unmanageable, thereby becoming infeasible regarding memory footprint and navigation itself. To abstract the necessary information into a usable representation for navigation, usually volumetric grid maps are applied. Although these approaches solve the memory and handling issues, current implementations tend to require high computational time for the insertion of new data. As a result the generated maps are often not up to date and incomplete due to dropped sensor data. This greatly impairs their usefulness for navigating robot systems in dynamically changing environments. In order to solve these issues we propose a novel probabilistic mapping framework based on OpenVDB, which is a hierarchical tree structure with efficient access methods to discretized volumetric data. By utilizing the fast direct access to the bitmasks of the underlying OpenVDB data structure, a significant performance boost for data insertion is achieved. Thus, enabling real-time processing of the incoming raw 3D sensor data. An in-depth evaluation of the proposed framework is provided, including a performance and memory footprint comparison against the often employed OctoMap framework. The evaluation reveals, that the presented VDB-Mapping is able to efficiently process long range data on high resolution grids.},
  keywords = {Memory management,Navigation,Probabilistic logic,Real-time systems,Robot sensing systems,Space missions,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/ZZGKV2HJ/Besselmann et al. - 2021 - VDB-Mapping A High Resolution and Real-Time Capab.pdf;/Users/kshitijgoel/Zotero/storage/EIZVC56J/9551430.html}
}

@incollection{best_decentralised_2020,
  title = {Decentralised {{Monte Carlo Tree Search}} for {{Active Perception}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XII}}: {{Proceedings}} of the {{Twelfth Workshop}} on the {{Algorithmic Foundations}} of {{Robotics}}},
  author = {Best, Graeme and Cliff, Oliver M. and Patten, Timothy and Mettu, Ramgopal R. and Fitch, Robert},
  editor = {Goldberg, Ken and Abbeel, Pieter and Bekris, Kostas and Miller, Lauren},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {864--879},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-43089-4_55},
  url = {https://doi.org/10.1007/978-3-030-43089-4_55},
  urldate = {2023-02-17},
  abstract = {We propose a decentralised variant of Monte Carlo tree search (MCTS) that is suitable for a variety of tasks in multi-robot active perception. Our algorithm allows each robot to optimise its own individual action space by maintaining a probability distribution over plans in the joint-action space. Robots periodically communicate a compressed form of these search trees, which are used to update the locally-stored joint distributions using an optimisation approach inspired by variational methods. Our method admits any objective function defined over robot actions, assumes intermittent communication, and is anytime.We extend the analysis of the standard MCTS for our algorithm and characterise asymptotic convergence under reasonable assumptions. We evaluate the practical performance of our method for generalised team orienteering and active object recognition using real data, and show that it compares favourably to centralised MCTS even with severely degraded communication. These examples support the relevance of our algorithm for real-world active perception with multi-robot systems.},
  isbn = {978-3-030-43089-4},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YFBEW2RM/Best et al. - 2020 - Decentralised Monte Carlo Tree Search for Active P.pdf}
}

@article{best_decmcts_2019,
  title = {Dec-{{MCTS}}: {{Decentralized}} Planning for Multi-Robot Active Perception},
  shorttitle = {Dec-{{MCTS}}},
  author = {Best, Graeme and Cliff, Oliver M and Patten, Timothy and Mettu, Ramgopal R and Fitch, Robert},
  year = {2019},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {38},
  number = {2-3},
  pages = {316--337},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364918755924},
  url = {https://doi.org/10.1177/0278364918755924},
  urldate = {2023-04-11},
  abstract = {We propose a decentralized variant of Monte Carlo tree search (MCTS) that is suitable for a variety of tasks in multi-robot active perception. Our algorithm allows each robot to optimize its own actions by maintaining a probability distribution over plans in the joint-action space. Robots periodically communicate a compressed form of their search trees, which are used to update the joint distribution using a distributed optimization approach inspired by variational methods. Our method admits any objective function defined over robot action sequences, assumes intermittent communication, is anytime, and is suitable for online replanning. Our algorithm features a new MCTS tree expansion policy that is designed for our planning scenario. We extend the theoretical analysis of standard MCTS to provide guarantees for convergence rates to the optimal payoff sequence. We evaluate the performance of our method for generalized team orienteering and online active object recognition using real data, and show that it compares favorably to centralized MCTS even with severely degraded communication. These examples demonstrate the suitability of our algorithm for real-world active perception with multiple robots.},
  file = {/Users/kshitijgoel/Zotero/storage/4UITPSTW/Best et al. - 2019 - Dec-MCTS Decentralized planning for multi-robot a.pdf}
}

@article{best_multirobot_2023,
  title = {Multi-Robot, Multi-Sensor Exploration of Multifarious Environments with Full Mission Aerial Autonomy},
  author = {Best, Graeme and Garg, Rohit and Keller, John and Hollinger, Geoffrey A. and Scherer, Sebastian},
  year = {2023},
  month = oct,
  journal = {The International Journal of Robotics Research},
  pages = {02783649231203342},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231203342},
  url = {https://doi.org/10.1177/02783649231203342},
  urldate = {2023-11-07},
  abstract = {We present a coordinated autonomy pipeline for multi-sensor exploration of confined environments. We simultaneously address four broad challenges that are typically overlooked in prior work: (a) make effective use of both range and vision sensing modalities, (b) perform this exploration across a wide range of environments, (c) be resilient to adverse events, and (d) execute this onboard teams of physical robots. Our solution centers around a behavior tree architecture, which adaptively switches between various behaviors involving coordinated exploration and responding to adverse events. Our exploration strategy exploits the benefits of both visual and range sensors with a generalized frontier-based exploration algorithm and an OpenVDB-based map processing pipeline. Our local planner utilizes a dynamically feasible trajectory library and a GPU-based Euclidean distance transform map to allow fast and safe navigation through both tight doorways and expansive spaces. The autonomy pipeline is evaluated with an extensive set of field experiments, with teams of up to three robots that fly up to 3~m/s and distances exceeding 1~km in confined spaces. We provide a summary of various field experiments and detail resilient behaviors that arose: maneuvering narrow doorways, adapting to unexpected environment changes, and emergency landing. Experiments are also detailed from the DARPA Subterranean Challenge, where our proposed autonomy pipeline contributed to us winning the ``Most Sectors Explored'' award. We provide an extended discussion of lessons learned, release software as open source, and present a video that illustrates our extensive field trials.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CB82KLPH/Best et al. - 2023 - Multi-robot, multi-sensor exploration of multifari.pdf}
}

@inproceedings{best_resilient_2022,
  title = {Resilient {{Multi-Sensor Exploration}} of {{Multifarious Environments}} with a {{Team}} of {{Aerial Robots}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Best, Graeme and Garg, Rohit and Keller, John and Hollinger, Geoffrey A. and Scherer, Sebastian},
  year = {2022},
  month = jun,
  volume = {18},
  url = {http://www.roboticsproceedings.org/rss18/p004.html},
  urldate = {2022-05-28},
  isbn = {978-0-9923747-8-5},
  file = {/Users/kshitijgoel/Zotero/storage/5L9ZFG6C/Best et al. - 2022 - Resilient Multi-Sensor Exploration of Multifarious.pdf;/Users/kshitijgoel/Zotero/storage/25AX9RL3/p004.html}
}

@misc{bhat_zoedepth_2023,
  title = {{{ZoeDepth}}: {{Zero-shot Transfer}} by {{Combining Relative}} and {{Metric Depth}}},
  shorttitle = {{{ZoeDepth}}},
  author = {Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and M{\"u}ller, Matthias},
  year = {2023},
  month = feb,
  number = {arXiv:2302.12288},
  eprint = {2302.12288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.12288},
  url = {http://arxiv.org/abs/2302.12288},
  urldate = {2024-12-17},
  abstract = {This paper tackles the problem of depth estimation from a single image. Existing work either focuses on generalization performance disregarding metric scale, i.e. relative depth estimation, or state-of-the-art results on specific datasets, i.e. metric depth estimation. We propose the first approach that combines both worlds, leading to a model with excellent generalization performance while maintaining metric scale. Our flagship model, ZoeD-M12-NK, is pre-trained on 12 datasets using relative depth and fine-tuned on two datasets using metric depth. We use a lightweight head with a novel bin adjustment design called metric bins module for each domain. During inference, each input image is automatically routed to the appropriate head using a latent classifier. Our framework admits multiple configurations depending on the datasets used for relative depth pre-training and metric fine-tuning. Without pre-training, we can already significantly improve the state of the art (SOTA) on the NYU Depth v2 indoor dataset. Pre-training on twelve datasets and fine-tuning on the NYU Depth v2 indoor dataset, we can further improve SOTA for a total of 21\% in terms of relative absolute error (REL). Finally, ZoeD-M12-NK is the first model that can jointly train on multiple datasets (NYU Depth v2 and KITTI) without a significant drop in performance and achieve unprecedented zero-shot generalization performance to eight unseen datasets from both indoor and outdoor domains. The code and pre-trained models are publicly available at https://github.com/isl-org/ZoeDepth .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/4RMM4TZG/Bhat et al. - 2023 - ZoeDepth Zero-shot Transfer by Combining Relative and Metric Depth.pdf;/Users/kshitijgoel/Zotero/storage/QYXRV6EB/2302.html}
}

@inproceedings{bhattacharjee_online_2023,
  title = {Online K-Means {{Clustering}} on {{Arbitrary Data Streams}}},
  booktitle = {Proceedings of {{The}} 34th {{International Conference}} on {{Algorithmic Learning Theory}}},
  author = {Bhattacharjee, Robi and Imola, Jacob and Moshkovitz, Michal and Dasgupta, Sanjoy},
  year = {2023},
  month = feb,
  pages = {204--236},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v201/bhattacharjee23b.html},
  urldate = {2024-12-19},
  abstract = {We consider \$k\$-means clustering in an online setting where each new data point is assigned to its closest cluster center and incurs a loss equal to the squared distance to that center, after which the algorithm is allowed to update its centers. The goal over a data stream \$X\$ is to achieve a total loss that is not too much larger than \$L(X, OPT\_k)\$, the best possible loss using \$k\$ fixed centers in hindsight. We start by introducing a data parameter, \${\textbackslash}Lambda(X)\$, such that for any online algorithm that maintains \$O(k {\textbackslash}, {\textbackslash}text\{poly\}({\textbackslash}log n))\$ centers after seeing \$n\$ points, there exists a data stream \$X\$ for which a loss of \${\textbackslash}Omega({\textbackslash}Lambda(X))\$ is inevitable. Next, we give a randomized algorithm that achieves online loss \$O({\textbackslash}Lambda(X) + L(X, OPT\_k))\$, while taking \$O(k {\textbackslash}, {\textbackslash}text\{poly\}({\textbackslash}log n))\$ centers and additional memory. It has an update time of \$O(k {\textbackslash}, {\textbackslash}text\{poly\}({\textbackslash}log n))\$ and is the first algorithm to achieve polynomial space and time complexity in the online setting. We note that our results have implications to the related streaming setting, where one final clustering is outputted, and the no-substitution setting, where center selections are permanent. We show a general reduction between the no-substitution cost of a blackbox algorithm and its online cost. Finally, we translate our algorithm to the no-substitution setting and streaming settings, and it competes with and can outperform existing work in the areas.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/U8EH9ZQD/Bhattacharjee et al. - 2023 - Online k-means Clustering on Arbitrary Data Streams.pdf}
}

@article{bhattacharyya_measure_1946,
  title = {On a {{Measure}} of {{Divergence}} between {{Two Multinomial Populations}}},
  author = {Bhattacharyya, A.},
  year = {1946},
  journal = {Sankhy{\=a}: The Indian Journal of Statistics (1933-1960)},
  volume = {7},
  number = {4},
  eprint = {25047882},
  eprinttype = {jstor},
  pages = {401--406},
  publisher = {Springer},
  issn = {0036-4452},
  url = {https://www.jstor.org/stable/25047882},
  urldate = {2024-03-28},
  file = {/Users/kshitijgoel/Zotero/storage/MX27L9DI/Bhattacharyya - 1946 - On a Measure of Divergence between Two Multinomial.pdf}
}

@inproceedings{biber_normal_2003,
  title = {The Normal Distributions Transform: A New Approach to Laser Scan Matching},
  shorttitle = {The Normal Distributions Transform},
  booktitle = {Proceedings 2003 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}} 2003) ({{Cat}}. {{No}}.{{03CH37453}})},
  author = {Biber, P. and Strasser, W.},
  year = {2003},
  month = oct,
  volume = {3},
  pages = {2743-2748 vol.3},
  doi = {10.1109/IROS.2003.1249285},
  url = {https://ieeexplore.ieee.org/abstract/document/1249285},
  urldate = {2024-02-04},
  abstract = {Matching 2D range scans is a basic component of many localization and mapping algorithms. Most scan match algorithms require finding correspondences between the used features, i.e. points or lines. We propose an alternative representation for a range scan, the normal distributions transform. Similar to an occupancy grid, we subdivide the 2D plane into cells. To each cell, we assign a normal distribution, which locally models the probability of measuring a point. The result of the transform is a piecewise continuous and differentiable probability density, that can be used to match another scan using Newton's algorithm. Thereby, no explicit correspondences have to be established. We present the algorithm in detail and show the application to relative position tracking and simultaneous localization and map building (SLAM). First results on real data demonstrate, that the algorithm is capable to map unmodified indoor environments reliable and in real time, even without using odometry data.},
  keywords = {Discrete transforms,Gaussian distribution,Indoor environments,Iterative closest point algorithm,Laser noise,Mobile robots,Paints,Probability,Simultaneous localization and mapping,Working environment noise},
  file = {/Users/kshitijgoel/Zotero/storage/GMLAPD4S/Biber and Strasser - 2003 - The normal distributions transform a new approach.pdf;/Users/kshitijgoel/Zotero/storage/4ES3PVXT/1249285.html}
}

@article{biggie_flexible_2023,
  title = {Flexible {{Supervised Autonomy}} for {{Exploration}} in {{Subterranean Environments}}},
  author = {Biggie, Harel and Rush, Eugene and Riley, Danny and Ahmad, Shakeeb and Ohradzansky, Michael and Harlow, Kyle and Miles, Michael and Torres, Daniel and McGuire, Steve and Frew, Eric and Heckman, Christoffer and Humbert, James},
  year = {2023},
  month = jan,
  journal = {Field Robotics},
  volume = {3},
  number = {1},
  pages = {125--189},
  issn = {27713989},
  doi = {10.55417/fr.2023004},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_3_files/Vol3_04.pdf},
  urldate = {2023-03-23},
  abstract = {While the capabilities of autonomous systems have been steadily improving in recent years, these systems still struggle to rapidly explore previously unknown environments without the aid of GPS-assisted navigation. The DARPA Subterranean (SubT) Challenge aimed to fast track the development of autonomous exploration systems by evaluating their performance in realworld underground search-and-rescue scenarios. Subterranean environments present a plethora of challenges for robotic systems, such as limited communications, complex topology, visually-degraded sensing, and harsh terrain. The presented solution enables long-term autonomy with minimal human supervision by combining a powerful and independent single-agent autonomy stack, with higher level mission management operating over a flexible mesh network. The autonomy suite deployed on quadruped and wheeled robots was fully independent, freeing the human supervision to loosely supervise the mission, and make high-impact strategic decisions. We also discuss lessons learned from fielding our system at the SubT Final Event, relating to vehicle versatility, system adaptability, and reconfigurable communications.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9FS7EH44/Biggie et al. - 2023 - Flexible Supervised Autonomy for Exploration in Su.pdf}
}

@article{bingham_antipodally_1974,
  title = {An {{Antipodally Symmetric Distribution}} on the {{Sphere}}},
  author = {Bingham, Christopher},
  year = {1974},
  journal = {The Annals of Statistics},
  volume = {2},
  number = {6},
  eprint = {2958339},
  eprinttype = {jstor},
  pages = {1201--1225},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2958339},
  urldate = {2024-07-02},
  abstract = {The distribution \${\textbackslash}Psi({\textbackslash}mathbf\{x\}; Z, M) = {\textbackslash}operatorname\{const\}. {\textbackslash}exp({\textbackslash}mathrm\{tr\} (ZM{\textasciicircum}T {\textbackslash}mathbf\{xx\}{\textasciicircum}T M))\$ on the unit sphere in three-space is discussed. It is parametrized by the diagonal shape and concentration matrix Z and the orthogonal orientation matrix M. {$\Psi$} is applicable in the statistical analysis of measurements of random undirected axes. Exact and asymptotic sampling distributions are derived. Maximum likelihood estimators for Z and M are found and their asymptotic properties elucidated. Inference procedures, including tests for isotropy and circular symmetry, are proposed. The application of {$\Psi$} is illustrated by a numerical example.},
  file = {/Users/kshitijgoel/Zotero/storage/A88LM52H/Bingham - 1974 - An Antipodally Symmetric Distribution on the Sphere.pdf}
}

@phdthesis{bingham_distributions_1964,
  title = {Distributions on the {{Sphere}} and on the {{Projective Plane}}},
  author = {BINGHAM, {\relax CHRISTOPHER}},
  year = {1964},
  address = {United States -- Connecticut},
  url = {https://www.proquest.com/docview/287951312/abstract/E51C362FF96146B7PQ/1},
  urldate = {2024-11-01},
  abstract = {A probability distribution of directions in three dimensional space which gives equal probability to opposite directions can be considered either as an antipodally symmetric distribution on the sphere or as a distribution on the projective plane. A particularly simple such distribution, expressed as a distribution on the sphere, is where X trZM'xx M.e F(1/2;3/2;2) 11 is a unit vector, M is a 3x3 orthogonal matrix, Z- and (1/2;3/2;2) is a confluent hypergeometric function of matrix argument. Previous work on distributions of directions is summarized in Chapters I and II. A particular case of the above distribution with circular symmetry is discussed in Chapter III. Maximum likelihood estimates for the parameters and methods of inference based on the like-lihood function are discussed. Estimation and inference for the general case are in Chapter IV. A new test statistic for isotropy for distributions of undirected axes is proposed in Chapter V, where methods for finding its moments are given. Its asymptotic distribution is derived. The theory is illustrated in Chapter VI, where a set of measurements of crystal axes, divided into subsamples, is analyzed. The circularly symmetric distribution of Chapter III is applied to one subsample. Chapter VII presents formulae and methods of computation, both direct and asymptotic, for the hypergeometric functions of a single variable and of a matrix variable which are fundamental to the distribution. Preliminary tables and graphs of F (1/2;3/2;2) and (a/ac, log,F, (1/2;3/2;2), 2- are provided.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9781082670671},
  langid = {english},
  school = {Yale University},
  keywords = {Pure sciences,Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/2D82MUP2/BINGHAM - 1964 - Distributions on the Sphere and on the Projective Plane.pdf}
}

@article{bircher_receding_2018,
  title = {Receding Horizon Path Planning for {{3D}} Exploration and Surface Inspection},
  author = {Bircher, Andreas and Kamel, Mina and Alexis, Kostas and Oleynikova, Helen and Siegwart, Roland},
  year = {2018},
  month = feb,
  journal = {Autonomous Robots},
  volume = {42},
  number = {2},
  pages = {291--306},
  issn = {1573-7527},
  doi = {10.1007/s10514-016-9610-0},
  url = {https://doi.org/10.1007/s10514-016-9610-0},
  urldate = {2022-05-20},
  abstract = {Within this paper a new path planning algorithm for autonomous robotic exploration and inspection is presented. The proposed method plans online in a receding horizon fashion by sampling possible future configurations in a geometric random tree. The choice of the objective function enables the planning for either the exploration of unknown volume or inspection of a given surface manifold in both known and unknown volume. Application to rotorcraft Micro Aerial Vehicles is presented, although planning for other types of robotic platforms is possible, even in the absence of a boundary value solver and subject to nonholonomic constraints. Furthermore, the method allows the integration of a wide variety of sensor models. The presented analysis of computational complexity and thorough simulations-based evaluation indicate good scaling properties with respect to the scenario complexity. Feasibility and practical applicability are demonstrated in real-life experimental test cases with full on-board computation.},
  langid = {english},
  keywords = {Aerial robotics,Autonomous inspection,Exploration planning,Next-best-view},
  file = {/Users/kshitijgoel/Zotero/storage/HYGN26JT/Bircher et al. - 2018 - Receding horizon path planning for 3D exploration .pdf}
}

@book{bishop_deep_2024,
  title = {Deep {{Learning}}: {{Foundations}} and {{Concepts}}},
  shorttitle = {Deep {{Learning}}},
  author = {Bishop, Christopher M. and Bishop, Hugh},
  year = {2024},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-45468-4},
  url = {https://link.springer.com/10.1007/978-3-031-45468-4},
  urldate = {2023-12-12},
  isbn = {978-3-031-45467-7 978-3-031-45468-4},
  langid = {english},
  keywords = {Convolutional networks,Decision theory,Deep learning,Directed graphical models,machine learning,Neural networks},
  file = {/Users/kshitijgoel/Zotero/storage/HBEJ4837/Bishop and Bishop - 2024 - Deep Learning Foundations and Concepts.pdf}
}

@book{bishop_pattern_2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  address = {New York},
  url = {https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception},
  file = {/Users/kshitijgoel/Zotero/storage/4GFHH3CP/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@misc{black_$p_0$_2024,
  title = {\${$\pi\_$}0\$: {{A Vision-Language-Action Flow Model}} for {{General Robot Control}}},
  shorttitle = {\${$\pi\_$}0\$},
  author = {Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and Jakubczak, Szymon and Jones, Tim and Ke, Liyiming and Levine, Sergey and {Li-Bell}, Adrian and Mothukuri, Mohith and Nair, Suraj and Pertsch, Karl and Shi, Lucy Xiaoyang and Tanner, James and Vuong, Quan and Walling, Anna and Wang, Haohuan and Zhilinsky, Ury},
  year = {2024},
  month = nov,
  number = {arXiv:2410.24164},
  eprint = {2410.24164},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.24164},
  url = {http://arxiv.org/abs/2410.24164},
  urldate = {2025-05-24},
  abstract = {Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/S43NRE8E/Black et al. - 2024 - $π_0$ A Vision-Language-Action Flow Model for General Robot Control.pdf;/Users/kshitijgoel/Zotero/storage/ZD2HZAZI/2410.html}
}

@misc{blanco-claraco_flexible_2024,
  title = {A Flexible Framework for Accurate {{LiDAR}} Odometry, Map Manipulation, and Localization},
  author = {{Blanco-Claraco}, Jos{\'e} Luis},
  year = {2024},
  month = jul,
  number = {arXiv:2407.20465},
  eprint = {2407.20465},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.20465},
  urldate = {2024-08-01},
  abstract = {Light Detection and Ranging (LiDAR)-based simultaneous localization and mapping (SLAM) is a core technology for autonomous vehicles and robots. Despite the intense research activity in this field, each proposed system uses a particular sensor post-processing pipeline and a single map representation format. The present work aims at introducing a revolutionary point of view for 3D LiDAR SLAM and localization: (1) using view-based maps as the fundamental representation of maps (``simple-maps''), which can then be used to generate arbitrary metric maps optimized for particular tasks, e.g. obstacle avoidance, real-time localization; and (2) by introducing a new framework in which mapping pipelines can be defined without coding, defining the connections of a network of reusable blocks much like deep-learning networks are designed by connecting layers of standardized elements. Moreover, the idea of including the current linear and angular velocity vectors as variables to be optimized within the Iterative Closest Point (ICP) loop is also introduced, leading to superior robustness against aggressive motion profiles without an IMU. The presented open-source ecosystem, released to ROS 2 and whose core component is dubbed MOLA-LO (MOLA LiDAR odometry), includes tools and prebuilt pipelines covering all the way from data acquisition to map editing and visualization, real-time localization, loop-closure detection, or map georeferencing from consumer-grade Global Navigation Satellite System (GNSS) receivers. Extensive experimental validation reveals that the proposal compares well to, or improves, former state-of-the-art (SOTA) LiDAR odometry systems, while also successfully mapping some hard sequences where others diverge. A proposed self-adaptive configuration has been used, without parameter changes, for all 3D LiDAR datasets with sensors between 16 and 128 rings, and has been extensively tested on 83 sequences over more than 250 km of automotive, hand-held, airborne, and quadruped LiDAR datasets, both indoors and outdoors, with single or multiple simultaneous LiDAR scanners. Additional specialized pipelines are also provided for 2D LiDARs and for drones, as examples of the framework flexibility. The possibility of handling a larger variety of robotics datasets also becomes a valuable tool in itself, easing benchmarking SLAM and perception solutions. The open-sourced implementation is available online at https://github.com/MOLAorg/mola.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/QBEUNMCZ/Blanco-Claraco - 2024 - A flexible framework for accurate LiDAR odometry, map manipulation, and localization.pdf}
}

@inproceedings{blanco-claraco_modular_2019,
  title = {A {{Modular Optimization Framework}} for {{Localization}} and {{Mapping}}},
  booktitle = {Robotics: {{Science}} and {{Systems XV}}},
  author = {{Blanco-Claraco}, Jose Luis},
  year = {2019},
  month = jun,
  volume = {15},
  url = {http://www.roboticsproceedings.org/rss15/p43.html},
  urldate = {2023-03-14},
  isbn = {978-0-9923747-5-4},
  file = {/Users/kshitijgoel/Zotero/storage/8TXZFR5A/Blanco-Claraco - 2019 - A Modular Optimization Framework for Localization .pdf}
}

@inproceedings{blau_rethinking_2019,
  title = {Rethinking {{Lossy Compression}}: {{The Rate-Distortion-Perception Tradeoff}}},
  shorttitle = {Rethinking {{Lossy Compression}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Blau, Yochai and Michaeli, Tomer},
  year = {2019},
  month = may,
  pages = {675--685},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/blau19a.html},
  urldate = {2024-04-28},
  abstract = {Lossy compression algorithms are typically designed and analyzed through the lens of Shannon's rate-distortion theory, where the goal is to achieve the lowest possible distortion (e.g., low MSE or high SSIM) at any given bit rate. However, in recent years, it has become increasingly accepted that "low distortion" is not a synonym for "high perceptual quality", and in fact optimization of one often comes at the expense of the other. In light of this understanding, it is natural to seek for a generalization of rate-distortion theory which takes perceptual quality into account. In this paper, we adopt the mathematical definition of perceptual quality recently proposed by Blau \& Michaeli (2018), and use it to study the three-way tradeoff between rate, distortion, and perception. We show that restricting the perceptual quality to be high, generally leads to an elevation of the rate-distortion curve, thus necessitating a sacrifice in either rate or distortion. We prove several fundamental properties of this triple-tradeoff, calculate it in closed form for a Bernoulli source, and illustrate it visually on a toy MNIST example.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FSIUHEU8/Blau and Michaeli - 2019 - Rethinking Lossy Compression The Rate-Distortion-.pdf;/Users/kshitijgoel/Zotero/storage/SBFQMFWX/Blau and Michaeli - 2019 - Rethinking Lossy Compression The Rate-Distortion-.pdf}
}

@article{blei_variational_2006,
  title = {Variational Inference for {{Dirichlet}} Process Mixtures},
  author = {Blei, David M. and Jordan, Michael I.},
  year = {2006},
  month = mar,
  journal = {Bayesian Analysis},
  volume = {1},
  number = {1},
  pages = {121--143},
  publisher = {International Society for Bayesian Analysis},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/06-BA104},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-1/Variational-inference-for-Dirichlet-process-mixtures/10.1214/06-BA104.full},
  urldate = {2024-11-15},
  abstract = {Dirichlet process (DP) mixture models are the cornerstone of nonparametric Bayesian statistics, and the development of Monte-Carlo Markov chain (MCMC) sampling methods for DP mixtures has enabled the application of nonparametric Bayesian methods to a variety of practical data analysis problems. However, MCMC sampling can be prohibitively slow, and it is important to explore alternatives. One class of alternatives is provided by variational methods, a class of deterministic algorithms that convert inference problems into optimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far, variational methods have mainly been explored in the parametric setting, in particular within the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001; Blei et al. 2003). In this paper, we present a variational inference algorithm for DP mixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms for DP mixtures of Gaussians and present an application to a large-scale image analysis problem.},
  keywords = {Bayesian computation,Dirichlet processes,hierarchical models,image processing,variational inference},
  file = {/Users/kshitijgoel/Zotero/storage/WKQZABUS/Blei and Jordan - 2006 - Variational inference for Dirichlet process mixtures.pdf}
}

@misc{blondel_elements_2025,
  title = {The {{Elements}} of {{Differentiable Programming}}},
  author = {Blondel, Mathieu and Roulet, Vincent},
  year = {2025},
  month = jun,
  number = {arXiv:2403.14606},
  eprint = {2403.14606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.14606},
  url = {http://arxiv.org/abs/2403.14606},
  urldate = {2025-07-09},
  abstract = {Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Programming Languages},
  file = {/Users/kshitijgoel/Zotero/storage/YUWTACMI/Blondel and Roulet - 2025 - The Elements of Differentiable Programming.pdf;/Users/kshitijgoel/Zotero/storage/3LU2DR4Y/2403.html}
}

@inproceedings{blosch_vision_2010,
  title = {Vision Based {{MAV}} Navigation in Unknown and Unstructured Environments},
  booktitle = {2010 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Bl{\"o}sch, Michael and Weiss, Stephan and Scaramuzza, Davide and Siegwart, Roland},
  year = {2010},
  month = may,
  pages = {21--28},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2010.5509920},
  url = {https://ieeexplore.ieee.org/abstract/document/5509920},
  urldate = {2023-11-14},
  abstract = {Within the research on Micro Aerial Vehicles (MAVs), the field on flight control and autonomous mission execution is one of the most active. A crucial point is the localization of the vehicle, which is especially difficult in unknown, GPS-denied environments. This paper presents a novel vision based approach, where the vehicle is localized using a downward looking monocular camera. A state-of-the-art visual SLAM algorithm tracks the pose of the camera, while, simultaneously, building an incremental map of the surrounding region. Based on this pose estimation a LQG/LTR based controller stabilizes the vehicle at a desired setpoint, making simple maneuvers possible like take-off, hovering, setpoint following or landing. Experimental data show that this approach efficiently controls a helicopter while navigating through an unknown and unstructured environment. To the best of our knowledge, this is the first work describing a micro aerial vehicle able to navigate through an unexplored environment (independently of any external aid like GPS or artificial beacons), which uses a single camera as only exteroceptive sensor.},
  file = {/Users/kshitijgoel/Zotero/storage/WKZULV6P/Blösch et al. - 2010 - Vision based MAV navigation in unknown and unstruc.pdf;/Users/kshitijgoel/Zotero/storage/X3E4FSPS/5509920.html}
}

@article{bobrovsky_classes_1987,
  title = {Some {{Classes}} of {{Global Cramer-Rao Bounds}}},
  author = {Bobrovsky, B. Z. and {Mayer-Wolf}, E. and Zakai, M.},
  year = {1987},
  journal = {The Annals of Statistics},
  volume = {15},
  number = {4},
  eprint = {2241683},
  eprinttype = {jstor},
  pages = {1421--1438},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2241683},
  urldate = {2024-04-25},
  abstract = {This paper considers Cramer-Rao type bounds for the estimation error of a parameter in a Bayesian setup. This class of bounds, introduced by Van Trees, proved useful in various stochastic communications and control problems. Two issues are considered in this paper. The first deals with a comparison of the tightness of several different versions of the bound in the multivariate case. The second introduces several useful generalizations of the original version of the bound.},
  file = {/Users/kshitijgoel/Zotero/storage/URZSWZ6N/Bobrovsky et al. - 1987 - Some Classes of Global Cramer-Rao Bounds.pdf}
}

@inproceedings{boda_correlated_2019,
  title = {Correlated Bandits or: {{How}} to Minimize Mean-Squared Error Online},
  shorttitle = {Correlated Bandits Or},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Boda, Vinay Praneeth and L.a, Prashanth},
  year = {2019},
  month = may,
  pages = {686--694},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/boda19a.html},
  urldate = {2024-04-28},
  abstract = {While the objective in traditional multi-armed bandit problems is to find the arm with the highest mean, in many settings, finding an arm that best captures information about other arms is of interest. This objective, however, requires learning the underlying correlation structure and not just the means. Sensors placement for industrial surveillance and cellular network monitoring are a few applications, where the underlying correlation structure plays an important role. Motivated by such applications, we formulate the correlated bandit problem, where the objective is to find the arm with the lowest mean-squared error (MSE) in estimating all the arms. To this end, we derive first an MSE estimator based on sample variances/covariances and show that our estimator exponentially concentrates around the true MSE. Under a best-arm identification framework, we propose a successive rejects type algorithm and provide bounds on the probability of error in identifying the best arm. Using minimax theory, we also derive fundamental performance limits for the correlated bandit problem.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3C7RPT52/Boda and L.a - 2019 - Correlated bandits or How to minimize mean-square.pdf}
}

@article{boda_reconstructing_2019,
  title = {Reconstructing {{Gaussian Sources}} by {{Spatial Sampling}}},
  author = {Boda, Vinay Praneeth},
  year = {2019},
  month = aug,
  journal = {IEEE Transactions on Information Theory},
  volume = {65},
  number = {8},
  pages = {5064--5079},
  issn = {1557-9654},
  doi = {10.1109/TIT.2019.2903152},
  url = {https://ieeexplore.ieee.org/abstract/document/8660725},
  urldate = {2024-04-28},
  abstract = {Consider a Gaussian memoryless multiple source (GMMS) with m components with joint probability distribution known only to lie in a given class of distributions. A subset of k {$\leq$} m components is sampled and compressed with the objective of reconstructing all the m components within a specified level of distortion under a mean-squared error criterion. In Bayesian and nonBayesian settings, the notion of universal sampling rate-distortion function for Gaussian sources is introduced to capture the optimal tradeoffs among sampling, compression rate, and distortion level. Single-letter characterizations are provided for the universal sampling rate-distortion function. Our achievability proofs highlight the following structural property: it is optimal to compress and reconstruct first the sampled components of the GMMS alone, and then form estimates for the unsampled components based on the former.},
  keywords = {Acoustic distortion,Bayes methods,Covariance matrices,Fixed-set sampling,gaussian memoryless multiple source,Probability density function,Rate distortion theory,Rate-distortion,sampling rate distortion function,universal sampling rate distortion function},
  file = {/Users/kshitijgoel/Zotero/storage/A9QW57WT/Boda - 2019 - Reconstructing Gaussian Sources by Spatial Samplin.pdf}
}

@article{boda_universal_2018,
  title = {Universal {{Sampling Rate Distortion}}},
  author = {Boda, Vinay Praneeth and Narayan, Prakash},
  year = {2018},
  month = dec,
  journal = {IEEE Transactions on Information Theory},
  volume = {64},
  number = {12},
  pages = {7742--7758},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2018.2857829},
  url = {https://ieeexplore.ieee.org/document/8416756/},
  urldate = {2024-04-24},
  abstract = {We examine the coordinated and universal rateefficient sampling of a subset of correlated discrete memoryless sources followed by lossy compression of the sampled sources. The goal is to reconstruct a predesignated subset of sources within a specified level of distortion. The combined sampling mechanism and rate distortion code are universal in that they are devised to perform robustly without exact knowledge of the underlying joint probability distribution of the sources. In Bayesian as well as nonBayesian settings, single-letter characterizations are provided for the universal sampling rate distortion function for fixedset sampling, independent random sampling, and memoryless random sampling. It is illustrated how these sampling mechanisms are successively better. Our achievability proofs bring forth new schemes for joint source distribution-learning and lossy compression.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/V4SBEUUV/Boda and Narayan - 2018 - Universal Sampling Rate Distortion.pdf}
}

@inproceedings{bogoslavskyi_fast_2016,
  title = {Fast Range Image-Based Segmentation of Sparse {{3D}} Laser Scans for Online Operation},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Bogoslavskyi, Igor and Stachniss, Cyrill},
  year = {2016},
  month = oct,
  pages = {163--169},
  issn = {2153-0866},
  doi = {10.1109/IROS.2016.7759050},
  url = {https://ieeexplore.ieee.org/document/7759050/?arnumber=7759050},
  urldate = {2025-03-01},
  abstract = {Object segmentation from 3D range data is an important topic in mobile robotics. A robot navigating in a dynamic environment needs to be aware of objects that might change or move. A segmentation of the laser scans into individual objects is typically the first processing step before a further analysis is performed. In this paper, we present a fast method that segments 3D range data into different objects, runs online, and has small computational demands. Our approach avoids the explicit computation of the 3D point cloud and performs all computations directly on a 2D range image, which enables a fast segmentation for each scan. A further relevant aspect of our method is that we can segment objects even if the 3D data is sparse. This is important for scanners such as the new Velodyne Puck. We implemented our approach in C++ and ROS and thoroughly tested it using different 3D scanners. Our method can operate at over 100 Hz for the 64-beam Velodyne scanner on a single core of a mobile CPU while producing high quality segmentation results. In addition to this, we make the source code for the approach available.},
  keywords = {Automobiles,Image segmentation,Laser beams,Measurement by laser beam,Robots,Sensors,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/7WVMN4G9/Bogoslavskyi and Stachniss - 2016 - Fast range image-based segmentation of sparse 3D laser scans for online operation.pdf;/Users/kshitijgoel/Zotero/storage/KQ7RDIC9/7759050.html}
}

@inproceedings{bogoslavskyi_fast_2024,
  title = {Fast and {{Robust Normal Estimation}} for {{Sparse LiDAR Scans}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Bogoslavskyi, Igor and Zampogiannis, Konstantinos and Phan, Raymond},
  year = {2024},
  month = may,
  pages = {6389--6395},
  doi = {10.1109/ICRA57147.2024.10611556},
  url = {https://ieeexplore.ieee.org/document/10611556/?arnumber=10611556},
  urldate = {2025-03-01},
  abstract = {Light Detection and Ranging (LiDAR) technology has proven to be an important part of many robotics systems. Surface normals estimated from LiDAR data are commonly used for a variety of tasks in such systems. As most of the today's mechanical LiDAR sensors produce sparse data, estimating normals from a single scan in a robust manner poses difficulties.In this paper, we address the problem of estimating normals for sparse LiDAR data avoiding the typical issues of smoothing out the normals in high curvature areas.Mechanical LiDARs rotate a set of rigidly mounted lasers. One firing of such a set of lasers produces an array of points where each point's neighbor is known due to the known firing pattern of the scanner. We use this knowledge to connect these points to their neighbors and label them using the angles of the lines connecting them. When estimating normals at these points, we only consider points with the same label as neighbors. This allows us to avoid estimating normals in high curvature areas.We evaluate our approach on various data, both self-recorded and publicly available, acquired using various sparse LiDAR sensors. We show that using our method for normal estimation leads to normals that are more robust in areas with high curvature which leads to maps of higher quality. We also show that our method only incurs a constant factor runtime overhead with respect to a lightweight baseline normal estimation procedure and is therefore suited for operation in computationally demanding environments.},
  keywords = {Estimation,Firing,Laser radar,Lasers,Mechanical sensors,Runtime,Smoothing methods},
  file = {/Users/kshitijgoel/Zotero/storage/JJ5YDXZD/Bogoslavskyi et al. - 2024 - Fast and Robust Normal Estimation for Sparse LiDAR Scans.pdf;/Users/kshitijgoel/Zotero/storage/MMMJVCJK/10611556.html}
}

@article{bohm_novel_2021,
  title = {A {{Novel Hilbert Curve}} for {{Cache-Locality Preserving Loops}}},
  author = {Bohm, Christian and Perdacher, Martin and Plant, Claudia},
  year = {2021},
  month = jun,
  journal = {IEEE Transactions on Big Data},
  volume = {7},
  number = {2},
  pages = {241--254},
  issn = {2332-7790, 2372-2096},
  doi = {10.1109/TBDATA.2018.2830378},
  url = {https://ieeexplore.ieee.org/document/8354853/},
  urldate = {2024-07-17},
  abstract = {Modern microprocessors offer a rich memory hierarchy including various levels of cache and registers. Some of these memories (like main memory, L3 cache) are big but slow and shared among all cores. Others (registers, L1 cache) are fast and exclusively assigned to a single core but small. Only if the data accesses have a high locality, we can avoid excessive data transfers between the memory hierarchy. In this paper we consider fundamental algorithms like matrix multiplication, K-Means, Cholesky decomposition as well as the algorithm by Floyd and Warshall typically operating in two or three nested loops. We propose to traverse these loops whenever possible not in the canonical order but in an order defined by a space-filling curve. This traversal order dramatically improves data locality over a wide granularity allowing not only to efficiently support a cache of a single, known size (cache conscious) but also a hierarchy of various caches where the effective size available to our algorithms may even be unknown (cache oblivious). We propose a new space-filling curve called Fast Unrestricted (FUR) Hilbert with the following advantages: (1) we overcome the usual limitation to square-like grid sizes where the side-length is a power of 2 or 3. Instead, our approach allows arbitrary loop boundaries for all variables. (2) FUR-Hilbert is non-recursive with a guaranteed constant worst case time complexity per loop iteration (in contrast to O(log(gridsize)) for previous methods). (3) Our non-recursive approach makes the application of our cache-oblivious loops in any host algorithm as easy as conventional loops and facilitates automatic optimization by the compiler. (4) We demonstrate that crucial algorithms like Cholesky decomposition as well as the algorithm by Floyd and Warshall by can be efficiently supported. (5) Extensive experiments on runtime efficiency, cache usage and energy consumption demonstrate the profit of our approach. We believe that future compilers could translate nested loops into cache-oblivious loops either fully automatic or by a user-guided analysis of the data dependency.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AD7JU8TB/Bohm et al. - 2021 - A Novel Hilbert Curve for Cache-Locality Preserving Loops.pdf}
}

@techreport{bommasani_opportunities_2023,
  title = {On the {{Opportunities}} and {{Risks}} of {{Foundation Models}}},
  author = {Bommasani, Rishi and Hudson, Drew A and Altman, Ehsan Adeli Russ and Arora, Simran},
  year = {2023},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XFCVF4HF/Bommasani et al. - On the Opportunities and Risks of Foundation Model.pdf}
}

@article{booth_exact_1981,
  title = {Exact {{Monte Carlo}} Solution of Elliptic Partial Differential Equations},
  author = {Booth, Thomas E},
  year = {1981},
  month = feb,
  journal = {Journal of Computational Physics},
  volume = {39},
  number = {2},
  pages = {396--404},
  issn = {0021-9991},
  doi = {10.1016/0021-9991(81)90159-5},
  url = {https://www.sciencedirect.com/science/article/pii/0021999181901595},
  urldate = {2023-09-21},
  abstract = {A continuous random walk procedure is developed for solving some elliptic partial differential equations with constant coefficients. The Monte Carlo method described here is exact (except possibly at the boundary) in the sense that the only error involved is the inherent statistical sampling error, that tends to zero as the sample size increases.},
  file = {/Users/kshitijgoel/Zotero/storage/HRXIFHK5/Booth - 1981 - Exact Monte Carlo solution of elliptic partial dif.pdf}
}

@phdthesis{border_next_2019,
  type = {Thesis},
  title = {Next Best View Planning with an Unstructured Representation},
  author = {Border, Rowan},
  year = {2019},
  url = {https://robotic-esp.com/papers/border_dphil19},
  urldate = {2024-06-13},
  abstract = {High-quality observations of the real world are crucial for creating realistic scene imitations and performing structural analysis. Observations can be used to produce 3D printed replicas of small-scale scenes (e.g., a toy bunny), conduct inspections of large-scale infrastructure (e.g., a building) or integrated into virtual environments that provide immersive experiences for our entertainment and training robotic systems. Scenes are observed by obtaining point measurements using a sensor from multiple views. These views can be chosen by a human operator or planned using knowledge of existing measurements or an a priori scene model. The challenge of selecting the `next' view of a scene to obtain that will provide the `best' improvement in an observation is known as the Next Best View (NBV) planning problem. This thesis presents work on NBV planning with a novel unstructured scene representation. In contrast to existing literature on the problem, which typically uses structured representations, an unstructured representation does not impose an external structure on scene observations. There is no reduction in the fidelity of information represented or simplifying assumptions made about the scene structure. This unstructured representation is used to create the Surface Edge Explorer (SEE), a novel NBV planning approach. Observed points are classified based on the local measurement density. Views are chosen to improve the surface coverage of an observation until a minimum point density has been attained. Experiments comparing SEE with structured approaches demonstrate that it is able to obtain an equivalent observation quality using fewer views and a lower computation time. Novel point-based techniques for considering occlusions and scene visibility are investigated. This work overcomes the raycasting constraints of existing methods used by structured approaches. The best performing strategies for addressing each of these challenges are integrated with SEE to create SEE++. An experimental comparison of SEE++ with SEE and structured approaches demonstrates that it achieves significant improvements in observation performance by requiring fewer views and shorter travel distances while maintaining a reasonable computation time. Observations of real world scenes using SEE and SEE++ illustrate the successful transference of their capabilities from a simulation environment to the real world. Qualitative results show that both approaches are able to obtain highly complete observations of several scenes with varying size and structural complexity using multiple sensor modalities. Quantitative results demonstrate that SEE++ observes the scenes with greater efficiency than SEE by utilising an increased computational time.},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/kshitijgoel/Zotero/storage/N9P97YGQ/Border - 2019 - Next best view planning with an unstructured representation.pdf}
}

@article{border_osprey_2024,
  title = {Osprey: {{Multisession Autonomous Aerial Mapping With LiDAR-Based SLAM}} and {{Next Best View Planning}}},
  shorttitle = {Osprey},
  author = {Border, Rowan and Chebrolu, Nived and Tao, Yifu and Gammell, Jonathan D. and Fallon, Maurice},
  year = {2024},
  journal = {IEEE Transactions on Field Robotics},
  volume = {1},
  pages = {113--130},
  issn = {2997-1101},
  doi = {10.1109/TFR.2024.3432031},
  url = {https://ieeexplore.ieee.org/document/10608162/?arnumber=10608162},
  urldate = {2024-10-30},
  abstract = {Aerial mapping systems are important for many surveying applications (e.g., industrial inspection or agricultural monitoring). Aerial platforms that can fly GPS-guided preplanned missions semiautonomously are already widely available, but fully autonomous systems can significantly improve efficiency. Autonomously mapping complex 3-D structures requires a system that performs online mapping and mission planning. This article presents Osprey, an autonomous aerial mapping system with state-of-the-art multisession light detection and ranging (LiDAR)-based mapping capabilities. It enables a nonexpert operator to specify a bounded target area that the aerial platform can then map autonomously over multiple flights. Field experiments with Osprey demonstrate that this system can achieve greater map coverage of large industrial sites than manual surveys with a pilot-flown aerial platform or a terrestrial laser scanner (TLS). Three sites, with a total ground coverage of 2528 {\textbackslash}mathrm {\textbackslash}text m{\textasciicircum}2 and a maximum height of 27 m, were mapped in separate missions using 112 min of autonomous flight time. True-color maps were created from images captured by Osprey using pointcloud and neural radiance field (NeRF) reconstruction methods. These maps provide useful data for structural inspection tasks.},
  keywords = {Autonomous aerial vehicles,autonomous robots,Cameras,Laser radar,Motion measurement,Odometry,Payloads,Planning,robot sensing systems,simultaneous localization and mapping (SLAM),Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/ICKMFFXQ/Border et al. - 2024 - Osprey Multisession Autonomous Aerial Mapping With LiDAR-Based SLAM and Next Best View Planning.pdf;/Users/kshitijgoel/Zotero/storage/WCXEZGUZ/10608162.html}
}

@inproceedings{border_surface_2018,
  title = {Surface {{Edge Explorer}} (See): {{Planning Next Best Views Directly}} from {{3D Observations}}},
  shorttitle = {Surface {{Edge Explorer}} (See)},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Border, Rowan and Gammell, Jonathan D. and Newman, Paul},
  year = {2018},
  month = may,
  pages = {6116--6123},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8461098},
  url = {https://ieeexplore.ieee.org/abstract/document/8461098},
  urldate = {2024-08-07},
  abstract = {Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.},
  keywords = {Computational modeling,Density measurement,Geometry,Planning,Surface treatment,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/LDKGKMEG/Border et al. - 2018 - Surface Edge Explorer (see) Planning Next Best Views Directly from 3D Observations.pdf;/Users/kshitijgoel/Zotero/storage/363RLRNA/8461098.html}
}

@article{border_surface_2024,
  title = {The Surface Edge Explorer ({{SEE}}): {{A}} Measurement-Direct Approach to next Best View Planning},
  shorttitle = {The Surface Edge Explorer ({{SEE}})},
  author = {Border, Rowan and Gammell, Jonathan D.},
  year = {2024},
  month = feb,
  journal = {The International Journal of Robotics Research},
  pages = {02783649241230098},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241230098},
  url = {https://doi.org/10.1177/02783649241230098},
  urldate = {2024-06-10},
  abstract = {High-quality observations of the real world are crucial for a variety of applications, including producing 3D printed replicas of small-scale scenes and conducting inspections of large-scale infrastructure. These 3D observations are commonly obtained by combining multiple sensor measurements from different views. Guiding the selection of suitable views is known as the Next Best View (NBV) planning problem. Most NBV approaches reason about measurements using rigid data structures (e.g., surface meshes or voxel grids). This simplifies next best view selection but can be computationally expensive, reduces real-world fidelity and couples the selection of a next best view with the final data processing. This paper presents the Surface Edge Explorer (SEE), a NBV approach that selects new observations directly from previous sensor measurements without requiring rigid data structures. SEE uses measurement density to propose next best views that increase coverage of insufficiently observed surfaces while avoiding potential occlusions. Statistical results from simulated experiments show that SEE can attain similar or better surface coverage with less observation time and travel distance than evaluated volumetric approaches on both small- and large-scale scenes. Real-world experiments demonstrate SEE autonomously observing a deer statue using a 3D sensor affixed to a robotic arm.},
  file = {/Users/kshitijgoel/Zotero/storage/N6L4WHYB/Border and Gammell - 2024 - The surface edge explorer (SEE) A measurement-direct approach to next best view planning.pdf}
}

@inproceedings{bourgault_information_2002,
  title = {Information Based Adaptive Robotic Exploration},
  booktitle = {{{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{System}}},
  author = {Bourgault, F. and Makarenko, A.A. and Williams, S.B. and Grocholsky, B. and {Durrant-Whyte}, H.F.},
  year = {2002},
  volume = {1},
  pages = {540--545},
  publisher = {IEEE},
  address = {Lausanne, Switzerland},
  doi = {10.1109/IRDS.2002.1041446},
  url = {http://ieeexplore.ieee.org/document/1041446/},
  urldate = {2023-10-28},
  abstract = {Explomtion involving mapping and concumnt localization in an unknown environment is a peruasive task in mobile robotics. In general, the accuracy of the mapping process depends directly on the accuracy of the localization process. This paper address the pmblem of m\&mizing the accuracy of the map building process during exploration by adaptively selecting control actions that mm'mize localisation accuracy. The map building and exploration task is modeled using an Occupancy Grid (OG) with concurrent localisation performed using a featurn-based Simultaneous Localisation And Mapping (SLAM) algorithm . Adaptive sensing aims at maximizing the map information b y simultaneously maximizing the q e c t e d Shannon infonation gain (Mutual Infomation) on the OG map and minimizing the uncertainty of the vehicle pose and map featum uncertainty in the SLAM process. The resulting map building system is demonstrated in an indoor environment wing data from a laser scanner mounted on a mobile platfonn.},
  isbn = {978-0-7803-7398-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/EGKAT4ED/Bourgault et al. - 2002 - Information based adaptive robotic exploration.pdf}
}

@misc{bousias_symmetriesenhanced_2025,
  title = {Symmetries-Enhanced {{Multi-Agent Reinforcement Learning}}},
  author = {Bousias, Nikolaos and Pertigkiozoglou, Stefanos and Daniilidis, Kostas and Pappas, George},
  year = {2025},
  month = apr,
  number = {arXiv:2501.01136},
  eprint = {2501.01136},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.01136},
  url = {http://arxiv.org/abs/2501.01136},
  urldate = {2025-08-12},
  abstract = {Multi-agent reinforcement learning has emerged as a powerful framework for enabling agents to learn complex, coordinated behaviors but faces persistent challenges regarding its generalization, scalability and sample efficiency. Recent advancements have sought to alleviate those issues by embedding intrinsic symmetries of the systems in the policy. Yet, most dynamical systems exhibit little to no symmetries to exploit. This paper presents a novel framework for embedding extrinsic symmetries in multi-agent system dynamics that enables the use of symmetry-enhanced methods to address systems with insufficient intrinsic symmetries, expanding the scope of equivariant learning to a wide variety of MARL problems. Central to our framework is the Group Equivariant Graphormer, a group-modular architecture specifically designed for distributed swarming tasks. Extensive experiments on a swarm of symmetry-breaking quadrotors validate the effectiveness of our approach, showcasing its potential for improved generalization and zero-shot scalability. Our method achieves significant reductions in collision rates and enhances task success rates across a diverse range of scenarios and varying swarm sizes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Multiagent Systems,Computer Science - Robotics,Mathematics - Representation Theory},
  file = {/Users/kshitijgoel/Zotero/storage/DVNXJ8ZE/Bousias et al. - 2025 - Symmetries-enhanced Multi-Agent Reinforcement Learning.pdf;/Users/kshitijgoel/Zotero/storage/H55I47B7/2501.html}
}

@article{box_note_1958,
  title = {A {{Note}} on the {{Generation}} of {{Random Normal Deviates}}},
  author = {Box, G. E. P. and Muller, Mervin E.},
  year = {1958},
  month = jun,
  journal = {The Annals of Mathematical Statistics},
  volume = {29},
  number = {2},
  pages = {610--611},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177706645},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-29/issue-2/A-Note-on-the-Generation-of-Random-Normal-Deviates/10.1214/aoms/1177706645.full},
  urldate = {2024-04-23},
  abstract = {The Annals of Mathematical Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/76TF68P7/Box and Muller - 1958 - A Note on the Generation of Random Normal Deviates.pdf}
}

@article{boyles_convergence_1983,
  title = {On the {{Convergence}} of the {{EM Algorithm}}},
  author = {Boyles, Russell A.},
  year = {1983},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {45},
  number = {1},
  eprint = {2345622},
  eprinttype = {jstor},
  pages = {47--50},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {0035-9246},
  url = {https://www.jstor.org/stable/2345622},
  urldate = {2023-02-18},
  abstract = {An example is given showing that a sequence generated by a GEM algorithm need not converge under the conditions stated in Dempster et al., (1977). Two general convergence results are presented which suggest that in practice a GEM sequence will converge to a compact connected set of local maxima of the likelihood function; this limit set may or may not consist of a single point.},
  file = {/Users/kshitijgoel/Zotero/storage/AHQ6EKZG/Boyles - 1983 - On the Convergence of the EM Algorithm.pdf}
}

@inproceedings{breitfeld_developing_2024,
  title = {Developing {{Local Trajectory Planning}} for a {{Lunar Micro Rover}}},
  booktitle = {2024 {{IEEE Aerospace Conference}}},
  author = {Breitfeld, Abigail and Wettergreen, David},
  year = {2024},
  month = mar,
  pages = {1--16},
  issn = {1095-323X},
  doi = {10.1109/AERO58975.2024.10521335},
  url = {https://ieeexplore.ieee.org/document/10521335/?arnumber=10521335},
  urldate = {2025-03-14},
  abstract = {The MoonRanger micro-rover will explore the South Pole of the Moon in search of water ice. Its small size, and therefore limited power and communication capabilities, necessitates autonomous navigation rather than teleoperation. MoonRanger's size and limited computing also introduce unique challenges to designing robust methods of navigation. This work describes the trajectory planning algorithms and architecture that will allow MoonRanger to operate safely and efficiently on the surface of the Moon. We verify that these methods meet mission requirements through tests in simulation and with a surrogate rover, and show that the rover effectively avoids dangers while making progress towards specified goals.},
  keywords = {Autonomous robots,Computer architecture,Ice,Moon,Navigation,South Pole,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/UBAQJVFL/Breitfeld and Wettergreen - 2024 - Developing Local Trajectory Planning for a Lunar Micro Rover.pdf;/Users/kshitijgoel/Zotero/storage/4DRU9ZJR/10521335.html}
}

@inproceedings{brianlee_upper_2021,
  title = {An {{Upper Confidence Bound}} for {{Simultaneous Exploration}} and {{Exploitation}} in {{Heterogeneous Multi-Robot Systems}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Brian Lee, Ki Myung and Kong, Felix and Cannizzaro, Ricardo and Palmer, Jennifer L. and Johnson, David and Yoo, Chanyeol and Fitch, Robert},
  year = {2021},
  month = may,
  pages = {8685--8691},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9560822},
  abstract = {Heterogeneous multi-robot systems are advantageous for operations in unknown environments because functionally specialised robots can gather environmental information, while others perform tasks. We de ne this decomposition as the scout--task robot architecture and show how it avoids the need to explicitly balance exploration and exploitation by permitting the system to do both simultaneously. The challenge is to guide exploration in a way that improves overall performance for time-limited tasks. We derive a novel upper confidence bound for simultaneous exploration and exploitation based on mutual information and present a general solution for scout--task coordination using decentralised Monte Carlo tree search. We evaluate the performance of our algorithms in a multi-drone surveillance scenario in which scout robots are equipped with low-resolution, long-range sensors and task robots capture detailed information using short-range sensors. The results address a new class of coordination problem for heterogeneous teams that has many practical applications.},
  keywords = {Automation,Conferences,Monte Carlo methods,Robot kinematics,Robot sensing systems,Sensors,Surveillance},
  file = {/Users/kshitijgoel/Zotero/storage/V6MZWGZN/Brian Lee et al. - 2021 - An Upper Confidence Bound for Simultaneous Explora.pdf;/Users/kshitijgoel/Zotero/storage/QQASDFPJ/9560822.html}
}

@inproceedings{brilli_monocular_2023,
  title = {Monocular {{Reactive Collision Avoidance}} for {{MAV Teleoperation}} with {{Deep Reinforcement Learning}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Brilli, Raffaele and Legittimo, Marco and Crocetti, Francesco and Leomanni, Mirko and Fravolini, Mario Luca and Costante, Gabriele},
  year = {2023},
  month = may,
  pages = {12535--12541},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160427},
  url = {https://ieeexplore.ieee.org/document/10160427/},
  urldate = {2023-09-27},
  abstract = {Enabling Micro Aerial Vehicles (MAVs) with semiautonomous capabilities to assist their teleoperation is crucial in several applications. Remote human operators do not have, in general, the situational awareness to perceive obstacles near the drone, nor the readiness to provide commands to avoid collisions. In this work, we devise a novel teleoperation setting that asks the operator to provide a simple high-level signal encoding the speed and the direction they expect the drone to follow. We then endow the MAV with an end-to-end Deep Reinforcement Learning (DRL) model that computes control commands to track the desired trajectory while performing collision avoidance. Differently from State-of-the-Art (SotA) works, it allows the robot to move freely in the 3D space, requires only the current RGB image captured by a monocular camera and the current robot position, and does not make any assumption about obstacle shape and size. We show the effectiveness and the generalization capabilities of our strategy by comparing it against a SotA baseline in photorealistic simulated environments.},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5IRG9S7F/Brilli et al. - 2023 - Monocular Reactive Collision Avoidance for MAV Tel.pdf}
}

@article{brink_unscented_2018,
  title = {Unscented {{Partial-Update Schmidt}}--{{Kalman Filter}}},
  author = {Brink, Kevin M.},
  year = {2018},
  journal = {Journal of Guidance, Control, and Dynamics},
  volume = {41},
  number = {4},
  pages = {929--935},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0731-5090},
  doi = {10.2514/1.G003225},
  url = {https://doi.org/10.2514/1.G003225},
  urldate = {2025-03-26},
  file = {/Users/kshitijgoel/Zotero/storage/Y35H7KEH/Brink - 2018 - Unscented Partial-Update Schmidt–Kalman Filter.pdf;/Users/kshitijgoel/Zotero/storage/76MJ4RCY/1.html}
}

@article{browne_survey_2012,
  title = {A {{Survey}} of {{Monte Carlo Tree Search Methods}}},
  author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  year = {2012},
  month = mar,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  volume = {4},
  number = {1},
  pages = {1--43},
  issn = {1943-0698},
  doi = {10.1109/TCIAIG.2012.2186810},
  url = {https://ieeexplore.ieee.org/document/6145622},
  urldate = {2024-11-15},
  abstract = {Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
  keywords = {Artificial intelligence,Artificial intelligence (AI),bandit-based methods,computer Go,Computers,Decision theory,game search,Game theory,Games,Markov processes,Monte Carlo methods,Monte Carlo tree search (MCTS),upper confidence bounds (UCB),upper confidence bounds for trees (UCT)},
  file = {/Users/kshitijgoel/Zotero/storage/U93BXV3G/Browne et al. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf;/Users/kshitijgoel/Zotero/storage/MJ5RKYE6/6145622.html}
}

@article{brugali_mobile_2025,
  title = {Mobile Robots Exploration Strategies and Requirements: {{A}} Systematic Mapping Study},
  shorttitle = {Mobile Robots Exploration Strategies and Requirements},
  author = {Brugali, Davide and Muratore, Luca and De Luca, Alessio},
  year = {2025},
  month = feb,
  journal = {The International Journal of Robotics Research},
  pages = {02783649241313471},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241313471},
  url = {https://doi.org/10.1177/02783649241313471},
  urldate = {2025-03-18},
  abstract = {A variety of autonomous exploration tasks have been successfully performed in several types of environments using different types of robotic platforms. The robotic task, the operational environment, and the robot embodiment represent the dimensions of the ``problem space'' in robot exploration. At the same time, a lot of exploration strategies are documented in the literature that provide partial solutions to the exploration problem. They define the ``solution space'' in robot exploration. To our knowledge, no previous work has provided a methodical overview of robot exploration strategies from the point of view of both the problem and solution spaces. In this systematic mapping study, we build a taxonomy of autonomous robot exploration strategies and application requirements and classify existing approaches according to it. The goal is to analyze research trends over time, and identify possible research gaps, open challenges, and promising future directions in order to support researchers and practitioners in generalizing, communicating, and applying the findings of the robot exploration knowledge field.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LX825V4K/Brugali et al. - 2025 - Mobile robots exploration strategies and requirements A systematic mapping study.pdf}
}

@inproceedings{brunel_splatplanner_2021,
  title = {{{SplatPlanner}}: {{Efficient Autonomous Exploration}} via {{Permutohedral Frontier Filtering}}},
  shorttitle = {{{SplatPlanner}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Brunel, Anthony and Bourki, Amine and Demonceaux, Cedric and Strauss, Olivier},
  year = {2021},
  month = may,
  pages = {608--615},
  publisher = {IEEE},
  address = {Xi'an, China},
  doi = {10.1109/ICRA48506.2021.9560896},
  url = {https://ieeexplore.ieee.org/document/9560896/},
  urldate = {2024-04-28},
  abstract = {We address the problem of autonomous exploration of unknown environments using a Micro Aerial Vehicle (MAV) equipped with an active depth sensor. As such, the task consists in mapping the gradually discovered environment while planning the envisioned trajectories in real-time, using on-board computation only. To do so, we present SplatPlanner, an end-to-end autonomous planner that is based on a novel Permutohedral Frontier Filtering (PFF) which relies on a combination of highly efficient operations stemming from bilateral filtering using permutohedral lattices to guide the entire exploration. In particular, our PFF is computationally linear in input size, nearly parameter-free, and aggregates spatial information about frontier-neighborhoods into density scores in one single step. Comparative experiments made on simulated environments of increasing complexity show our method consistently outperforms recent state-of-theart methods in terms of computational efficiency, exploration speed and qualitative coverage of scenes. Finally, we also display the practical capabilities of our end-to-end system in a challenging real-flight scenario.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-7281-9077-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/29EZCEBX/Brunel et al. - 2021 - SplatPlanner Efficient Autonomous Exploration via.pdf}
}

@article{bry_aggressive_2015,
  title = {Aggressive Flight of Fixed-Wing and Quadrotor Aircraft in Dense Indoor Environments},
  author = {Bry, Adam and Richter, Charles and Bachrach, Abraham and Roy, Nicholas},
  year = {2015},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {34},
  number = {7},
  pages = {969--1002},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364914558129},
  url = {https://doi.org/10.1177/0278364914558129},
  urldate = {2023-02-17},
  abstract = {In this paper, we describe trajectory planning and state estimation algorithms for aggressive flight of micro aerial vehicles in known, obstacle-dense environments. Finding aggressive but dynamically feasible and collision-free trajectories in cluttered environments requires trajectory optimization and state estimation in the full state space of the vehicle, which is usually computationally infeasible on realistic timescales for real vehicles and sensors. We first build on previous work of van Nieuwstadt and Murray and Mellinger and Kumar, to show how a search process can be coupled with optimization in the output space of a differentially flat vehicle model to find aggressive trajectories that utilize the full maneuvering capabilities of a quadrotor. We further extend this work to vehicles with complex, Dubins-type dynamics and present a novel trajectory representation called a ?Dubins?Polynomial trajectory?, which allows us to optimize trajectories for fixed-wing vehicles. To provide accurate state estimation for aggressive flight, we show how the Gaussian particle filter can be extended to allow laser rangefinder localization to be combined with a Kalman filter. This formulation allows similar estimation accuracy to particle filtering in the full vehicle state but with an order of magnitude more efficiency. We conclude with experiments demonstrating the execution of quadrotor and fixed-wing trajectories in cluttered environments. We show results of aggressive flight at speeds of up to 8?m/s for the quadrotor and 11?m/s for the fixed-wing aircraft.},
  file = {/Users/kshitijgoel/Zotero/storage/8NHAFATY/Bry et al. - 2015 - Aggressive flight of fixed-wing and quadrotor airc.pdf}
}

@inproceedings{bry_rapidlyexploring_2011,
  title = {Rapidly-Exploring {{Random Belief Trees}} for Motion Planning under Uncertainty},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Bry, Adam and Roy, Nicholas},
  year = {2011},
  month = may,
  pages = {723--730},
  publisher = {IEEE},
  address = {Shanghai, China},
  doi = {10.1109/ICRA.2011.5980508},
  url = {http://ieeexplore.ieee.org/document/5980508/},
  urldate = {2024-01-24},
  abstract = {In this paper we address the problem of motion planning in the presence of state uncertainty, also known as planning in belief space. The work is motivated by planning domains involving nontrivial dynamics, spatially varying measurement properties, and obstacle constraints. To make the problem tractable, we restrict the motion plan to a nominal trajectory stabilized with a linear estimator and controller. This allows us to predict distributions over future states given a candidate nominal trajectory. Using these distributions to ensure a bounded probability of collision, the algorithm incrementally constructs a graph of trajectories through state space, while efficiently searching over candidate paths through the graph at each iteration. This process results in a search tree in belief space that provably converges to the optimal path. We analyze the algorithm theoretically and also provide simulation results demonstrating its utility for balancing information gathering to reduce uncertainty and finding low cost paths.},
  isbn = {978-1-61284-386-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8VU8DAVP/Bry and Roy - 2011 - Rapidly-exploring Random Belief Trees for motion p.pdf}
}

@book{bryant_computer_2016,
  title = {Computer Systems: A Programmer's Perspective},
  shorttitle = {Computer Systems},
  author = {Bryant, Randal E. and O'Hallaron, David R.},
  year = {2016},
  edition = {Third edition},
  publisher = {Pearson},
  address = {Boston},
  isbn = {978-0-13-409266-9},
  langid = {english},
  lccn = {QA76.5 .B795 2016},
  keywords = {Computer systems,Computers,Telecommunication,User interfaces (Computer systems)},
  file = {/Users/kshitijgoel/Zotero/storage/ADLM6B93/Bryant and O'Hallaron - 2016 - Computer systems a programmer's perspective.pdf}
}

@inproceedings{budden_gaussian_2020,
  title = {Gaussian {{Gated Linear Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Budden, David and Marblestone, Adam and Sezener, Eren and Lattimore, Tor and Wayne, Gregory and Veness, Joel},
  year = {2020},
  volume = {33},
  pages = {16508--16519},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/c0356641f421b381e475776b602a5da8-Abstract.html},
  urldate = {2024-06-06},
  abstract = {We propose the Gaussian Gated Linear Network (G-GLN), an extension to the recently proposed GLN family of deep neural networks. Instead of using backpropagation to learn features, GLNs have a distributed and local credit assignment mechanism based on optimizing a convex objective. This gives rise to many desirable properties including universality, data-efficient online learning, trivial interpretability and robustness to catastrophic forgetting. We extend the GLN framework from classification to multiple regression and density modelling by generalizing geometric mixing to a product of Gaussian densities. The G-GLN achieves competitive or state-of-the-art performance on several univariate and multivariate regression benchmarks, and we demonstrate its applicability to practical tasks including online contextual bandits and density estimation via denoising.},
  file = {/Users/kshitijgoel/Zotero/storage/94URUQ33/Budden et al. - 2020 - Gaussian Gated Linear Networks.pdf}
}

@article{bujack_nonriemannian_2022,
  title = {The Non-{{Riemannian}} Nature of Perceptual Color Space},
  author = {Bujack, Roxana and Teti, Emily and Miller, Jonah and Caffrey, Elektra and Turton, Terece L.},
  year = {2022},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {18},
  pages = {e2119753119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2119753119},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2119753119},
  urldate = {2024-07-02},
  abstract = {The scientific community generally agrees on the theory, introduced by Riemann and furthered by Helmholtz and Schr{\"o}dinger, that perceived color space is not Euclidean but rather, a three-dimensional Riemannian space. We show that the principle of diminishing returns applies to human color perception. This means that large color differences cannot be derived by adding a series of small steps, and therefore, perceptual color space cannot be described by a Riemannian geometry. This finding is inconsistent with the current approaches to modeling perceptual color space. Therefore, the assumed shape of color space requires a paradigm shift. Consequences of this apply to color metrics that are currently used in image and video processing, color mapping, and the paint and textile industries. These metrics are valid only for small differences. Rethinking them outside of a Riemannian setting could provide a path to extending them to large differences. This finding further hints at the existence of a second-order Weber--Fechner law describing perceived differences.},
  file = {/Users/kshitijgoel/Zotero/storage/LGXJIRQP/Bujack et al. - 2022 - The non-Riemannian nature of perceptual color space.pdf}
}

@article{bukal_composite_2014,
  title = {Composite Distance Based Approach to von {{Mises}} Mixture Reduction},
  author = {Bukal, Mario and Markovi{\'c}, Ivan and Petrovi{\'c}, Ivan},
  year = {2014},
  month = nov,
  journal = {Information Fusion},
  volume = {20},
  pages = {136--145},
  issn = {15662535},
  doi = {10.1016/j.inffus.2014.01.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253514000086},
  urldate = {2024-07-14},
  abstract = {This paper presents a systematic approach for component number reduction in mixtures of exponential families, putting a special emphasis on the von Mises mixtures. We propose to formulate the problem as an optimization problem utilizing a new class of computationally tractable composite distance measures as cost functions, namely the composite R{\'e}nyi a-divergences, which include the composite Kullback--Leibler distance as a special case. Furthermore, we prove that the composite divergence bounds from above the corresponding intractable R{\'e}nyi a-divergence between a pair of mixtures. As a solution to the optimization problem we synthesize that two existing suboptimal solution strategies, the generalized k-means and a pairwise merging approach, are actually minimization methods for the composite distance measures. Moreover, in the present paper the existing joining algorithm is also extended for comparison purposes. The algorithms are implemented and their reduction results are compared and discussed on two examples of von Mises mixtures: a synthetic mixture and a real-world mixture used in people trajectory shape analysis.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/RCSJV62Y/Bukal et al. - 2014 - Composite distance based approach to von Mises mixture reduction.pdf}
}

@inproceedings{burgard_collaborative_2000,
  title = {Collaborative Multi-Robot Exploration},
  booktitle = {Proceedings 2000 {{ICRA}}. {{Millennium Conference}}. {{IEEE International Conference}} on {{Robotics}} and {{Automation}}. {{Symposia Proceedings}} ({{Cat}}. {{No}}.{{00CH37065}})},
  author = {Burgard, W. and Moors, M. and Fox, D. and Simmons, R. and Thrun, S.},
  year = {2000},
  month = apr,
  volume = {1},
  pages = {476-481 vol.1},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2000.844100},
  url = {https://ieeexplore.ieee.org/document/844100?arnumber=844100},
  abstract = {In this paper we consider the problem of exploring an unknown environment by a team of robots. As in single-robot exploration the goal is to minimize the overall exploration time. The key problem to be solved therefore is to choose appropriate target points for the individual robots so that they simultaneously explore different regions of their environment. We present a probabilistic approach for the coordination of multiple robots which, in contrast to previous approaches, simultaneously takes into account the costs of reaching a target point and the utility of target points. The utility of target points is given by the size of the unexplored area that a robot can cover with its sensors upon reaching a target position. Whenever a target point is assigned to a specific robot, the utility of the unexplored area visible from this target position is reduced for the other robots. This way, a team of multiple robots assigns different target points to the individual robots. The technique has been implemented and tested extensively in real-world experiments and simulation runs. The results given in this paper demonstrate that our coordination technique significantly reduces the exploration time compared to previous approaches.},
  keywords = {Collaboration,Computer science,Costs,Mobile robots,Multirobot systems,Redundancy,Robot kinematics,Robot sensing systems,Testing,Traveling salesman problems},
  file = {/Users/kshitijgoel/Zotero/storage/SDC4538X/Burgard et al. - 2000 - Collaborative multi-robot exploration.pdf;/Users/kshitijgoel/Zotero/storage/6EJNG9BS/844100.html}
}

@article{burgard_coordinated_2005,
  title = {Coordinated Multi-Robot Exploration},
  author = {Burgard, W. and Moors, M. and Stachniss, C. and Schneider, F.E.},
  year = {2005},
  month = jun,
  journal = {IEEE Transactions on Robotics},
  volume = {21},
  number = {3},
  pages = {376--386},
  issn = {1552-3098},
  doi = {10.1109/TRO.2004.839232},
  url = {http://ieeexplore.ieee.org/document/1435481/},
  urldate = {2023-11-01},
  abstract = {In this paper, we consider the problem of exploring an unknown environment with a team of robots. As in single-robot exploration the goal is to minimize the overall exploration time. The key problem to be solved in the context of multiple robots is to choose appropriate target points for the individual robots so that they simultaneously explore different regions of the environment. We present an approach for the coordination of multiple robots, which simultaneously takes into account the cost of reaching a target point and its utility. Whenever a target point is assigned to a specific robot, the utility of the unexplored area visible from this target position is reduced. In this way, different target locations are assigned to the individual robots. We furthermore describe how our algorithm can be extended to situations in which the communication range of the robots is limited. Our technique has been implemented and tested extensively in real-world experiments and simulation runs. The results demonstrate that our technique effectively distributes the robots over the environment and allows them to quickly accomplish their mission.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZHAJ3AHR/Burgard et al. - 2005 - Coordinated multi-robot exploration.pdf}
}

@book{burke_applied_1985,
  title = {Applied {{Differential Geometry}}},
  author = {Burke, William L.},
  year = {1985},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781139171786},
  url = {https://www.cambridge.org/core/books/applied-differential-geometry/842A9E5B501DA7A3EB8EF2E14A799157},
  urldate = {2024-07-23},
  abstract = {This is a self-contained introductory textbook on the calculus of differential forms and modern differential geometry. The intended audience is physicists, so the author emphasises applications and geometrical reasoning in order to give results and concepts a precise but intuitive meaning without getting bogged down in analysis. The large number of diagrams helps elucidate the fundamental ideas. Mathematical topics covered include differentiable manifolds, differential forms and twisted forms, the Hodge star operator, exterior differential systems and symplectic geometry. All of the mathematics is motivated and illustrated by useful physical examples.},
  isbn = {978-0-521-26929-2},
  file = {/Users/kshitijgoel/Zotero/storage/7GXZXARR/842A9E5B501DA7A3EB8EF2E14A799157.html}
}

@inproceedings{burri_realtime_2015,
  title = {Real-Time Visual-Inertial Mapping, Re-Localization and Planning Onboard {{MAVs}} in Unknown Environments},
  booktitle = {2015 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Burri, Michael and Oleynikova, Helen and Achtelik, Markus W. and Siegwart, Roland},
  year = {2015},
  month = sep,
  pages = {1872--1878},
  doi = {10.1109/IROS.2015.7353622},
  abstract = {In this work, we present an MAV system that is able to relocalize itself, create consistent maps and plan paths in full 3D in previously unknown environments. This is solely based on vision and IMU measurements with all components running onboard and in real-time. We use visual-inertial odometry to keep the MAV airborne safely locally, as well as for exploration of the environment based on high-level input by an operator. A globally consistent map is constructed in the background, which is then used to correct for drift of the visual odometry algorithm. This map serves as an input to our proposed global planner, which finds dynamic 3D paths to any previously visited place in the map, without the use of teach and repeat algorithms. In contrast to previous work, all components are executed onboard and in real-time without any prior knowledge of the environment.},
  keywords = {Buildings,Cameras,Helicopters,Inspection,Planning,Real-time systems,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/SBKYJLQI/Burri et al. - 2015 - Real-time visual-inertial mapping, re-localization.pdf;/Users/kshitijgoel/Zotero/storage/R8TIT87X/7353622.html}
}

@article{burt_laplacian_1983,
  title = {The {{Laplacian Pyramid}} as a {{Compact Image Code}}},
  author = {Burt, P. and Adelson, E.},
  year = {1983},
  month = apr,
  journal = {IEEE Transactions on Communications},
  volume = {31},
  number = {4},
  pages = {532--540},
  issn = {1558-0857},
  doi = {10.1109/TCOM.1983.1095851},
  url = {https://ieeexplore.ieee.org/document/1095851},
  urldate = {2024-04-28},
  abstract = {We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding.},
  keywords = {Data compression,Data structures,Entropy,Frequency,Image coding,Image sampling,Laplace equations,Low pass filters,Pixel,Shape},
  file = {/Users/kshitijgoel/Zotero/storage/XTZ4DEY3/Burt and Adelson - 1983 - The Laplacian Pyramid as a Compact Image Code.pdf;/Users/kshitijgoel/Zotero/storage/Y8S2V9NF/1095851.html}
}

@inproceedings{bylow_realtime_2013,
  title = {Real-{{Time Camera Tracking}} and {{3D Reconstruction Using Signed Distance Functions}}},
  booktitle = {Robotics: {{Science}} and {{Systems IX}}},
  author = {Bylow, Erik and Sturm, J{\"u}rgen and Kerl, Christian and Kahl, Fredrik and Cremers, Daniel},
  year = {2013},
  month = jun,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2013.IX.035},
  url = {http://www.roboticsproceedings.org/rss09/p35.pdf},
  urldate = {2022-02-06},
  isbn = {978-981-07-3937-9},
  file = {/Users/kshitijgoel/Zotero/storage/4RZUHRP6/Bylow et al. - 2013 - Real-Time Camera Tracking and 3D Reconstruction Us.pdf}
}

@inproceedings{c_speeding_2024,
  title = {Speeding up {{NAS}} with {{Adaptive Subset Selection}}},
  booktitle = {Proceedings of the {{Third International Conference}} on {{Automated Machine Learning}}},
  author = {C, Vishak Prasad and White, Colin and Nayak, Sibasis and Jain, Paarth and Shameem, Aziz and Garg, Prateek and Ramakrishnan, Ganesh},
  year = {2024},
  month = oct,
  pages = {3/1-23},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v256/c24a.html},
  urldate = {2025-02-27},
  abstract = {A majority of recent developments in neural architecture search (NAS) have been aimed at decreasing the computational cost of various techniques without affecting their final performance. Towards this goal, several low-fidelity and performance prediction methods have been considered, including those that train only on subsets of the training data. In this work, we present an adaptive subset selection approach to NAS and present it as complementary to state-of-the-art NAS approaches. We uncover a natural connection between one-shot NAS algorithms and adaptive subset selection and devise an algorithm that makes use of state-of-the-art techniques from both areas. We use these techniques to substantially reduce the runtime of DARTS-PT (a leading one-shot NAS algorithm), as well as BOHB and DEHB (leading multi-fidelity optimization algorithms), with minimal sacrifice to accuracy. In experiments, we find architectures on CIFAR-10 that give 5\% increase in performance over DARTS-PT while reducing the time required by more than 8 times. Our results are consistent across multiple datasets, and towards full reproducibility, we release all our code at {\textbackslash}url\{https://anonymous.4open.science/r/SubsetSelection\_NAS-87B3\}.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XTQ9HQCN/C et al. - 2024 - Speeding up NAS with Adaptive Subset Selection.pdf}
}

@article{cadena_present_2016,
  title = {Past, {{Present}}, and {{Future}} of {{Simultaneous Localization}} and {{Mapping}}: {{Toward}} the {{Robust-Perception Age}}},
  shorttitle = {Past, {{Present}}, and {{Future}} of {{Simultaneous Localization}} and {{Mapping}}},
  author = {Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and Scaramuzza, Davide and Neira, Jos{\'e} and Reid, Ian and Leonard, John J.},
  year = {2016},
  month = dec,
  journal = {IEEE Transactions on Robotics},
  volume = {32},
  number = {6},
  pages = {1309--1332},
  issn = {1941-0468},
  doi = {10.1109/TRO.2016.2624754},
  abstract = {Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?},
  keywords = {Factor graphs,Graph theory,localization,Localization,mapping,maximum a posteriori estimation,perception,robots,Robustness,sensing,Service robots,simultaneous localization and mapping (SLAM),Simultaneous location and mapping},
  file = {/Users/kshitijgoel/Zotero/storage/6V3LQXEC/Cadena et al. - 2016 - Past, Present, and Future of Simultaneous Localiza.pdf;/Users/kshitijgoel/Zotero/storage/R7FNQNJX/stamp.html}
}

@article{cai_chime_2019,
  title = {Chime: {{Clustering}} of {{High-Dimensional Gaussian Mixtures}} with {{Em Algorithm}} and {{Its Optimality}}},
  shorttitle = {Chime},
  author = {Cai, T. Tony and Ma, Jing and Zhang, Linjun},
  year = {2019},
  journal = {The Annals of Statistics},
  volume = {47},
  number = {3},
  eprint = {26730422},
  eprinttype = {jstor},
  pages = {1234--1267},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/26730422},
  urldate = {2024-07-11},
  abstract = {Unsupervised learning is an important problem in statistics and machine learning with a wide range of applications. In this paper, we study clustering of high-dimensional Gaussian mixtures and propose a procedure, called CHIME, that is based on the EM algorithm and a direct estimation method for the sparse discriminant vector. Both theoretical and numerical properties of CHIME are investigated. We establish the optimal rate of convergence for the excess misclustering error and show that CHIME is minimax rate optimal. In addition, the optimality of the proposed estimator of the discriminant vector is also established. Simulation studies show that CHIME outperforms the existing methods under a variety of settings. The proposed CHIME procedure is also illustrated in an analysis of a glioblastoma gene expression data set and shown to have superior performance. Clustering of Gaussian mixtures in the conventional low-dimensional setting is also considered. The technical tools developed for the high-dimensional setting are used to establish the optimality of the clustering procedure that is based on the classical EM algorithm.},
  file = {/Users/kshitijgoel/Zotero/storage/VTWSA7RK/Cai et al. - 2019 - Chime Clustering of High-Dimensional Gaussian Mixtures with Em Algorithm and Its Optimality.pdf}
}

@article{cai_energyaware_2023,
  title = {Energy-{{Aware}}, {{Collision-Free Information Gathering}} for {{Heterogeneous Robot Teams}}},
  author = {Cai, Xiaoyi and Schlotfeldt, Brent and Khosoussi, Kasra and Atanasov, Nikolay and Pappas, George J. and How, Jonathan P.},
  year = {2023},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {4},
  pages = {2585--2602},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3257512},
  abstract = {This article considers the problem of safely coordinating a team of sensor-equipped robots to reduce uncertainty about a dynamical process, where the objective tradeoffs information gain and energy cost. Optimizing this tradeoff is desirable, but leads to a nonmonotone objective function in the set of robot trajectories. Therefore, common multirobot planners based on coordinate descent lose their performance guarantees. Furthermore, methods that handle nonmonotonicity lose their performance guarantees when subject to interrobot collision avoidance constraints. As it is desirable to retain both the performance guarantee and safety guarantee, this work proposes a hierarchical approach with a distributed planner that uses local search with a worst-case performance guarantees and a decentralized controller based on control barrier functions that ensures safety and encourages timely arrival at sensing locations. Via extensive simulations, hardware-in-the-loop tests, and hardware experiments, we demonstrate that the proposed approach achieves a better tradeoff between sensing and energy cost than coordinate-descent-based algorithms.},
  keywords = {Collision avoidance,multirobot systems,reactive sensor-based mobile planning,Robot kinematics,Robot sensing systems,Robots,Safety,Sensors,target tracking,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/9WN5LLI3/Cai et al. - 2023 - Energy-Aware, Collision-Free Information Gathering.pdf;/Users/kshitijgoel/Zotero/storage/ELCMBZZL/10089205.html}
}

@article{cai_estimation_2024,
  title = {Estimation and Inference for Minimizer and Minimum of Convex Functions: {{Optimality}}, Adaptivity and Uncertainty Principles},
  shorttitle = {Estimation and Inference for Minimizer and Minimum of Convex Functions},
  author = {Cai, T. Tony and Chen, Ran and Zhu, Yuancheng},
  year = {2024},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {52},
  number = {1},
  pages = {392--411},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/24-AOS2355},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-1/Estimation-and-inference-for-minimizer-and-minimum-of-convex-functions/10.1214/24-AOS2355.full},
  urldate = {2024-05-09},
  abstract = {Optimal estimation and inference for both the minimizer and minimum of a convex regression function under the white noise and nonparametric regression models are studied in a nonasymptotic local minimax framework, where the performance of a procedure is evaluated at individual functions. Fully adaptive and computationally efficient algorithms are proposed and sharp minimax lower bounds are given for both the estimation accuracy and expected length of confidence intervals for the minimizer and minimum. The nonasymptotic local minimax framework brings out new phenomena in simultaneous estimation and inference for the minimizer and minimum. We establish a novel uncertainty principle that provides a fundamental limit on how well the minimizer and minimum can be estimated simultaneously for any convex regression function. A similar result holds for the expected length of the confidence intervals for the minimizer and minimum.},
  keywords = {62G08,62G20,62G99,Adaptivity,Confidence interval,Minimax optimality,modulus of continuity,Nonparametric regression,uncertainty principle,White noise model},
  file = {/Users/kshitijgoel/Zotero/storage/5LXI6RHK/Cai et al. - 2024 - Estimation and inference for minimizer and minimum of convex functions Optimality, adaptivity and u.pdf}
}

@inproceedings{cai_finite_2021,
  title = {Finite Mixture Models Do Not Reliably Learn the Number of Components},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Cai, Diana and Campbell, Trevor and Broderick, Tamara},
  year = {2021},
  month = jul,
  pages = {1158--1169},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/cai21a.html},
  urldate = {2024-03-01},
  abstract = {Scientists and engineers are often interested in learning the number of subpopulations (or components) present in a data set. A common suggestion is to use a finite mixture model (FMM) with a prior on the number of components. Past work has shown the resulting FMM component-count posterior is consistent; that is, the posterior concentrates on the true, generating number of components. But consistency requires the assumption that the component likelihoods are perfectly specified, which is unrealistic in practice. In this paper, we add rigor to data-analysis folk wisdom by proving that under even the slightest model misspecification, the FMM component-count posterior diverges: the posterior probability of any particular finite number of components converges to 0 in the limit of infinite data. Contrary to intuition, posterior-density consistency is not sufficient to establish this result. We develop novel sufficient conditions that are more realistic and easily checkable than those common in the asymptotics literature. We illustrate practical consequences of our theory on simulated and real data.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/F6ES6VPH/Cai et al. - 2021 - Finite mixture models do not reliably learn the nu.pdf;/Users/kshitijgoel/Zotero/storage/WR2TM8GQ/Cai et al. - 2021 - Finite mixture models do not reliably learn the nu.pdf}
}

@article{cai_occupancy_2024,
  title = {Occupancy {{Grid Mapping Without Ray-Casting}} for {{High-Resolution LiDAR Sensors}}},
  author = {Cai, Yixi and Kong, Fanze and Ren, Yunfan and Zhu, Fangcheng and Lin, Jiarong and Zhang, Fu},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {172--192},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3323936},
  url = {https://ieeexplore.ieee.org/document/10286126},
  urldate = {2024-05-07},
  abstract = {Occupancy mapping is a fundamental component of robotic systems to reason about the unknown and known regions of the environment. This article presents an efficient occupancy mapping framework for high-resolution light detection and ranging (LiDAR) sensors, termed D-Map. The framework introduces three main novelties to address the computational efficiency challenges of occupancy mapping. First, we use a depth image to determine the occupancy state of regions instead of the traditional ray-casting method. Second, we introduce an efficient on-tree update strategy on a tree-based map structure. These two techniques avoid redundant visits to small cells, significantly reducing the number of cells to be updated. Third, we remove known cells from the map at each update by leveraging the low false alarm rate of LiDAR sensors. This approach not only enhances our framework's update efficiency by reducing map size but also endows it with an interesting decremental property, which we have named D-Map. To support our design, we provide theoretical analyzes of the accuracy of the depth image projection and time complexity of occupancy updates. Furthermore, we conduct extensive benchmark experiments on various LiDAR sensors in both public and private datasets. Our framework demonstrates superior efficiency in comparison with other state-of-the-art methods while maintaining comparable mapping accuracy and high memory efficiency. We demonstrate two real-world applications of D-Map for real-time occupancy mapping on a handheld device and an aerial platform carrying a high-resolution LiDAR.},
  keywords = {Computational efficiency,Image resolution,Laser radar,Light detection and ranging (LiDAR) Perception,Memory management,occupancy mapping,Octrees,range sensing,Robot sensing systems,Sensors},
  file = {/Users/kshitijgoel/Zotero/storage/T8DUA8QJ/Cai et al. - 2024 - Occupancy Grid Mapping Without Ray-Casting for High-Resolution LiDAR Sensors.pdf}
}

@article{calders_3d_2020,
  title = {{{3D Imaging Insights}} into {{Forests}} and {{Coral Reefs}}},
  author = {Calders, Kim and Phinn, Stuart and Ferrari, Renata and Leon, Javier and Armston, John and Asner, Gregory P. and Disney, Mathias},
  year = {2020},
  month = jan,
  journal = {Trends in Ecology \& Evolution},
  volume = {35},
  number = {1},
  pages = {6--9},
  issn = {0169-5347},
  doi = {10.1016/j.tree.2019.10.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0169534719302836},
  urldate = {2024-11-27},
  abstract = {Forests and coral reefs are structurally complex ecosystems threatened by climate change. In situ 3D imaging measurements provide unprecedented, quantitative, and detailed structural information that allows testing of hypotheses relating form to function. This affords new insights into both individual organisms and their relationship to their surroundings and neighbours.},
  file = {/Users/kshitijgoel/Zotero/storage/JCJPVZTC/Calders et al. - 2020 - 3D Imaging Insights into Forests and Coral Reefs.pdf;/Users/kshitijgoel/Zotero/storage/UNT6UCWE/S0169534719302836.html}
}

@article{calinon_gaussians_2020,
  title = {Gaussians on {{Riemannian Manifolds}}: {{Applications}} for {{Robot Learning}} and {{Adaptive Control}}},
  shorttitle = {Gaussians on {{Riemannian Manifolds}}},
  author = {Calinon, Sylvain},
  year = {2020},
  month = jun,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {27},
  number = {2},
  pages = {33--45},
  issn = {1558-223X},
  doi = {10.1109/MRA.2020.2980548},
  url = {https://ieeexplore.ieee.org/abstract/document/9057576},
  urldate = {2025-06-12},
  abstract = {This article presents an overview of robot learning and adaptive control applications that can benefit from a joint use of Riemannian geometry and probabilistic representations. The roles of Riemannian manifolds, geodesics, and parallel transport in robotics are discussed, and several forms of manifolds already employed in robotics are explained. A varied range of techniques employing Gaussian distributions on Riemannian manifolds is then introduced, and two example applications are presented, involving the control of a prosthetic hand from surface electromyography (sEMG) data and the teleoperation of a bimanual underwater robot.},
  keywords = {Adaptive control,Covariance matrices,Geometry,Manifolds,Robot learning,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/KUVYYW3B/Calinon - 2020 - Gaussians on Riemannian Manifolds Applications for Robot Learning and Adaptive Control.pdf}
}

@article{calinon_learning_2007,
  title = {On {{Learning}}, {{Representing}}, and {{Generalizing}} a {{Task}} in a {{Humanoid Robot}}},
  author = {Calinon, Sylvain and Guenter, Florent and Billard, Aude},
  year = {2007},
  month = apr,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume = {37},
  number = {2},
  pages = {286--298},
  issn = {1941-0492},
  doi = {10.1109/TSMCB.2006.886952},
  abstract = {We present a programming-by-demonstration framework for generically extracting the relevant features of a given task and for addressing the problem of generalizing the acquired knowledge to different contexts. We validate the architecture through a series of experiments, in which a human demonstrator teaches a humanoid robot simple manipulatory tasks. A probability-based estimation of the relevance is suggested by first projecting the motion data onto a generic latent space using principal component analysis. The resulting signals are encoded using a mixture of Gaussian/Bernoulli distributions (Gaussian mixture model/Bernoulli mixture model). This provides a measure of the spatio-temporal correlations across the different modalities collected from the robot, which can be used to determine a metric of the imitation performance. The trajectories are then generalized using Gaussian mixture regression. Finally, we analytically compute the trajectory which optimizes the imitation metric and use this to generalize the skill to different contexts},
  keywords = {Encoding,Feature extraction,Gaussian mixture model (GMM),h uman-robot interaction (HRI),human motion subspace,Humanoid robots,Humans,learning by imitation,metric of imitation,Motion analysis,Motion estimation,Optimal control,Orbital robotics,Principal component analysis,programming by demonstration (PbD),Robot programming},
  file = {/Users/kshitijgoel/Zotero/storage/W3ZL3TEJ/Calinon et al. - 2007 - On Learning, Representing, and Generalizing a Task.pdf;/Users/kshitijgoel/Zotero/storage/QLJJZ86A/4126276.html}
}

@inproceedings{campos_fast_2019,
  title = {Fast and {{Robust Initialization}} for {{Visual-Inertial SLAM}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Campos, Carlos and Montiel, Jos{\'e} M.M. and Tard{\'o}s, Juan D.},
  year = {2019},
  month = may,
  pages = {1288--1294},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8793718},
  url = {https://ieeexplore.ieee.org/document/8793718/?arnumber=8793718},
  urldate = {2024-12-17},
  abstract = {Visual-inertial SLAM (VI-SLAM) requires a good initial estimation of the initial velocity, orientation with respect to gravity and gyroscope and accelerometer biases. In this paper we build on the initialization method proposed by Martinelli [1] and extended by Kaiser et al. [2], modifying it to be more general and efficient. We improve accuracy with several rounds of visual-inertial bundle adjustment, and robustify the method with novel observability and consensus tests, that discard erroneous solutions. Our results on the EuRoC dataset show that, while the original method produces scale errors up to 156\%, our method is able to consistently initialize in less than two seconds with scale errors around 5\%, which can be further reduced to less than 1\% performing visual-inertial bundle adjustment after ten seconds.},
  keywords = {Accelerometers,Cameras,Feature extraction,Gravity,Jacobian matrices,Observability,Simultaneous localization and mapping},
  file = {/Users/kshitijgoel/Zotero/storage/SYB7D8QN/Campos et al. - 2019 - Fast and Robust Initialization for Visual-Inertial SLAM.pdf;/Users/kshitijgoel/Zotero/storage/UYAZQJVD/8793718.html}
}

@article{candela_approach_2022,
  title = {An {{Approach}} to {{Science}} and {{Risk-Aware Planetary Rover Exploration}}},
  author = {Candela, Alberto and Wettergreen, David},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {9691--9698},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3191949},
  abstract = {This work grapples with the challenge of directing autonomous decision making by planetary rovers conducting science investigations. Most of the related work addresses obstacle avoidance and traversabilty, while less work seeks to directly improve science yield. This research develops a comprehensive approach for planetary rovers that accounts for both science investigation and mobility risk. We present a probabilistic framework that quantifies these two attributes of rover exploration and generates paths that constrain risk while increasing science return. Specifically, science productivity is measured and improved using formal principles from information theory and statistical learning for decision making. Risk is estimated using a probabilistic model that predicts rover wheel slippage based on geometric and semantic information. Our method is evaluated in a simulation study using real Mars surface data that is relevant for both science and terrain investigations. Experimental analysis verifies the effectiveness of our approach.},
  keywords = {Extraterrestrial measurements,Geology,Mars,Minerals,Motion and path planning,Planning,Probabilistic logic,probability and statistical methods,space robotics and automation,Space vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/T4JAQ35A/Candela and Wettergreen - 2022 - An Approach to Science and Risk-Aware Planetary Ro.pdf}
}

@inproceedings{canovas_coarse_2019,
  title = {A {{Coarse}} and {{Relevant 3D Representation}} for {{Fast}} and {{Lightweight RGB-D Mapping}}},
  booktitle = {International {{Conference}} on {{Computer Vision Theory}} and {{Applications}} - {{VISAPP}} 2018},
  author = {Canovas, Bruce and Rombaut, Mich{\`e}le and N{\`e}gre, Amaury and Olympieff, Serge and Pellerin, Denis},
  year = {2019},
  month = feb,
  series = {International {{Conference}} on {{Computer Vision Theory}} and {{Applications}} - {{VISAPP}} 2018},
  address = {Prague, Czech Republic},
  url = {https://hal.science/hal-02068740},
  urldate = {2025-02-07},
  abstract = {In this paper we present a novel lightweight and simple 3D representation for real-time dense 3D mapping of static environments with an RGB-D camera. Our approach builds and updates a low resolution 3D model of an observed scene as an unordered set of new primitives called supersurfels, which can be seen as elliptical planar patches, generated from superpixels segmented RGB-D live measurements. While most of the actual solutions focuse on the accuracy of the reconstructed 3D model, the implemented method is well-adapted to run on robots with reduced/limited computing capacity and memory size, which do not need a highly detailed map of their environment but can settle for an approximate one.},
  keywords = {Dense Reconstruction,Fusion,RGB-D,Robotics,Superpixel,Surfel},
  file = {/Users/kshitijgoel/Zotero/storage/NHLRJJ44/Canovas et al. - 2019 - A Coarse and Relevant 3D Representation for Fast and Lightweight RGB-D Mapping.pdf}
}

@inproceedings{cao_autonomous_2022,
  title = {Autonomous {{Exploration Development Environment}} and the {{Planning Algorithms}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Cao, Chao and Zhu, Hongbiao and Yang, Fan and Xia, Yukun and Choset, Howie and Oh, Jean and Zhang, Ji},
  year = {2022},
  month = may,
  pages = {8921--8928},
  doi = {10.1109/ICRA46639.2022.9812330},
  abstract = {Autonomous Exploration Development Environment is an open-source repository released to facilitate development of high-level planning algorithms and integration of com-plete autonomous navigation systems. The repository contains representative simulation environment models, fundamental navigation modules, e.g., local planner, terrain traversability analysis, waypoint following, and visualization tools. Together with two of our high-level planner releases - TARE planner for exploration and FAR planner for route planning, we detail usage of the three open-source repositories and share experiences in integration of autonomous navigation systems. We use DARPA Subterranean Challenge as a use case where the repositories together form the main navigation system of the CMU-OSU Team. In the end, we discuss a few potential use cases in extended applications.},
  keywords = {Analytical models,Automation,Autonomous robots,Navigation,Open source software,Planning,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/26EM88WI/Cao et al. - 2022 - Autonomous Exploration Development Environment and.pdf;/Users/kshitijgoel/Zotero/storage/R6UYF6HA/9812330.html}
}

@inproceedings{cao_exploring_2021,
  title = {Exploring {{Large}} and {{Complex Environments Fast}} and {{Efficiently}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Cao, Chao and Zhu, Hongbiao and Choset, Howie and Zhang, Ji},
  year = {2021},
  month = may,
  pages = {7781--7787},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561916},
  url = {https://ieeexplore.ieee.org/document/9561916},
  urldate = {2024-11-15},
  abstract = {This paper describes a novel framework for autonomous exploration in large and complex environments. We show that the framework is efficient as a result of its hierarchical structure, where at one level it maintains a sparse representation of the environment and at another level, a dense representation is used within a local planning horizon around the robot. The exploration path is computed at the two levels, coarsely at the global scale and finely around the robot. Such a framework produces detailed paths in the vicinity of the robot, while trades off data resolution far away from the robot for computational efficiency. In experiments, we evaluate our method with a real robot exploring large and complex indoor and outdoor environments. Results show that our method is twice as efficient in covering spaces while using less than one-fifth of processing in comparison to state-of-the-art methods.},
  keywords = {Automation,Computational efficiency,Conferences,Electric breakdown,Planning,Robots,Runtime},
  file = {/Users/kshitijgoel/Zotero/storage/HCX8TPD7/Cao et al. - 2021 - Exploring Large and Complex Environments Fast and Efficiently.pdf;/Users/kshitijgoel/Zotero/storage/8VZH6763/9561916.html}
}

@article{cao_exploring_2023,
  title = {Exploring the {{Most Sectors}} at the {{DARPA Subterranean Challenge Finals}}},
  author = {Cao, Chao and Nogueira, Lucas and Zhu, Hongbiao and Keller, John and Best, Graeme and Garg, Rohit and Kohanbash, David and Maier, Jay and Zhao, Shibo and Yang, Fan and Cujic, Katarina and Darnley, Ryan and DeBortoli, Robert and Drozd, Bill and Sun, Peigen and Higgins, Ian and Willits, Steven and Armstrong, Greg and Zhang, Ji and Hollinger, Geoffrey and Travers, Matthew and Scherer, Sebastian},
  year = {2023},
  month = jan,
  journal = {Field Robotics},
  volume = {3},
  number = {1},
  pages = {801--836},
  issn = {27713989},
  doi = {10.55417/fr.2023025},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_3_files/Vol3_25.pdf},
  urldate = {2023-08-23},
  abstract = {Autonomous robot navigation in austere environments is critical to missions like ``search and rescue'', yet it remains difficult to achieve. The recent DARPA Subterranean Challenge (SubT) highlights prominent challenges including GPS-denied navigation through rough terrains, rapid exploration in large-scale three-dimensional (3D) space, and interrobot coordination over unreliable communication. Solving these challenges requires both mechanical resilience and algorithmic intelligence. Here, we present our approach that leverages a fleet of custom-built heterogeneous robots and an autonomy stack for robust navigation in challenging environments. Our approach has demonstrated superior navigation performance in the SubT Final Event, resulting in the fastest traversal and most thorough exploration of the environment, which won the ``Most Sectors Explored Award.'' This paper details our approach from two aspects: mechanical designs of a marsupial ground-and-aerial system to overcome mobility challenges and autonomy algorithms enabling collective rapid exploration. We also provide lessons learned in the design, development, and deployment of complex but resilient robotic systems to overcome real-world navigation challenges.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/44DZCN23/Cao et al. - 2023 - Exploring the Most Sectors at the DARPA Subterrane.pdf}
}

@article{cao_gvins_2022,
  title = {{{GVINS}}: {{Tightly Coupled GNSS}}--{{Visual}}--{{Inertial Fusion}} for {{Smooth}} and {{Consistent State Estimation}}},
  shorttitle = {{{GVINS}}},
  author = {Cao, Shaozu and Lu, Xiuyuan and Shen, Shaojie},
  year = {2022},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {4},
  pages = {2004--2021},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3133730},
  abstract = {Visual--inertial odometry (VIO) is known to suffer from drifting, especially over long-term runs. In this article, we present GVINS, a nonlinear optimization-based system that tightly fuses global navigation satellite system (GNSS) raw measurements with visual and inertial information for real-time and drift-free stateestimation. Our system aims to provide accurate global six-degree-of-freedom estimation under complex indoor--outdoor environments, where GNSS signals may be intermittent or even inaccessible. To establish the connection between global measurements and local states, a coarse-to-fine initialization procedure is proposed to efficiently calibrate the transformation online and initialize GNSS states from only a short window of measurements. The GNSS code pseudorange and Doppler shift measurements, along with visual and inertial information, are then modeled and used to constrain the system states in a factor graph framework. For complex and GNSS-unfriendly areas, the degenerate cases are discussed and carefully handled to ensure robustness. Thanks to the tightly coupled multisensor approach and system design, our system fully exploits the merits of three types of sensors and is able to seamlessly cope with the transition between indoor and outdoor environments, where satellites are lost and reacquired. We extensively evaluate the proposed system by both simulation and real-world experiments, and the results demonstrate that our system substantially suppresses the drift of the VIO and preserves the local accuracy in spite of noisy GNSS measurements. The versatility and robustness of the system are verified on large-scale data collected in challenging environments. In addition, experiments show that our system can still benefit from the presence of only one satellite, whereas at least four satellites are required for its conventional GNSS counterparts.},
  keywords = {Clocks,Codes,Global navigation satellite system,Localization,Receivers,Satellites,sensor fusion,simultaneous localization and mapping (SLAM),state estimation,State estimation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/LKMC4LPB/Cao et al. - 2022 - GVINS Tightly Coupled GNSS–Visual–Inertial Fusion.pdf;/Users/kshitijgoel/Zotero/storage/J9GTLTY6/9667780.html}
}

@article{cao_heuristic_2024,
  title = {Heuristic {{Search}} for the {{Orienteering Problem}} with {{Time-Varying Reward}}},
  author = {Cao, Chao and Xu, Jinyun and Zhang, Ji and Choset, Howie and Ren, Zhongqiang},
  year = {2024},
  month = jun,
  journal = {Proceedings of the International Symposium on Combinatorial Search},
  volume = {17},
  pages = {11--19},
  issn = {2832-9163},
  doi = {10.1609/socs.v17i1.31537},
  url = {https://ojs.aaai.org/index.php/SOCS/article/view/31537},
  urldate = {2024-06-06},
  abstract = {The Orienteering Problem (OP) seeks a path on a graph to maximize total rewards collected subject to a path length budget. Typically, a reward is achieved by visiting a vertex in the graph, and such a reward is constant for all time. This paper considers a variant of OP where the reward of each vertex is an arbitrary time-dependent function, and hence the name time-varying reward OP (TR-OP). To solve this problem, we develop a novel heuristic search algorithm called Reward Maximization A* (RMA*), which is guaranteed to find an optimal solution to TR-OP. We also develop a fast method to compute an admissible heuristic for RMA* that can effectively direct the search to save computational effort. Furthermore, we introduce a hyper-parameter in RMA* that trades off between solution quality and runtime efficiency for RMA*. We benchmark RMA* against a recent dynamic programming (DP) approach, which runs fast in practice, but has no guarantee of the solution optimality. In our tests, RMA* reduces the runtime by up to 70\% compared to DP. By adjusting the hyper-parameter, RMA* is able to find solutions with up to 30\% more rewards than those found by DP.},
  copyright = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VX7KBVXH/Cao et al. - 2024 - Heuristic Search for the Orienteering Problem with Time-Varying Reward.pdf}
}

@article{cao_representation_2023,
  title = {Representation Granularity Enables Time-Efficient Autonomous Exploration in Large, Complex Worlds},
  author = {Cao, C. and Zhu, H. and Ren, Z. and Choset, H. and Zhang, J.},
  year = {2023},
  month = jul,
  journal = {Science Robotics},
  volume = {8},
  number = {80},
  pages = {eadf0970},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.adf0970},
  url = {https://www.science.org/doi/10.1126/scirobotics.adf0970},
  urldate = {2023-07-20},
  abstract = {We propose a dual-resolution scheme to achieve time-efficient autonomous exploration with one or many robots. The scheme maintains a high-resolution local map of the robot's immediate vicinity and a low-resolution global map of the remaining areas of the environment. We believe that the strength of our approach lies in this low- and high-resolution representation of the environment: The high-resolution local map ensures that the robots observe the entire region in detail, and because the local map is bounded, so is the computation burden to process it. The low-resolution global map directs the robot to explore the broad space and only requires lightweight computation and low bandwidth to communicate among the robots. This paper shows the strength of this approach for both single-robot and multirobot exploration. For multirobot exploration, we also introduce a ``pursuit'' strategy for sharing information among robots with limited communication. This strategy directs the robots to opportunistically approach each other. We found that the scheme could produce exploration paths with a bounded difference in length compared with the theoretical shortest paths. Empirically, for single-robot exploration, our method produced 80\% higher time efficiency with 50\% lower computational runtimes than state-of-the-art methods in more than 300 simulation and real-world experiments. For multirobot exploration, our pursuit strategy demonstrated higher exploration time efficiency than conventional strategies in more than 3400 simulation runs with up to 20 robots. Last, we discuss how our method was deployed in the DARPA Subterranean Challenge and demonstrated the fastest and most complete exploration among all teams.},
  file = {/Users/kshitijgoel/Zotero/storage/G4UZBXKF/Cao et al. - 2023 - Representation granularity enables time-efficient .pdf}
}

@article{cao_singlecell_2019,
  title = {The Single-Cell Transcriptional Landscape of Mammalian Organogenesis},
  author = {Cao, Junyue and Spielmann, Malte and Qiu, Xiaojie and Huang, Xingfan and Ibrahim, Daniel M. and Hill, Andrew J. and Zhang, Fan and Mundlos, Stefan and Christiansen, Lena and Steemers, Frank J. and Trapnell, Cole and Shendure, Jay},
  year = {2019},
  month = feb,
  journal = {Nature},
  volume = {566},
  number = {7745},
  pages = {496--502},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-0969-x},
  url = {https://www.nature.com/articles/s41586-019-0969-x},
  urldate = {2024-07-17},
  abstract = {Mammalian organogenesis is a remarkable process. Within a short timeframe, the cells of the three germ layers transform into an embryo that includes most of the major internal and external organs. Here we investigate the transcriptional dynamics of mouse organogenesis at single-cell resolution. Using single-cell combinatorial indexing, we profiled the transcriptomes of around 2 million cells derived from 61 embryos staged between 9.5 and 13.5 days of gestation, in a single experiment. The resulting `mouse organogenesis cell atlas' (MOCA) provides a global view of developmental processes during this critical window. We~use Monocle 3 to identify hundreds of cell types and 56 trajectories, many of which are detected only because of the depth of cellular coverage, and collectively define thousands of corresponding marker genes. We explore the dynamics of gene expression within cell types and trajectories over time, including focused analyses of the apical ectodermal ridge, limb mesenchyme and skeletal muscle.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Cell lineage,Transcriptomics},
  file = {/Users/kshitijgoel/Zotero/storage/B6KDRUHS/Cao et al. - 2019 - The single-cell transcriptional landscape of mammalian organogenesis.pdf}
}

@inproceedings{cao_tare_2021,
  title = {{{TARE}}: {{A Hierarchical Framework}} for {{Efficiently Exploring Complex 3D Environments}}},
  shorttitle = {{{TARE}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVII}}},
  author = {Cao, Chao and Zhu, Hongbiao and Choset, Howie and Zhang, Ji},
  year = {2021},
  month = jul,
  volume = {17},
  url = {http://www.roboticsproceedings.org/rss17/p018.html},
  urldate = {2023-02-08},
  isbn = {978-0-9923747-7-8},
  file = {/Users/kshitijgoel/Zotero/storage/7KGRK49T/Cao et al. - 2021 - TARE A Hierarchical Framework for Efficiently Exp.pdf}
}

@article{cappe_online_2009,
  title = {On-{{Line Expectation}}--{{Maximization Algorithm}} for Latent {{Data Models}}},
  author = {Capp{\'e}, Olivier and Moulines, Eric},
  year = {2009},
  month = jun,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {71},
  number = {3},
  pages = {593--613},
  issn = {1369-7412},
  doi = {10.1111/j.1467-9868.2009.00698.x},
  url = {https://doi.org/10.1111/j.1467-9868.2009.00698.x},
  urldate = {2024-03-28},
  abstract = {We propose a generic on-line (also sometimes called adaptive or recursive) version of the expectation--maximization (EM) algorithm applicable to latent variable models of independent observations. Compared with the algorithm of Titterington, this approach is more directly connected to the usual EM algorithm and does not rely on integration with respect to the complete-data distribution. The resulting algorithm is usually simpler and is shown to achieve convergence to the stationary points of the Kullback--Leibler divergence between the marginal distribution of the observation and the model distribution at the optimal rate, i.e. that of the maximum likelihood estimator. In addition, the approach proposed is also suitable for conditional (or regression) models, as illustrated in the case of the mixture of linear regressions model.},
  file = {/Users/kshitijgoel/Zotero/storage/2EYZDTRA/Cappé and Moulines - 2009 - On-Line Expectation–Maximization Algorithm for lat.pdf;/Users/kshitijgoel/Zotero/storage/QJQZ929L/7092936.html}
}

@article{cardona_planning_2024,
  title = {Planning for Heterogeneous Teams of Robots with Temporal Logic, Capability, and Resource Constraints},
  author = {Cardona, Gustavo A. and Vasile, Cristian-Ioan},
  year = {2024},
  month = nov,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {13},
  pages = {2089--2111},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241247285},
  url = {https://doi.org/10.1177/02783649241247285},
  urldate = {2025-04-16},
  abstract = {This paper presents a comprehensive approach for planning for teams of heterogeneous robots with different capabilities and the transportation of resources. We use Capability Temporal Logic (CaTL), a formal language that helps express tasks involving robots with multiple capabilities with spatial, temporal, and logical constraints. We extend CaTL to also capture resource constraints, where resources can be divisible and indivisible, for instance, sand and bricks, respectively. Robots transport resources using various storage types, such as uniform (shared storage among resources) and compartmental (individual storage per resource). Robots' resource transportation capacity is defined based on resource type and robot class. Robot and resource dynamics and the CaTL mission are jointly encoded in a Mixed Integer Linear Programming (MILP), which maximizes disjoint robot and resource robustness while minimizing spurious movement of both. We propose a multi-robustness approach for Multi-Class Signal Temporal Logic (mcSTL), allowing for generalized quantitative semantics across multiple predicate classes. Thus, we compute availability robustness scores for robots and resources separately. Finally, we conduct multiple experiments demonstrating functionality and time performance by varying resources and storage types.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LXZZ6863/Cardona and Vasile - 2024 - Planning for heterogeneous teams of robots with temporal logic, capability, and resource constraints.pdf}
}

@article{carlone_attention_2019,
  title = {Attention and {{Anticipation}} in {{Fast Visual-Inertial Navigation}}},
  author = {Carlone, Luca and Karaman, Sertac},
  year = {2019},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {35},
  number = {1},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2872402},
  abstract = {We study a visual-inertial navigation (VIN) problem in which a robot needs to estimate its state using an on-board camera and an inertial sensor, without any prior knowledge of the external environment. We consider the case in which the robot can allocate limited resources to VIN, due to tight computational constraints. Therefore, we answer the following question: under limited resources, what are the most relevant visual cues to maximize the performance of VIN? Our approach has four key ingredients. First, it is task-driven, in that the selection of the visual cues is guided by a metric quantifying the VIN performance. Second, it exploits the notion of anticipation, since it uses a simplified model for forward-simulation of robot dynamics, predicting the utility of a set of visual cues over a future time horizon. Third, it is efficient and easy to implement, since it leads to a greedy algorithm for the selection of the most relevant visual cues. Fourth, it provides formal performance guarantees: we leverage submodularity to prove that the greedy selection cannot be far from the optimal (combinatorial) selection. Simulations and real experiments on agile drones show that our approach ensures state-of-the-art VIN performance while maintaining a lean processing time. In the easy scenarios, our approach outperforms appearance-based feature selection in terms of localization errors. In the most challenging scenarios, it enables accurate VIN while appearance-based feature selection fails to track robot's motion during aggressive maneuvers.},
  keywords = {Aerial robotics,computer vision,Feature extraction,Hardware,Navigation,Robot sensing systems,sensor fusion,simultaneous localization and mapping (SLAM),Task analysis,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/6WRR8HJD/Carlone and Karaman - 2019 - Attention and Anticipation in Fast Visual-Inertial.pdf;/Users/kshitijgoel/Zotero/storage/UHG59P3W/8526341.html}
}

@article{carlone_estimation_2023,
  title = {Estimation {{Contracts}} for {{Outlier-Robust Geometric Perception}}},
  author = {Carlone, Luca},
  year = {2023},
  month = jun,
  journal = {Foundations and Trends{\textregistered} in Robotics},
  volume = {11},
  number = {2-3},
  pages = {90--224},
  publisher = {Now Publishers, Inc.},
  issn = {1935-8253, 1935-8261},
  doi = {10.1561/2300000077},
  url = {https://www.nowpublishers.com/article/Details/ROB-077},
  urldate = {2024-06-11},
  abstract = {Estimation Contracts for Outlier-Robust Geometric Perception},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CB2X4ST4/Carlone - 2023 - Estimation Contracts for Outlier-Robust Geometric Perception.pdf}
}

@inproceedings{carreira-perpinan_acceleration_2006,
  title = {Acceleration {{Strategies}} for {{Gaussian Mean-Shift Image Segmentation}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {{Carreira-Perpinan}, M.A.},
  year = {2006},
  month = jun,
  volume = {1},
  pages = {1160--1167},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.44},
  url = {https://ieeexplore.ieee.org/document/1640881},
  urldate = {2024-03-11},
  abstract = {Gaussian mean-shift (GMS) is a clustering algorithm that has been shown to produce good image segmentations (where each pixel is represented as a feature vector with spatial and range components). GMS operates by defining a Gaussian kernel density estimate for the data and clustering together points that converge to the same mode under a fixed-point iterative scheme. However, the algorithm is slow, since its complexity is O(kN2), where N is the number of pixels and k the average number of iterations per pixel. We study four acceleration strategies for GMS based on the spatial structure of images and on the fact that GMS is an expectation-maximisation (EM) algorithm: spatial discretisation, spatial neighbourhood, sparse EM and EM-Newton algorithm. We show that the spatial discretisation strategy can accelerate GMS by one to two orders of magnitude while achieving essentially the same segmentation; and that the other strategies attain speedups of less than an order of magnitude.},
  keywords = {Acceleration,Bandwidth,Clustering algorithms,Computer science,Equations,Image converters,Image segmentation,Iterative algorithms,Kernel,Pixel},
  file = {/Users/kshitijgoel/Zotero/storage/NUK8QE8D/Carreira-Perpinan - 2006 - Acceleration Strategies for Gaussian Mean-Shift Im.pdf;/Users/kshitijgoel/Zotero/storage/X65Y5XCV/1640881.html}
}

@inproceedings{carreira-perpinan_fast_2006,
  title = {Fast Nonparametric Clustering with {{Gaussian}} Blurring Mean-Shift},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning  - {{ICML}} '06},
  author = {{Carreira-Perpi{\~n}{\'a}n}, Miguel {\'A}.},
  year = {2006},
  pages = {153--160},
  publisher = {ACM Press},
  address = {Pittsburgh, Pennsylvania},
  doi = {10.1145/1143844.1143864},
  url = {http://portal.acm.org/citation.cfm?doid=1143844.1143864},
  urldate = {2022-05-28},
  abstract = {We revisit Gaussian blurring mean-shift (GBMS), a procedure that iteratively sharpens a dataset by moving each data point according to the Gaussian mean-shift algorithm (GMS). (1) We give a criterion to stop the procedure as soon as clustering structure has arisen and show that this reliably produces image segmentations as good as those of GMS but much faster. (2) We prove that GBMS has convergence of cubic order with Gaussian clusters (much faster than GMS's, which is of linear order) and that the local principal component converges last, which explains the powerful clustering and denoising properties of GBMS. (3) We show a connection with spectral clustering that suggests GBMS is much faster. (4) We further accelerate GBMS by interleaving connected-components and blurring steps, achieving 2{\texttimes}--4{\texttimes} speedups without introducing an approximation error. In summary, our accelerated GBMS is a simple, fast, nonparametric algorithm that achieves segmentations of state-of-the-art quality.},
  isbn = {978-1-59593-383-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GX25NY3F/Carreira-Perpiñán - 2006 - Fast nonparametric clustering with Gaussian blurri.pdf}
}

@article{carreira-perpinan_modefinding_2000,
  title = {Mode-Finding for Mixtures of {{Gaussian}} Distributions},
  author = {{Carreira-Perpinan}, M.A.},
  year = {2000},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {22},
  number = {11},
  pages = {1318--1323},
  issn = {1939-3539},
  doi = {10.1109/34.888716},
  abstract = {Gradient-quadratic and fixed-point iteration algorithms and appropriate values for their control parameters are derived for finding all modes of a Gaussian mixture, a problem with applications in clustering and regression. The significance of the modes found is quantified locally by Hessian-based error bars and globally by the entropy as sparseness measure.},
  keywords = {Algorithm design and analysis,Bars,Bayesian methods,Clustering algorithms,Covariance matrix,Entropy,Gaussian distribution,Hidden Markov models,Machine learning algorithms,Speech analysis},
  file = {/Users/kshitijgoel/Zotero/storage/X6YKY9VW/888716.html}
}

@inproceedings{carrillo_comparison_2012,
  title = {On the Comparison of Uncertainty Criteria for Active {{SLAM}}},
  booktitle = {2012 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Carrillo, Henry and Reid, Ian and Castellanos, Jose A.},
  year = {2012},
  month = may,
  pages = {2080--2087},
  publisher = {IEEE},
  address = {St Paul, MN, USA},
  doi = {10.1109/ICRA.2012.6224890},
  url = {http://ieeexplore.ieee.org/document/6224890/},
  urldate = {2023-10-23},
  abstract = {In this paper, we consider the computation of the D-optimality criterion as a metric for the uncertainty of a SLAM system. Properties regarding the use of this uncertainty criterion in the active SLAM context are highlighted, and comparisons against the A-optimality criterion and entropy are presented. This paper shows that contrary to what has been previously reported, the D-optimality criterion is indeed capable of giving fruitful information as a metric for the uncertainty of a robot performing SLAM. Finally, through various experiments with simulated and real robots, we support our claims and show that the use of D-opt has desirable effects in various SLAM related tasks such as active mapping and exploration.},
  isbn = {978-1-4673-1405-3 978-1-4673-1403-9 978-1-4673-1578-4 978-1-4673-1404-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ENDAG282/Carrillo et al. - 2012 - On the comparison of uncertainty criteria for acti.pdf}
}

@inproceedings{caseiro_semiintrinsic_2012,
  title = {Semi-Intrinsic {{Mean Shift}} on {{Riemannian Manifolds}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2012},
  author = {Caseiro, Rui and Henriques, Jo{\~a}o F. and Martins, Pedro and Batista, Jorge},
  editor = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  pages = {342--355},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33718-5_25},
  abstract = {The original mean shift algorithm [1] on Euclidean spaces (MS) was extended in [2] to operate on general Riemannian manifolds. This extension is extrinsic (Ext-MS) since the mode seeking is performed on the tangent spaces [3], where the underlying curvature is not fully considered (tangent spaces are only valid in a small neighborhood). In [3] was proposed an intrinsic mean shift designed to operate on two particular Riemannian manifolds (IntGS-MS), i.e. Grassmann and Stiefel manifolds (using manifold-dedicated density kernels). It is then natural to ask whether mean shift could be intrinsically extended to work on a large class of manifolds. We propose a novel paradigm to intrinsically reformulate the mean shift on general Riemannian manifolds. This is accomplished by embedding the Riemannian manifold into a Reproducing Kernel Hilbert Space (RKHS) by using a general and mathematically well-founded Riemannian kernel function, i.e. heat kernel [5]. The key issue is that when the data is implicitly mapped to the Hilbert space, the curvature of the manifold is taken into account (i.e. exploits the underlying information of the data). The inherent optimization is then performed on the embedded space. Theoretic analysis and experimental results demonstrate the promise and effectiveness of this novel paradigm.},
  isbn = {978-3-642-33718-5},
  langid = {english},
  keywords = {Heat Kernel,Reproduce Kernel Hilbert Space,Riemannian Manifold,Tangent Space,Vector Bundle},
  file = {/Users/kshitijgoel/Zotero/storage/FCQH66GV/Caseiro et al. - 2012 - Semi-intrinsic Mean Shift on Riemannian Manifolds.pdf}
}

@inproceedings{cederborg_incremental_2010,
  title = {Incremental Local Online {{Gaussian Mixture Regression}} for Imitation Learning of Multiple Tasks},
  booktitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Cederborg, Thomas and Li, Ming and Baranes, Adrien and Oudeyer, Pierre-Yves},
  year = {2010},
  month = oct,
  pages = {267--274},
  issn = {2153-0866},
  doi = {10.1109/IROS.2010.5652040},
  abstract = {Gaussian Mixture Regression has been shown to be a powerful and easy-to-tune regression technique for imitation learning of constrained motor tasks in robots. Yet, current formulations are not suited when one wants a robot to learn incrementally and online a variety of new context-dependant tasks whose number and complexity is not known at programming time, and when the demonstrator is not allowed to tell the system when he introduces a new task (but rather the system should infer this from the continuous sensorimotor context). In this paper, we show that this limitation can be addressed by introducing an Incremental, Local and Online variation of Gaussian Mixture Regression (ILO-GMR) which successfully allows a simulated robot to learn incrementally and online new motor tasks through modelling them locally as dynamical systems, and able to use the sensorimotor context to cope with the absence of categorical information both during demonstrations and when a reproduction is asked to the system. Moreover, we integrate a complementary statistical technique which allows the system to incrementally learn various tasks which can be intrinsically defined in different frames of reference, which we call framings, without the need to tell the system which particular framing should be used for each task: this is inferred automatically by the system.},
  keywords = {Computational modeling,Context,Databases,Hidden Markov models,Robot kinematics,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/T3MKYTG7/Cederborg et al. - 2010 - Incremental local online Gaussian Mixture Regressi.pdf;/Users/kshitijgoel/Zotero/storage/VASD2Y83/5652040.html}
}

@phdthesis{ceron_algebraic_2017,
  title = {Algebraic {{Statistics}} of {{Gaussian Mixtures}}},
  author = {Cer{\'o}n, Carlos Enrique Am{\'e}ndola},
  year = {2017},
  address = {Berlin},
  langid = {english},
  school = {TU Berlin},
  file = {/Users/kshitijgoel/Zotero/storage/3TIQL9Z6/Cerón - Algebraic Statistics of Gaussian Mixtures.pdf}
}

@inproceedings{cesare_multiuav_2015,
  title = {Multi-{{UAV}} Exploration with Limited Communication and Battery},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Cesare, Kyle and Skeele, Ryan and Yoo, Soo-Hyun and Zhang, Yawei and Hollinger, Geoffrey},
  year = {2015},
  month = may,
  pages = {2230--2235},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7139494},
  url = {https://ieeexplore.ieee.org/abstract/document/7139494},
  urldate = {2024-02-10},
  abstract = {We propose a multi-robot exploration algorithm that uses adaptive coordination to provide heterogeneous behavior. The key idea is to maximize the efficiency of exploring and mapping an unknown environment when a team is faced with unreliable communication and limited battery life (e.g., with aerial rotorcraft). The proposed algorithm utilizes four states: explore, meet, sacrifice, and relay. The explore state uses a frontier-based exploration algorithm, the meet state returns to the last known location of communication to share data, the sacrifice state sends the robot out to explore without consideration of remaining battery, and the relay state lands the robot until a meeting occurs. This approach allows robots to take on the role of a relay to improve communication between team members. In addition, the robots can ``sacrifice'' themselves by continuing to explore even when they do not have sufficient battery to return to the base station. We compare the performance of the proposed approach to state-of-the-art frontier-based exploration, and results show gains in explored area. The feasibility of components of the proposed approach is also demonstrated on a team of two custom-built quadcopters exploring an office environment.},
  keywords = {Algorithm design and analysis,Base stations,Batteries,Relays,Robot kinematics,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/MZNX7J8A/Cesare et al. - 2015 - Multi-UAV exploration with limited communication a.pdf;/Users/kshitijgoel/Zotero/storage/5PSDD8HA/7139494.html}
}

@inproceedings{cetingul_intrinsic_2009,
  title = {Intrinsic Mean Shift for Clustering on {{Stiefel}} and {{Grassmann}} Manifolds},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Cetingul, Hasan Ertan and Vidal, Rene},
  year = {2009},
  month = jun,
  pages = {1896--1902},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2009.5206806},
  url = {https://ieeexplore.ieee.org/document/5206806},
  urldate = {2024-06-27},
  abstract = {The mean shift algorithm, which is a nonparametric density estimator for detecting the modes of a distribution on a Euclidean space, was recently extended to operate on analytic manifolds. The extension is extrinsic in the sense that the inherent optimization is performed on the tangent spaces of these manifolds. This approach specifically requires the use of the exponential map at each iteration. This paper presents an alternative mean shift formulation, which performs the iterative optimization ``on'' the manifold of interest and intrinsically locates the modes via consecutive evaluations of a mapping. In particular, these evaluations constitute a modified gradient ascent scheme that avoids the computation of the exponential maps for Stiefel and Grassmann manifolds. The performance of our algorithm is evaluated by conducting extensive comparative studies on synthetic data as well as experiments on object categorization and segmentation of multiple motions.},
  keywords = {Algorithm design and analysis,Clustering algorithms,Computer vision,Gene expression,Image segmentation,Iterative algorithms,Kernel,Motion segmentation,Performance analysis,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/EXEWPZUP/Cetingul and Vidal - 2009 - Intrinsic mean shift for clustering on Stiefel and Grassmann manifolds.pdf;/Users/kshitijgoel/Zotero/storage/NCZPUT6L/5206806.html}
}

@article{chan_redunet_2022,
  title = {{{ReduNet}}: {{A White-box Deep Network}} from the {{Principle}} of {{Maximizing Rate Reduction}}},
  shorttitle = {{{ReduNet}}},
  author = {Chan, Kwan Ho Ryan and Yu, Yaodong and You, Chong and Qi, Haozhi and Wright, John and Ma, Yi},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {114},
  pages = {1--103},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v23/21-0631.html},
  urldate = {2024-04-03},
  abstract = {This work attempts to provide a plausible theoretical framework that aims to interpret modern deep (convolutional) networks from the principles of data compression and discriminative representation. We argue that for high-dimensional multi-class data, the optimal linear discriminative representation maximizes the coding rate difference between the whole dataset and the average of all the subsets. We show that the basic iterative gradient ascent scheme for optimizing the rate reduction objective naturally leads to a multi-layer deep network, named ReduNet, which shares common characteristics of modern deep networks. The deep layered architectures, linear and nonlinear operators, and even parameters of the network are all explicitly constructed layer-by-layer via forward propagation, although they are amenable to fine-tuning via back propagation. All components of so-obtained ``white-box'' network have precise optimization, statistical, and geometric interpretation. Moreover, all linear operators of the so-derived network naturally become multi-channel convolutions when we enforce classification to be rigorously shift-invariant. The derivation in the invariant setting suggests a trade-off between sparsity and invariance, and also indicates that such a deep convolution network is significantly more efficient to construct and learn in the spectral domain. Our preliminary simulations and experiments clearly verify the effectiveness of both the rate reduction objective and the associated ReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.},
  file = {/Users/kshitijgoel/Zotero/storage/PBW97M28/Chan et al. - 2022 - ReduNet A White-box Deep Network from the Princip.pdf;/Users/kshitijgoel/Zotero/storage/4CSDTWDH/Ma-Lab-Berkeley.html}
}

@inproceedings{chan_updating_1982,
  title = {Updating {{Formulae}} and a {{Pairwise Algorithm}} for {{Computing Sample Variances}}},
  booktitle = {{{COMPSTAT}} 1982 5th {{Symposium}} Held at {{Toulouse}} 1982},
  author = {Chan, T. F. and Golub, G. H. and LeVeque, R. J.},
  editor = {Caussinus, H. and Ettinger, P. and Tomassone, R.},
  year = {1982},
  pages = {30--41},
  publisher = {Physica-Verlag HD},
  address = {Heidelberg},
  doi = {10.1007/978-3-642-51461-6_3},
  abstract = {A general formula is presented son. computing the sample valiance son a sample of size mtn given the means and valiance son two subsamples of sizes m and n. This formula is used in the construction of a pairwise algorithm son computing the valiance. Other applications are discussed as well including the use of updating formulae in a parallel computing environment. we present resume and rounding error analyze son several numerical schemes.},
  isbn = {978-3-642-51461-6},
  langid = {english},
  keywords = {Correct Digit,Double Precision,Error Analysis,Single Precision,Stanford Linear Accelerator},
  file = {/Users/kshitijgoel/Zotero/storage/DWZRAW6J/Chan et al. - 1982 - Updating Formulae and a Pairwise Algorithm for Computing Sample Variances.pdf}
}

@article{chang_dlite_2023,
  title = {D-{{Lite}}: {{Navigation-Oriented Compression}} of {{3D Scene Graphs}} for {{Multi-Robot Collaboration}}},
  shorttitle = {D-{{Lite}}},
  author = {Chang, Yun and Ballotta, Luca and Carlone, Luca},
  year = {2023},
  month = nov,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {11},
  pages = {7527--7534},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3320011},
  url = {https://ieeexplore.ieee.org/document/10265226},
  urldate = {2024-05-07},
  abstract = {For a multi-robot team that collaboratively explores an unknown environment, it is of vital importance that the collected information is efficiently shared among robots in order to support exploration and navigation tasks. Practical constraints of wireless channels, such as limited bandwidth, urge robots to carefully select information to be transmitted. In this letter, we consider the case where environmental information is modeled using a 3D Scene Graph, a hierarchical map representation that describes both geometric and semantic aspects of the environment. Then, we leverage graph-theoretic tools, namely graph spanners, to design greedy algorithms that efficiently compress 3D Scene Graphs with the aim of enabling communication between robots under bandwidth constraints. Our compression algorithms are navigation-oriented in that they are designed to approximately preserve shortest paths between locations of interest while meeting a user-specified communication budget constraint. The effectiveness of the proposed algorithms is demonstrated in robot navigation experiments in a realistic simulator.},
  keywords = {Bandwidth,Communication constraints,graph spanner,multi-robot SLAM,multi-robot systems,Navigation,Robots,semantic scene understanding,Semantics,Solid modeling,Task analysis,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/XAUMIK5T/Chang et al. - 2023 - D-Lite Navigation-Oriented Compression of 3D Scene Graphs for Multi-Robot Collaboration.pdf;/Users/kshitijgoel/Zotero/storage/6X7UPQFY/10265226.html}
}

@article{chang_lamp_2022,
  title = {{{LAMP}} 2.0: {{A Robust Multi-Robot SLAM System}} for {{Operation}} in {{Challenging Large-Scale Underground Environments}}},
  shorttitle = {{{LAMP}} 2.0},
  author = {Chang, Yun and Ebadi, Kamak and Denniston, Christopher E. and Ginting, Muhammad Fadhil and Rosinol, Antoni and Reinke, Andrzej and Palieri, Matteo and Shi, Jingnan and Chatterjee, Arghya and Morrell, Benjamin and {Agha-mohammadi}, Ali-akbar and Carlone, Luca},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {9175--9182},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3191204},
  url = {https://ieeexplore.ieee.org/document/9830862},
  urldate = {2024-02-05},
  abstract = {Search and rescue with a team of heterogeneous mobile robots in unknown and large-scale underground environments requires high-precision localization and mapping. This crucial requirement is faced with many challenges in complex and perceptually-degraded subterranean environments, as the onboard perception system is required to operate in off-nominal conditions (poor visibility due to darkness and dust, rugged and muddy terrain, and the presence of self-similar and ambiguous scenes). In a disaster response scenario and in the absence of prior information about the environment, robots must rely on noisy sensor data and perform Simultaneous Localization and Mapping (SLAM) to build a 3D map of the environment and localize themselves and potential survivors. To that end, this letter reports on a multi-robot SLAM system developed by team CoSTAR in the context of the DARPA Subterranean Challenge. We extend our previous work, LAMP, by incorporating a single-robot front-end interface that is adaptable to different odometry sources and lidar configurations, a scalable multi-robot front-end to support inter- and intra-robot loop closure detection for large scale environments and multi-robot teams, and a robust back-end equipped with an outlier-resilient pose graph optimization based on Graduated Non-Convexity. We provide a detailed ablation study on the multi-robot front-end and back-end, and assess the overall system performance in challenging real-world datasets collected across mines, power plants, and caves in the United States. We also release our multi-robot back-end datasets (and the corresponding ground truth), which can serve as challenging benchmarks for large-scale underground SLAM.},
  keywords = {Field robots,Laser radar,Location awareness,multi-robot SLAM,multi-robot systems,Optimization,Point cloud compression,Robot kinematics,Robots,Simultaneous localization and mapping,SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/BHGMMF8E/Chang et al. - 2022 - LAMP 2.0 A Robust Multi-Robot SLAM System for Ope.pdf;/Users/kshitijgoel/Zotero/storage/UNQKYNTU/9830862.html}
}

@inproceedings{changoluisacaiza_autonomous_2024,
  title = {Autonomous {{Exploration}} of {{Unknown 3D Environments Using}} a {{Frontier-Based Collector Strategy}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Changoluisa Caiza, Iv{\'a}n D. and Milas, Ana and Montes Grova, Marco A. and {Javier P{\'e}rez-Grau}, Francisco and Petrovic, Tamara},
  year = {2024},
  month = may,
  pages = {13566--13572},
  doi = {10.1109/ICRA57147.2024.10611139},
  url = {https://ieeexplore.ieee.org/document/10611139/?arnumber=10611139},
  urldate = {2024-12-11},
  abstract = {Autonomous exploration using unmanned aerial vehicles (UAVs) is essential for various tasks such as building inspections, rescue operations, deliveries, and warehousing. However, there are two main limitations to previous approaches: they may not be able to provide a complete map of the environment and assume that the map built during exploration is accurate enough for safe navigation, which is usually not the case. To address these limitations, a novel exploration method is proposed that combines frontier-based exploration with a collector strategy that achieves global exploration and complete map creation. In each iteration, the collector strategy stores and validates frontiers detected during exploration and selects the next best frontier to navigate to. The collector strategy ensures global exploration by balancing the exploitation of a known map with the exploration of unknown areas. In addition, the online path replanning ensures safe navigation through the map created during motion. The performance of the proposed method is verified by exploring 3D simulation environments in comparison with the state-of-the-art methods. Finally, the proposed approach is validated in a real-world experiment.},
  keywords = {Buildings,Inspection,Navigation,Three-dimensional displays,Video on demand,Warehousing,Web sites},
  file = {/Users/kshitijgoel/Zotero/storage/Z3YXMTIX/Changoluisa Caiza et al. - 2024 - Autonomous Exploration of Unknown 3D Environments Using a Frontier-Based Collector Strategy.pdf;/Users/kshitijgoel/Zotero/storage/Z789GWTK/10611139.html}
}

@inproceedings{chaplot_active_2018,
  title = {Active {{Neural Localization}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Chaplot, Devendra Singh and Parisotto, Emilio and Salakhutdinov, Ruslan},
  year = {2018},
  month = feb,
  url = {https://openreview.net/forum?id=ry6-G_66b},
  urldate = {2023-10-28},
  abstract = {Localization is the problem of estimating the location of an autonomous agent from an observation and a map of the environment. Traditional methods of localization, which filter the belief based on the observations, are sub-optimal in the number of steps required, as they do not decide the actions taken by the agent. We propose "Active Neural Localizer", a fully differentiable neural network that learns to localize efficiently. The proposed model incorporates ideas of traditional filtering-based localization methods, by using a structured belief of the state with multiplicative interactions to propagate belief, and combines it with a policy model to minimize the number of steps required for localization. Active Neural Localizer is trained end-to-end with reinforcement learning. We use a variety of simulation environments for our experiments which include random 2D mazes, random mazes in the Doom game engine and a photo-realistic environment in the Unreal game engine. The results on the 2D environments show the effectiveness of the learned policy in an idealistic setting while results on the 3D environments demonstrate the model's capability of learning the policy and perceptual model jointly from raw-pixel based RGB observations. We also show that a model trained on random textures in the Doom environment generalizes well to a photo-realistic office space environment in the Unreal engine.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/K5AEPWI8/Chaplot et al. - 2018 - Active Neural Localization.pdf}
}

@inproceedings{chaplot_learning_2020,
  title = {Learning {{To Explore Using Active Neural SLAM}}},
  booktitle = {Eighth {{International Conference}} on {{Learning Representations}}},
  author = {Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta, Saurabh and Gupta, Abhinav and Salakhutdinov, Ruslan},
  year = {2020},
  month = apr,
  url = {https://iclr.cc/virtual_2020/poster_HklXn1BKDH.html},
  urldate = {2023-11-01},
  abstract = {This work presents a modular and hierarchical approach to learn policies for exploring 3D environments, called `Active Neural SLAM'. Our approach leverages the strengths of both classical and learning-based methods, by using analytical path planners with learned SLAM module, and global and local policies. The use of learning provides flexibility with respect to input modalities (in the SLAM module), leverages structural regularities of the world (in global policies), and provides robustness to errors in state estimation (in local policies). Such use of learning within each module retains its benefits, while at the same time, hierarchical decomposition and modular training allow us to sidestep the high sample complexities associated with training end-to-end policies. Our experiments in visually and physically realistic simulated 3D environments demonstrate the effectiveness of our approach over past learning and geometry-based approaches. The proposed model can also be easily transferred to the PointGoal task and was the winning entry of CVPR 2019 Habitat PointGoal Navigation Challenge.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z6YLURZ9/Chaplot et al. - 2020 - Learning To Explore Using Active Neural SLAM.pdf}
}

@inproceedings{charatan_pixelsplat_2024,
  title = {{{pixelSplat}}: {{3D Gaussian Splats}} from {{Image Pairs}} for {{Scalable Generalizable 3D Reconstruction}}},
  shorttitle = {{{pixelSplat}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Charatan, David and Li, Sizhe Lester and Tagliasacchi, Andrea and Sitzmann, Vincent},
  year = {2024},
  pages = {19457--19467},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Charatan_pixelSplat_3D_Gaussian_Splats_from_Image_Pairs_for_Scalable_Generalizable_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/WS28Z5LH/Charatan et al. - 2024 - pixelSplat 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction.pdf}
}

@inproceedings{charrow_informationtheoretic_2015,
  title = {Information-Theoretic Mapping Using {{Cauchy-Schwarz Quadratic Mutual Information}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Charrow, Benjamin and Liu, Sikang and Kumar, Vijay and Michael, Nathan},
  year = {2015},
  month = may,
  pages = {4791--4798},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7139865},
  url = {https://ieeexplore.ieee.org/document/7139865},
  urldate = {2024-11-15},
  abstract = {We develop a computationally efficient control policy for active perception that incorporates explicit models of sensing and mobility to build 3D maps with ground and aerial robots. Like previous work, our policy maximizes an information-theoretic objective function between the discrete occupancy belief distribution (e.g., voxel grid) and future measurements that can be made by mobile sensors. However, our work is unique in three ways. First, we show that by using Cauchy-Schwarz Quadratic Mutual Information (CSQMI), we get significant gains in efficiency. Second, while most previous methods adopt a myopic, gradient-following approach that yields poor convergence properties, our algorithm searches over a set of paths and is less susceptible to local minima. In doing so, we explicitly incorporate models of sensors, and model the dependence (and independence) of measurements over multiple time steps in a path. Third, because we consider models of sensing and mobility, our method naturally applies to both ground and aerial vehicles. The paper describes the basic models, the problem formulation and the algorithm, and demonstrates applications via simulation and experimentation.},
  keywords = {Entropy,Mutual information,Robot sensing systems,Three-dimensional displays,Time measurement},
  file = {/Users/kshitijgoel/Zotero/storage/XQI5K28E/Charrow et al. - 2015 - Information-theoretic mapping using Cauchy-Schwarz Quadratic Mutual Information.pdf;/Users/kshitijgoel/Zotero/storage/S9M2QU6D/7139865.html}
}

@inproceedings{charrow_informationtheoretic_2015a,
  title = {Information-{{Theoretic Planning}} with {{Trajectory Optimization}} for {{Dense 3D Mapping}}},
  booktitle = {Robotics: {{Science}} and {{Systems XI}}},
  author = {Charrow, Benjamin and Kahn, Gregory and Patil, Sachin and Liu, Sikang and Goldberg, Ken and Abbeel, Pieter and Michael, Nathan and Kumar, Vijay},
  year = {2015},
  month = jul,
  volume = {11},
  url = {http://www.roboticsproceedings.org/rss11/p03.html},
  urldate = {2023-01-20},
  isbn = {978-0-9923747-1-6},
  file = {/Users/kshitijgoel/Zotero/storage/VZQX643D/Charrow et al. - 2015 - Information-Theoretic Planning with Trajectory Opt.pdf}
}

@inproceedings{chaslot_parallel_2008,
  title = {Parallel {{Monte-Carlo Tree Search}}},
  booktitle = {Computers and {{Games}}},
  author = {Chaslot, Guillaume M. J. -B. and Winands, Mark H. M. and {van den Herik}, H. Jaap},
  editor = {{van den Herik}, H. Jaap and Xu, Xinhe and Ma, Zongmin and Winands, Mark H. M.},
  year = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {60--71},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-87608-3_6},
  url = {https://link.springer.com/chapter/10.1007/978-3-540-87608-3_6},
  abstract = {Monte-Carlo Tree Search (MCTS) is a new best-first search method that started a revolution in the field of Computer Go. Parallelizing MCTS is an important way to increase the strength of any Go program. In this article, we discuss three parallelization methods for MCTS: leaf parallelization, root parallelization, and tree parallelization. To be effective tree parallelization requires two techniques: adequately handling of (1) local mutexes and (2) virtual loss. Experiments in 13{\texttimes}13 Go reveal that in the program Mango root parallelization may lead to the best results for a specific time setting and specific program parameters. However, as soon as the selection mechanism is able to handle more adequately the balance of exploitation and exploration, tree parallelization should have attention too and could become a second choice for parallelizing MCTS. Preliminary experiments on the smaller 9{\texttimes}9 board provide promising prospects for tree parallelization.},
  isbn = {978-3-540-87608-3},
  langid = {english},
  keywords = {Board Size,Leaf Node,Parallelization Method,Simulated Game,Time Setting},
  file = {/Users/kshitijgoel/Zotero/storage/7X7EI3JJ/Chaslot et al. - 2008 - Parallel Monte-Carlo Tree Search.pdf}
}

@incollection{chataigner_arsi_2020,
  title = {{{ARSI}}: {{An Aerial Robot}} for {{Sewer Inspection}}},
  shorttitle = {{{ARSI}}},
  booktitle = {Advances in {{Robotics Research}}: {{From Lab}} to {{Market}}: {{ECHORD}}++: {{Robotic Science Supporting Innovation}}},
  author = {Chataigner, Fran{\c c}ois and Cavestany, Pedro and Soler, Marcel and Rizzo, Carlos and Gonzalez, Jesus-Pablo and Bosch, Carles and Gibert, Jaume and Torrente, Antonio and Gomez, Ra{\'u}l and Serrano, Daniel},
  editor = {Grau, Antoni and Morel, Yannick and {Puig-Pey}, Ana and Cecchi, Francesca},
  year = {2020},
  pages = {249--274},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-22327-4_12},
  url = {https://doi.org/10.1007/978-3-030-22327-4_12},
  urldate = {2024-08-13},
  abstract = {In this chapter we present the Autonomous Robot for Sewer Inspection (ARSI), a robotic system designed to make the work of inspection brigades safer and more efficient. ARSI uses an autonomous Micro Air Vehicle (MAV) to collect HD imagery and structural data in the sewers, while operators remain on the surface to supervise missions. Our compact quadrotor design is lightweight and robust, with a flight autonomy of 15 min and a payload capacity of 1 kg. It can be deployed without any special equipment, and operates in sewer tunnels as narrow as 80 cm. The sensor payload collects inspection data as well as inputs for the onboard software, allowing the ARSI MAV to follow pre-planned inspection paths autonomously. User-friendly interfaces are provided to plan, execute, and monitor sewer inspections. Data collected by the MAV onboard sensors is processed by our offline algorithms to generate detailed 3D models of the sewers, and perform automatic visual and structural analysis. Our data analysis software allows ARSI users to review all information and generate inspection reports for their clients. Our system was tested and validated during rigorous field tests in the city of Barcelona, Spain.},
  isbn = {978-3-030-22327-4},
  langid = {english},
  keywords = {Autonomous,Communications,Detection,Drone,Inspection,MAV,Robot,Sewer,Structural defects},
  file = {/Users/kshitijgoel/Zotero/storage/ZRSS4LHS/Chataigner et al. - 2020 - ARSI An Aerial Robot for Sewer Inspection.pdf}
}

@misc{chen_3d_2024,
  title = {{{3D Reconstruction}} with {{Fast Dipole Sums}}},
  author = {Chen, Hanyu and Miller, Bailey and Gkioulekas, Ioannis},
  year = {2024},
  month = sep,
  number = {arXiv:2405.16788},
  eprint = {2405.16788},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.16788},
  urldate = {2024-11-10},
  abstract = {We introduce a method for high-quality 3D reconstruction from multi-view images. Our method uses a new point-based representation, the regularized dipole sum, which generalizes the winding number to allow for interpolation of per-point attributes in point clouds with noisy or outlier points. Using regularized dipole sums, we represent implicit geometry and radiance fields as per-point attributes of a dense point cloud, which we initialize from structure from motion. We additionally derive Barnes-Hut fast summation schemes for accelerated forward and adjoint dipole sum queries. These queries facilitate the use of ray tracing to efficiently and differentiably render images with our point-based representations, and thus update their point attributes to optimize scene geometry and appearance. We evaluate our method in inverse rendering applications against state-of-the-art alternatives, based on ray tracing of neural representations or rasterization of Gaussian point-based representations. Our method significantly improves 3D reconstruction quality and robustness at equal runtimes, while also supporting more general rendering methods such as shadow rays for direct illumination.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/4XATCIAI/Chen et al. - 2024 - 3D Reconstruction with Fast Dipole Sums.pdf;/Users/kshitijgoel/Zotero/storage/T6ZMH4X6/2405.html}
}

@misc{chen_activegamer_2025,
  title = {{{ActiveGAMER}}: {{Active GAussian Mapping}} through {{Efficient Rendering}}},
  shorttitle = {{{ActiveGAMER}}},
  author = {Chen, Liyan and Zhan, Huangying and Chen, Kevin and Xu, Xiangyu and Yan, Qingan and Cai, Changjiang and Xu, Yi},
  year = {2025},
  month = jan,
  number = {arXiv:2501.06897},
  eprint = {2501.06897},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.06897},
  url = {http://arxiv.org/abs/2501.06897},
  urldate = {2025-01-16},
  abstract = {We introduce ActiveGAMER, an active mapping system that utilizes 3D Gaussian Splatting (3DGS) to achieve high-quality, real-time scene mapping and exploration. Unlike traditional NeRF-based methods, which are computationally demanding and restrict active mapping performance, our approach leverages the efficient rendering capabilities of 3DGS, allowing effective and efficient exploration in complex environments. The core of our system is a rendering-based information gain module that dynamically identifies the most informative viewpoints for next-best-view planning, enhancing both geometric and photometric reconstruction accuracy. ActiveGAMER also integrates a carefully balanced framework, combining coarse-to-fine exploration, post-refinement, and a global-local keyframe selection strategy to maximize reconstruction completeness and fidelity. Our system autonomously explores and reconstructs environments with state-of-the-art geometric and photometric accuracy and completeness, significantly surpassing existing approaches in both aspects. Extensive evaluations on benchmark datasets such as Replica and MP3D highlight ActiveGAMER's effectiveness in active mapping tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/X3KQNW5H/Chen et al. - 2025 - ActiveGAMER Active GAussian Mapping through Efficient Rendering.pdf;/Users/kshitijgoel/Zotero/storage/VIXU7IYA/2501.html}
}

@article{chen_adaptive_2021,
  title = {Adaptive Robust Local Online Density Estimation for Streaming Data},
  author = {Chen, Zhong and Fang, Zhide and Sheng, Victor and Zhao, Jiabin and Fan, Wei and Edwards, Andrea and Zhang, Kun},
  year = {2021},
  month = jun,
  journal = {International Journal of Machine Learning and Cybernetics},
  volume = {12},
  number = {6},
  pages = {1803--1824},
  issn = {1868-808X},
  doi = {10.1007/s13042-021-01275-y},
  url = {https://doi.org/10.1007/s13042-021-01275-y},
  urldate = {2024-07-12},
  abstract = {Accurate online density estimation is crucial to numerous applications that are prevalent with streaming data. Existing online approaches for density estimation somewhat lack prompt adaptability and robustness when facing concept-drifting and noisy streaming data, resulting in delayed or even deteriorated approximations. To alleviate this issue, in this work, we first propose an adaptive local online kernel density estimator (ALoKDE) for real-time density estimation on data streams. ALoKDE consists of two tightly integrated strategies: (1) a statistical test for concept drift detection and (2) an adaptive weighted local online density estimation when a drift does occur. Specifically, using a weighted form, ALoKDE seeks to provide an unbiased estimation by factoring in the statistical hallmarks of the latest learned distribution and any potential distributional changes that could be introduced by each incoming instance. A robust variant of ALoKDE, i.e., R-ALoKDE, is further developed to effectively handle data streams with varied types/levels of noise. Moreover, we analyze the asymptotic properties of ALoKDE and R-ALoKDE, and also derive their theoretical error bounds regarding bias, variance, MSE and MISE. Extensive comparative studies on various artificial and real-world (noisy) streaming data demonstrate the efficacies of ALoKDE and R-ALoKDE in online density estimation and real-time classification (with noise).},
  langid = {english},
  keywords = {Adaptive bandwidth selection,Adaptive weighting factor optimization,Ensemble learning,Local sampling,Online density estimation,Streaming data},
  file = {/Users/kshitijgoel/Zotero/storage/68PVI9BD/Chen et al. - 2021 - Adaptive robust local online density estimation for streaming data.pdf}
}

@article{chen_adaptive_2024,
  title = {Adaptive {{Robotic Information Gathering}} via Non-Stationary {{Gaussian}} Processes},
  author = {Chen, Weizhe and Khardon, Roni and Liu, Lantao},
  year = {2024},
  month = apr,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {4},
  pages = {405--436},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231184498},
  url = {https://doi.org/10.1177/02783649231184498},
  urldate = {2024-04-19},
  abstract = {Robotic Information Gathering (RIG) is a foundational research topic that answers how a robot (team) collects informative data to efficiently build an accurate model of an unknown target function under robot embodiment constraints. RIG has many applications, including but not limited to autonomous exploration and mapping, 3D reconstruction or inspection, search and rescue, and environmental monitoring. A RIG system relies on a probabilistic model's prediction uncertainty to identify critical areas for informative data collection. Gaussian processes (GPs) with stationary kernels have been widely adopted for spatial modeling. However, real-world spatial data is typically non-stationary---different locations do not have the same degree of variability. As a result, the prediction uncertainty does not accurately reveal prediction error, limiting the success of RIG algorithms. We propose a family of non-stationary kernels named Attentive Kernel (AK), which is simple and robust and can extend any existing kernel to a non-stationary one. We evaluate the new kernel in elevation mapping tasks, where AK provides better accuracy and uncertainty quantification over the commonly used stationary kernels and the leading non-stationary kernels. The improved uncertainty quantification guides the downstream informative planner to collect more valuable data around the high-error area, further increasing prediction accuracy. A field experiment demonstrates that the proposed method can guide an Autonomous Surface Vehicle (ASV) to prioritize data collection in locations with significant spatial variations, enabling the model to characterize salient environmental features.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QHV8W3LZ/Chen et al. - 2024 - Adaptive Robotic Information Gathering via non-sta.pdf}
}

@inproceedings{chen_ak_2022,
  title = {{{AK}}: {{Attentive Kernel}} for {{Information Gathering}}},
  shorttitle = {{{AK}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Chen, Weizhe and Khardon, Roni and Liu, Lantao},
  year = {2022},
  month = jun,
  volume = {18},
  url = {http://www.roboticsproceedings.org/rss18/p047.html},
  urldate = {2022-09-01},
  isbn = {978-0-9923747-8-5},
  file = {/Users/kshitijgoel/Zotero/storage/6XH4JHAT/Chen et al. - 2022 - AK Attentive Kernel for Information Gathering.pdf;/Users/kshitijgoel/Zotero/storage/E3MJ7KNF/p047.html}
}

@inproceedings{chen_astralis_2022,
  title = {Astralis: {{A High-Fidelity Simulator}} for {{Heterogeneous Robot}} and {{Human-Robot Teaming}}},
  shorttitle = {Astralis},
  booktitle = {2022 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Chen, Gong and {Nguyen-Nam}, Duong and Meghjani, Malika and Tri, Phan Minh and Prasetyo, Marcel Bartholomeus and Daffa, Mohammad Alif and Quek, Tony Q. S.},
  year = {2022},
  month = nov,
  pages = {353--359},
  publisher = {IEEE},
  address = {Sevilla, Spain},
  doi = {10.1109/SSRR56537.2022.10018667},
  url = {https://ieeexplore.ieee.org/document/10018667/},
  urldate = {2024-01-24},
  abstract = {We introduce Astralis simulator, a high-fidelity robot simulation platform for the development of multi-robot and human-robot coordination algorithms which can be seamlessly translated to real-world environments. The simulator provides novel features of dynamically initializing the virtual environment with real-world 3D point cloud data and a uniformly random arrangement of static and dynamic obstacles in the environment. This allows the user to generate several variants of a base scenario for strategic planning and algorithm validation. The simulator can receive high-level command inputs to control a team of Unmanned Aerial Vehicles (UAVs), Unmanned Ground Vehicles (UGVs), and human avatars. The simulated robot models are built with high fidelity control and navigation capabilities which can be readily deployed on real robot platforms. We use Astralis simulator to analyze human-robot coordination algorithms for tracking, following and leading targets in a search and rescue mission. The algorithm is validated using a UAV and a UGV in simulation and on physical platforms. Our simulator provides comparable results to the real-world experiments in terms of the executed trajectories by the robots.},
  isbn = {978-1-6654-5680-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M9E6GNC8/Chen et al. - 2022 - Astralis A High-Fidelity Simulator for Heterogene.pdf}
}

@article{chen_continuous_2024,
  title = {Continuous {{Occupancy Mapping}} in {{Dynamic Environments Using Particles}}},
  author = {Chen, Gang and Dong, Wei and Peng, Peng and {Alonso-Mora}, Javier and Zhu, Xiangyang},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {64--84},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3323841},
  url = {https://ieeexplore.ieee.org/document/10285872/},
  urldate = {2024-02-05},
  abstract = {Particle-based dynamic occupancy maps were proposed in recent years to model the obstacles in dynamic environments. Current particle-based maps describe the occupancy status in discrete grid form and suffer from the grid size problem, wherein a large grid size is unfavorable for motion planning while a small grid size lowers efficiency and causes gaps and inconsistencies. To tackle this problem, this article generalizes the particle-based map into continuous space and builds an efficient 3-D egocentric local map. A dual-structure subspace division paradigm, composed of a voxel subspace division and a novel pyramid-like subspace division, is proposed to propagate particles and update the map efficiently with the consideration of occlusions. The occupancy status at an arbitrary point in the map space can then be estimated with the weights of the particles. To reduce the noise in modeling static and dynamic obstacles simultaneously, an initial velocity estimation approach and a mixture model are utilized. Experimental results show that our map can effectively and efficiently model both dynamic obstacles and static obstacles. Compared to the state-of-the-art grid-form particle-based map, our map enables continuous occupancy estimation and substantially improves the mapping performance at different resolutions.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VMXSD7PD/Chen et al. - 2024 - Continuous Occupancy Mapping in Dynamic Environmen.pdf}
}

@inproceedings{chen_densefusion_2020,
  title = {{{DenseFusion}}: {{Large-Scale Online Dense Pointcloud}} and {{DSM Mapping}} for {{UAVs}}},
  shorttitle = {{{DenseFusion}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Chen, Lin and Zhao, Yong and Xu, Shibiao and Bu, Shuhui and Han, Pengcheng and Wan, Gang},
  year = {2020},
  month = oct,
  pages = {4766--4773},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341413},
  abstract = {With the rapidly developing unmanned aerial vehicles, the requirements of generating maps efficiently and quickly are increasing. To realize online mapping, we develop a real-time dense mapping framework named DenseFusion which can incrementally generates dense geo-referenced 3D point cloud, digital orthophoto map (DOM) and digital surface model (DSM) from sequential aerial images with optional GPS information. The proposed method works in real-time on standard CPUs even for processing high resolution images. Based on the advanced monocular SLAM, our system first estimates appropriate camera poses and extracts effective keyframes, and next constructs virtual stereo-pair from consecutive frame to generate pruned dense 3D point clouds; then a novel realtime DSM fusion method is proposed which can incrementally process dense point cloud. Finally, a high efficiency visualization system is developed to adopt dynamic levels of detail (LoD) method, which makes it render dense point cloud and DSM smoothly. The performance of the proposed method is evaluated through qualitative and quantitative experiments. The results indicate that compared to traditional structure from motion based approaches, the presented framework is able to output both large-scale high-quality DOM and DSM in real-time with low computational cost.},
  keywords = {Real-time systems,Structure from motion,Surface reconstruction,Surface treatment,Three-dimensional displays,Unmanned aerial vehicles,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/636CDAQJ/Chen et al. - 2020 - DenseFusion Large-Scale Online Dense Pointcloud a.pdf;/Users/kshitijgoel/Zotero/storage/9TVKA6ZN/stamp.html}
}

@inproceedings{chen_fast_2022,
  title = {Fast {{3D Sparse Topological Skeleton Graph Generation}} for {{Mobile Robot Global Planning}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Chen, Xinyi and Zhou, Boyu and Lin, Jiarong and Zhang, Yichen and Zhang, Fu and Shen, Shaojie},
  year = {2022},
  month = oct,
  pages = {10283--10289},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981397},
  url = {https://ieeexplore.ieee.org/document/9981397/},
  urldate = {2025-08-06},
  abstract = {In recent years, mobile robots are becoming ambitious and deployed in large-scale scenarios. Serving as a high-level understanding of environments, a sparse skeleton graph is beneficial for more efficient global planning. Currently, existing solutions for skeleton graph generation suffer from several major limitations, including poor adaptiveness to different map representations, dependency on robot inspection trajectories and high computational overhead. In this paper, we propose an efficient and flexible algorithm generating a trajectory-independent 3D sparse topological skeleton graph capturing the spatial structure of the free space. In our method, an efficient ray sampling and validating mechanism are adopted to find distinctive free space regions, which contributes to skeleton graph vertices, with traversability between adjacent vertices as edges. A cycle formation scheme is also utilized to maintain skeleton graph compactness. Benchmark comparison with state-of-the-art works demonstrates that our approach generates sparse graphs in a substantially shorter time, giving high-quality global planning paths. Experiments conducted in real-world maps further validate the capability of our method in real-world scenarios. Our method will be made open source to benefit the community.},
  keywords = {Benchmark testing,Inspection,Mobile robots,Planning,Skeleton,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/ZIQCWIQG/Chen et al. - 2022 - Fast 3D Sparse Topological Skeleton Graph Generation for Mobile Robot Global Planning.pdf}
}

@misc{chen_fogros2ft_2024,
  title = {{{FogROS2-FT}}: {{Fault Tolerant Cloud Robotics}}},
  shorttitle = {{{FogROS2-FT}}},
  author = {Chen, Kaiyuan and Hari, Kush and Chung, Trinity and Wang, Michael and Tian, Nan and Juette, Christian and Ichnowski, Jeffrey and Ren, Liu and Kubiatowicz, John and Stoica, Ion and Goldberg, Ken},
  year = {2024},
  month = dec,
  number = {arXiv:2412.05408},
  eprint = {2412.05408},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.05408},
  url = {http://arxiv.org/abs/2412.05408},
  urldate = {2024-12-10},
  abstract = {Cloud robotics enables robots to offload complex computational tasks to cloud servers for performance and ease of management. However, cloud compute can be costly, cloud services can suffer occasional downtime, and connectivity between the robot and cloud can be prone to variations in network Quality-of-Service (QoS). We present FogROS2-FT (Fault Tolerant) to mitigate these issues by introducing a multi-cloud extension that automatically replicates independent stateless robotic services, routes requests to these replicas, and directs the first response back. With replication, robots can still benefit from cloud computations even when a cloud service provider is down or there is low QoS. Additionally, many cloud computing providers offer low-cost spot computing instances that may shutdown unpredictably. Normally, these low-cost instances would be inappropriate for cloud robotics, but the fault tolerance nature of FogROS2-FT allows them to be used reliably. We demonstrate FogROS2-FT fault tolerance capabilities in 3 cloud-robotics scenarios in simulation (visual object detection, semantic segmentation, motion planning) and 1 physical robot experiment (scan-pick-and-place). Running on the same hardware specification, FogROS2-FT achieves motion planning with up to 2.2x cost reduction and up to a 5.53x reduction on 99 Percentile (P99) long-tail latency. FogROS2-FT reduces the P99 long-tail latency of object detection and semantic segmentation by 2.0x and 2.1x, respectively, under network slowdown and resource contention.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Networking and Internet Architecture,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/I2JIWP9Y/Chen et al. - 2024 - FogROS2-FT Fault Tolerant Cloud Robotics.pdf;/Users/kshitijgoel/Zotero/storage/7RC9R9KK/2412.html}
}

@article{chen_g2sdf_2025,
  title = {G2-{{SDF}}: {{Geometry-Guided Neural Signed Distance Fields}} for {{Scalable}} and {{Detailed Reconstruction}}},
  shorttitle = {G2-{{SDF}}},
  author = {Chen, Kai and Cao, Jiahang and Li, Yulin and Li, Haoang and Ma, Jun},
  year = {2025},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3585381},
  url = {https://ieeexplore.ieee.org/document/11066249/},
  urldate = {2025-07-08},
  abstract = {Effcient reconstruction methods, particularly capable of providing detailed information on obstacle distances across diverse environments, are crucial for effective robot motion planning. In this context, neural Signed Distance Fields (SDFs) offer a powerful solution by learning implicit representations of environments, enabling fast and precise distance queries to obstacles. In this work, we introduce G2-SDF, a method designed to achieve scalable and detailed reconstruction of environments while ensuring high training effciency. In particular, our approach utilizes a precise normal direction sampling strategy, which incorporates a rapid normal estimation technique to compute accurate boundaries along surface normals. This effectively flters out erroneous samples and enhances SDF accuracy. To mitigate catastrophic forgetting in incremental learning scenarios, we propose a fne-grained voxel sliding window method that effciently manages historical data while optimizing video memory usage. Subsequently, we partition feature areas based on the calculated normal boundaries and implement an importance sampling strategy that emphasizes capturing detailed regions. We evaluate G2-SDF on both indoor (Replica and ScanNet) and outdoor (Maicity and Newer College Quad) datasets. Our method surpasses existing approaches and achieves superior reconstruction accuracy while maintaining high effciency in scalable environments.},
  keywords = {Accuracy,deep learning for visual perception,Estimation,Feature extraction,incremental learning,Incremental learning,Memory management,Monte Carlo methods,Point cloud compression,Surface reconstruction,Training,Vectors,Visual learning},
  file = {/Users/kshitijgoel/Zotero/storage/8JYKW79F/Chen et al. - 2025 - G2-SDF Geometry-Guided Neural Signed Distance Fields for Scalable and Detailed Reconstruction.pdf}
}

@article{chen_gpuaccelerated_2022,
  title = {{{GPU-Accelerated Incremental Euclidean Distance Transform}} for {{Online Motion Planning}} of {{Mobile Robots}}},
  author = {Chen, Yizhou and Lai, Shupeng and Cui, Jinqiang and Wang, Biao and Chen, Ben M.},
  year = {2022},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {3},
  pages = {6894--6901},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3177852},
  url = {https://ieeexplore.ieee.org/document/9782137},
  urldate = {2024-01-27},
  abstract = {In this letter, we present a volumetric mapping system that effectively calculates Occupancy Grid Maps (OGMs) and Euclidean Distance Transforms (EDTs) with parallel computing. Unlike these mappers for high-precision structural reconstruction, our system incrementally constructs global EDT and outputs high-frequency local distance information for online robot motion planning. The proposed system receives multiple types of sensor inputs and constructs OGM without down-sampling. Using GPU programming techniques, the system quickly computes EDT in parallel within local volume. The new observation is continuously integrated into the global EDT using the parallel wavefront algorithm while preserving the historical observations. Experiments with datasets have shown that our proposed approach outperforms existing state-of-the-art robot mapping systems and is particularly suitable for mapping unexplored areas. In its actual implementations on aerial and ground vehicles, the proposed system achieves real-time performance with limited onboard computational resources.},
  keywords = {Casting,Euclidean distance,Mapping,Mobile robots,motion and path planning,Planning,Real-time systems,Robot sensing systems,Transforms},
  file = {/Users/kshitijgoel/Zotero/storage/SAFR8V6X/Chen et al. - 2022 - GPU-Accelerated Incremental Euclidean Distance Tra.pdf;/Users/kshitijgoel/Zotero/storage/UXYT7MUK/9782137.html}
}

@inproceedings{chen_informative_2022,
  title = {Informative {{Planning}} in the {{Presence}} of {{Outliers}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Chen, Weizhe and Liu, Lantao},
  year = {2022},
  month = may,
  pages = {5311--5318},
  doi = {10.1109/ICRA46639.2022.9812267},
  abstract = {Informative planning seeks a sequence of actions that guide the robot to collect the most informative data to build a large-scale environmental model or learn a dynamical system. Existing work in informative planning mainly focuses on proposing new planners and applying them to various robotic applications such as environmental monitoring, autonomous exploration, and system identification. The informative planners optimize an objective given by a probabilistic model, e.g., Gaussian process regression (GPR). In practice, the ubiquitous sensing outliers can easily affect the model, resulting in a misleading objective. A straightforward solution is to filter out the outliers in the sensing data stream using an off-the-shelf outlier detector. However, informative samples are also scarce by definition so they might be falsely filtered out. In this paper, we propose a method to enable the robot to re-visit the locations where outliers were sampled besides optimizing the informative planning objective. The robot can collect more samples in the vicinity of outliers and update the outlier detector to reduce the number of false alarms. We achieve this by designing a new objective for the Pareto Monte Carlo tree search (MCTS). We demonstrate that the proposed framework performs better than applying an outlier detector naively.},
  keywords = {Detectors,Gaussian processes,Monte Carlo methods,Planning,Probabilistic logic,Robot sensing systems,Search problems},
  file = {/Users/kshitijgoel/Zotero/storage/YFDBQG8X/Chen and Liu - 2022 - Informative Planning in the Presence of Outliers.pdf;/Users/kshitijgoel/Zotero/storage/AU2PRQAK/9812267.html}
}

@article{chen_nonparametric_2016,
  title = {Nonparametric {{Modal Regression}}},
  author = {Chen, Yen-Chi and Genovese, Christopher R. and Tibshirani, Ryan J. and Wasserman, Larry},
  year = {2016},
  journal = {The Annals of Statistics},
  volume = {44},
  number = {2},
  eprint = {43818618},
  eprinttype = {jstor},
  pages = {489--514},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/43818618},
  urldate = {2024-04-25},
  abstract = {Modal regression estimates the local modes of the distribution of Y given X = x, instead of the mean, as in the usual regression sense, and can hence reveal important structure missed by usual regression methods. We study a simple nonparametric method for modal regression, based on a kernel density estimate (KDE) of the joint distribution of Y and X. We derive asymptotic error bounds for this method, and propose techniques for constructing confidence sets and prediction sets. The latter is used to select the smoothing bandwidth of the underlying KDE. The idea behind modal regression is connected to many others, such as mixture regression and density ridge estimation, and we discuss these ties as well.},
  file = {/Users/kshitijgoel/Zotero/storage/PD27D4DR/Chen et al. - 2016 - Nonparametric Modal Regression.pdf}
}

@article{chen_optimal_1995,
  title = {Optimal {{Rate}} of {{Convergence}} for {{Finite Mixture Models}}},
  author = {Chen, Jiahua},
  year = {1995},
  journal = {The Annals of Statistics},
  volume = {23},
  number = {1},
  eprint = {2242408},
  eprinttype = {jstor},
  pages = {221--233},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2242408},
  urldate = {2024-04-26},
  abstract = {In finite mixture models, we establish the best possible rate of convergence for estimating the mixing distribution. We find that the key for estimating the mixing distribution is the knowledge of the number of components in the mixture. While a \${\textbackslash}sqrt n\$-consistent rate is achievable when the exact number of components is known, the best possible rate is only n-1/4 when it is unknown. Under a strong identifiability condition, it is shown that this rate is reached by some minimum distance estimators. Most commonly used models are found to satisfy the strong identifiability condition.},
  file = {/Users/kshitijgoel/Zotero/storage/BLWGDP48/Chen - 1995 - Optimal Rate of Convergence for Finite Mixture Mod.pdf}
}

@misc{chen_pgsr_2024,
  title = {{{PGSR}}: {{Planar-based Gaussian Splatting}} for {{Efficient}} and {{High-Fidelity Surface Reconstruction}}},
  shorttitle = {{{PGSR}}},
  author = {Chen, Danpeng and Li, Hai and Ye, Weicai and Wang, Yifan and Xie, Weijian and Zhai, Shangjin and Wang, Nan and Liu, Haomin and Bao, Hujun and Zhang, Guofeng},
  year = {2024},
  month = jun,
  number = {arXiv:2406.06521},
  eprint = {2406.06521},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.06521},
  urldate = {2024-06-16},
  abstract = {Recently, 3D Gaussian Splatting (3DGS) has attracted widespread attention due to its high-quality rendering, and ultra-fast training and rendering speed. However, due to the unstructured and irregular nature of Gaussian point clouds, it is difficult to guarantee geometric reconstruction accuracy and multi-view consistency simply by relying on image reconstruction loss. Although many studies on surface reconstruction based on 3DGS have emerged recently, the quality of their meshes is generally unsatisfactory. To address this problem, we propose a fast planar-based Gaussian splatting reconstruction representation (PGSR) to achieve high-fidelity surface reconstruction while ensuring high-quality rendering. Specifically, we first introduce an unbiased depth rendering method, which directly renders the distance from the camera origin to the Gaussian plane and the corresponding normal map based on the Gaussian distribution of the point cloud, and divides the two to obtain the unbiased depth. We then introduce single-view geometric, multi-view photometric, and geometric regularization to preserve global geometric accuracy. We also propose a camera exposure compensation model to cope with scenes with large illumination variations. Experiments on indoor and outdoor scenes show that our method achieves fast training and rendering while maintaining high-fidelity rendering and geometric reconstruction, outperforming 3DGS-based and NeRF-based methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/PLRZ2JVK/Chen et al. - 2024 - PGSR Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction.pdf}
}

@article{chen_rast_2023,
  title = {{{RAST}}: {{Risk-Aware Spatio-Temporal Safety Corridors}} for {{MAV Navigation}} in {{Dynamic Uncertain Environments}}},
  shorttitle = {{{RAST}}},
  author = {Chen, Gang and Wu, Siyuan and Shi, Moji and Dong, Wei and Zhu, Hai and {Alonso-Mora}, Javier},
  year = {2023},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {2},
  pages = {808--815},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3231832},
  abstract = {Autonomous navigation of Micro Aerial Vehicles (MAVs) in dynamic and unknown environments is a complex and challenging task. Current works rely on assumptions to solve the problem. The MAV's pose is precisely known, the dynamic obstacles can be explicitly segmented from static ones, their number is known and fixed, or they can be modeled with given shapes. In this letter, we present a method for MAV navigation in dynamic uncertain environments without making any of these assumptions. The method employs a particle-based dynamic map to represent the local environment and predicts it to the near future. Collision risk is defined based on the predicted maps and a series of risk-aware spatio-temporal (RAST) safety corridors are constructed, which are finally used to optimize a dynamically-feasible collision-free trajectory for the MAV. We compared our method with several state-of-the-art works in 12000 simulation tests in Gazebo with the physical engine enabled. The results show that our method has the highest success rate at different uncertainty levels. Finally, we validated the proposed method in real experiments.},
  keywords = {Aerial systems,collision avoidance,Location awareness,motion and path planning,Navigation,perception and autonomy,Safety,Shape,Trajectory optimization,Uncertainty,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/IGBSY6FG/Chen et al. - 2023 - RAST Risk-Aware Spatio-Temporal Safety Corridors .pdf}
}

@misc{chen_safersplat_2024,
  title = {{{SAFER-Splat}}: {{A Control Barrier Function}} for {{Safe Navigation}} with {{Online Gaussian Splatting Maps}}},
  shorttitle = {{{SAFER-Splat}}},
  author = {Chen, Timothy and Swann, Aiden and Yu, Javier and Shorinwa, Ola and Murai, Riku and Kennedy III, Monroe and Schwager, Mac},
  year = {2024},
  month = sep,
  number = {arXiv:2409.09868},
  eprint = {2409.09868},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.09868},
  urldate = {2024-09-20},
  abstract = {SAFER-Splat (Simultaneous Action Filtering and Environment Reconstruction) is a real-time, scalable, and minimally invasive action filter, based on control barrier functions, for safe robotic navigation in a detailed map constructed at runtime using Gaussian Splatting (GSplat). We propose a novel Control Barrier Function (CBF) that not only induces safety with respect to all Gaussian primitives in the scene, but when synthesized into a controller, is capable of processing hundreds of thousands of Gaussians while maintaining a minimal memory footprint and operating at 15 Hz during online Splat training. Of the total compute time, a small fraction of it consumes GPU resources, enabling uninterrupted training. The safety layer is minimally invasive, correcting robot actions only when they are unsafe. To showcase the safety filter, we also introduce SplatBridge, an open-source software package built with ROS for real-time GSplat mapping for robots. We demonstrate the safety and robustness of our pipeline first in simulation, where our method is 20-50x faster, safer, and less conservative than competing methods based on neural radiance fields. Further, we demonstrate simultaneous GSplat mapping and safety filtering on a drone hardware platform using only on-board perception. We verify that under teleoperation a human pilot cannot invoke a collision. Our videos and codebase can be found at https://chengine.github.io/safer-splat.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/MGGQEZC7/Chen et al. - 2024 - SAFER-Splat A Control Barrier Function for Safe Navigation with Online Gaussian Splatting Maps.pdf}
}

@article{chen_scalable_2013,
  title = {Scalable Real-Time Volumetric Surface Reconstruction},
  author = {Chen, Jiawen and Bautembach, Dennis and Izadi, Shahram},
  year = {2013},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {4},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2461912.2461940},
  url = {https://dl.acm.org/doi/10.1145/2461912.2461940},
  urldate = {2022-04-03},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3XC7NLZD/Chen et al. - 2013 - Scalable real-time volumetric surface reconstructi.pdf}
}

@article{chen_splatnav_2025,
  title = {Splat-{{Nav}}: {{Safe Real-Time Robot Navigation}} in {{Gaussian Splatting Maps}}},
  shorttitle = {Splat-{{Nav}}},
  author = {Chen, Timothy and Shorinwa, Ola and Bruno, Joseph and Swann, Aiden and Yu, Javier and Zeng, Weijia and Nagami, Keiko and Dames, Philip and Schwager, Mac},
  year = {2025},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2025.3552348},
  url = {https://ieeexplore.ieee.org/document/10930696/},
  urldate = {2025-04-16},
  abstract = {We present Splat-Nav, a real-time robot navigation pipeline for Gaussian Splatting (GSplat) scenes, a powerful new 3D scene representation. Splat-Nav consists of two components: 1) Splat-Plan, a safe planning module, and 2) Splat-Loc, a robust vision-based pose estimation module. Splat-Plan builds a safe-by-construction polytope corridor through the map based on mathematically rigorous collision constraints and then constructs a B{\'e}zier curve trajectory through this corridor. Splat-Loc provides real-time recursive state estimates given only an RGB feed from an on-board camera, leveraging the point-cloud representation inherent in GSplat scenes. Working together, these modules give robots the ability to recursively re-plan smooth and safe trajectories to goal locations. Goals can be specified with position coordinates, or with language commands by using a semantic GSplat. We demonstrate improved safety compared to point cloud-based methods in extensive simulation experiments. In a total of 126 hardware flights, we demonstrate equivalent safety and speed compared to motion capture and visual odometry, but without a manual frame alignment required by those methods. We show online re-planning at more than 2 Hz and pose estimation at about 25 Hz, an order of magnitude faster than Neural Radiance Field (NeRF)-based navigation methods, thereby enabling real-time navigation. We provide experiment videos on our project page at https://chengine.github.io/splatnav/. Our codebase and ROS nodes can be found at https://github.com/chengine/splatnav.},
  keywords = {Cameras,Collision avoidance,Collision Avoidance,Localization,Location awareness,Navigation,Neural radiance field,Planning,Real-time systems,Robots,Three-dimensional displays,Trajectory,Vision-Based Navigation},
  file = {/Users/kshitijgoel/Zotero/storage/V5X98LPB/Chen et al. - 2025 - Splat-Nav Safe Real-Time Robot Navigation in Gaussian Splatting Maps.pdf}
}

@misc{chen_surgicalgs_2024,
  title = {{{SurgicalGS}}: {{Dynamic 3D Gaussian Splatting}} for {{Accurate Robotic-Assisted Surgical Scene Reconstruction}}},
  shorttitle = {{{SurgicalGS}}},
  author = {Chen, Jialei and Zhang, Xin and Islam, Mobarakol and Vasconcelos, Francisco and Stoyanov, Danail and Elson, Daniel S. and Huang, Baoru},
  year = {2024},
  month = oct,
  number = {arXiv:2410.09292},
  eprint = {2410.09292},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.09292},
  urldate = {2024-11-10},
  abstract = {Accurate 3D reconstruction of dynamic surgical scenes from endoscopic video is essential for robotic-assisted surgery. While recent 3D Gaussian Splatting methods have shown promise in achieving high-quality reconstructions with fast rendering speeds, their use of inverse depth loss functions compresses depth variations. This can lead to a loss of fine geometric details, limiting their ability to capture precise 3D geometry and effectiveness in intraoperative application. To address these challenges, we present SurgicalGS, a dynamic 3D Gaussian Splatting framework specifically designed for surgical scene reconstruction with improved geometric accuracy. Our approach first initialises a Gaussian point cloud using depth priors, employing binary motion masks to identify pixels with significant depth variations and fusing point clouds from depth maps across frames for initialisation. We use the Flexible Deformation Model to represent dynamic scene and introduce a normalised depth regularisation loss along with an unsupervised depth smoothness constraint to ensure more accurate geometric reconstruction. Extensive experiments on two real surgical datasets demonstrate that SurgicalGS achieves state-of-the-art reconstruction quality, especially in terms of accurate geometry, advancing the usability of 3D Gaussian Splatting in robotic-assisted surgery.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/JEMQXCAH/Chen et al. - 2024 - SurgicalGS Dynamic 3D Gaussian Splatting for Accurate Robotic-Assisted Surgical Scene Reconstructio.pdf;/Users/kshitijgoel/Zotero/storage/GW5MHWJD/2410.html}
}

@misc{chen_survey_2024,
  title = {A {{Survey}} on {{3D Gaussian Splatting}}},
  author = {Chen, Guikun and Wang, Wenguan},
  year = {2024},
  month = jul,
  number = {arXiv:2401.03890},
  eprint = {2401.03890},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2401.03890},
  urldate = {2024-08-22},
  abstract = {3D Gaussian splatting (GS) has recently emerged as a transformative technique in the realm of explicit radiance field and computer graphics. This innovative approach, characterized by the utilization of millions of learnable 3D Gaussians, represents a significant departure from mainstream neural radiance field approaches, which predominantly use implicit, coordinate-based models to map spatial coordinates to pixel values. 3D GS, with its explicit scene representation and differentiable rendering algorithm, not only promises real-time rendering capability but also introduces unprecedented levels of editability. This positions 3D GS as a potential game-changer for the next generation of 3D reconstruction and representation. In the present paper, we provide the first systematic overview of the recent developments and critical contributions in the domain of 3D GS. We begin with a detailed exploration of the underlying principles and the driving forces behind the emergence of 3D GS, laying the groundwork for understanding its significance. A focal point of our discussion is the practical applicability of 3D GS. By enabling unprecedented rendering speed, 3D GS opens up a plethora of applications, ranging from virtual reality to interactive media and beyond. This is complemented by a comparative analysis of leading 3D GS models, evaluated across various benchmark tasks to highlight their performance and practical utility. The survey concludes by identifying current challenges and suggesting potential avenues for future research in this domain. Through this survey, we aim to provide a valuable resource for both newcomers and seasoned researchers, fostering further exploration and advancement in applicable and explicit radiance field representation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Multimedia},
  file = {/Users/kshitijgoel/Zotero/storage/AAFKTMIA/Chen and Wang - 2024 - A Survey on 3D Gaussian Splatting.pdf}
}

@article{cheng_mean_1995,
  title = {Mean Shift, Mode Seeking, and Clustering},
  author = {Cheng, Yizong},
  year = {1995},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {17},
  number = {8},
  pages = {790--799},
  issn = {1939-3539},
  doi = {10.1109/34.400568},
  url = {https://ieeexplore.ieee.org/document/400568},
  urldate = {2024-11-15},
  abstract = {Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed in the paper. This generalization makes some k-means like clustering algorithms its special cases. It is shown that mean shift is a mode-seeking process on the surface constructed with a "shadow" kernal. For Gaussian kernels, mean shift is a gradient mapping. Convergence is studied for mean shift iterations. Cluster analysis if treated as a deterministic problem of finding a fixed point of mean shift that characterizes the data. Applications in clustering and Hough transform are demonstrated. Mean shift is also considered as an evolutionary strategy that performs multistart global optimization.{$<>$}},
  keywords = {Algorithm design and analysis,Clustering algorithms,Computer science,Convergence,Iterative algorithms,Kernel,Surface treatment},
  file = {/Users/kshitijgoel/Zotero/storage/JAWK39F8/Cheng - 1995 - Mean shift, mode seeking, and clustering.pdf;/Users/kshitijgoel/Zotero/storage/D9BFPWLB/400568.html}
}

@inproceedings{cheng_realtime_2022,
  title = {Real-{{Time Trajectory Planning}} for {{Autonomous Driving}} with {{Gaussian Process}} and {{Incremental Refinement}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Cheng, Jie and Chen, Yingbing and Zhang, Qingwen and Gan, Lu and Liu, Chengju and Liu, Ming},
  year = {2022},
  month = may,
  pages = {8999--9005},
  doi = {10.1109/ICRA46639.2022.9812405},
  abstract = {Real-time kinodynamic trajectory planning in dy-namic environments is critical yet challenging for autonomous driving. In this paper, we propose an efficient trajectory plan-ning system for autonomous driving in complex dynamic sce-narios through iterative and incremental path-speed optimization. Exploiting the decoupled structure of the planning prob-lem, a path planner based on Gaussian process first generates a continuous arc-length parameterized path in the Fren{\'e}t frame, considering static obstacle avoidance and curvature constraints. We theoretically prove that it is a good generalization of the well-known jerk optimal solution. An efficient s-t graph search method is introduced to find a speed profile along the generated path to deal with dynamic environments. Finally, the path and speed are optimized incrementally and iteratively to ensure kinodynamic feasibility. Various simulated scenarios with both static obstacles and dynamic agents verify the effectiveness and robustness of our proposed method. Experimental results show that our method can run at 20 Hz. The source code is released as an open-source package.},
  keywords = {Gaussian processes,Probabilistic logic,Real-time systems,Robustness,Search methods,Trajectory planning,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/DIZ8L9XZ/Cheng et al. - 2022 - Real-Time Trajectory Planning for Autonomous Drivi.pdf;/Users/kshitijgoel/Zotero/storage/A2596598/9812405.html}
}

@misc{chi_safe_2024,
  title = {Safe {{Dynamic Motion Generation}} in {{Configuration Space Using Differentiable Distance Fields}}},
  author = {Chi, Xuemin and Li, Yiming and Huang, Jihao and Dai, Bolun and Liu, Zhitao and Calinon, Sylvain},
  year = {2024},
  month = dec,
  number = {arXiv:2412.16456},
  eprint = {2412.16456},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.16456},
  url = {http://arxiv.org/abs/2412.16456},
  urldate = {2024-12-31},
  abstract = {Generating collision-free motions in dynamic environments is a challenging problem for high-dimensional robotics, particularly under real-time constraints. Control Barrier Functions (CBFs), widely utilized in safety-critical control, have shown significant potential for motion generation. However, for high-dimensional robot manipulators, existing QP formulations and CBF-based methods rely on positional information, overlooking higher-order derivatives such as velocities. This limitation may lead to reduced success rates, decreased performance, and inadequate safety constraints. To address this, we construct time-varying CBFs (TVCBFs) that consider velocity conditions for obstacles. Our approach leverages recent developments on distance fields for articulated manipulators, a differentiable representation that enables the mapping of objects' position and velocity into the robot's joint space, offering a comprehensive understanding of the system's interactions. This allows the manipulator to be treated as a point-mass system thus simplifying motion generation tasks. Additionally, we introduce a time-varying control Lyapunov function (TVCLF) to enable whole-body contact motions. Our approach integrates the TVCBF, TVCLF, and manipulator physical constraints within a unified QP framework. We validate our method through simulations and comparisons with state-of-the-art approaches, demonstrating its effectiveness on a 7-axis Franka robot in real-world experiments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/IQN62N5D/Chi et al. - 2024 - Safe Dynamic Motion Generation in Configuration Space Using Differentiable Distance Fields.pdf;/Users/kshitijgoel/Zotero/storage/SG5KLLC2/2412.html}
}

@article{chiang_geometric_2005,
  title = {Geometric {{Programming}} for {{Communication Systems}}},
  author = {Chiang, Mung},
  year = {2005},
  month = jul,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {2},
  number = {1--2},
  pages = {1--154},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000005},
  url = {https://www.nowpublishers.com/article/Details/CIT-005},
  urldate = {2024-04-29},
  abstract = {Geometric Programming for Communication Systems},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QKKQH3JT/Chiang - 2005 - Geometric Programming for Communication Systems.pdf}
}

@article{chipade_aerial_2023,
  title = {Aerial {{Swarm Defense Using Interception}} and {{Herding Strategies}}},
  author = {Chipade, Vishnu S. and Panagou, Dimitra},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {3821--3837},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3292514},
  url = {https://ieeexplore.ieee.org/document/10190092},
  urldate = {2023-10-17},
  abstract = {This article presents a multimode solution to the problem of defending a circular protected area (target) from a wide range of attacks by swarms of risk-taking and/or risk-averse attacking agents (attackers). The proposed multimode solution combines two defense strategies, namely: 1) an interception strategy for a team of defenders to intercept multiple risk-taking attackers while ensuring that the defenders do not collide with each other; 2) a herding strategy to herd a swarm of risk-averse attackers to a safe area. In particular, we develop mixed integer programs (MIPs) and geometry-inspired heuristics to distribute and assign and/or reassign the defenders to interception and herding tasks under different spatiotemporal behaviors by the attackers such as splitting into smaller swarms to evade defenders easily or high-speed maneuvers by some risk-taking attackers to maximize damage to the protected area. We provide theoretical as well as numerical comparison of the computational costs of these MIPs and the heuristics, and demonstrate the overall approach in simulations.},
  keywords = {Airports,Autonomous agents,Behavioral sciences,Clustering algorithms,cooperative robots,Data structures,Games,Heuristic algorithms,multirobot systems,Robots,task assignment},
  file = {/Users/kshitijgoel/Zotero/storage/NKRNZQ7Y/Chipade and Panagou - 2023 - Aerial Swarm Defense Using Interception and Herdin.pdf;/Users/kshitijgoel/Zotero/storage/UN6URE93/Chipade and Panagou - 2023 - Aerial Swarm Defense Using Interception and Herdin.pdf;/Users/kshitijgoel/Zotero/storage/9WA4GMZE/10190092.html}
}

@incollection{chirikjian_gaussian_2009,
  title = {Gaussian {{Distributions}} and the {{Heat Equation}}},
  booktitle = {Stochastic {{Models}}, {{Information Theory}}, and {{Lie Groups}}, {{Volume}} 1: {{Classical Results}} and {{Geometric Methods}}},
  author = {Chirikjian, Gregory S.},
  editor = {Chirikjian, Gregory S.},
  year = {2009},
  series = {Applied and {{Numerical Harmonic Analysis}}},
  pages = {31--61},
  publisher = {Birkh{\"a}user},
  address = {Boston},
  doi = {10.1007/978-0-8176-4803-9_2},
  url = {https://doi.org/10.1007/978-0-8176-4803-9_2},
  urldate = {2023-10-15},
  abstract = {In this chapter the Gaussian distribution is defined and its properties are explored. The chapter starts with the definition of a Gaussian distribution on the real line. In the process of exploring the properties of the Gaussian on the line, the Fourier transform and heat equation are introduced, and their relationship to the Gaussian is developed. The Gaussian distribution in multiple dimensions is defined, as are clipped and folded versions of this distribution. Some concepts from probability and statistics such as mean, variance, marginalization, and conditioning of probability densities are introduced in a concrete way using the Gaussian as the primary example. The properties of the Gaussian distribution are fundamental to understanding the concept of white noise, which is the driving process for all of the stochastic processes studied in this book. The main things to take away from this chapter are: To become familiar with the Gaussian distribution and its properties, and to be comfortable in performing integrals involving multi-dimensional Gaussians; To become acquainted with the concepts of mean, covariance, and informationtheoretic entropy; To understand how to marginalize and convolve probability densities, to compute conditional densities, and to fold and clip Gaussians; To observe that there is a relationship between Gaussian distributions and the heat equation; To know where to begin if presented with a diffusion equation, the symmetries of which are desired.},
  isbn = {978-0-8176-4803-9},
  langid = {english},
  keywords = {Heat Equation,Marginal Density,Multivariate Gaussian Distribution,Real Line,Symmetry Analysis},
  file = {/Users/kshitijgoel/Zotero/storage/7J45ZD2U/Chirikjian - 2009 - Gaussian Distributions and the Heat Equation.pdf}
}

@book{chirikjian_stochastic_2009,
  title = {Stochastic {{Models}}, {{Information Theory}}, and {{Lie Groups}}, {{Volume}} 1: {{Classical Results}} and {{Geometric Methods}}},
  shorttitle = {Stochastic {{Models}}, {{Information Theory}}, and {{Lie Groups}}, {{Volume}} 1},
  author = {Chirikjian, Gregory S.},
  year = {2009},
  series = {Applied and {{Numerical Harmonic Analysis}}},
  publisher = {Birkh{\"a}user},
  address = {Boston},
  doi = {10.1007/978-0-8176-4803-9},
  url = {https://link.springer.com/10.1007/978-0-8176-4803-9},
  urldate = {2023-10-15},
  isbn = {978-0-8176-4802-2 978-0-8176-4803-9},
  langid = {english},
  keywords = {communication,differentiable manifolds,diffusion processes motion groups,Fokker-Planck equation,Gaussian Distributions Heat Equ,information,information theory,noncommutative harmonic analysis,phase noise,probability theory in Euclidean space,stochastic models information theory Lie groups},
  file = {/Users/kshitijgoel/Zotero/storage/8Q47HAA8/Chirikjian - 2009 - Stochastic Models, Information Theory, and Lie Gro.pdf}
}

@book{chirikjian_stochastic_2012,
  title = {Stochastic {{Models}}, {{Information Theory}}, and {{Lie Groups}}, {{Volume}} 2: {{Analytic Methods}} and {{Modern Applications}}},
  shorttitle = {Stochastic {{Models}}, {{Information Theory}}, and {{Lie Groups}}, {{Volume}} 2},
  author = {Chirikjian, Gregory S.},
  year = {2012},
  series = {Applied and {{Numerical Harmonic Analysis}}},
  publisher = {Birkh{\"a}user Boston},
  address = {Boston},
  doi = {10.1007/978-0-8176-4944-9},
  url = {https://link.springer.com/10.1007/978-0-8176-4944-9},
  urldate = {2024-04-23},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-0-8176-4943-2 978-0-8176-4944-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IVABA2SM/Chirikjian - 2012 - Stochastic Models, Information Theory, and Lie Gro.pdf}
}

@inproceedings{chiuso_visual_1998,
  title = {Visual Tracking of Points as Estimation on the Unit Sphere},
  booktitle = {The Confluence of Vision and Control},
  author = {Chiuso, Alessandro and Picci, Giorgio},
  editor = {Kriegman, David J. and Hager, Gregory D. and Morse, A. Stephen},
  year = {1998},
  pages = {90--105},
  publisher = {Springer},
  address = {London},
  doi = {10.1007/BFb0109665},
  abstract = {In this paper we consider the problem of estimating the direction of points moving in space from noisy projections. This problem occurs in computer vision and has traditionally been treated by ad hoc statistical methods in the literature. We formulate it as a Bayesian estimation problem on the unit sphere and we discuss a natural probabilistic structure which makes this estimation problem tractable. Exact recursive solutions are given for sequential observations of a fixed target point, while for a moving object we provide optimal approximate solutions which are very simple and similar to the Kalman Filter recursions. We believe that the proposed method has a potential for generalization to more complicated situations. These include situations where the observed object is formed by a set of rigidly connected feature points of a scene in relative motion with respect to the observer or the case where we may want to track a moving straight line, a moving plane or points constrained on a plane, or, more generally, points belonging to some smooth curve or surface moving in {$\mathbb{R}$}3. These problems have a more complicate geometric structure which we plan to analyze in future work. Here, rather than the geometry, we shall concentrate on the fundamental statistical aspects of the problem.},
  isbn = {978-1-84628-528-8},
  langid = {english},
  keywords = {Conditional Density,Optimal Approximate Solution,Random Rotation,Unit Sphere,Visual Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/ZA82J2WW/Chiuso and Picci - 1998 - Visual tracking of points as estimation on the unit sphere.pdf}
}

@misc{cho_learning_2014,
  title = {Learning {{Phrase Representations}} Using {{RNN Encoder-Decoder}} for {{Statistical Machine Translation}}},
  author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  year = {2014},
  month = sep,
  number = {arXiv:1406.1078},
  eprint = {1406.1078},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1406.1078},
  url = {http://arxiv.org/abs/1406.1078},
  urldate = {2024-12-10},
  abstract = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/M84LZLKB/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.pdf;/Users/kshitijgoel/Zotero/storage/TB6PAQZP/1406.html}
}

@article{choi_continuous_2009,
  title = {Continuous {{Collision Detection}} for {{Ellipsoids}}},
  author = {Choi, Yi-King and Chang, Jung-Woo and Wang, Wenping and Kim, Myung-Soo and Elber, Gershon},
  year = {2009},
  month = mar,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {15},
  number = {2},
  pages = {311--325},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2008.80},
  url = {https://ieeexplore.ieee.org/abstract/document/4522546},
  urldate = {2024-10-26},
  abstract = {We present an accurate and efficient algorithm for continuous collision detection between two moving ellipsoids. We start with a highly optimized implementation of interference testing between two stationary ellipsoids based on an algebraic condition described in terms of the signs of roots of the characteristic equation of two ellipsoids. Then we derive a time-dependent characteristic equation for two moving ellipsoids, which enables us to develop a real-time algorithm for computing the time intervals in which two moving ellipsoids collide. The effectiveness of our approach is demonstrated with several practical examples.},
  keywords = {Charge coupled devices,Computational Geometry and Object Modeling,Computational modeling,Ellipsoids,Equations,Interference,Motion detection,Object detection,Physics computing,Robots,Testing,Three-Dimensional Graphics and Realism},
  file = {/Users/kshitijgoel/Zotero/storage/22UJ5FPY/Choi et al. - 2009 - Continuous Collision Detection for Ellipsoids.pdf}
}

@inproceedings{choi_efficient_2021,
  title = {Efficient {{Multimodal Belief Propagation}} for {{Robust SLAM Using Clustering Based Reparameterization}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Choi, Seungwon and Kim, Tae-Wan},
  year = {2021},
  month = sep,
  pages = {3354--3360},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/IROS51168.2021.9636040},
  url = {https://ieeexplore.ieee.org/document/9636040/},
  urldate = {2024-06-23},
  abstract = {Due to the presence of ambiguities caused by sensor noise and structural similarity, simultaneous localization and mapping (SLAM) observation models are typically multimodal. The multimodal inference process can be directly dealt with by belief propagation (BP) using weighted Gaussian mixture messages, but for efficiency, a combinatorial explosion of the complexity must be suitably relaxed. In this study, we present an effective multimodal BP SLAM for robust inference with ambiguities. Using Gaussian bandwidth mean shift and cluster-based reparameterization, we reduce the number of Gaussian components in each message due to the BP nature. The proposed algorithm reduces the number of components of the product by summarizing indistinguishable modes in weighted Gaussian mixtures and keeping only the significant modes, making BP computationally efficient.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-6654-1714-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MJVCZ8GD/Choi and Kim - 2021 - Efficient Multimodal Belief Propagation for Robust SLAM Using Clustering Based Reparameterization.pdf}
}

@misc{choi_meshgs_2024,
  title = {{{MeshGS}}: {{Adaptive Mesh-Aligned Gaussian Splatting}} for {{High-Quality Rendering}}},
  shorttitle = {{{MeshGS}}},
  author = {Choi, Jaehoon and Lee, Yonghan and Lee, Hyungtae and Kwon, Heesung and Manocha, Dinesh},
  year = {2024},
  month = oct,
  number = {arXiv:2410.08941},
  eprint = {2410.08941},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.08941},
  urldate = {2024-10-15},
  abstract = {Recently, 3D Gaussian splatting has gained attention for its capability to generate high-fidelity rendering results. At the same time, most applications such as games, animation, and AR/VR use mesh-based representations to represent and render 3D scenes. We propose a novel approach that integrates mesh representation with 3D Gaussian splats to perform high-quality rendering of reconstructed real-world scenes. In particular, we introduce a distance-based Gaussian splatting technique to align the Gaussian splats with the mesh surface and remove redundant Gaussian splats that do not contribute to the rendering. We consider the distance between each Gaussian splat and the mesh surface to distinguish between tightly-bound and loosely-bound Gaussian splats. The tightly-bound splats are flattened and aligned well with the mesh geometry. The loosely-bound Gaussian splats are used to account for the artifacts in reconstructed 3D meshes in terms of rendering. We present a training strategy of binding Gaussian splats to the mesh geometry, and take into account both types of splats. In this context, we introduce several regularization techniques aimed at precisely aligning tightly-bound Gaussian splats with the mesh surface during the training process. We validate the effectiveness of our method on large and unbounded scene from mip-NeRF 360 and Deep Blending datasets. Our method surpasses recent mesh-based neural rendering techniques by achieving a 2dB higher PSNR, and outperforms mesh-based Gaussian splatting methods by 1.3 dB PSNR, particularly on the outdoor mip-NeRF 360 dataset, demonstrating better rendering quality. We provide analyses for each type of Gaussian splat and achieve a reduction in the number of Gaussian splats by 30\% compared to the original 3D Gaussian splatting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/Q7SJRVHV/Choi et al. - 2024 - MeshGS Adaptive Mesh-Aligned Gaussian Splatting for High-Quality Rendering.pdf;/Users/kshitijgoel/Zotero/storage/TWKUFBRP/2410.html}
}

@inproceedings{choi_robust_2015,
  title = {Robust {{Reconstruction}} of {{Indoor Scenes}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Choi, Sungjoon and Zhou, Qian-Yi and Koltun, Vladlen},
  year = {2015},
  pages = {5556--5565},
  url = {https://openaccess.thecvf.com/content_cvpr_2015/html/Choi_Robust_Reconstruction_of_2015_CVPR_paper.html},
  urldate = {2022-06-11},
  file = {/Users/kshitijgoel/Zotero/storage/CBR2M4MX/Choi et al. - 2015 - Robust Reconstruction of Indoor Scenes.pdf;/Users/kshitijgoel/Zotero/storage/NI26NKJM/Choi_Robust_Reconstruction_of_2015_CVPR_paper.html}
}

@article{choudhury_datadriven_2018,
  title = {Data-Driven Planning via Imitation Learning},
  author = {Choudhury, Sanjiban and Bhardwaj, Mohak and Arora, Sankalp and Kapoor, Ashish and Ranade, Gireeja and Scherer, Sebastian and Dey, Debadeepta},
  year = {2018},
  month = dec,
  journal = {The International Journal of Robotics Research},
  volume = {37},
  number = {13-14},
  pages = {1632--1672},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364918781001},
  url = {https://doi.org/10.1177/0278364918781001},
  urldate = {2023-04-28},
  abstract = {Robot planning is the process of selecting a sequence of actions that optimize for a task=specific objective. For instance, the objective for a navigation task would be to find collision-free paths, whereas the objective for an exploration task would be to map unknown areas. The optimal solutions to such tasks are heavily influenced by the implicit structure in the environment, i.e. the configuration of objects in the world. State-of-the-art planning approaches, however, do not exploit this structure, thereby expending valuable effort searching the action space instead of focusing on potentially good actions. In this paper, we address the problem of enabling planners to adapt their search strategies by inferring such good actions in an efficient manner using only the information uncovered by the search up until that time. We formulate this as a problem of sequential decision making under uncertainty where at a given iteration a planning policy must map the state of the search to a planning action. Unfortunately, the training process for such partial-information-based policies is slow to converge and susceptible to poor local minima. Our key insight is that if we could fully observe the underlying world map, we would easily be able to disambiguate between good and bad actions. We hence present a novel data-driven imitation learning framework to efficiently train planning policies by imitating a clairvoyant oracle: an oracle that at train time has full knowledge about the world map and can compute optimal decisions. We leverage the fact that for planning problems, such oracles can be efficiently computed and derive performance guarantees for the learnt policy. We examine two important domains that rely on partial-information-based policies: informative path planning and search-based motion planning. We validate the approach on a spectrum of environments for both problem domains, including experiments on a real UAV, and show that the learnt policy consistently outperforms state-of-the-art algorithms. Our framework is able to train policies that achieve up to 39\% more reward than state-of-the art information-gathering heuristics and a 70? speedup as compared with A* on search-based planning problems. Our approach paves the way forward for applying data-driven techniques to other such problem domains under the umbrella of robot planning.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YLVL2HBJ/Choudhury et al. - 2018 - Data-driven planning via imitation learning.pdf}
}

@inproceedings{choudhury_theoretical_2015,
  title = {Theoretical {{Limits}} of {{Speed}} and {{Resolution}} for {{Kinodynamic Planning}} in a {{Poisson Forest}}},
  booktitle = {Robotics: {{Science}} and {{Systems XI}}},
  author = {Choudhury, Sanjiban and Scherer, Sebastian and Bagnell, Andrew},
  year = {2015},
  month = jul,
  volume = {11},
  url = {https://www.roboticsproceedings.org/rss11/p05.html},
  urldate = {2023-07-19},
  isbn = {978-0-9923747-1-6},
  file = {/Users/kshitijgoel/Zotero/storage/8EVFTPKM/Choudhury et al. - 2015 - Theoretical Limits of Speed and Resolution for Kin.pdf}
}

@inproceedings{chu_image_2024,
  title = {Image {{Clustering}} via the {{Priniciple}} of {{Rate Reduction}} in the {{Age}} of {{Pre-trained Models}}},
  booktitle = {International {{Conference}} on {{Learning Representations}} ({{ICLR}})},
  author = {Chu, Tianzhe and Tong, Shengbang and Ding, Tianjiao and Dai, Xili and Haeffele, Benjamin D and Vidal, Rene and Ma, Yi},
  year = {2024},
  address = {Vienna, Austria},
  url = {https://openreview.net/pdf?id=ptCIlV24YZ},
  abstract = {The advent of large pre-trained models has brought about a paradigm shift in both visual representation learning and natural language processing. However, clustering unlabeled images, as a fundamental and classic machine learning problem, still lacks an effective solution, particularly for large-scale datasets. In this paper, we propose a novel image clustering pipeline that leverages the powerful feature representation of large pre-trained models such as CLIP and cluster images effectively and efficiently at scale. We first developed a novel algorithm to estimate the number of clusters in a given dataset. We then show that the pre-trained features are significantly more structured by further optimizing the rate reduction objective. The resulting features may significantly improve the clustering accuracy, e.g., from 57\% to 66\% on ImageNet-1k. Furthermore, by leveraging CLIP's multimodality bridge between image and text, we develop a simple yet effective self-labeling algorithm that produces meaningful captions for the clusters. Through extensive experiments, we show that our pipeline works well on standard datasets such as CIFAR-10, CIFAR-100, and ImageNet-1k. It also extends to datasets that are not curated for clustering, such as LAION-Aesthetics and WikiArts. We released the code in https://github.com/LeslieTrue/CPP.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3TSI9JJC/Chu et al. - 2024 - IMAGE CLUSTERING VIA THE PRINCIPLE OF RATE REDUCTION IN THE AGE OF PRE-TRAINED MODELS.pdf}
}

@inproceedings{chuang_infoot_2023,
  title = {{{InfoOT}}: {{Information Maximizing Optimal Transport}}},
  shorttitle = {{{InfoOT}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Chuang, Ching-Yao and Jegelka, Stefanie and {Alvarez-Melis}, David},
  year = {2023},
  month = jul,
  pages = {6228--6242},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/chuang23a.html},
  urldate = {2023-07-17},
  abstract = {Optimal transport aligns samples across distributions by minimizing the transportation cost between them, e.g., the geometric distances. Yet, it ignores coherence structure in the data such as clusters, does not handle outliers well, and cannot integrate new data points. To address these drawbacks, we propose InfoOT, an information-theoretic extension of optimal transport that maximizes the mutual information between domains while minimizing geometric distances. The resulting objective can still be formulated as a (generalized) optimal transport problem, and can be efficiently solved by projected gradient descent. This formulation yields a new projection method that is robust to outliers and generalizes to unseen samples. Empirically, InfoOT improves the quality of alignments across benchmarks in domain adaptation, cross-domain retrieval, and single-cell alignment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G2GM5PPR/Chuang et al. - 2023 - InfoOT Information Maximizing Optimal Transport.pdf}
}

@article{chung_distributed_2022,
  title = {A {{Distributed Service-Matching Coverage Via Heterogeneous Agents}}},
  author = {Chung, Yi-fan and Kia, Solmaz S.},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {4400--4407},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3148472},
  abstract = {We propose a distributed deployment solution for a group of networked agents that should provide a service for a large set of targets, which densely populate a finite area. The agents are heterogeneous in the sense that their quality of service (QoS), modeled as spatial Gaussian distribution, is different. To provide the best service, the objective is to deploy the agents such that their collective QoS distribution is as close as possible to the density distribution of the targets in the sense of the Kullback-Leibler divergence (KLD) measure. We propose a distributed consensus-based expectation-maximization (EM) algorithm to estimate the target density distribution, modeled as a Gaussian mixture model (GMM). Different than the existing algorithms, our proposed distributed EM algorithm enables every agent in the network to obtain an estimate of the GMM model of the distribution of the targets even if only a subset of agents can measure the targets locally. The GMM not only gives an estimate of the targets' distribution but also clusters the targets to a set of subgroups, each of which is represented by one of the GMM's Gaussian bases. We use the KLD measure to evaluate the similarity between the QoS distribution of each agent and each Gaussian basis/cluster. A distributed assignment problem is then formulated and solved as a discrete optimal mass transport problem that allocates each agent to a target cluster by taking the KLD as the assignment cost. We demonstrate our results by a sensor deployment for event detection where the sensor's QoS is modeled as an anisotropic Gaussian distribution.},
  keywords = {distributed sensor deployment,distributed task assignment,Event detection,Gaussian distribution,Gaussian mixture model,Kullback-Leibler divergence,Monitoring,Multi-sensor deployment,Partitioning algorithms,Quality of service,Sensors,Wireless communication},
  file = {/Users/kshitijgoel/Zotero/storage/CYC3Y663/Chung and Kia - 2022 - A Distributed Service-Matching Coverage Via Hetero.pdf;/Users/kshitijgoel/Zotero/storage/PFLG6GIX/9705524.html}
}

@article{chung_survey_2018,
  title = {A {{Survey}} on {{Aerial Swarm Robotics}}},
  author = {Chung, Soon-Jo and Paranjape, Aditya Avinash and Dames, Philip and Shen, Shaojie and Kumar, Vijay},
  year = {2018},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {34},
  number = {4},
  pages = {837--855},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2857475},
  abstract = {The use of aerial swarms to solve real-world problems has been increasing steadily, accompanied by falling prices and improving performance of communication, sensing, and processing hardware. The commoditization of hardware has reduced unit costs, thereby lowering the barriers to entry to the field of aerial swarm robotics. A key enabling technology for swarms is the family of algorithms that allow the individual members of the swarm to communicate and allocate tasks amongst themselves, plan their trajectories, and coordinate their flight in such a way that the overall objectives of the swarm are achieved efficiently. These algorithms, often organized in a hierarchical fashion, endow the swarm with autonomy at every level, and the role of a human operator can be reduced, in principle, to interactions at a higher level without direct intervention. This technology depends on the clever and innovative application of theoretical tools from control and estimation. This paper reviews the state of the art of these theoretical tools, specifically focusing on how they have been developed for, and applied to, aerial swarms. Aerial swarms differ from swarms of ground-based vehicles in two respects: they operate in a three-dimensional space and the dynamics of individual vehicles adds an extra layer of complexity. We review dynamic modeling and conditions for stability and controllability that are essential in order to achieve cooperative flight and distributed sensing. The main sections of this paper focus on major results covering trajectory generation, task allocation, adversarial control, distributed sensing, monitoring, and mapping. Wherever possible, we indicate how the physics and subsystem technologies of aerial robots are brought to bear on these individual areas.},
  keywords = {Aerial robotics,distributed robot systems,Mathematical model,networked robots,Planning,Robot kinematics,Robot sensing systems,Unmanned aerial vehicles,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/YEZZQ7JS/Chung et al. - 2018 - A Survey on Aerial Swarm Robotics.pdf;/Users/kshitijgoel/Zotero/storage/B3QBQJ38/stamp.html}
}

@incollection{cieslewski_exploration_2022,
  title = {Exploration {{Without Global Consistency Using Local Volume Consolidation}}},
  booktitle = {Robotics {{Research}}},
  author = {Cieslewski, Titus and Ziegler, Andreas and Scaramuzza, Davide},
  editor = {Asfour, Tamim and Yoshida, Eiichi and Park, Jaeheung and Christensen, Henrik and Khatib, Oussama},
  year = {2022},
  volume = {20},
  pages = {559--574},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-95459-8_34},
  url = {https://link.springer.com/10.1007/978-3-030-95459-8_34},
  urldate = {2024-12-26},
  isbn = {978-3-030-95458-1 978-3-030-95459-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/E8H6EWBB/1909.01423}
}

@inproceedings{cieslewski_rapid_2017,
  title = {Rapid Exploration with Multi-Rotors: {{A}} Frontier Selection Method for High Speed Flight},
  shorttitle = {Rapid Exploration with Multi-Rotors},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Cieslewski, Titus and Kaufmann, Elia and Scaramuzza, Davide},
  year = {2017},
  month = sep,
  pages = {2135--2142},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8206030},
  url = {https://ieeexplore.ieee.org/document/8206030},
  urldate = {2024-11-16},
  abstract = {Exploring and mapping previously unknown environments while avoiding collisions with obstacles is a fundamental task for autonomous robots. In scenarios where this needs to be done rapidly, multi-rotors are a good choice for the task, as they can cover ground at potentially very high velocities. Flying at high velocities, however, implies the ability to rapidly plan trajectories and to react to new information quickly. In this paper, we propose an extension to classical frontier-based exploration that facilitates exploration at high speeds. The extension consists of a reactive mode in which the multi-rotor rapidly selects a goal frontier from its field of view. The goal frontier is selected in a way that minimizes the change in velocity necessary to reach it. While this approach can increase the total path length, it significantly reduces the exploration time, since the multi-rotor can fly at consistently higher speeds.},
  keywords = {Robot sensing systems,Space exploration,Trajectory,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/7RIFU6AR/Cieslewski et al. - 2017 - Rapid exploration with multi-rotors A frontier selection method for high speed flight.pdf;/Users/kshitijgoel/Zotero/storage/ARLTAXDY/8206030.html}
}

@inproceedings{cihlarova_cooperative_2024,
  title = {Cooperative {{Indoor Exploration Leveraging}} a {{Mixed-Size UAV Team}} with {{Heterogeneous Sensors}}},
  booktitle = {2024 {{IEEE}} 20th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Cihl{\'a}{\v r}ov{\'a}, Michaela and Pritzl, V{\'a}clav and Saska, Martin},
  year = {2024},
  month = aug,
  pages = {3850--3857},
  issn = {2161-8089},
  doi = {10.1109/CASE59546.2024.10711365},
  url = {https://ieeexplore.ieee.org/document/10711365/?arnumber=10711365},
  urldate = {2024-12-11},
  abstract = {Heterogeneous teams of Unmanned Aerial Vehicles (UAVs) can enhance the exploration capabilities of aerial robots by exploiting different strengths and abilities of varying UAVs. This paper presents a novel method for exploring unknown indoor spaces with a team of UAVs of different sizes and sensory equipment. We propose a frontier-based exploration with two task allocation strategies: a greedy strategy that assigns Points of Interest (POIs) based on Euclidean distance and UAV priority and an optimization strategy that solves a minimum-cost flow problem. The proposed method utilizes the SphereMap algorithm to assess the accessibility of the POIs and generate paths that account for obstacle distances, including collision avoidance maneuvers among UAVs. The proposed approach was validated through simulation testing and real-world experiments that evaluated the method's performance on board the UAVs.The paper is supported by the multimedia materials available at https://mrs.felk.cvut.cz/case2024exploration.},
  keywords = {Autonomous aerial vehicles,Computer aided software engineering,Euclidean distance,Location awareness,Optimization,Resource management,Robot sensing systems,Sensors,Space exploration,Testing},
  file = {/Users/kshitijgoel/Zotero/storage/775D986X/Cihlářová et al. - 2024 - Cooperative Indoor Exploration Leveraging a Mixed-Size UAV Team with Heterogeneous Sensors.pdf;/Users/kshitijgoel/Zotero/storage/LZ223VSU/10711365.html}
}

@article{clark_nonparametric_2021,
  title = {Nonparametric {{Continuous Sensor Registration}}},
  author = {Clark, William and Ghaffari, Maani and Bloch, Anthony},
  year = {2021},
  journal = {Journal of Machine Learning Research},
  volume = {22},
  number = {271},
  pages = {1--50},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v22/20-1468.html},
  urldate = {2024-12-02},
  abstract = {This paper develops a new mathematical framework that enables nonparametric joint semantic and geometric representation of continuous functions using data. The joint embedding is modeled by representing the processes in a reproducing kernel Hilbert space. The functions can be defined on arbitrary smooth manifolds where the action of a Lie group aligns them. The continuous functions allow the registration to be independent of a specific signal resolution. The framework is fully analytical with a closed-form derivation of the Riemannian gradient and Hessian. We study a more specialized but widely used case where the Lie group acts on functions isometrically. We solve the problem by maximizing the inner product between two functions defined over data, while the continuous action of the rigid body motion Lie group is captured through the integration of the flow in the corresponding Lie algebra. Low-dimensional cases are derived with numerical examples to show the generality of the proposed framework. The high-dimensional derivation for the special Euclidean group acting on the Euclidean space showcases the point cloud registration and bird's-eye view map registration abilities. An implementation of this framework for RGB-D cameras outperforms the state-of-the-art robust visual odometry and performs well in texture and structure-scarce environments.},
  file = {/Users/kshitijgoel/Zotero/storage/52ESURV7/Clark et al. - 2021 - Nonparametric Continuous Sensor Registration.pdf;/Users/kshitijgoel/Zotero/storage/D75BY8FC/c-sensor-registration.html}
}

@article{clark_propeml_2022,
  title = {{{PropEM-L}}: {{Radio Propagation Environment Modeling}} and {{Learning}} for {{Communication-Aware Multi-Robot Exploration}}},
  shorttitle = {{{PropEM-L}}},
  author = {Clark, Lillian and Edlund, Jeffrey A. and Net, Marc Sanchez and Vaquero, Tiago Stegun and {Agha-mohammadi}, Ali-akbar},
  year = {2022},
  month = may,
  journal = {arXiv:2205.01267 [cs]},
  eprint = {2205.01267},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2205.01267},
  urldate = {2022-05-11},
  abstract = {Multi-robot exploration of complex, unknown environments benefits from the collaboration and cooperation offered by inter-robot communication. Accurate radio signal strength prediction enables communication-aware exploration. Models which ignore the effect of the environment on signal propagation or rely on a priori maps suffer in unknown, communication-restricted (e.g. subterranean) environments. In this work, we present Propagation Environment Modeling and Learning (PropEM-L), a framework which leverages real-time sensor-derived 3D geometric representations of an environment to extract information about line of sight between radios and attenuating walls/obstacles in order to accurately predict received signal strength (RSS). Our data-driven approach combines the strengths of well-known models of signal propagation phenomena (e.g. shadowing, reflection, diffraction) and machine learning, and can adapt online to new environments. We demonstrate the performance of PropEM-L on a six-robot team in a communication-restricted environment with subway-like, mine-like, and cave-like characteristics, constructed for the 2021 DARPA Subterranean Challenge. Our findings indicate that PropEM-L can improve signal strength prediction accuracy by up to 44\% over a log-distance path loss model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/ITFL7NHC/Clark et al. - 2022 - PropEM-L Radio Propagation Environment Modeling a.pdf;/Users/kshitijgoel/Zotero/storage/7IF8IDMD/2205.html}
}

@inproceedings{coffin_multiagent_2022,
  title = {Multi-{{Agent Dynamic Ergodic Search}} with {{Low-Information Sensors}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Coffin, Howard and Abraham, Ian and Sartoretti, Guillaume and Dillstrom, Tyler and Choset, Howie},
  year = {2022},
  month = may,
  pages = {11480--11486},
  doi = {10.1109/ICRA46639.2022.9812037},
  abstract = {The long-term goal of this work is to enable agents with low-information sensors to perform tasks usually restricted to ones with more sophisticated, high-information sensing capabilities. Our approach is to regulate the motion of these low-information agents to obtain ``high-information'' results. As a first step, we consider a multi-agent system tasked with locating and tracking a moving target using only noisy binary sensors that measure the presence (or lack thereof) of a target in the sensor's field of view. To generate effective paths for these agents, we use ergodic trajectory optimization with a novel mutual information map that is fast to compute and can handle the discontinuous measurement models often associated with low-information sensing. We compare our approach with existing motion planning methods in multiple simulated experiments. Our experiments show that agents using our method outperform purely coverage-based approaches as well as naive ergodic approaches.},
  keywords = {Noise measurement,Planning,Robot sensing systems,Sensor systems,Target tracking,Task analysis,Velocity measurement},
  file = {/Users/kshitijgoel/Zotero/storage/CFFZH9YT/Coffin et al. - 2022 - Multi-Agent Dynamic Ergodic Search with Low-Inform.pdf;/Users/kshitijgoel/Zotero/storage/DC7E27M5/9812037.html}
}

@misc{cohn_active_1996,
  title = {Active {{Learning}} with {{Statistical Models}}},
  author = {Cohn, D. A. and Ghahramani, Z. and Jordan, M. I.},
  year = {1996},
  month = mar,
  number = {arXiv:cs/9603104},
  eprint = {cs/9603104},
  publisher = {arXiv},
  doi = {10.48550/arXiv.cs/9603104},
  url = {http://arxiv.org/abs/cs/9603104},
  urldate = {2025-02-12},
  abstract = {For many types of machine learning algorithms, one can compute the statistically `optimal' way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/kshitijgoel/Zotero/storage/ULJ3TLEH/Cohn et al. - 1996 - Active Learning with Statistical Models.pdf;/Users/kshitijgoel/Zotero/storage/64PGCKT2/9603104.html}
}

@inproceedings{collins_efficient_2020,
  title = {Efficient {{Planning}} for {{High-Speed MAV Flight}} in {{Unknown Environments Using Online Sparse Topological Graphs}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Collins, Matthew and Michael, Nathan},
  year = {2020},
  month = may,
  pages = {11450--11456},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9197167},
  abstract = {Safe high-speed autonomous navigation for MAVs in unknown environments requires fast planning to enable the robot to adapt and react quickly to incoming information about obstacles within the world. Furthermore, when operating in environments not known a priori, the robot may make decisions that lead to dead ends, necessitating global replanning through a map of the environment outside of a local planning grid. This work proposes a computationally-efficient planning architecture for safe high-speed operation in unknown environments that incorporates a notion of longer-term memory into the planner enabling the robot to accurately plan to locations no longer contained within a local map. A motion primitive-based local receding horizon planner that uses a probabilistic collision avoidance methodology enables the robot to generate safe plans at fast replan rates. To provide global guidance, a memory-efficient sparse topological graph is created online from a time history of the robot's path and a geometric notion of visibility within the environment to search for alternate pathways towards the desired goal if a dead end is encountered. The safety and performance of the proposed planning system is evaluated at speeds up to 10m/s, and the approach is tested in a set of large-scale, complex simulation environments containing dead ends. These scenarios lead to failure cases for competing methods; however, the proposed approach enables the robot to safely reroute and reach the desired goal.},
  keywords = {Collision avoidance,Libraries,Planning,Robot sensing systems,Safety,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/6FK6YMGI/Collins and Michael - 2020 - Efficient Planning for High-Speed MAV Flight in Un.pdf;/Users/kshitijgoel/Zotero/storage/TPUUQBBV/9197167.html}
}

@phdthesis{collins_model_1993,
  title = {Model Acquisition Using Stochastic Projective Geometry},
  author = {Collins, Robert Thomas},
  year = {1993},
  address = {United States -- Massachusetts},
  url = {https://www.proquest.com/docview/304057570/abstract/A97A029DC30747BAPQ/1},
  urldate = {2024-06-28},
  abstract = {This thesis presents a methodology for scene reconstruction that is based on the principles of projective geometry, while dealing with uncertainty at a fundamental level. Uncertainty in geometric features is represented and manipulated using probability density functions on projective space, allowing geometric constructions to be carried out via statistical inference. The main contribution of this thesis is the development of stochastic projective geometry, a formalism for performing uncertain geometric reasoning during the scene reconstruction process. The homogeneous coordinates of points and lines in the projective plane are represented by antipodal pairs of points on the unit sphere, and geometric uncertainty in their location is represented using Bingham's distribution. Geometric reasoning about homogeneous coordinate vectors reduces to well-defined manipulations on probability density functions. For example, a Bayesian approach to evidence combination on the sphere is presented for fusing noisy homogeneous coordinate observations constrained by known projective incidence relations. The result is an uncertainty calculus in projective space analogous to the Gaussian uncertainty calculus in affine space. The main strength of the Gaussian calculus is maintained, namely its uniform treatment of uncertainty in stages of the geometric reasoning process. At the same time, the limitations of the Gaussian density function as a representation of uncertainty in projective space are removed. The effectiveness of stochastic projective geometry for dealing with noisy projective relationships is demonstrated on three geometric vision problems: deriving line and plane orientations using vanishing point analysis, partitioning scene features into planar patches using line correspondence stereo, and extending a partial model of planar surface structure using projective invariants.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798208683651},
  langid = {english},
  school = {University of Massachusetts Amherst},
  keywords = {Applied sciences,scene reconstruction},
  file = {/Users/kshitijgoel/Zotero/storage/JKHTALGM/Collins - Model acquisition using stochastic projective geometry.pdf}
}

@article{comaniciu_algorithm_2003,
  title = {An Algorithm for Data-Driven Bandwidth Selection},
  author = {Comaniciu, D.},
  year = {2003},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {25},
  number = {2},
  pages = {281--288},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2003.1177159},
  url = {https://ieeexplore.ieee.org/document/1177159},
  urldate = {2024-06-03},
  abstract = {The analysis of a feature space that exhibits multiscale patterns often requires kernel estimation techniques with locally adaptive bandwidths, such as the variable-bandwidth mean shift. Proper selection of the kernel bandwidth is, however, a critical step for superior space analysis and partitioning. This paper presents a mean shift-based approach for local bandwidth selection in the multimodal, multivariate case. The method is based on a fundamental property of normal distributions regarding the bias of the normalized density gradient. This paper demonstrates that, within the large sample approximation, the local covariance is estimated by the matrix that maximizes the magnitude of the normalized mean shift vector. Using this property, the paper develops a reliable algorithm which takes into account the stability of local bandwidth estimates across scales. The validity of the theoretical results is proven in various space partitioning experiments involving the variable-bandwidth mean shift.},
  keywords = {Bandwidth,Computer vision,Covariance matrix,Gaussian distribution,Kernel,Partitioning algorithms,Pattern analysis,Performance analysis,Stability,Statistical analysis},
  file = {/Users/kshitijgoel/Zotero/storage/CENSLC67/Comaniciu - 2003 - An algorithm for data-driven bandwidth selection.pdf;/Users/kshitijgoel/Zotero/storage/585PLUED/1177159.html}
}

@article{comaniciu_mean_2002,
  title = {Mean Shift: A Robust Approach toward Feature Space Analysis},
  shorttitle = {Mean Shift},
  author = {Comaniciu, D. and Meer, P.},
  year = {2002},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {5},
  pages = {603--619},
  issn = {01628828},
  doi = {10.1109/34.1000236},
  url = {http://ieeexplore.ieee.org/document/1000236/},
  urldate = {2022-03-19},
  file = {/Users/kshitijgoel/Zotero/storage/2W8673V3/Comaniciu and Meer - 2002 - Mean shift a robust approach toward feature space.pdf}
}

@inproceedings{comaniciu_variable_2001,
  title = {The Variable Bandwidth Mean Shift and Data-Driven Scale Selection},
  booktitle = {Proceedings {{Eighth IEEE International Conference}} on {{Computer Vision}}. {{ICCV}} 2001},
  author = {Comaniciu, D. and Ramesh, V. and Meer, P.},
  year = {2001},
  month = jul,
  volume = {1},
  pages = {438-445 vol.1},
  doi = {10.1109/ICCV.2001.937550},
  url = {https://ieeexplore.ieee.org/document/937550},
  urldate = {2024-02-23},
  abstract = {We present two solutions for the scale selection problem in computer vision. The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient. Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information. The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector. Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness.},
  keywords = {Adaptive estimation,Bandwidth,Computer vision,Data mining,Educational institutions,Image analysis,Image segmentation,Kernel,Laplace equations,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/V3Q8G6NL/Comaniciu et al. - 2001 - The variable bandwidth mean shift and data-driven .pdf;/Users/kshitijgoel/Zotero/storage/U9QLTCH5/937550.html}
}

@inproceedings{concha_dpptam_2015,
  title = {{{DPPTAM}}: {{Dense}} Piecewise Planar Tracking and Mapping from a Monocular Sequence},
  shorttitle = {{{DPPTAM}}},
  booktitle = {2015 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Concha, Alejo and Civera, Javier},
  year = {2015},
  month = sep,
  pages = {5686--5693},
  doi = {10.1109/IROS.2015.7354184},
  url = {https://ieeexplore.ieee.org/abstract/document/7354184},
  urldate = {2025-01-09},
  abstract = {This paper proposes a direct monocular SLAM algorithm that estimates a dense reconstruction of a scene in real-time on a CPU. Highly textured image areas are mapped using standard direct mapping techniques [1], that minimize the photometric error across different views. We make the assumption that homogeneous-color regions belong to approximately planar areas. Our contribution is a new algorithm for the estimation of such planar areas, based on the information of a superpixel segmentation and the semidense map from highly textured areas. We compare our approach against several alternatives using the public TUM dataset [2] and additional live experiments with a hand-held camera. We demonstrate that our proposal for piecewise planar monocular SLAM is faster, more accurate and more robust than the piecewise planar baseline [3]. In addition, our experimental results show how the depth regularization of monocular maps can damage its accuracy, being the piecewise planar assumption a reasonable option in indoor scenarios.},
  keywords = {Cameras,Estimation,Image reconstruction,Robustness,Simultaneous localization and mapping,Three-dimensional displays,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/P859NMJQ/Concha and Civera - 2015 - DPPTAM Dense piecewise planar tracking and mapping from a monocular sequence.pdf;/Users/kshitijgoel/Zotero/storage/ET383G7B/7354184.html}
}

@inproceedings{connolly_determination_1985,
  title = {The Determination of next Best Views},
  booktitle = {Proceedings. 1985 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Connolly, C.},
  year = {1985},
  volume = {2},
  pages = {432--435},
  publisher = {{Institute of Electrical and Electronics Engineers}},
  address = {St. Louis, MO, USA},
  doi = {10.1109/ROBOT.1985.1087372},
  url = {http://ieeexplore.ieee.org/document/1087372/},
  urldate = {2023-10-23},
  abstract = {Therearesituations in which one would like to know a good sequence of rangeimage views for obtaining a complete model of a scene. Thipsaper describes two algorithms which use partiaolctree models to determintehe "best" next view to take.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/96GXW9KX/Connolly - 1985 - The determination of next best views.pdf}
}

@article{constantinopoulos_bayesian_2006,
  title = {Bayesian Feature and Model Selection for {{Gaussian}} Mixture Models},
  author = {Constantinopoulos, C. and Titsias, M.K. and Likas, A.},
  year = {2006},
  month = jun,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {28},
  number = {6},
  pages = {1013--1018},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2006.111},
  abstract = {We present a Bayesian method for mixture model training that simultaneously treats the feature selection and the model selection problem. The method is based on the integration of a mixture model formulation that takes into account the saliency of the features and a Bayesian approach to mixture learning that can be used to estimate the number of mixture components. The proposed learning algorithm follows the variational framework and can simultaneously optimize over the number of components, the saliency of the features, and the parameters of the mixture model. Experimental results using high-dimensional artificial and real data illustrate the effectiveness of the method.},
  keywords = {Bayesian approach,Bayesian methods,Clustering algorithms,feature selection,Mixture models,model selection,Monte Carlo methods,Optimization methods,Parameter estimation,Unsupervised learning,variational training.},
  file = {/Users/kshitijgoel/Zotero/storage/D8QZAGIR/Constantinopoulos et al. - 2006 - Bayesian feature and model selection for Gaussian .pdf;/Users/kshitijgoel/Zotero/storage/4SCTIWPV/stamp.html}
}

@article{constantinopoulos_unsupervised_2007,
  title = {Unsupervised {{Learning}} of {{Gaussian Mixtures Based}} on {{Variational Component Splitting}}},
  author = {Constantinopoulos, Constantinos and Likas, Aristidis},
  year = {2007},
  month = may,
  journal = {IEEE Transactions on Neural Networks},
  volume = {18},
  number = {3},
  pages = {745--755},
  issn = {1941-0093},
  doi = {10.1109/TNN.2006.891114},
  url = {https://ieeexplore.ieee.org/document/4182372},
  urldate = {2024-06-07},
  abstract = {In this paper, we present an incremental method for model selection and learning of Gaussian mixtures based on the recently proposed variational Bayes approach. The method adds components to the mixture using a Bayesian splitting test procedure: a component is split into two components and then variational update equations are applied only to the parameters of the two components. As a result, either both components are retained in the model or one of them is found to be redundant and is eliminated from the model. In our approach, the model selection problem is treated locally, in a region of the data space, so we can set more informative priors based on the local data distribution. A modified Bayesian mixture model is presented to implement this approach, along with a learning algorithm that iteratively applies a splitting test on each mixture component. Experimental results and comparisons with two other techniques testify for the adequacy of the proposed approach},
  keywords = {Bayesian methods,Clustering,Clustering algorithms,Computer science education,Covariance matrix,Educational programs,Equations,mixture models,model selection,Optimization methods,Stability,Testing,Unsupervised learning,variational Bayes methods},
  file = {/Users/kshitijgoel/Zotero/storage/SZCA2BUM/Constantinopoulos and Likas - 2007 - Unsupervised Learning of Gaussian Mixtures Based on Variational Component Splitting.pdf;/Users/kshitijgoel/Zotero/storage/9G7VIAWZ/4182372.html}
}

@article{corah_communicationefficient_2019,
  title = {Communication-{{Efficient Planning}} and {{Mapping}} for {{Multi-Robot Exploration}} in {{Large Environments}}},
  author = {Corah, Micah and O'Meadhra, Cormac and Goel, Kshitij and Michael, Nathan},
  year = {2019},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {2},
  pages = {1715--1721},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2897368},
  url = {https://ieeexplore.ieee.org/document/8633953},
  urldate = {2024-11-15},
  abstract = {This letter presents a framework for planning and perception for multi-robot exploration in large and unstructured three-dimensional environments. We employ a Gaussian mixture model for global mapping to model complex environment geometries while maintaining a small memory footprint which enables distributed operation with a low volume of communication. We then generate a local occupancy grid for use in planning from the Gaussian mixture model using Monte Carlo ray tracing. Then, a finite-horizon, information-based planner uses this local map and optimizes sequences of observations locally while accounting for the global distribution of information in the robot state space which we model using a library of informative views. Simulation results demonstrate that the proposed system is able to maintain efficiency and completeness in exploration while only requiring a low rate of communication.},
  keywords = {Aerial systems: perception and autonomy,Gaussian mixture model,Libraries,mapping,networked Robots,Planning,Robot kinematics,Robot sensing systems,robotic exploration},
  file = {/Users/kshitijgoel/Zotero/storage/4ERDNGTK/Corah et al. - 2019 - Communication-Efficient Planning and Mapping for Multi-Robot Exploration in Large Environments.pdf;/Users/kshitijgoel/Zotero/storage/3ZBXWRXM/8633953.html}
}

@inproceedings{corah_distributed_2018,
  title = {Distributed {{Submodular Maximization}} on {{Partition Matroids}} for {{Planning}} on {{Large Sensor Networks}}},
  booktitle = {2018 {{IEEE Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Corah, Micah and Michael, Nathan},
  year = {2018},
  month = dec,
  pages = {6792--6799},
  issn = {2576-2370},
  doi = {10.1109/CDC.2018.8619396},
  url = {https://ieeexplore.ieee.org/document/8619396},
  urldate = {2024-11-15},
  abstract = {Many problems that are relevant to sensor networks such as active sensing and coverage planning have objectives that exhibit diminishing returns and specifically are submodular. When each agent selects an action local space of actions, sequential maximization techniques for submodular function maximization obtain solutions within half of optimal even though such problems are often NP-Hard. However, adapting methods for submodular function maximization to distributed computation on sensor networks is challenging as sequential execution of planning steps is time-consuming and inefficient. Further, prior works have found that planners suffer severely impaired worst-case performance whenever large numbers of agents plan in parallel. This work develops new tools for analysis of submodular maximization problems which we apply to design of randomized distributed planners that provide constant-factor suboptimality approaching that of standard sequential planners. These bounds apply when the objective satisfies a higher-order monotonicity condition and when cumulative interactions between agents are proportional to the optimal objective value. Problems including generalizations of sensor coverage satisfy these conditions when agents have spatially local sensing actions and limited sensor range. We present simulation results for two such cases.},
  keywords = {Directed acyclic graph,Linear programming,Mutual information,Planning,Redundancy,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/9YQV3G8I/Corah and Michael - 2018 - Distributed Submodular Maximization on Partition Matroids for Planning on Large Sensor Networks.pdf}
}

@inproceedings{corah_efficient_2017,
  title = {Efficient {{Online Multi-robot Exploration}} via {{Distributed Sequential Greedy Assignment}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIII}}},
  author = {Corah, Micah and Michael, Nathan},
  year = {2017},
  month = jul,
  volume = {13},
  url = {http://www.roboticsproceedings.org/rss13/p70.html},
  urldate = {2023-02-17},
  isbn = {978-0-9923747-3-0},
  file = {/Users/kshitijgoel/Zotero/storage/NS8MR8HZ/Corah and Michael - 2017 - Efficient Online Multi-robot Exploration via Distr.pdf}
}

@phdthesis{corah_sensor_2021,
  title = {Sensor {{Planning}} for {{Large Numbers}} of {{Robots}}},
  author = {Corah, Micah},
  year = {2021},
  month = feb,
  eprint = {2102.04054},
  primaryclass = {cs, eess, math},
  url = {http://arxiv.org/abs/2102.04054},
  urldate = {2022-10-05},
  abstract = {*The following abbreviates the abstract. Please refer to the thesis for the full abstract.* After a disaster, locating and extracting victims quickly is critical because mortality rises rapidly after the first two days. To assist search and rescue teams and improve response times, teams of camera-equipped aerial robots can engage in tasks such as mapping buildings and locating victims. These sensing tasks encapsulate difficult (NP-Hard) problems. One way to simplify planning for these tasks is to focus on maximizing sensing performance over a short time horizon. Specifically, consider the problem of how to select motions for a team of robots to maximize a notion of sensing quality (the sensing objective) over the near future, say by maximizing the amount of unknown space in a map that robots will observe over the next several seconds. By repeating this process regularly, the team can react quickly to new observations as they work to complete the sensing task. In technical terms, this planning and control process forms an example of receding-horizon control. Fortunately, common sensing objectives benefit from well-known monotonicity properties (e.g. submodularity), and greedy algorithms can exploit these monotonicity properties to solve the receding-horizon optimization problems that we study near-optimally. However, greedy algorithms typically force robots to make decisions sequentially so that planning time grows with the number of robots. Further, recent works that investigate sequential greedy planning, have demonstrated that reducing the number of sequential steps while retaining suboptimality guarantees can be hard or impossible. We demonstrate that halting growth in planning time is sometimes possible. To do so, we introduce novel greedy algorithms involving fixed numbers of sequential steps.},
  archiveprefix = {arXiv},
  school = {arXiv},
  keywords = {Computer Science - Information Theory,Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
  file = {/Users/kshitijgoel/Zotero/storage/NJSNAJTU/Corah - 2021 - Sensor Planning for Large Numbers of Robots.pdf;/Users/kshitijgoel/Zotero/storage/WR3IKKVQ/2102.html}
}

@inproceedings{corah_volumetric_2021,
  title = {Volumetric {{Objectives}} for {{Multi-Robot Exploration}} of {{Three-Dimensional Environments}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Corah, Micah and Michael, Nathan},
  year = {2021},
  month = may,
  pages = {9043--9050},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561226},
  url = {https://ieeexplore.ieee.org/document/9561226/?arnumber=9561226},
  urldate = {2024-11-17},
  abstract = {Volumetric objectives for exploration and perception tasks seek to capture a sense of value (or reward) for hypothetical observations at one or more camera views for robots operating in unknown environments. For example, a volumetric objective may reward robots proportionally to the expected volume of unknown space to be observed. We identify connections between existing information-theoretic and coverage objectives in terms of expected coverage, particularly that mutual information without noise is a special case of expected coverage. Likewise, we provide the first comparison, of which we are aware, between information-based approximations and coverage objectives for exploration, and we find, perhaps surprisingly, that coverage objectives can significantly outperform information-based objectives in practice. Additionally, the analysis for information and coverage objectives demonstrates that Randomized Sequential Partitions---a method for efficient distributed sensor planning---applies for both classes of objectives, and we provide simulation results in a variety of environments for as many as 32 robots.},
  keywords = {Automation,Cameras,Conferences,Object recognition,Robot vision systems,Simulation,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/H4ECRLQU/Corah and Michael - 2021 - Volumetric Objectives for Multi-Robot Exploration of Three-Dimensional Environments.pdf;/Users/kshitijgoel/Zotero/storage/FLVGNKMJ/9561226.html}
}

@inproceedings{corduneanu_hyperparameters_2001,
  title = {Hyperparameters for {{Soft Bayesian Model Selection}}},
  booktitle = {International {{Workshop}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Corduneanu, Adrian and Bishop, Christopher M.},
  year = {2001},
  month = jan,
  pages = {63--70},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/r3/corduneanu01a.html},
  urldate = {2024-06-08},
  abstract = {Mixture models, in which a probability distribution is represented as a linear superposition of component distributions, are widely used in statistical modeling and pattern recognition. One of the ...},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/EAGQYWA2/Corduneanu and Bishop - 2001 - Hyperparameters for Soft Bayesian Model Selection.pdf}
}

@book{cormen_introduction_2022,
  title = {Introduction to Algorithms},
  author = {Cormen, Thomas H. and Leiserson, Charles Eric and Rivest, Ronald L. and Stein, Clifford},
  year = {2022},
  edition = {Fourth edition},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusett},
  abstract = {"The leading introductory textbook and reference on algorithms"--},
  isbn = {978-0-262-04630-5},
  lccn = {QA76.6 .C662 2022},
  keywords = {Computer algorithms,Computer programming},
  file = {/Users/kshitijgoel/Zotero/storage/FINT58FT/Cormen et al. - 2022 - Introduction to algorithms.pdf}
}

@book{cover_elements_2006,
  title = {Elements of {{Information Theory}} ({{Wiley Series}} in {{Telecommunications}} and {{Signal Processing}})},
  author = {Cover, Thomas M. and Thomas, Joy A.},
  year = {2006},
  publisher = {Wiley-Interscience},
  address = {USA},
  isbn = {978-0-471-24195-9}
}

@article{cramariuc_maplab_2023,
  title = {Maplab 2.0 -- {{A Modular}} and {{Multi-Modal Mapping Framework}}},
  author = {Cramariuc, Andrei and Bernreiter, Lukas and Tschopp, Florian and Fehr, Marius and Reijgwart, Victor and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
  year = {2023},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {2},
  pages = {520--527},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3227865},
  abstract = {Integration of multiple sensor modalities and deep learning into Simultaneous Localization And Mapping (SLAM) systems are areas of significant interest in current research. Multi-modality is a stepping stone towards achieving robustness in challenging environments and interoperability of heterogeneous multi-robot systems with varying sensor setups. With maplab 2.0, we provide a versatile open-source platform that facilitates developing, testing, and integrating new modules and features into a fully-fledged SLAM system. Through extensive experiments, we show that maplab 2.0's accuracy is comparable to the state-of-the-art on the HILTI 2021 benchmark. Additionally, we showcase the flexibility of our system with three use cases: i) large-scale ({\textbackslash}sim10 {\textbackslash}textkm) multi-robot multi-session (23 missions) mapping, ii) integration of non-visual landmarks, and iii) incorporating a semantic object-based loop closure module into the mapping framework.},
  keywords = {Laser radar,mapping,multi-robot SLAM,Robot sensing systems,Semantics,Servers,Simultaneous localization and mapping,SLAM,Three-dimensional displays,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/NTVKHVZI/Cramariuc et al. - 2023 - maplab 2.0 – A Modular and Multi-Modal Mapping Fra.pdf;/Users/kshitijgoel/Zotero/storage/CF4KIFFX/stamp.html}
}

@book{cramer_mathematical_1999,
  title = {Mathematical {{Methods}} of {{Statistics}} ({{PMS-9}})},
  author = {Cram{\'e}r, Harald},
  year = {1999},
  eprint = {j.ctt1bpm9r4},
  eprinttype = {jstor},
  publisher = {Princeton University Press},
  url = {https://www.jstor.org/stable/j.ctt1bpm9r4},
  urldate = {2025-06-03},
  abstract = {In this classic of statistical mathematical theory, Harald Cram{\'e}r joins the two major lines of development in the field: while British and American statisticians were developing the science of statistical inference, French and Russian probabilitists transformed the classical calculus of probability into a rigorous and pure mathematical theory. The result of Cram{\'e}r's work is a masterly exposition of the mathematical methods of modern statistics that set the standard that others have since sought to follow.  For anyone with a working knowledge of undergraduate mathematics the book is self contained. The first part is an introduction to the fundamental concept of a distribution and of integration with respect to a distribution. The second part contains the general theory of random variables and probability distributions while the third is devoted to the theory of sampling, statistical estimation, and tests of significance.},
  isbn = {978-0-691-00547-8}
}

@article{crane_geodesics_2013,
  title = {Geodesics in Heat: {{A}} New Approach to Computing Distance Based on Heat Flow},
  shorttitle = {Geodesics in Heat},
  author = {Crane, Keenan and Weischedel, Clarisse and Wardetzky, Max},
  year = {2013},
  month = oct,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {5},
  pages = {152:1--152:11},
  issn = {0730-0301},
  doi = {10.1145/2516971.2516977},
  url = {https://dl.acm.org/doi/10.1145/2516971.2516977},
  urldate = {2023-09-21},
  abstract = {We introduce the heat method for computing the geodesic distance to a specified subset (e.g., point or curve) of a given domain. The heat method is robust, efficient, and simple to implement since it is based on solving a pair of standard linear elliptic problems. The resulting systems can be prefactored once and subsequently solved in near-linear time. In practice, distance is updated an order of magnitude faster than with state-of-the-art methods, while maintaining a comparable level of accuracy. The method requires only standard differential operators and can hence be applied on a wide variety of domains (grids, triangle meshes, point clouds, etc.). We provide numerical evidence that the method converges to the exact distance in the limit of refinement; we also explore smoothed approximations of distance suitable for applications where greater regularity is required.},
  keywords = {Digital geometry processing,discrete differential geometry,distance transform,geodesic distance,heat kernel},
  file = {/Users/kshitijgoel/Zotero/storage/TMEF3LSV/Crane et al. - 2013 - Geodesics in heat A new approach to computing dis.pdf}
}

@article{crane_heat_2017,
  title = {The Heat Method for Distance Computation},
  author = {Crane, Keenan and Weischedel, Clarisse and Wardetzky, Max},
  year = {2017},
  month = oct,
  journal = {Communications of the ACM},
  volume = {60},
  number = {11},
  pages = {90--99},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3131280},
  url = {https://dl.acm.org/doi/10.1145/3131280},
  urldate = {2022-04-19},
  abstract = {We introduce the heat method for solving the single- or multiple-source shortest path problem on both flat and curved domains. A key insight is that distance computation can be split into two stages: first find the direction along which distance is increasing, then compute the distance itself. The heat method is robust, efficient, and simple to implement since it is based on solving a pair of standard sparse linear systems. These systems can be factored once and subsequently solved in near-linear time, substantially reducing amortized cost. Real-world performance is an order of magnitude faster than state-of-the-art methods, while maintaining a comparable level of accuracy. The method can be applied in any dimension, and on any domain that admits a gradient and inner product---including regular grids, triangle meshes, and point clouds. Numerical evidence indicates that the method converges to the exact distance in the limit of refinement; we also explore smoothed approximations of distance suitable for applications where greater regularity is desired.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XCJIDERJ/Crane et al. - 2017 - The heat method for distance computation.pdf}
}

@phdthesis{cristofalo_perception_2020,
  title = {Perception for {{Control}} and {{Control}} for {{Perception}} of {{Vision-Based Autonomous Aerial Robots}}},
  author = {Cristofalo, Eric},
  year = {2020},
  address = {United States -- California},
  url = {https://www.proquest.com/docview/2600829189/abstract/43038028338C4AC4PQ/1},
  urldate = {2024-02-25},
  abstract = {The mission of this thesis is to develop visual perception and feedback control algorithms for autonomous aerial robots that are equipped with an onboard camera. We introduce light-weight algorithms that parse images from the robot's camera directly into feedback signals for control laws that improve perception quality. We emphasize the co-design, analysis, and implementation of the perception, planning, and control tasks to ensure that the entire autonomy pipeline is suitable for aerial robots with real-world constraints. The methods presented in this thesis further leverage perception for control and control for perception: the former uses perception to inform the robot how to act while the later uses robotic control to improve the robot's perception of the world. Perception in this work refers to the processing of raw sensor measurements and the estimation of state values while control refers to the planning of useful robot motions and control inputs based on these state estimates. The major capability that we enable is a robot's ability to sense this unmeasured scene geometry as well as the three-dimensional (3D) robot pose from images acquired by its onboard camera. Our algorithms specifically enable a UAV with an onboard camera to use control to reconstruct the 3D geometry of its environment in a both sparse sense and a dense sense, estimate its own global pose with respect to the environment, and estimate the relative poses of other UAVs and dynamic objects of interest in the scene. All methods are implemented on real robots with real-world sensory, power, communication, and computation constraints to demonstrate the need for tightly-coupled, fast perception and control in robot autonomy. Depth estimation at specific pixel locations is often considered to be a perception-specific task for a single robot. We instead control the robot to steer a sensor to improve this depth estimation. First, we develop an active perception controller that maneuvers a quadrotor with a downward facing camera according to the gradient of maximum uncertainty reduction for a sparse subset of image features. This allows us to actively build a 3D point cloud representation of the scene quickly and thus enabling fast situational awareness for the aerial robot. Our method reduces uncertainty more quickly than state-of-the-art approaches for approximately an order of magnitude less computation time. Second, we autonomously control the focus mechanism on a camera lens to build metric-scale, dense depth maps that are suitable for robotic localization and navigation. Compared to the depth data from an off-the-shelf RGB-D sensor (Microsoft Kinect), our Depth-from-Focus method recovers the depth for 88\% of the pixels with no RGB-D measurements in near-field regime (0.0 - 0.5 meters), making it a suitable complimentary sensor for RGB-D. We demonstrate dense sensing on a ground robot localization application and with AirSim, an advanced aerial robot simulator. We then consider applications where groups of aerial robots with monocular cameras seek to estimate their pose, or position and orientation, in the environment. Examples include formation control, target tracking, drone racing, and pose graph optimization. Here, we employ ideas from control theory to perform the pose estimation. We first propose the tight-coupling of pairwise relative pose estimation with cooperative control methods for distributed formation control using quadrotors with downward facing cameras, target tracking in a heterogenous robot system, and relative pose estimation for competitive drone racing. We experimentally validate all methods with real-time perception and control implementations. Finally, we develop a distributed pose graph optimization method for networks of robots with noisy relative pose measurements. Unlike existing pose graph optimization methods, our method is inspired by control theoretic approaches to distributed formation control. We leverage tools from Lyapunov theory and multi-agent consensus to derive a relative pose estimation algorithm with provable performance guarantees. Our method also reaches consensus 13x faster than a state-of-the-art centralized strategy and reaches solutions that are approximately 6x more accurate than decentralized pose estimation methods. While the computation times between our method and the benchmarch distributed method are similar for small networks, ours outperforms the benchmark by a factor of 100 on networks with large numbers of robots ({$>$} 1000). Our approach is easy to implement and fast, making it suitable for a distributed backend in a SLAM application. Our methods will ultimately allow micro aerial vehicles to perform more complicated tasks. Our focus on tightly-coupled perception and control leads to algorithms that are streamlined for real aerial robots with real constraints. These robots will be more flexible for applications including infrastructure inspection, automated farming, and cinematography. Our methods will also enable more robot-to-robot collaboration since we present effective ways to estimate the relative pose between them. Multi-robot systems will be an important part of the robotic future as they are robust to the failure of individual robots and allow complex computation to be distributed amongst the agents. Most of all, our methods allow robots to be more self sufficient by utilizing their onboard camera and by accurately estimating the world's structure. We believe these methods will enable aerial robots to better understand our 3D world.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798494461766},
  langid = {english},
  school = {Stanford University},
  keywords = {Cameras,Computer science,Equilibrium,Localization,Optimization algorithms,Robotics,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/KMMMKW8Y/Cristofalo - 2020 - Perception for Control and Control for Perception .pdf}
}

@techreport{csikos_problems_2020,
  title = {Problems and {{Exercises}} in {{Classical Differential Geometry}}},
  author = {Csik{\'o}s, Bal{\'a}zs},
  year = {2020},
  address = {Budapest, Hungary},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/A5IVX8XP/Moussong - Made within the framework of the project Nr. EFOP-3.4.3-16-2016-00011, entitled “A fels˝ooktat´as ho.pdf}
}

@article{csiszar_information_2004,
  title = {Information {{Theory}} and {{Statistics}}: {{A Tutorial}}},
  shorttitle = {Information {{Theory}} and {{Statistics}}},
  author = {Csisz{\'a}r, I. and Shields, P. C.},
  year = {2004},
  month = dec,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {1},
  number = {4},
  pages = {417--528},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000004},
  url = {https://www.nowpublishers.com/article/Details/CIT-004},
  urldate = {2024-04-29},
  abstract = {Information Theory and Statistics: A Tutorial},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XW3GSK6K/Csiszár and Shields - 2004 - Information Theory and Statistics A Tutorial.pdf}
}

@article{cui_pointcloud_2019,
  title = {Point-{{Cloud Compression}}: {{Moving Picture Experts Group}}'s {{New Standard}} in 2020},
  shorttitle = {Point-{{Cloud Compression}}},
  author = {Cui, Li and Mekuria, Rufael and Preda, Marius and Jang, Euee S.},
  year = {2019},
  month = jul,
  journal = {IEEE Consumer Electronics Magazine},
  volume = {8},
  number = {4},
  pages = {17--21},
  issn = {2162-2256},
  doi = {10.1109/MCE.2019.2905483},
  abstract = {Consumer- and industry-level 3d sensing devices are becoming more common than ever before, increasing the amount of available 3D point-cloud data. The full geometry and details of a 3D scene can be captured by 3D scans, which are useful in many applications, including virtual reality (VR), 3D video, robotics, and geographic information access. However, it is often problematic to efficiently store, exchange, and access the large volume of these point-cloud data sets. To address these challenges, the Moving Picture Experts Group (MPEG) initiated a standardization activity on point-cloud compression (PCC). This article provides an overview of MPEG?s ground-breaking PCC standardization efforts as of January 2018, which are set to be finished by 2020.},
  keywords = {Encoding,Geometry,Image coding,Image color analysis,MPEG standards,Octrees,Three-dimensional displays,Transform coding},
  file = {/Users/kshitijgoel/Zotero/storage/9ZUYQL3P/Cui et al. - 2019 - Point-Cloud Compression Moving Picture Experts Gr.pdf;/Users/kshitijgoel/Zotero/storage/YUSHJ8TX/stamp.html}
}

@inproceedings{curless_volumetric_1996,
  title = {A Volumetric Method for Building Complex Models from Range Images},
  booktitle = {Proceedings of the 23rd Annual Conference on {{Computer}} Graphics and Interactive Techniques},
  author = {Curless, Brian and Levoy, Marc},
  year = {1996},
  month = aug,
  series = {{{SIGGRAPH}} '96},
  pages = {303--312},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/237170.237269},
  url = {https://doi.org/10.1145/237170.237269},
  urldate = {2022-02-06},
  isbn = {978-0-89791-746-9},
  keywords = {isosurface extraction,range image integration,surface fitting,three-dimensional shape recovery},
  file = {/Users/kshitijgoel/Zotero/storage/4HCW3TE8/Curless and Levoy - 1996 - A volumetric method for building complex models fr.pdf}
}

@article{cutts_planetary_1995,
  title = {Planetary Exploration by Robotic Aerovehicles},
  author = {Cutts, James A. and Nock, Kerry T. and Jones, Jack A. and Rodriguez, Guillermo and Balaram, J.},
  year = {1995},
  month = dec,
  journal = {Autonomous Robots},
  volume = {2},
  number = {4},
  pages = {261--282},
  issn = {1573-7527},
  doi = {10.1007/BF00710794},
  url = {https://doi.org/10.1007/BF00710794},
  urldate = {2023-04-14},
  abstract = {Planetary aerobots are a new type of telerobotic science platform that can fly and navigate in a dynamic 3-dimensional atmospheric environment, thus enabling the global in situ exploration of planetary atmospheres and surfaces. Aerobots are enabled by a new concept in planetary balloon altitude control, developed at JPL, which employs reversible-fluid changes to permit repeated excursions in altitude. The essential physics and thermodynamics ofreversible-fluid altitude control have been demonstrated in a series of altitude-control experiments conducted in the Earth's atmosphere, which are described. Aerobot altitude-control technology will be important in the exploration of seven planets and satellites in our solar system. Three of these objects---Venus, Mars, and the Saturnian satellite Titan---have accessible solid surfaces and atmospheres dominated by the dense gases nitrogen or carbon dioxide. They will be explored with aerobots using helium or hydrogen as their primary means of buoyancy. The other four planets---Jupiter, Saturn, Uranus, and Neptune---have deep atmospheres that are predominantly hydrogen. It may be possible to explore these atmospheres with aerobots inflated with atmospheric gas that is then radiatively heated from the hotter gaseous depths below. To fulfill their potential, aerobots to explore the planets will need autonomous state estimators to guide their observations and provide information to the altitude-control systems. The techniques of acquiring these data remotely are outlined. Aerobots will also use on board altitude control and navigation systems to execute complex flight paths including descent to the surface and exploiting differential wind velocities to access different latitude belts. Approaches to control of these systems are examined. The application of aerobots to Venus exploration is explored in some detail: The most ambitious mission described, the Venus Flyer Robot (VFR), would have the capability to make repeated short excursions to the high-temperature surface environment of Venus to acquire data and then return to the Earth-like upper atmosphere to communicate and recool its electronic systems. Finally a Planetary Aerobot Testbed is discussed which will conduct Earth atmospheric flights to validate autonomous-state-estimator techniques and flight-path-control techniques needed for future planetary missions.},
  langid = {english},
  keywords = {aerobot,balloons,mobile robots,navigation,planetary exploration},
  file = {/Users/kshitijgoel/Zotero/storage/TCIKWHQQ/Cutts et al. - 1995 - Planetary exploration by robotic aerovehicles.pdf}
}

@book{cuzzolin_geometry_2021,
  title = {The {{Geometry}} of {{Uncertainty}}: {{The Geometry}} of {{Imprecise Probabilities}}},
  shorttitle = {The {{Geometry}} of {{Uncertainty}}},
  author = {Cuzzolin, Fabio},
  year = {2021},
  series = {Artificial {{Intelligence}}: {{Foundations}}, {{Theory}}, and {{Algorithms}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-63153-6},
  url = {http://link.springer.com/10.1007/978-3-030-63153-6},
  urldate = {2024-06-04},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-030-63152-9 978-3-030-63153-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5VADC2I3/Cuzzolin - 2021 - The Geometry of Uncertainty The Geometry of Imprecise Probabilities.pdf}
}

@article{dagan_exact_2022,
  title = {Exact and {{Approximate Heterogeneous Bayesian Decentralized Data Fusion}}},
  author = {Dagan, Ofer and Ahmed, Nisar R.},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--15},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3226115},
  abstract = {In Bayesian peer-to-peer decentralized data fusion, the underlying distributions held locally by autonomous agents are frequently assumed to be over the same set of variables (homogeneous). This requires each agent to process and communicate the full global joint distribution, and thus, leads to high computation and communication costs irrespective of relevancy to specific local objectives. This work formulates and studies heterogeneous decentralized fusion problems, defined as the set of problems in which either the communicated or the processed distributions describe different, but overlapping, random states of interest that are subsets of a larger full global joint state. We exploit the conditional independence structure of such problems and provide a rigorous derivation of novel exact and approximate conditionally factorized heterogeneous fusion rules. We further develop a new version of the homogeneous channel filter algorithm to enable conservative heterogeneous fusion for smoothing and filtering scenarios in dynamic problems. Numerical examples show more than 99.5\% potential communication reduction for heterogeneous channel filter fusion, and a multitarget tracking simulation shows that these methods provide consistent estimates while remaining computationally scalable.},
  keywords = {Bayes methods,Bayesian decentralized data fusion (DDF),Data integration,distributed robot systems,Dynamical systems,Heuristic algorithms,multirobot systems,Robots,sensor fusion,Target tracking,Time measurement},
  file = {/Users/kshitijgoel/Zotero/storage/QMUCNKZW/Dagan and Ahmed - 2022 - Exact and Approximate Heterogeneous Bayesian Decen.pdf;/Users/kshitijgoel/Zotero/storage/NWGUQG87/stamp.html}
}

@article{dahlin_creating_2023,
  title = {Creating {{Star Worlds}}: {{Reshaping}} the {{Robot Workspace}} for {{Online Motion Planning}}},
  shorttitle = {Creating {{Star Worlds}}},
  author = {Dahlin, Albin and Karayiannidis, Yiannis},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {3655--3670},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3279029},
  url = {https://ieeexplore.ieee.org/document/10164805},
  urldate = {2023-10-17},
  abstract = {Closed-loop motion planning is suitable for obstacle avoidance in dynamically changing environments due to its reactive nature, and various methods have been presented to provide (almost) global convergence. A common assumption in the control design is that the robot operates in a disjoint star world, i.e., all obstacles are strictly starshaped and mutually disjoint. However, in real-life scenarios obstacles may intersect due to expanded obstacle regions corresponding to robot radius or safety margins. To broaden the applicability of closed-loop motion planning methods, such as harmonic potential fields, we propose a method to reshape a workspace of intersecting obstacles into a disjoint star world. The algorithm is based on two novel concepts presented here, namely, admissible kernel and starshaped hull with specified kernel, which are closely related to the notion of starshaped hull. The utilization of the proposed method is illustrated with examples of a robot operating in a 2-D workspace using a harmonic potential field approach in combination with the developed algorithm.},
  file = {/Users/kshitijgoel/Zotero/storage/4B7QXHU7/Dahlin and Karayiannidis - 2023 - Creating Star Worlds Reshaping the Robot Workspac.pdf}
}

@misc{dai_exploratory_2021,
  title = {Exploratory {{Factor Analysis}} of {{Data}} on a {{Sphere}}},
  author = {Dai, Fan and Dorman, Karin S. and Dutta, Somak and Maitra, Ranjan},
  year = {2021},
  month = nov,
  number = {arXiv:2111.04940},
  eprint = {2111.04940},
  primaryclass = {q-bio, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2111.04940},
  urldate = {2024-07-24},
  abstract = {Data on high-dimensional spheres arise frequently in many disciplines either naturally or as a consequence of preliminary processing and can have intricate dependence structure that needs to be understood. We develop exploratory factor analysis of the projected normal distribution to explain the variability in such data using a few easily interpreted latent factors. Our methodology provides maximum likelihood estimates through a novel fast alternating expectation profile conditional maximization algorithm. Results on simulation experiments on a wide range of settings are uniformly excellent. Our methodology provides interpretable and insightful results when applied to tweets with the \${\textbackslash}\#MeToo\$ hashtag in early December 2018, to time-course functional Magnetic Resonance Images of the average pre-teen brain at rest, to characterize handwritten digits, and to gene expression data from cancerous cells in the Cancer Genome Atlas.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {60E05 62H05 62H11 62H25 62H35 62P10 62P15 62P25,G.3,I.2,I.4,I.5,I.6,I.7,J.3,J.4,Quantitative Biology - Genomics,Statistics - Applications,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/kshitijgoel/Zotero/storage/9FBBB4MN/Dai et al. - 2021 - Exploratory Factor Analysis of Data on a Sphere.pdf}
}

@inproceedings{dai_fast_2020,
  title = {Fast {{Frontier-based Information-driven Autonomous Exploration}} with an {{MAV}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dai, Anna and Papatheodorou, Sotiris and Funk, Nils and Tzoumanikas, Dimos and Leutenegger, Stefan},
  year = {2020},
  month = may,
  pages = {9570--9576},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196707},
  url = {https://ieeexplore.ieee.org/document/9196707},
  urldate = {2024-11-15},
  abstract = {Exploration and collision-free navigation through an unknown environment is a fundamental task for autonomous robots. In this paper, a novel exploration strategy for Micro Aerial Vehicles (MAVs) is presented. The goal of the exploration strategy is the reduction of map entropy regarding occupancy probabilities, which is reflected in a utility function to be maximised. We achieve fast and efficient exploration performance with tight integration between our octree-based occupancy mapping approach, frontier extraction, and motion planning-as a hybrid between frontier-based and sampling-based exploration methods. The computationally expensive frontier clustering employed in classic frontier-based exploration is avoided by exploiting the implicit grouping of frontier voxels in the underlying octree map representation. Candidate next-views are sampled from the map frontiers and are evaluated using a utility function combining map entropy and travel time, where the former is computed efficiently using sparse raycasting. These optimisations along with the targeted exploration of frontier-based methods result in a fast and computationally efficient exploration planner. The proposed method is evaluated using both simulated and real-world experiments, demonstrating clear advantages over state-of-the-art approaches.},
  keywords = {Aerial Systems: Perception and Autonomy,Entropy,Measurement,Octrees,Planning,Robot sensing systems,Task analysis,Visual-Based Navigation},
  file = {/Users/kshitijgoel/Zotero/storage/R6C249DF/Dai et al. - 2020 - Fast Frontier-based Information-driven Autonomous Exploration with an MAV.pdf;/Users/kshitijgoel/Zotero/storage/2BBD5TEV/9196707.html}
}

@article{dai_fastreactive_2021,
  title = {Fast-{{Reactive Probabilistic Motion Planning}} for {{High-Dimensional Robots}}},
  author = {Dai, Siyu and Hofmann, Andreas and Williams, Brian},
  year = {2021},
  month = oct,
  journal = {SN Computer Science},
  volume = {2},
  number = {6},
  pages = {484},
  issn = {2661-8907},
  doi = {10.1007/s42979-021-00878-0},
  url = {https://doi.org/10.1007/s42979-021-00878-0},
  urldate = {2024-01-24},
  abstract = {Many real-world robotic operations that involve high-dimensional humanoid robots require fast reaction to plan disturbances and probabilistic guarantees over collision risks, whereas most probabilistic motion planning approaches developed for car-like robots cannot be directly applied to high-dimensional robots. In this paper, we present probabilistic Chekov (p-Chekov), a fast-reactive motion planning system that can provide safety guarantees for high-dimensional robots suffering from process noises and observation noises. Leveraging recent advances in machine learning as well as our previous work in deterministic motion planning that integrated trajectory optimization into a sparse roadmap framework, p-Chekov demonstrates its superiority in terms of collision avoidance ability and planning speed in high-dimensional robotic motion planning tasks in complex environments without the convexification of obstacles. Comprehensive theoretical and empirical analysis provided in this paper shows that p-Chekov can effectively satisfy user-specified chance constraints over collision risk in practical robotic manipulation tasks.},
  langid = {english},
  keywords = {Machine learning,Manipulation,Motion planning,Risk-aware planning},
  file = {/Users/kshitijgoel/Zotero/storage/VMBLPTCI/Dai et al. - 2021 - Fast-Reactive Probabilistic Motion Planning for Hi.pdf}
}

@article{damani_primal2_2021,
  title = {{{PRIMAL}}{$_2$}: {{Pathfinding Via Reinforcement}} and {{Imitation Multi-Agent Learning}} - {{Lifelong}}},
  shorttitle = {{{PRIMAL}}{$_{2}$}},
  author = {Damani, Mehul and Luo, Zhiyao and Wenzel, Emerson and Sartoretti, Guillaume},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {2666--2673},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3062803},
  url = {https://ieeexplore.ieee.org/document/9366340},
  urldate = {2025-08-08},
  abstract = {Multi-agent path finding (MAPF) is an indispensable component of large-scale robot deployments in numerous domains ranging from airport management to warehouse automation. In particular, this work addresses lifelong MAPF (LMAPF) -- an online variant of the problem where agents are immediately assigned a new goal upon reaching their current one -- in dense and highly structured environments, typical of real-world warehouse operations. Effectively solving LMAPF in such environments requires expensive coordination between agents as well as frequent replanning abilities, a daunting task for existing coupled and decoupled approaches alike. With the purpose of achieving considerable agent coordination without any compromise on reactivity and scalability, we introduce PRIMAL{$_2$}, a distributed reinforcement learning framework for LMAPF where agents learn fully decentralized policies to reactively plan paths online in a partially observable world. We extend our previous work, which was effective in low-density sparsely occupied worlds, to highly structured and constrained worlds by identifying behaviors and conventions which improve implicit agent coordination, and enable their learning through the construction of a novel local agent observation and various training aids. We present extensive results of PRIMAL{$_2$} in both MAPF and LMAPF environments and compare its performance to state-of-the-art planners in terms of makespan and throughput. We show that PRIMAL{$_2$} significantly surpasses our previous work and performs comparably to these baselines, while allowing real-time re-planning and scaling up to 2048 agents.},
  keywords = {Deep learning in robotics and automation,distributed robot systems,multi-robot systems,Planning,Reinforcement learning,Robot kinematics,Robots,Scalability,Task analysis,Training},
  file = {/Users/kshitijgoel/Zotero/storage/VAEXYCJ7/Damani et al. - 2021 - PRIMAL₂ Pathfinding Via Reinforcement and Imitation Multi-Agent Learning - Lifelong.pdf}
}

@article{dang_graphbased_2020,
  title = {Graph-Based Subterranean Exploration Path Planning Using Aerial and Legged Robots},
  author = {Dang, Tung and Tranzatto, Marco and Khattak, Shehryar and Mascarich, Frank and Alexis, Kostas and Hutter, Marco},
  year = {2020},
  journal = {Journal of Field Robotics},
  volume = {37},
  number = {8},
  pages = {1363--1388},
  issn = {1556-4967},
  doi = {10.1002/rob.21993},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21993},
  urldate = {2023-02-13},
  abstract = {Autonomous exploration of subterranean environments remains a major challenge for robotic systems. In response, this paper contributes a novel graph-based subterranean exploration path planning method that is attuned to key topological properties of subterranean settings, such as large-scale tunnel-like networks and complex multibranched topologies. Designed both for aerial and legged robots, the proposed method is structured around a bifurcated local- and global-planner architecture. The local planner utilizes a rapidly exploring random graph to reliably and efficiently identify paths that optimize an exploration gain within a local subspace, while simultaneously avoiding obstacles, respecting applicable traversability constraints and honoring dynamic limitations of the robots. Reflecting the fact that multibranched and tunnel-like networks of underground environments can often lead to dead-ends and accounting for the robot endurance, the global planning layer works in conjunction with the local planner to incrementally build a sparse global graph and is engaged when the system must be repositioned to a previously identified frontier of the exploration space, or commanded to return-to-home. The designed planner is detailed with respect to its computational complexity and compared against state-of-the-art approaches. Emphasizing field experimentation, the method is evaluated within multiple real-life deployments using aerial robots and the ANYmal legged system inside both long-wall and room-and-pillar underground mines in the United States and in Switzerland, as well as inside an underground bunker. The presented results further include missions conducted within the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge, a relevant competition on underground exploration.},
  langid = {english},
  keywords = {aerial robots,legged robots,path planning,subterranean robotics},
  file = {/Users/kshitijgoel/Zotero/storage/H7TQWETP/Dang et al. - 2020 - Graph-based subterranean exploration path planning.pdf;/Users/kshitijgoel/Zotero/storage/W63NBGHP/rob.html}
}

@inproceedings{dang_visual_2018,
  title = {Visual {{Saliency-Aware Receding Horizon Autonomous Exploration}} with {{Application}} to {{Aerial Robotics}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dang, Tung and Papachristos, Christos and Alexis, Kostas},
  year = {2018},
  month = may,
  pages = {2526--2533},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8460992},
  abstract = {This paper presents a novel strategy for autonomous visual saliency-aware receding horizon exploration of unknown environments using aerial robots. Through a model of visual attention, incrementally built maps are annotated regarding the visual importance and saliency of different objects and entities in the environment. Provided this information, a path planner that simultaneously optimizes for exploration of unknown space, and also directs the robot's attention to focus on the most salient objects, is developed. Following a two-step optimization paradigm, the algorithm first samples a random tree and identifies the branch maximizing for new volume to be explored. The first viewpoint of this path is then provided as a reference to the second planning step. Within that, a new tree is spanned, admissible branches arriving at the reference viewpoint while respecting a time budget dependent on the robot endurance and its environment exploration rate are found and evaluated in terms of reobserving salient regions at sufficient resolution. The best branch is then selected and executed by the robot, and the whole process is iteratively repeated. The proposed method is evaluated regarding its ability to provide increased attention toward salient objects, is verified to run onboard a small aerial robot, and is demonstrated in a set of challenging experimental studies.},
  keywords = {Computational modeling,Path planning,Planning,Robot sensing systems,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/YUGE2VT2/Dang et al. - 2018 - Visual Saliency-Aware Receding Horizon Autonomous .pdf;/Users/kshitijgoel/Zotero/storage/S7B7FJQU/stamp.html}
}

@inproceedings{daoud_collaborative_2022,
  title = {Collaborative {{Human-Robot Exploration}} via {{Implicit Coordination}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Daoud, Yves Georgy and Goel, Kshitij and Michael, Nathan and Tabib, Wennie},
  year = {2022},
  month = nov,
  pages = {80--86},
  issn = {2475-8426},
  doi = {10.1109/SSRR56537.2022.10018729},
  abstract = {This paper develops a methodology for collaborative human-robot exploration that leverages implicit coordination. Most autonomous single- and multi-robot exploration systems require a remote operator to provide explicit guidance to the robotic team. Few works consider how to embed the human partner alongside robots to provide guidance in the field. A remaining challenge for collaborative human-robot exploration is efficient communication of goals from the human to the robot. In this paper we develop a methodology that implicitly communicates a region of interest from a helmet-mounted depth camera on the human's head to the robot and an information gain-based exploration objective that biases motion planning within the viewpoint provided by the human. The result is an aerial system that safely accesses regions of interest that may not be immediately viewable or reachable by the human. The approach is evaluated in simulation and with hardware experiments in a motion capture arena. Videos of the simulation and hardware experiments are available at: https://youtu.be/7jgkBpVFIoE.},
  copyright = {All rights reserved},
  keywords = {Collaboration,Hardware,Robot kinematics,Robot vision systems,Safety,Transforms,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/VHLE8ZHU/Daoud et al. - 2022 - Collaborative Human-Robot Exploration via Implicit.pdf;/Users/kshitijgoel/Zotero/storage/B3VAV72W/10018729.html}
}

@inproceedings{dasgupta_hierarchical_2008,
  title = {Hierarchical Sampling for Active Learning},
  booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning},
  author = {Dasgupta, Sanjoy and Hsu, Daniel},
  year = {2008},
  month = jul,
  series = {{{ICML}} '08},
  pages = {208--215},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1390156.1390183},
  url = {https://dl.acm.org/doi/10.1145/1390156.1390183},
  urldate = {2025-02-18},
  abstract = {We present an active learning scheme that exploits cluster structure in data.},
  isbn = {978-1-60558-205-4},
  file = {/Users/kshitijgoel/Zotero/storage/9WKMBRWS/Dasgupta and Hsu - 2008 - Hierarchical sampling for active learning.pdf}
}

@inproceedings{dasgupta_learning_1999,
  title = {Learning Mixtures of {{Gaussians}}},
  booktitle = {40th {{Annual Symposium}} on {{Foundations}} of {{Computer Science}} ({{Cat}}. {{No}}.{{99CB37039}})},
  author = {Dasgupta, S.},
  year = {1999},
  month = oct,
  pages = {634--644},
  issn = {0272-5428},
  doi = {10.1109/SFFCS.1999.814639},
  url = {https://ieeexplore.ieee.org/document/814639},
  urldate = {2024-06-26},
  abstract = {Mixtures of Gaussians are among the most fundamental and widely used statistical models. Current techniques for learning such mixtures from data are local search heuristics with weak performance guarantees. We present the first provably correct algorithm for learning a mixture of Gaussians. This algorithm is very simple and returns the true centers of the Gaussians to within the precision specified by the user with high probability. It runs in time only linear in the dimension of the data and polynomial in the number of Gaussians.},
  keywords = {Astrophysics,Clustering algorithms,Electrical capacitance tomography,Gaussian processes,Geology,History,Probability,Psychology,Read only memory,Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/VFCSNQXB/Dasgupta - 1999 - Learning mixtures of Gaussians.pdf}
}

@article{dasgupta_neural_2024,
  title = {A Neural Algorithm for Computing Bipartite Matchings},
  author = {Dasgupta, Sanjoy and Meirovitch, Yaron and Zheng, Xingyu and Bush, Inle and Lichtman, Jeff W. and Navlakha, Saket},
  year = {2024},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {37},
  pages = {e2321032121},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2321032121},
  url = {https://pnas.org/doi/10.1073/pnas.2321032121},
  urldate = {2025-06-13},
  abstract = {Finding optimal bipartite matchings---e.g., matching medical students to hospitals for residency, items to buyers in an auction, or papers to reviewers for peer review---is a fundamental combinatorial optimization problem. We found a distributed algorithm for computing matchings by studying the development of the neuromuscular circuit. The neuromuscular circuit can be viewed as a bipartite graph formed between motor neurons and muscle fibers. In newborn animals, neurons and fibers are densely connected, but after development, each fiber is typically matched (i.e., connected) to exactly one neuron. We cast this synaptic pruning process as a distributed matching (or assignment) algorithm, where motor neurons ``compete'' with each other to ``win'' muscle fibers. We show that this algorithm is simple to implement, theoretically sound, and effective in practice when evaluated on real-world bipartite matching problems. Thus, insights from the development of neural circuits can inform the design of algorithms for fundamental computational problems.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FAJNFXTQ/Dasgupta et al. - 2024 - A neural algorithm for computing bipartite matchings.pdf}
}

@misc{dasgupta_online_2024,
  title = {Online {{Consistency}} of the {{Nearest Neighbor Rule}}},
  author = {Dasgupta, Sanjoy and So, Geelon},
  year = {2024},
  month = oct,
  number = {arXiv:2410.23644},
  eprint = {2410.23644},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.23644},
  url = {http://arxiv.org/abs/2410.23644},
  urldate = {2025-06-13},
  abstract = {In the realizable online setting, a learner is tasked with making predictions for a stream of instances, where the correct answer is revealed after each prediction. A learning rule is online consistent if its mistake rate eventually vanishes. The nearest neighbor rule (Fix and Hodges, 1951) is a fundamental prediction strategy, but it is only known to be consistent under strong statistical or geometric assumptions: the instances come i.i.d. or the label classes are well-separated. We prove online consistency for all measurable functions in doubling metric spaces under the mild assumption that the instances are generated by a process that is uniformly absolutely continuous with respect to a finite, upper doubling measure.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/8PVYETWY/Dasgupta and So - 2024 - Online Consistency of the Nearest Neighbor Rule.pdf;/Users/kshitijgoel/Zotero/storage/488W7QSF/2410.html}
}

@inproceedings{davis_differential_2006,
  title = {Differential {{Entropic Clustering}} of {{Multivariate Gaussians}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Davis, Jason and Dhillon, Inderjit},
  year = {2006},
  volume = {19},
  publisher = {MIT Press},
  url = {https://papers.nips.cc/paper_files/paper/2006/hash/8c9a14ffebb7677d033ffce847991293-Abstract.html},
  urldate = {2024-06-06},
  abstract = {Gaussian data is pervasive and many learning algorithms (e.g., k -means) model their inputs as a single sample drawn from a multivariate Gaussian. However, in many real-life settings, each input object is best described by multiple samples drawn from a multivariate Gaussian. Such data can arise, for example, in a movie review database where each movie is rated by several users, or in time-series domains such as sensor networks. Here, each input can be naturally described by both a mean vector and covariance matrix which parameterize the Gaussian distribution. In this paper, we consider the problem of clustering such input objects, each represented as a multivariate Gaussian. We formulate the problem using an information theoretic approach and draw several interesting theoretical connections to Bregman divergences and also Bregman matrix divergences. We evaluate our method across several domains, including synthetic data, sensor network data, and a statistical debugging application.},
  file = {/Users/kshitijgoel/Zotero/storage/9KGMNS44/Davis and Dhillon - 2006 - Differential Entropic Clustering of Multivariate Gaussians.pdf}
}

@inproceedings{davis_relationship_2006,
  title = {The Relationship between {{Precision-Recall}} and {{ROC}} Curves},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning},
  author = {Davis, Jesse and Goadrich, Mark},
  year = {2006},
  month = jun,
  series = {{{ICML}} '06},
  pages = {233--240},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1143844.1143874},
  url = {https://doi.org/10.1145/1143844.1143874},
  urldate = {2022-08-31},
  abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
  isbn = {978-1-59593-383-6},
  file = {/Users/kshitijgoel/Zotero/storage/IUGLXTUX/Davis and Goadrich - 2006 - The relationship between Precision-Recall and ROC .pdf}
}

@inproceedings{dean_analysis_1988,
  title = {An Analysis of Time-Dependent Planning},
  booktitle = {Proceedings of the {{Seventh AAAI National Conference}} on {{Artificial Intelligence}}},
  author = {Dean, Thomas and Boddy, Mark},
  year = {1988},
  month = aug,
  series = {{{AAAI}}'88},
  pages = {49--54},
  publisher = {AAAI Press},
  address = {Saint Paul, Minnesota},
  urldate = {2025-02-14},
  abstract = {This paper presents a framework for exploring issues in time-dependent planning: planning in which the time available to respond to predicted events varies, and the decision making required to formulate effective responses is complex. Our analysis of time-dependent planning suggests an approach based on a class of algorithms that we call anytime algorithms. Anytime algorithms can be interrupted at any point during computation to return a result whose utility is a function of computation time. We explore methods for solving time-dependent planning problems based on the properties of anytime algorithms.}
}

@inproceedings{degol_geometryinformed_2016,
  title = {Geometry-{{Informed Material Recognition}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {DeGol, Joseph and {Golparvar-Fard}, Mani and Hoiem, Derek},
  year = {2016},
  pages = {1554--1562},
  url = {https://openaccess.thecvf.com/content_cvpr_2016/html/DeGol_Geometry-Informed_Material_Recognition_CVPR_2016_paper.html},
  urldate = {2025-01-09},
  file = {/Users/kshitijgoel/Zotero/storage/W9TGQPXV/DeGol et al. - 2016 - Geometry-Informed Material Recognition.pdf}
}

@inproceedings{deisenroth_distributed_2015,
  title = {Distributed {{Gaussian Processes}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Deisenroth, Marc and Ng, Jun Wei},
  year = {2015},
  month = jun,
  pages = {1481--1490},
  publisher = {PMLR},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v37/deisenroth15.html},
  urldate = {2024-11-30},
  abstract = {To scale Gaussian processes (GPs) to large data sets we introduce the robust Bayesian Committee Machine (rBCM), a practical and scalable product-of-experts model for large-scale distributed GP regression. Unlike state-of-the-art sparse GP approximations, the rBCM is conceptually simple and does not rely on inducing or variational parameters. The key idea is to recursively distribute computations to independent computational units and, subsequently, recombine them to form an overall result. Efficient closed-form inference allows for straightforward parallelisation and distributed computations with a small memory footprint. The rBCM is independent of the computational graph and can be used on heterogeneous computing infrastructures, ranging from laptops to clusters. With sufficient computing resources our distributed GP model can handle arbitrarily large data sets.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HBMCC5AP/Deisenroth and Ng - 2015 - Distributed Gaussian Processes.pdf}
}

@article{delbracio_mobile_2021,
  title = {Mobile {{Computational Photography}}: {{A Tour}}},
  shorttitle = {Mobile {{Computational Photography}}},
  author = {Delbracio, Mauricio and Kelly, Damien and Brown, Michael S. and Milanfar, Peyman},
  year = {2021},
  month = sep,
  journal = {Annual Review of Vision Science},
  volume = {7},
  number = {Volume 7, 2021},
  pages = {571--604},
  publisher = {Annual Reviews},
  issn = {2374-4642, 2374-4650},
  doi = {10.1146/annurev-vision-093019-115521},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-vision-093019-115521},
  urldate = {2024-08-17},
  abstract = {The first mobile camera phone was sold only 20 years ago, when taking pictures with one\&apos;s phone was an oddity, and sharing pictures online was unheard of. Today, the smartphone is more camera than phone. How did this happen? This transformation was enabled by advances in computational photography---the science and engineering of making great images from small-form-factor, mobile cameras. Modern algorithmic and computing advances, including machine learning, have changed the rules of photography, bringing to it new modes of capture, postprocessing, storage, and sharing. In this review, we give a brief history of mobile computational photography and describe some of the key technological components, including burst photography, noise reduction, and super-resolution. At each step, we can draw naive parallels to the human visual system.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4CLZQTVA/Delbracio et al. - 2021 - Mobile Computational Photography A Tour.pdf;/Users/kshitijgoel/Zotero/storage/Y2LXT5VV/annurev-vision-093019-115521.html}
}

@article{dellaportas_multivariate_2006,
  title = {Multivariate Mixtures of Normals with Unknown Number of Components},
  author = {Dellaportas, Petros and Papageorgiou, Ioulia},
  year = {2006},
  month = jan,
  journal = {Statistics and Computing},
  volume = {16},
  number = {1},
  pages = {57--68},
  issn = {1573-1375},
  doi = {10.1007/s11222-006-5338-6},
  url = {https://doi.org/10.1007/s11222-006-5338-6},
  urldate = {2024-02-11},
  abstract = {We present full Bayesian analysis of finite mixtures of multivariate normals with unknown number of components. We adopt reversible jump Markov chain Monte Carlo and we construct, in a manner similar to that of Richardson and Green (1997), split and merge moves that produce good mixing of the Markov chains. The split moves are constructed on the space of eigenvectors and eigenvalues of the current covariance matrix so that the proposed covariance matrices are positive definite. Our proposed methodology has applications in classification and discrimination as well as heterogeneity modelling. We test our algorithm with real and simulated data.},
  langid = {english},
  keywords = {Bayesian inference,Classification,Markov chain Monte Carlo,Prediction,Reversible jump},
  file = {/Users/kshitijgoel/Zotero/storage/YLUCGH3U/Dellaportas and Papageorgiou - 2006 - Multivariate mixtures of normals with unknown numb.pdf}
}

@inproceedings{delmerico_benchmark_2018,
  title = {A {{Benchmark Comparison}} of {{Monocular Visual-Inertial Odometry Algorithms}} for {{Flying Robots}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Delmerico, Jeffrey and Scaramuzza, Davide},
  year = {2018},
  month = may,
  pages = {2502--2509},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8460664},
  url = {https://ieeexplore.ieee.org/document/8460664/?arnumber=8460664},
  urldate = {2024-12-16},
  abstract = {Flying robots require a combination of accuracy and low latency in their state estimation in order to achieve stable and robust flight. However, due to the power and payload constraints of aerial platforms, state estimation algorithms must provide these qualities under the computational constraints of embedded hardware. Cameras and inertial measurement units (IMUs) satisfy these power and payload constraints, so visual-inertial odometry (VIO) algorithms are popular choices for state estimation in these scenarios, in addition to their ability to operate without external localization from motion capture or global positioning systems. It is not clear from existing results in the literature, however, which VIO algorithms perform well under the accuracy, latency, and computational constraints of a flying robot with onboard state estimation. This paper evaluates an array of publicly-available VIO pipelines (MSCKF, OKVIS, ROVIO, VINS-Mono, SVO+MSF, and SVO+GTSAM) on different hardware configurations, including several single-board computer systems that are typically found on flying robots. The evaluation considers the pose estimation accuracy, per-frame processing time, and CPU and memory load while processing the EuRoC datasets, which contain six degree of freedom (6DoF) trajectories typical of flying robots. We present our complete results as a benchmark for the research community.},
  keywords = {Hardware,Optimization,Pipelines,Robot sensing systems,State estimation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/XKTF65NT/Delmerico and Scaramuzza - 2018 - A Benchmark Comparison of Monocular Visual-Inertial Odometry Algorithms for Flying Robots.pdf;/Users/kshitijgoel/Zotero/storage/NP49KHRP/8460664.html}
}

@article{delmerico_comparison_2018,
  title = {A Comparison of Volumetric Information Gain Metrics for Active {{3D}} Object Reconstruction},
  author = {Delmerico, Jeffrey and Isler, Stefan and Sabzevari, Reza and Scaramuzza, Davide},
  year = {2018},
  month = feb,
  journal = {Autonomous Robots},
  volume = {42},
  number = {2},
  pages = {197--208},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-017-9634-0},
  url = {http://link.springer.com/10.1007/s10514-017-9634-0},
  urldate = {2022-04-19},
  abstract = {In this paper, we investigate the following question: when performing next best view selection for volumetric 3D reconstruction of an object by a mobile robot equipped with a dense (camera-based) depth sensor, what formulation of information gain is best? To address this question, we propose several new ways to quantify the volumetric information (VI) contained in the voxels of a probabilistic volumetric map, and compare them to the state of the art with extensive simulated experiments. Our proposed formulations incorporate factors such as visibility likelihood and the likelihood of seeing new parts of the object. The results of our experiments allow us to draw some clear conclusions about the VI formulations that are most effective in different mobile-robot reconstruction scenarios. To the best of our knowledge, this is the first comparative survey of VI formulation performance for active 3D object reconstruction. Additionally, our modular software framework is adaptable to other robotic platforms and general reconstruction problems, and we release it open source for autonomous reconstruction tasks.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/S56U7L3L/Delmerico et al. - 2018 - A comparison of volumetric information gain metric.pdf}
}

@article{delmerico_current_2019,
  title = {The Current State and Future Outlook of Rescue Robotics},
  author = {Delmerico, Jeffrey and Mintchev, Stefano and Giusti, Alessandro and Gromov, Boris and Melo, Kamilo and Horvat, Tomislav and Cadena, Cesar and Hutter, Marco and Ijspeert, Auke and Floreano, Dario and Gambardella, Luca M. and Siegwart, Roland and Scaramuzza, Davide},
  year = {2019},
  journal = {Journal of Field Robotics},
  volume = {36},
  number = {7},
  pages = {1171--1191},
  issn = {1556-4967},
  doi = {10.1002/rob.21887},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21887},
  urldate = {2022-02-08},
  abstract = {Robotic technologies, whether they are remotely operated vehicles, autonomous agents, assistive devices, or novel control interfaces, offer many promising capabilities for deployment in real-world environments. Postdisaster scenarios are a particularly relevant target for applying such technologies, due to the challenging conditions faced by rescue workers and the possibility to increase their efficacy while decreasing the risks they face. However, field-deployable technologies for rescue work have requirements for robustness, speed, versatility, and ease of use that may not be matched by the state of the art in robotics research. This paper aims to survey the current state of the art in ground and aerial robots, marine and amphibious systems, and human--robot control interfaces and assess the readiness of these technologies with respect to the needs of first responders and disaster recovery efforts. We have gathered expert opinions from emergency response stakeholders and researchers who conduct field deployments with them to understand these needs, and we present this assessment as a way to guide future research toward technologies that will make an impact in real-world disaster response and recovery.},
  langid = {english},
  keywords = {emergency response,extreme environments,search and rescue robotics},
  file = {/Users/kshitijgoel/Zotero/storage/JIC62DS2/Delmerico et al. - 2019 - The current state and future outlook of rescue rob.pdf;/Users/kshitijgoel/Zotero/storage/XWTH9D53/rob.html}
}

@article{delon_wassersteintype_2020,
  title = {A {{Wasserstein-Type Distance}} in the {{Space}} of {{Gaussian Mixture Models}}},
  author = {Delon, Julie and Desolneux, Agn{\`e}s},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {13},
  number = {2},
  pages = {936--970},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/19M1301047},
  url = {https://epubs.siam.org/doi/abs/10.1137/19M1301047},
  urldate = {2024-10-14},
  abstract = {In this paper, we introduce a notion of barycenter in the Wasserstein space which generalizes McCann's interpolation to the case of more than two measures. We provide existence, uniqueness, characterizations, and regularity of the barycenter and relate it to the multimarginal optimal transport problem considered by Gangbo and {\'S}wi{\k e}ch in [Comm. Pure Appl. Math., 51 (1998), pp. 23--45]. We also consider some examples and, in particular, rigorously solve the Gaussian case. We finally discuss convexity of functionals in the Wasserstein space.},
  file = {/Users/kshitijgoel/Zotero/storage/I9WR5Z9C/Delon and Desolneux - 2020 - A Wasserstein-Type Distance in the Space of Gaussian Mixture Models.pdf}
}

@article{dempster_maximum_1977,
  title = {Maximum {{Likelihood}} from {{Incomplete Data Via}} the {{EM Algorithm}}},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  year = {1977},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {39},
  number = {1},
  pages = {1--22},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1977.tb01600.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1977.tb01600.x},
  urldate = {2023-02-02},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
  langid = {english},
  keywords = {em algorithm,incomplete data,maximum likelihood,posterior mode},
  file = {/Users/kshitijgoel/Zotero/storage/UQDTXX75/Dempster et al. - 1977 - Maximum Likelihood from Incomplete Data Via the EM.pdf;/Users/kshitijgoel/Zotero/storage/XTEPYJSJ/j.2517-6161.1977.tb01600.html}
}

@inproceedings{desa_point_2024,
  title = {Point {{Cloud-Based Control Barrier Function Regression}} for {{Safe}} and {{Efficient Vision-Based Control}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {De Sa, Massimiliano and Kotaru, Prasanth and Sreenath, Koushil},
  year = {2024},
  month = may,
  pages = {366--372},
  doi = {10.1109/ICRA57147.2024.10610647},
  url = {https://ieeexplore.ieee.org/document/10610647},
  urldate = {2024-12-09},
  abstract = {Control barrier functions have become an increasingly popular framework for safe real-time control. In this work, we present a computationally low-cost framework for synthesizing barrier functions over point cloud data for safe vision-based control. We take advantage of surface geometry to locally define and synthesize a quadratic CBF over a point cloud. This CBF is used in a CBF-QP for control and verified in simulation on quadrotors and in hardware on quadrotors and the TurtleBot3. This technique enables safe navigation through unstructured and dynamically changing environments and is shown to be significantly more efficient than current methods.},
  keywords = {Geometry,Hardware,Navigation,Point cloud compression,Quadrotors,Real-time systems,Robotics and automation},
  file = {/Users/kshitijgoel/Zotero/storage/HHXM2R8W/De Sa et al. - 2024 - Point Cloud-Based Control Barrier Function Regression for Safe and Efficient Vision-Based Control.pdf}
}

@phdthesis{desai_decentralized_2021,
  type = {{{CMU-RI-TR-21-57}}},
  title = {Decentralized {{Navigation}} of {{Quadrotor Teams}} in {{Uncertain Workspaces}}},
  author = {Desai, Arjav Ashesh},
  year = {2021},
  month = aug,
  address = {Pittsburgh, PA, USA},
  url = {https://www.ri.cmu.edu/publications/decentralized-navigation-of-quadrotor-teams-in-uncertain-workspaces/},
  urldate = {2022-04-19},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/XE7P575W/_.pdf}
}

@incollection{desai_decentralized_2022,
  title = {Decentralized {{Multi-robot Planning}} in {{Dynamic 3D Workspaces}}},
  booktitle = {Distributed {{Autonomous Robotic Systems}}},
  author = {Desai, Arjav and Michael, Nathan},
  year = {2022},
  volume = {22},
  pages = {45--57},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-92790-5_4},
  url = {https://link.springer.com/10.1007/978-3-030-92790-5_4},
  urldate = {2022-04-28},
  abstract = {We consider the problem of decentralized multi-robot kinodynamic motion planning in dynamic workspaces. The proposed approach leverages offline precomputation on an invariant planning representation (invariant geometric tree) for low latency online planning and replanning amidst unpredictably moving dynamic obstacles to generate kinodynamically feasible and collision-free time-parameterized polynomial trajectories. Simulation results with up to 10 robots in dynamic workspaces composed of varying obstacle densities (up to 30\% by volume) and speeds (up to 2.5 m/s) suggest the use of the proposed methodology for real-time kinodynamic replanning in dynamic workspaces.},
  isbn = {978-3-030-92789-9 978-3-030-92790-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/S7PDXYKC/Desai and Michael - 2022 - Decentralized Multi-robot Planning in Dynamic 3D W.pdf}
}

@inproceedings{desai_efficient_2019,
  title = {Efficient {{Kinodynamic Multi-Robot Replanning}} in {{Known Workspaces}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Desai, Arjav and Collins, Matthew and Michael, Nathan},
  year = {2019},
  month = may,
  pages = {1021--1027},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8793647},
  url = {https://ieeexplore.ieee.org/document/8793647/},
  urldate = {2024-03-01},
  abstract = {In this work, we consider the problem of online centralized kinodynamic multi-robot replanning (from potentially non-stationary initial states) and coordination in known and cluttered workspaces. Offline state lattice reachability analysis is leveraged to decouple the planning problem into two sequential graph searches---one in the explicit geometric graph of the environment and the other in the graph of the higher-order derivatives of the robot's state---in a manner such that the intermediate vertices of a safe set of geometric paths are guaranteed to have a feasible assignment of higher-order derivatives. Without additional iterative refinement procedures, the resulting time parameterized polynomial trajectories are dynamically feasible and collision-free. Planning results with up to 20 robots in two and three dimensional workspaces suggest the suitability of the proposed approach for multi-robot replanning in known environments.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VYUX8DYF/Desai et al. - 2019 - Efficient Kinodynamic Multi-Robot Replanning in Kn.pdf}
}

@article{desai_parsimonious_2021,
  title = {Parsimonious Neural Networks Learn Interpretable Physical Laws},
  author = {Desai, Saaketh and Strachan, Alejandro},
  year = {2021},
  month = jun,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {12761},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-92278-w},
  url = {https://www.nature.com/articles/s41598-021-92278-w},
  urldate = {2024-12-19},
  abstract = {Abstract             Machine learning is playing an increasing role in the physical sciences and significant progress has been made towards embedding domain knowledge into models. Less explored is its use to discover interpretable physical laws from data. We propose parsimonious neural networks (PNNs) that combine neural networks with evolutionary optimization to find models that balance accuracy with parsimony. The power and versatility of the approach is demonstrated by developing models for classical mechanics and to predict the melting temperature of materials from fundamental properties. In the first example, the resulting PNNs are easily interpretable as Newton's second law, expressed as a non-trivial time integrator that exhibits time-reversibility and conserves energy, where the parsimony is critical to extract underlying symmetries from the data. In the second case, the PNNs not only find the celebrated Lindemann melting law, but also new relationships that outperform it in the pareto sense of parsimony vs. accuracy.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G5PQ6WUE/Desai and Strachan - 2021 - Parsimonious neural networks learn interpretable physical laws.pdf}
}

@misc{developers_betaflight_2025,
  title = {Betaflight/Betaflight},
  author = {Developers, Betaflight},
  year = {2025},
  month = may,
  url = {https://github.com/betaflight/betaflight},
  urldate = {2025-05-30},
  abstract = {Open Source Flight Controller Firmware},
  copyright = {GPL-3.0},
  howpublished = {Betaflight},
  keywords = {betaflight,cleanflight,flight-controller,hacktoberfest}
}

@misc{developers_tensorflow_2022,
  title = {{{TensorFlow}}},
  author = {Developers, TensorFlow},
  year = {2022},
  month = may,
  doi = {10.5281/zenodo.6574269},
  url = {https://zenodo.org/record/6574269},
  urldate = {2023-02-02},
  abstract = {TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications.},
  howpublished = {Zenodo},
  file = {/Users/kshitijgoel/Zotero/storage/XYYZ6LPJ/6574269.html}
}

@misc{dexheimer_como_2024,
  title = {{{COMO}}: {{Compact Mapping}} and {{Odometry}}},
  shorttitle = {{{COMO}}},
  author = {Dexheimer, Eric and Davison, Andrew J.},
  year = {2024},
  month = apr,
  number = {arXiv:2404.03531},
  eprint = {2404.03531},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2404.03531},
  urldate = {2024-06-09},
  abstract = {We present COMO, a real-time monocular mapping and odometry system that encodes dense geometry via a compact set of 3D anchor points. Decoding anchor point projections into dense geometry via per-keyframe depth covariance functions guarantees that depth maps are joined together at visible anchor points. The representation enables joint optimization of camera poses and dense geometry, intrinsic 3D consistency, and efficient second-order inference. To maintain a compact yet expressive map, we introduce a frontend that leverages the covariance function for tracking and initializing potentially visually indistinct 3D points across frames. Altogether, we introduce a real-time system capable of estimating accurate poses and consistent geometry.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/SQZTKU85/Dexheimer and Davison - 2024 - COMO Compact Mapping and Odometry.pdf}
}

@inproceedings{dexheimer_efficient_2020,
  title = {Efficient {{Multiresolution Scrolling Grid}} for {{Stereo Vision-based MAV Obstacle Avoidance}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dexheimer, Eric and Mangelson, Joshua G. and Scherer, Sebastian and Kaess, Michael},
  year = {2020},
  month = oct,
  pages = {4758--4765},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341718},
  url = {https://ieeexplore.ieee.org/document/9341718},
  urldate = {2024-06-09},
  abstract = {Fast, aerial navigation in cluttered environments requires a suitable map representation for path planning. In this paper, we propose the use of an efficient, structured multiresolution representation that expands the sensor range of dense local grids for memory-constrained platforms. While similar data structures have been proposed, we avoid processing redundant occupancy information and use the organization of the grid to improve efficiency. By layering 3D circular buffers that double in resolution at each level, obstacles near the robot are represented at finer resolutions while coarse spatial information is maintained at greater distances. We also introduce a novel method for efficiently calculating the Euclidean distance transform on the multiresolution grid by leveraging its structure. Lastly, we utilize our proposed framework to demonstrate improved stereo camera-based MAV obstacle avoidance with an optimization-based planner in simulation.},
  keywords = {Collision avoidance,Organizations,Path planning,Robot sensing systems,Spatial resolution,Three-dimensional displays,Transforms},
  file = {/Users/kshitijgoel/Zotero/storage/978MBAAS/Dexheimer et al. - 2020 - Efficient Multiresolution Scrolling Grid for Stereo Vision-based MAV Obstacle Avoidance.pdf;/Users/kshitijgoel/Zotero/storage/GBGF4DN2/9341718.html}
}

@inproceedings{dexheimer_learning_2023,
  title = {Learning a {{Depth Covariance Function}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Dexheimer, Eric and Davison, Andrew J.},
  year = {2023},
  pages = {13122--13131},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Dexheimer_Learning_a_Depth_Covariance_Function_CVPR_2023_paper.html},
  urldate = {2024-06-09},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JGUQVJDB/Dexheimer and Davison - 2023 - Learning a Depth Covariance Function.pdf}
}

@inproceedings{dharmadhikari_autonomous_2023,
  title = {Autonomous {{Exploration}} and {{General Visual Inspection}} of {{Ship Ballast Water Tanks Using Aerial Robots}}},
  booktitle = {2023 21st {{International Conference}} on {{Advanced Robotics}} ({{ICAR}})},
  author = {Dharmadhikari, Mihir and De Petris, Paolo and Kulkarni, Mihir and Khedekar, Nikhil and Nguyen, Huan and Stene, Arnt Erik and Sj{\o}vold, Eivind and Solheim, Kristian and Gussiaas, Bente and Alexis, Kostas},
  year = {2023},
  month = dec,
  pages = {409--416},
  publisher = {IEEE},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.1109/ICAR58858.2023.10406928},
  url = {https://ieeexplore.ieee.org/document/10406928/},
  urldate = {2024-02-29},
  abstract = {This paper presents a solution for the autonomous exploration and inspection of Ballast Water Tanks (BWTs) of marine vessels using aerial robots. Ballast tank compartments are critical for a vessel's safety and correspond to confined environments often connected through particularly narrow manholes. The method enables their volumetric exploration combined with visual inspection subject to constraints regarding the viewing distance from a surface. We present evaluation studies in simulation, in a mission consisting of 18 BWT compartments, and in 3 field experiments inside real vessels. The data from one of the experiments is also post-processed to generate semantically-segmented meshes of inspection-important geometries. Geometric models can be associated with onboard camera images for detailed and intuitive analysis.},
  isbn = {979-8-3503-4229-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8SUHYB8X/Dharmadhikari et al. - 2023 - Autonomous Exploration and General Visual Inspecti.pdf}
}

@inproceedings{dharmadhikari_manhole_2023,
  title = {Manhole {{Detection}} and {{Traversal}} for {{Exploration}} of {{Ballast Water Tanks}} Using {{Micro Aerial Vehicles}}},
  booktitle = {2023 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Dharmadhikari, Mihir and De Petris, Paolo and Nguyen, Huan and Kulkarni, Mihir and Khedekar, Nikhil and Alexis, Kostas},
  year = {2023},
  month = jun,
  pages = {103--109},
  publisher = {IEEE},
  address = {Warsaw, Poland},
  doi = {10.1109/ICUAS57906.2023.10156214},
  url = {https://ieeexplore.ieee.org/document/10156214/},
  urldate = {2024-02-29},
  abstract = {This paper presents a method for the autonomous exploration of multiple compartments of a Ballast Water Tank inside a vessel using Micro Aerial Vehicles. Navigation across the compartments of ballast tanks often requires the robot to pass through narrow cross-section ``manholes'' (e.g., 0.8{\texttimes}0.6m). Hence, this work presents an algorithm to explicitly detect and localize such manholes using 3D LiDAR data and a strategy to reliably navigate through them to enable autonomous exploration of multiple compartments of the tank. Two ablation studies are presented analyzing the effective 3D space with respect to the manhole in which reliable detection takes place. Furthermore, the method is evaluated onboard a collision-tolerant aerial robot in two autonomous exploration experiments in relevant mock-up scenarios.},
  isbn = {979-8-3503-1037-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BMURYGBS/Dharmadhikari et al. - 2023 - Manhole Detection and Traversal for Exploration of.pdf}
}

@inproceedings{dharmadhikari_motion_2020,
  title = {Motion {{Primitives-based Path Planning}} for {{Fast}} and {{Agile Exploration}} Using {{Aerial Robots}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dharmadhikari, Mihir and Dang, Tung and Solanka, Lukas and Loje, Johannes and Nguyen, Huan and Khedekar, Nikhil and Alexis, Kostas},
  year = {2020},
  month = may,
  pages = {179--185},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196964},
  url = {https://ieeexplore.ieee.org/document/9196964},
  urldate = {2024-11-15},
  abstract = {This paper presents a novel path planning strategy for fast and agile exploration using aerial robots. Tailored to the combined need for large-scale exploration of challenging and confined environments, despite the limited endurance of micro aerial vehicles, the proposed planner employs motion primitives to identify admissible paths that search the configuration space, while exploiting the dynamic flight properties of small aerial robots. Utilizing a computationally efficient volumetric representation of the environment, the planner provides fast collision-free and future-safe paths that maximize the expected exploration gain and ensure continuous fast navigation through the unknown environment. The new method is field-verified in a set of deployments relating to subterranean exploration and specifically, in both modern and abandoned underground mines in Northern Nevada utilizing a 0.55m-wide collision-tolerant flying robot exploring with a speed of up to 2m/s and navigating sections with width as small as 0.8m.},
  keywords = {Collision avoidance,Dynamics,Educational robots,Path planning,Unmanned aerial vehicles,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/GB49ZDGU/Dharmadhikari et al. - 2020 - Motion Primitives-based Path Planning for Fast and Agile Exploration using Aerial Robots.pdf;/Users/kshitijgoel/Zotero/storage/IUCAVZRR/9196964.html}
}

@inproceedings{dharmadhikari_semanticsaware_2023,
  title = {Semantics-Aware {{Exploration}} and {{Inspection Path Planning}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Dharmadhikari, Mihir and Alexis, Kostas},
  year = {2023},
  month = may,
  pages = {3360--3367},
  doi = {10.1109/ICRA48891.2023.10160469},
  abstract = {This paper contributes a novel strategy for semantics-aware autonomous exploration and inspection path planning. Attuned to the fact that environments that need to be explored often involve a sparse set of semantic entities of particular interest, the proposed method offers volumetric exploration combined with two new planning behaviors that together ensure that a complete mesh model is reconstructed for each semantic, while its surfaces are observed at appropriate resolution and through suitable viewing angles. Evaluated in extensive simulation studies and experimental results using a flying robot, the planner delivers efficient combined exploration and high-fidelity inspection planning that is focused on the semantics of interest. Comparisons against relevant methods of the state-of-the-art are further presented.},
  keywords = {Image quality,Inspection,Measurement,Path planning,Planning,Semantics,Surface reconstruction},
  file = {/Users/kshitijgoel/Zotero/storage/EY2XGXT2/Dharmadhikari and Alexis - 2023 - Semantics-aware Exploration and Inspection Path Pl.pdf}
}

@inproceedings{dhawale_efficient_2020,
  title = {Efficient {{Parametric Multi-Fidelity Surface Mapping}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVI}}},
  author = {Dhawale, Aditya and Michael, Nathan},
  year = {2020},
  month = jul,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2020.XVI.073},
  url = {http://www.roboticsproceedings.org/rss16/p073.pdf},
  urldate = {2021-09-29},
  isbn = {978-0-9923747-6-1},
  file = {/Users/kshitijgoel/Zotero/storage/NRPBX2EC/Dhawale and Michael - 2020 - Efficient Parametric Multi-Fidelity Surface Mappin.pdf;/Users/kshitijgoel/Zotero/storage/CEEU3AWD/p073.html}
}

@inproceedings{dhawale_fast_2018,
  title = {Fast {{Monte-Carlo Localization}} on {{Aerial Vehicles Using Approximate Continuous Belief Representations}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Dhawale, Aditya and Shankar, Kumar Shaurya and Michael, Nathan},
  year = {2018},
  pages = {5851--5859},
  url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.html},
  urldate = {2022-05-11},
  file = {/Users/kshitijgoel/Zotero/storage/VYTVG8A2/Dhawale et al. - 2018 - Fast Monte-Carlo Localization on Aerial Vehicles U.pdf;/Users/kshitijgoel/Zotero/storage/D6FZE9F3/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.html}
}

@phdthesis{dhawale_hierarchical_2020,
  title = {Hierarchical {{Gaussian Distributions}} for {{Real-Time SLAM}}},
  author = {Dhawale, Aditya},
  year = {2020},
  month = may,
  address = {Pittsburgh, PA, USA},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/DEUUZYNC/Dhawale - Hierarchical Gaussian Distributions for Real-Time .pdf}
}

@inproceedings{dhawale_reactive_2018,
  title = {Reactive {{Collision Avoidance Using Real-Time Local Gaussian Mixture Model Maps}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dhawale, Aditya and Yang, Xuning and Michael, Nathan},
  year = {2018},
  month = oct,
  pages = {3545--3550},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8593723},
  url = {https://ieeexplore.ieee.org/document/8593723},
  urldate = {2024-01-27},
  abstract = {In unknown, cluttered environments, robots require online real-time mapping and collision checking in order to navigate robustly. Discrete map representations are inefficient for collision checking as they are expensive in terms of memory and computation. This paper takes a probabilistic approach to local mapping by representing the environment as a Gaussian Mixture Model (GMM) and leverages its geometric properties to enable efficient collision checking given a time-parameterized trajectory. In contrast to current discretization-based methods, a GMM preserves geometric coverage of the environment without losing representation accuracy with varying map resolutions. We introduce a novel GMM local mapping algorithm that can be used with a single depth camera processed on a single CPU, and provide algorithms for collision avoidance given arbitrary trajectory representations. Finally, we provide experimentation results demonstrating safety, efficiency, and data coverage for real-time collision avoidance with a quadrotor navigating in a cluttered environment.},
  keywords = {Collision avoidance,Current measurement,Gaussian mixture model,Real-time systems,Robot sensing systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/ZG6HEQIR/Dhawale et al. - 2018 - Reactive Collision Avoidance Using Real-Time Local.pdf;/Users/kshitijgoel/Zotero/storage/7VVV5WJA/8593723.html}
}

@article{diaz-frances_existence_2013,
  title = {On the Existence of a Normal Approximation to the Distribution of the Ratio of Two Independent Normal Random Variables},
  author = {{D{\'i}az-Franc{\'e}s}, Elo{\'i}sa and Rubio, Francisco J.},
  year = {2013},
  month = may,
  journal = {Statistical Papers},
  volume = {54},
  number = {2},
  pages = {309--323},
  issn = {1613-9798},
  doi = {10.1007/s00362-012-0429-2},
  url = {https://doi.org/10.1007/s00362-012-0429-2},
  urldate = {2024-07-24},
  abstract = {The distribution of the ratio of two independent normal random variables X and Y is heavy tailed and has no moments. The shape of its density can be unimodal, bimodal, symmetric, asymmetric, and/or even similar to a normal distribution close to its mode. To our knowledge, conditions for a reasonable normal approximation to the distribution of Z =~X/Y have been presented in scientific literature only through simulations and empirical results. A proof of the existence of a proposed normal approximation to the distribution of Z, in an interval I centered at {$\beta$} =~E(X) /E(Y), is given here for the case where both X and Y are independent, have positive means, and their coefficients of variation fulfill some conditions. In addition, a graphical informative way of assessing the closeness of the distribution of a particular ratio X/Y to the proposed normal approximation is suggested by means of a receiver operating characteristic (ROC) curve.},
  langid = {english},
  keywords = {62E17,Coefficient of variation,Ratio of normal means,ROC curve},
  file = {/Users/kshitijgoel/Zotero/storage/F8SKMFMT/Díaz-Francés and Rubio - 2013 - On the existence of a normal approximation to the distribution of the ratio of two independent norma.pdf}
}

@misc{dickson_realtime_2024,
  title = {Real-{{Time Trajectory Generation}} for {{Soft Robot Manipulators Using Differential Flatness}}},
  author = {Dickson, Akua and Garcia, Juan C. Pacheco and Jing, Ran and Anderson, Meredith L. and Sabelhaus, Andrew P.},
  year = {2024},
  month = dec,
  number = {arXiv:2412.08568},
  eprint = {2412.08568},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.08568},
  url = {http://arxiv.org/abs/2412.08568},
  urldate = {2024-12-13},
  abstract = {Soft robots have the potential to interact with sensitive environments and perform complex tasks effectively. However, motion plans and trajectories for soft manipulators are challenging to calculate due to their deformable nature and nonlinear dynamics. This article introduces a fast real-time trajectory generation approach for soft robot manipulators, which creates dynamically-feasible motions for arbitrary kinematically-feasible paths of the robot's end effector. Our insight is that piecewise constant curvature (PCC) dynamics models of soft robots can be differentially flat, therefore control inputs can be calculated algebraically rather than through a nonlinear differential equation. We prove this flatness under certain conditions, with the curvatures of the robot as the flat outputs. Our two-step trajectory generation approach uses an inverse kinematics procedure to calculate a motion plan of robot curvatures per end-effector position, then, our flatness diffeomorphism generates corresponding control inputs that respect velocity. We validate our approach through simulations of our representative soft robot manipulator along three different trajectories, demonstrating a margin of 23x faster than real-time at a frequency of 100 Hz. This approach could allow fast verifiable replanning of soft robots' motions in safety-critical physical environments, crucial for deployment in the real world.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/6FKRY3TN/Dickson et al. - 2024 - Real-Time Trajectory Generation for Soft Robot Manipulators Using Differential Flatness.pdf;/Users/kshitijgoel/Zotero/storage/SEW474QG/2412.html}
}

@article{dierckx_algorithm_1975,
  title = {An Algorithm for Smoothing, Differentiation and Integration of Experimental Data Using Spline Functions},
  author = {Dierckx, P.},
  year = {1975},
  month = sep,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {1},
  number = {3},
  pages = {165--184},
  issn = {0377-0427},
  doi = {10.1016/0771-050X(75)90034-0},
  url = {https://www.sciencedirect.com/science/article/pii/0771050X75900340},
  urldate = {2025-08-02},
  abstract = {This paper presents an algorithm for fitting a smoothing spline function to a set of experimental or tabulated data. The obtained spline approximation can be used for differentiation and integration of the given discrete function. Because of the ease of computation and the good conditioning properties we use normalised B-splines to represent the smoothing spline. A Fortran implementation of the algorithm is given.},
  file = {/Users/kshitijgoel/Zotero/storage/AR5CCL9W/Dierckx - 1975 - An algorithm for smoothing, differentiation and integration of experimental data using spline functi.pdf;/Users/kshitijgoel/Zotero/storage/YMSF9S5U/0771050X75900340.html}
}

@inproceedings{dieuleveut_federatedem_2021,
  title = {Federated-{{EM}} with Heterogeneity Mitigation and Variance Reduction},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Dieuleveut, Aymeric and Fort, Gersende and Moulines, Eric and Robin, Genevi{\`e}ve},
  year = {2021},
  volume = {34},
  pages = {29553--29566},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/f740c8d9c193f16d8a07d3a8a751d13f-Abstract.html},
  urldate = {2023-02-18},
  abstract = {The Expectation Maximization (EM) algorithm is the default algorithm for inference in latent variable models. As in any other field of machine learning, applications of latent variable models to very large datasets make the use of advanced parallel and distributed architecture mandatory. This paper introduces FedEM, which is the first extension of the EM algorithm to the federated learning context. FedEM is  a new communication efficient method, which handles partial participation of local devices, and is robust to  heterogeneous distribution of the datasets. To alleviate the communication bottleneck, FedEM compresses appropriately defined complete data sufficient statistics. We also develop and analyze an extension of FedEM to further incorporate a variance reduction scheme. In all cases, we derive finite-time complexity bounds for smooth non-convex problems.  Numerical results are presented to support our theoretical findings, as well as an application to federated missing values imputation for biodiversity monitoring.},
  file = {/Users/kshitijgoel/Zotero/storage/8ADTQZ46/Dieuleveut et al. - 2021 - Federated-EM with heterogeneity mitigation and var.pdf}
}

@article{dillencourt_general_1992,
  title = {A General Approach to Connected-Component Labeling for Arbitrary Image Representations},
  author = {Dillencourt, Michael B. and Samet, Hanan and Tamminen, Markku},
  year = {1992},
  month = apr,
  journal = {J. ACM},
  volume = {39},
  number = {2},
  pages = {253--280},
  issn = {0004-5411},
  doi = {10.1145/128749.128750},
  url = {https://dl.acm.org/doi/10.1145/128749.128750},
  urldate = {2025-01-09},
  abstract = {An improved and general approach to connected-component labeling of images is presented. The algorithm presented in this paper processes images in predetermined order, which means that the processing order depends only on the image representation scheme and not on specific properties of the image. The algorithm handles a wide variety of image representation schemes (rasters, run lengths, quadrees, bintrees, etc.). How to adapt the standard UNION-FIND algorithm to permit reuse of temporary labels is shown. This is done using a technique called  age balancing, in which, when two labels are merged, the older label becomes the father of the younger label. This technique can be made to coexist with the more conventional rule of weight     balancing, in which the label with more descendants becomes the father of the label with fewer descendants. Various image scanning orders are examined and classified. It is also shown that when the algorithm is specialized to a pixel array scanned in raster order, the total processing time is linear in the number of pixels. The linear-time processing time follows from a special property of the UNION-FIND algorithm, which may be of independent interest. This property states that under certain restrictions on the input, UNION-FIND runs in time linear in the number of FIND and UNION operations. Under these restrictions, linear-time performance can be achieved without resorting to the more complicated  Gabow-Tarjan algorithm for disjoint set union.},
  file = {/Users/kshitijgoel/Zotero/storage/MKKVILUC/Dillencourt et al. - 1992 - A general approach to connected-component labeling for arbitrary image representations.pdf}
}

@article{dimmig_survey_2025,
  title = {Survey of {{Simulators}} for {{Aerial Robots}}: {{An Overview}} and {{In-Depth Systematic Comparisons}} [{{Survey}}]},
  shorttitle = {Survey of {{Simulators}} for {{Aerial Robots}}},
  author = {Dimmig, Cora A. and Silano, Giuseppe and McGuire, Kimberly and Gabellieri, Chiara and H{\"o}nig, Wolfgang and Moore, Joseph and Kobilarov, Marin},
  year = {2025},
  month = jun,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {32},
  number = {2},
  pages = {153--166},
  issn = {1558-223X},
  doi = {10.1109/MRA.2024.3433171},
  url = {https://ieeexplore.ieee.org/document/10665978/},
  urldate = {2025-08-12},
  abstract = {Uncrewed Aerial Vehicle (UAV) research faces challenges with safety, scalability, costs, and ecological impact when conducting hardware testing. High-fidelity simulators offer a vital solution by replicating real-world conditions to enable the development and evaluation of novel perception and control algorithms. However, the large number of available simulators poses a significant challenge for researchers to determine which simulator best suits their specific use-case, based on each simulator's limitations and customization readiness. In this paper we present an overview of 43 UAV simulators, including in-depth, systematic comparisons for 17 of the simulators. Additionally, we present a set of decision factors for selection of simulators, aiming to enhance the efficiency and safety of research endeavors.},
  keywords = {Aerodynamics,Autonomous aerial vehicles,Force,Robots,Scalability,Sensors,Torque,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/VJQS5Z9J/Dimmig et al. - 2025 - Survey of Simulators for Aerial Robots An Overview and In-Depth Systematic Comparisons [Survey].pdf}
}

@inproceedings{ding_unsupervised_2023,
  title = {Unsupervised {{Manifold Linearizing}} and {{Clustering}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Ding, Tianjiao and Tong, Shengbang and Chan, Kwan Ho Ryan and Dai, Xili and Ma, Yi and Haeffele, Benjamin D.},
  year = {2023},
  pages = {5450--5461},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.html},
  urldate = {2024-12-19},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/V7LLJZYB/Ding et al. - 2023 - Unsupervised Manifold Linearizing and Clustering.pdf}
}

@article{doan_hm4_2021,
  title = {{{HM}}{$^4$}: {{Hidden Markov Model With Memory Management}} for {{Visual Place Recognition}}},
  shorttitle = {{{HM}}{$^{4}$}},
  author = {Doan, Anh-Dzung and Latif, Yasir and Chin, Tat-Jun and Reid, Ian},
  year = {2021},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {1},
  pages = {167--174},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.3036615},
  abstract = {Visual placerecognition needs to be robust against appearance variability due to natural and man-made causes. Training data collection should thus be an ongoing process to allow continuous appearance changes to be recorded. However, this creates an unboundedly-growing database that poses time and memory scalability challenges for place recognition methods. To tackle the scalability issue for visual place recognition in autonomous driving, we develop a Hidden Markov Model approach with a two-tiered memory management. Our algorithm, dubbed HM4, exploits temporal look-ahead to transfer promising candidate images between passive storage and active memory when needed. The inference process takes into account both promising images and a coarse representations of the full database. We show that this allows constant time and space inference for a fixed coverage area. The coarse representations can also be updated incrementally to absorb new data. To further reduce the memory requirements, we derive a compact image representation inspired by Locality Sensitive Hashing (LSH). Through experiments on real world data, we demonstrate the excellent scalability and accuracy of the approach under appearance changes and provide comparisons against state-of-the-art techniques.},
  keywords = {Databases,Hidden Markov models,Image representation,Localization,Measurement,Memory management,Scalability,SLAM,vision-based navigation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/MLMCPL7E/Doan et al. - 2021 - HM⁴ Hidden Markov Model With Memory Management fo.pdf;/Users/kshitijgoel/Zotero/storage/6ZCK8XSM/stamp.html}
}

@article{dobrea_rover_2025,
  title = {Rover {{Science Autonomy}} in {{Planetary Exploration}}: {{Field Analog Tests}}},
  shorttitle = {Rover {{Science Autonomy}} in {{Planetary Exploration}}},
  author = {Dobrea, Eldar Z. Noe and Banks, Maria E. and Clark, Roger N. and Wettergreen, David and Candela, Alberto and Hendrix, Amanda and Ahrens, Caitlin and Bell, Ernie and Breitfeld, Abigail and Bristow, Thomas F. and Buxner, Sanlyn and Hansen, Margaret and Holsclaw, Gregory M. and Knightly, Paul and Kramer, Georgiana and Kumari, Nandita and Lane, Melissa D. and Martin, Audrey and Meier, McKayla L. and Patterson, Ruby and Pearson, Neil and Prettyman, Thomas and Swayze, Gregg A. and Vaniman, David and Vijayarangan, Srinivasan and Vilas, Faith and Wright, Shawn P.},
  year = {2025},
  month = feb,
  journal = {The Planetary Science Journal},
  volume = {6},
  number = {2},
  pages = {51},
  publisher = {IOP Publishing},
  issn = {2632-3338},
  doi = {10.3847/PSJ/adaa78},
  url = {https://iopscience.iop.org/article/10.3847/PSJ/adaa78/meta},
  urldate = {2025-03-14},
  abstract = {Rover Science Autonomy in Planetary Exploration: Field Analog Tests, Dobrea, Eldar Z. Noe, Banks, Maria E., Clark, Roger N., Wettergreen, David, Candela, Alberto, Hendrix, Amanda, Ahrens, Caitlin, Bell, Ernie, Breitfeld, Abigail, Bristow, Thomas F., Buxner, Sanlyn, Hansen, Margaret, Holsclaw, Gregory M., Knightly, Paul, Kramer, Georgiana, Kumari, Nandita, Lane, Melissa D., Martin, Audrey, L. Meier, McKayla, Patterson, Ruby, Pearson, Neil, Prettyman, Thomas, Swayze, Gregg A., Vaniman, David, Vijayarangan, Srinivasan, Vilas, Faith, Wright, Shawn P.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G8N3D796/Dobrea et al. - 2025 - Rover Science Autonomy in Planetary Exploration Field Analog Tests.pdf}
}

@mastersthesis{dodik_path_2020,
  title = {Path {{Guiding}} Using a {{Spatio-Directional Mixture Model}}},
  author = {Dodik, Ana},
  year = {2020},
  url = {https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/411118/Dodik_Ana.pdf},
  urldate = {2024-06-13},
  school = {ETH Zurich},
  file = {/Users/kshitijgoel/Zotero/storage/ZE6CDCNK/Dodik - 2020 - Path Guiding using a Spatio-Directional Mixture Model.pdf}
}

@article{dodik_path_2022,
  title = {Path {{Guiding Using Spatio-Directional Mixture Models}}},
  author = {Dodik, Ana and Papas, Marios and {\"O}ztireli, Cengiz and M{\"u}ller, Thomas},
  year = {2022},
  journal = {Computer Graphics Forum},
  volume = {41},
  number = {1},
  pages = {172--189},
  issn = {1467-8659},
  doi = {10.1111/cgf.14428},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14428},
  urldate = {2023-03-17},
  abstract = {We propose a learning-based method for light-path construction in path tracing algorithms, which iteratively optimizes and samples from what we refer to as spatio-directional Gaussian mixture models (SDMMs). In particular, we approximate incident radiance as an online-trained 5D mixture that is accelerated by a D-tree. Using the same framework, we approximate BSDFs as pre-trained D mixtures, where is the number of BSDF parameters. Such an approach addresses two major challenges in path-guiding models. First, the 5D radiance representation naturally captures correlation between the spatial and directional dimensions. Such correlations are present in, for example parallax and caustics. Second, by using a tangent-space parameterization of Gaussians, our spatio-directional mixtures can perform approximate product sampling with arbitrarily oriented BSDFs. Existing models are only able to do this by either foregoing anisotropy of the mixture components or by representing the radiance field in local (normal aligned) coordinates, which both make the radiance field more difficult to learn. An additional benefit of the tangent-space parameterization is that each individual Gaussian is mapped to the solid sphere with low distortion near its centre of mass. Our method performs especially well on scenes with small, localized luminaires that induce high spatio-directional correlation in the incident radiance.},
  langid = {english},
  keywords = {Global Illumination,Methods and Applications,Monte Carlo Techniques,Ray Tracing,Rendering},
  file = {/Users/kshitijgoel/Zotero/storage/6A7FEZR3/Dodik et al. - 2022 - Path Guiding Using Spatio-Directional Mixture Mode.pdf;/Users/kshitijgoel/Zotero/storage/R7ICZ68B/cgf.html}
}

@inproceedings{doherty_bayesian_2017,
  title = {Bayesian Generalized Kernel Inference for Occupancy Map Prediction},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Doherty, Kevin and Wang, Jinkun and Englot, Brendan},
  year = {2017},
  month = may,
  pages = {3118--3124},
  doi = {10.1109/ICRA.2017.7989356},
  url = {https://ieeexplore.ieee.org/document/7989356},
  urldate = {2024-11-15},
  abstract = {We consider the problem of building accurate and descriptive 3D occupancy maps of an environment from sparse and noisy range sensor data. We seek to accomplish this task by constructing a predictive model online and inferring the occupancy probability of regions we have not directly observed. We propose a novel algorithm leveraging recent advances in data structures for mapping, sparse kernels, and Bayesian nonparametric inference. The resulting inference model has several desirable properties in comparison to existing methods, including speed of computation, the ability to be recursively updated without approximation, and consistency between batch and online inference. The method also reverts to the use of a specified prior state when insufficient relevant training data exist to predict the occupancy probability of a query point, a property which is attractive for motion planning and exploration applications with mobile robots.},
  keywords = {Bayes methods,Data models,Kernel,Predictive models,Three-dimensional displays,Training,Training data},
  file = {/Users/kshitijgoel/Zotero/storage/269HY9K8/Doherty et al. - 2017 - Bayesian generalized kernel inference for occupancy map prediction.pdf;/Users/kshitijgoel/Zotero/storage/WP8DPZVX/7989356.html}
}

@article{doherty_learningaided_2019,
  title = {Learning-{{Aided}} 3-{{D Occupancy Mapping With Bayesian Generalized Kernel Inference}}},
  author = {Doherty, Kevin and Shan, Tixiao and Wang, Jinkun and Englot, Brendan},
  year = {2019},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {35},
  number = {4},
  pages = {953--966},
  issn = {1941-0468},
  doi = {10.1109/TRO.2019.2912487},
  url = {https://ieeexplore.ieee.org/document/8713569},
  urldate = {2024-11-15},
  abstract = {In this paper, we consider the problem of building descriptive three-dimensional (3-D) maps from sparse and noisy range sensor data. We expand our previously proposed method leveraging Bayesian kernel inference for prediction of occupancy in locations not directly observed by a range sensor. In this paper, we show that our kernel inference approach generalizes previous ``counting sensor model'' approaches from discrete occupancy grids to continuous maps. Our approach enables prediction about occupancy in regions unobserved by the range sensor based on local measurements, and smoothly transitions to a prior in regions lacking sufficient data for reliable inference. Furthermore, we demonstrate quantitatively using simulated data that the mapping performance of our method can be improved by considering rays as continuous observations, rather than sampling discrete free-space point observations along rays. Though the maps produced by our method are in principle continuous, discretizing space affords us several computational advantages, including the ability to apply recursive Bayesian updates, that allow us to perform inference very efficiently, even on large datasets. To demonstrate this advantage, we present experimental results applying this method to large-scale lidar data collected with a ground robot, showing real-time performance. Other field robotics applications, including underwater 3-D mapping with sonar, are explored qualitatively.},
  keywords = {Bayes methods,Computational modeling,Field robots,Gaussian processes,Kernel,learning and adaptive systems,mapping,Planning,range sensing,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/WTEZLDKU/Doherty et al. - 2019 - Learning-Aided 3-D Occupancy Mapping With Bayesian Generalized Kernel Inference.pdf}
}

@inproceedings{doherty_probabilistic_2016,
  title = {Probabilistic Map Fusion for Fast, Incremental Occupancy Mapping with {{3D Hilbert}} Maps},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Doherty, Kevin and Wang, Jinkun and Englot, Brendan},
  year = {2016},
  month = may,
  pages = {1011--1018},
  doi = {10.1109/ICRA.2016.7487233},
  abstract = {We present a novel formulation of Hilbert mapping in which we construct a global occupancy map by incrementally fusing local overlapping Hilbert maps. Rather than maintain a single supervised learning model for the entire map, a new model is trained with each of a robot's range scans, and queried at all points within the robot's perceptual field. We treat the probabilistic output of the classifier as a sensor, employing sensor fusion to merge local maps. This formulation allows Hilbert mapping to be used incrementally in real-world mapping scenarios with overlap between sensor observations. The methodology is applied to three-dimensional map-building, and evaluated using real and simulated 3D range data.},
  keywords = {Gaussian processes,Kernel,Logistics,Robot sensing systems,Training},
  file = {/Users/kshitijgoel/Zotero/storage/TQTMHH86/Doherty et al. - 2016 - Probabilistic map fusion for fast, incremental occ.pdf;/Users/kshitijgoel/Zotero/storage/ZGVMBDQJ/stamp.html}
}

@article{dokmanic_euclidean_2015,
  title = {Euclidean {{Distance Matrices}}: {{Essential}} Theory, Algorithms, and Applications},
  shorttitle = {Euclidean {{Distance Matrices}}},
  author = {Dokmanic, Ivan and Parhizkar, Reza and Ranieri, Juri and Vetterli, Martin},
  year = {2015},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {32},
  number = {6},
  pages = {12--30},
  issn = {1558-0792},
  doi = {10.1109/MSP.2015.2398954},
  url = {https://ieeexplore.ieee.org/document/7298562/?arnumber=7298562},
  urldate = {2024-07-12},
  abstract = {Euclidean distance matrices (EDMs) are matrices of the squared distances between points. The definition is deceivingly simple; thanks to their many useful properties, they have found applications in psychometrics, crystallography, machine learning, wireless sensor networks, acoustics, and more. Despite the usefulness of EDMs, they seem to be insufficiently known in the signal processing community. Our goal is to rectify this mishap in a concise tutorial. We review the fundamental properties of EDMs, such as rank or (non)definiteness, and show how the various EDM properties can be used to design algorithms for completing and denoising distance data. Along the way, we demonstrate applications to microphone position calibration, ultrasound tomography, room reconstruction from echoes, and phase retrieval. By spelling out the essential algorithms, we hope to fast-track the readers in applying EDMs to their own problems. The code for all of the described algorithms and to generate the figures in the article is available online at http://lcav.epfl.ch/ivan.dokmanic. Finally, we suggest directions for further research.},
  keywords = {Eigenvalues and eigenfunctions,Euclidean distance,Image reconstruction,Reflection,Signal processing algorithms,Symmetric matrices},
  file = {/Users/kshitijgoel/Zotero/storage/SAHVLMZC/Dokmanic et al. - 2015 - Euclidean Distance Matrices Essential theory, algorithms, and applications.pdf;/Users/kshitijgoel/Zotero/storage/U3R9FGB5/7298562.html}
}

@inproceedings{dominguez-conti_visualinertial_2018,
  title = {Visual-{{Inertial SLAM Initialization}}: {{A General Linear Formulation}} and a {{Gravity-Observing Non-Linear Optimization}}},
  shorttitle = {Visual-{{Inertial SLAM Initialization}}},
  booktitle = {2018 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}})},
  author = {{Dom{\'i}nguez-Conti}, Javier and Yin, Jianfeng and Alami, Yacine and Civera, Javier},
  year = {2018},
  month = oct,
  pages = {37--45},
  issn = {1554-7868},
  doi = {10.1109/ISMAR.2018.00027},
  url = {https://ieeexplore.ieee.org/document/8613749},
  urldate = {2024-12-17},
  abstract = {The initialization is one of the less reliable pieces of Visual-Inertial SLAM (VI-SLAM) and Odometry (VI-O). The estimation of the initial state (camera poses, IMU states and landmark positions) from the first data readings lacks the accuracy and robustness of other parts of the pipeline, and most algorithms have high failure rates and/or initialization delays up to tens of seconds. Such initialization is critical for AR systems, as the failures and delays of the current approaches can ruin the user experience or mandate impractical guided calibration. In this paper we address the state initialization problem using a monocular-inertial sensor setup, the most common in AR platforms. Our contributions are 1) a general linear formulation to obtain an initialization seed, and 2) a non-linear optimization scheme, including gravity, to refine the seed. Our experimental results, in a public dataset, show that our approach improves the accuracy and robustness of current VI state initialization schemes.},
  keywords = {Cameras,Feature extraction,Gravity,Mathematical model,Optimization,Robustness,Sensor Fusion,Simultaneous localization and mapping,Visual Inertial Initialization,Visual Inertial Localization,Visual Inertial Mapping,Visual Inertial SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/6UH8CJ5R/Domínguez-Conti et al. - 2018 - Visual-Inertial SLAM Initialization A General Linear Formulation and a Gravity-Observing Non-Linear.pdf;/Users/kshitijgoel/Zotero/storage/ZDK44CXB/8613749.html}
}

@article{dong_ash_2023,
  title = {{{ASH}}: {{A Modern Framework}} for {{Parallel Spatial Hashing}} in {{3D Perception}}},
  shorttitle = {{{ASH}}},
  author = {Dong, Wei and Lao, Yixing and Kaess, Michael and Koltun, Vladlen},
  year = {2023},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {45},
  number = {5},
  pages = {5417--5435},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3214347},
  url = {https://ieeexplore.ieee.org/document/9918017},
  urldate = {2024-06-07},
  abstract = {We present ASH, a modern and high-performance framework for parallel spatial hashing on GPU. Compared to existing GPU hash map implementations, ASH achieves higher performance, supports richer functionality, and requires fewer lines of code (LoC) when used for implementing spatially varying operations from volumetric geometry reconstruction to differentiable appearance reconstruction. Unlike existing GPU hash maps, the ASH framework provides a versatile tensor interface, hiding low-level details from the users. In addition, by decoupling the internal hashing data structures and key-value data in buffers, we offer direct access to spatially varying data via indices, enabling seamless integration to modern libraries such as PyTorch. To achieve this, we 1) detach stored key-value data from the low-level hash map implementation; 2) bridge the pointer-first low level data structures to index-first high-level tensor interfaces via an index heap; 3) adapt both generic and non-generic integer-only hash map implementations as backends to operate on multi-dimensional keys. We first profile our hash map against state-of-the-art hash maps on synthetic data to show the performance gain from this architecture. We then show that ASH can consistently achieve higher performance on various large-scale 3D perception tasks with fewer LoC by showcasing several applications, including 1) point cloud voxelization, 2) retargetable volumetric scene reconstruction, 3) non-rigid point cloud registration and volumetric deformation, and 4) spatially varying geometry and appearance refinement. ASH and its example applications are open sourced in Open3D (http://www.open3d.org).},
  keywords = {Arrays,Ash,autodiff,GPU,Graphics processing units,Image reconstruction,Parallel hashing,shape-from-shading,SLAM,Task analysis,Tensors,Three-dimensional displays,volumetric reconstruction},
  file = {/Users/kshitijgoel/Zotero/storage/QJTMGZRB/Dong et al. - 2023 - ASH A Modern Framework for Parallel Spatial Hashing in 3D Perception.pdf;/Users/kshitijgoel/Zotero/storage/BWKDQZVR/9918017.html}
}

@inproceedings{dong_fast_2023,
  title = {Fast {{Monocular Scene Reconstruction With Global-Sparse Local-Dense Grids}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Dong, Wei and Choy, Christopher and Loop, Charles and Litany, Or and Zhu, Yuke and Anandkumar, Anima},
  year = {2023},
  pages = {4263--4272},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Dong_Fast_Monocular_Scene_Reconstruction_With_Global-Sparse_Local-Dense_Grids_CVPR_2023_paper.html},
  urldate = {2024-03-27},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HV7K34AZ/Dong et al. - 2023 - Fast Monocular Scene Reconstruction With Global-Sp.pdf}
}

@inproceedings{dong_fast_2024,
  title = {Fast and {{Communication-Efficient Multi-UAV Exploration Via Voronoi Partition}} on {{Dynamic Topological Graph}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Dong, Qianli and Xi, Haobo and Zhang, Shiyong and Bi, Qingchen and Li, Tianyi and Wang, Ziyu and Zhang, Xuebo},
  year = {2024},
  month = oct,
  pages = {14063--14070},
  issn = {2153-0866},
  doi = {10.1109/IROS58592.2024.10801613},
  url = {https://ieeexplore.ieee.org/document/10801613/?arnumber=10801613},
  urldate = {2025-03-31},
  abstract = {Efficient data transmission and reasonable task allocation are important to improve multi-robot exploration efficiency. However, most communication data types typically contain redundant information and thus require massive communication volume. Moreover, exploration-oriented task allocation is far from trivial and becomes even more challenging for resource-limited unmanned aerial vehicles (UAVs). In this paper, we propose a fast and communication-efficient multi-UAV exploration method for exploring large environments. We first design a multi-robot dynamic topological graph (MR-DTG) consisting of nodes representing the explored and exploring regions and edges connecting nodes. Supported by MR-DTG, our method achieves efficient communication by only transferring the necessary information required by exploration planning. To further improve the exploration efficiency, a hierarchical multi-UAV exploration method is devised using MR-DTG. Specifically, the graph Voronoi partition is used to allocate MR-DTG's nodes to the closest UAVs, considering the actual motion cost, thus achieving reasonable task allocation. To our knowledge, this is the first work to address multi-UAV exploration using graph Voronoi partition. The proposed method is compared with a state-of-the-art method in simulations. The results show that the proposed method is able to reduce the exploration time and communication volume by up to 38.3\% and 95.5\%, respectively. Finally, the effectiveness of our method is validated in the real-world experiment with 6 UAVs. We will release the source code to benefit the community.},
  keywords = {Costs,Data communication,Intelligent robots,Location awareness,Noise,Planning,Resource management,Source coding,Three-dimensional displays,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/L983P54X/Dong et al. - 2024 - Fast and Communication-Efficient Multi-UAV Exploration Via Voronoi Partition on Dynamic Topological.pdf;/Users/kshitijgoel/Zotero/storage/DGUBYB8I/10801613.html}
}

@phdthesis{dong_large_2023,
  title = {Large {{Scale Dense 3D Reconstruction}} via {{Sparse Representations}}},
  author = {Dong, Wei},
  year = {2023},
  month = may,
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/3RUVTWLG/Dong - Large Scale Dense 3D Reconstruction via Sparse Representations.pdf}
}

@article{dong_mrgmmapping_2022,
  title = {{{MR-GMMapping}}: {{Communication Efficient Multi-Robot Mapping System}} via {{Gaussian Mixture Model}}},
  shorttitle = {{{MR-GMMapping}}},
  author = {Dong, Haolin and Yu, Jincheng and Xu, Yuanfan and Xu, Zhilin and Shen, Zhaoyang and Tang, Jiahao and Shen, Yuan and Wang, Yu},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {3294--3301},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3145059},
  url = {https://ieeexplore.ieee.org/document/9691844},
  urldate = {2024-11-15},
  abstract = {Collaborative perception in unknown environments is a critical task for multi-robot systems. Without external positioning, multi-robot mapping systems have relied on the transfer of place recognition (PR) descriptors or sensor data for the relative pose estimation (RelPose) and share their local maps for relative localization. Thus, in a communication limited environment, data transmission can become a significant communication bottleneck in the multi-robot mapping system. To address this limitation, we propose MR-GMMapping, a Multi-Robot GMM-based mapping system in which robots perform relative localization only with GMM submaps to reduce data transmission and storage. For mapping, we propose GMM submap construction strategy with an adaptive model selection method, which makes robots dynamically select the appropriate number of Gaussian components. For applications, we realize fully GMM-submap-based PR, RelPose, and local planner. Robots are able to perform relative localization without the aid of other forms of maps or information, which makes them favorable for environments with communication constraints. Experiments show that our GMM Submap extraction strategy improves 11\% translation precision and 30\% rotation precision in RelPose, compared to RelPose on point clouds and GMM frames. Our experiments also show the feasibility of the GMM-based local planner and a 98\% data transmission reduction compared to point cloud maps. MR-GMMapping is published as an open-source ROS project at https://github.com/efc-robot/gmm\_map\_python.git.},
  keywords = {Data communication,mapping,Merging,Multi-robot SLAM,Multi-robot systems,Point cloud compression,Robot kinematics,Robot sensing systems,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/L3YV5M73/Dong et al. - 2022 - MR-GMMapping Communication Efficient Multi-Robot Mapping System via Gaussian Mixture Model.pdf;/Users/kshitijgoel/Zotero/storage/V54XAJIV/9691844.html}
}

@inproceedings{dong_rethinking_2023,
  title = {Rethinking {{Information-theoretic Generalization}}: {{Loss Entropy Induced PAC Bounds}}},
  shorttitle = {Rethinking {{Information-theoretic Generalization}}},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  author = {Dong, Yuxin and Gong, Tieliang and Chen, Hong and Yu, Shujian and Li, Chen},
  year = {2023},
  month = oct,
  url = {https://openreview.net/forum?id=GWSIo2MzuH},
  urldate = {2024-04-28},
  abstract = {Information-theoretic generalization analysis has achieved astonishing success in characterizing the generalization capabilities of noisy and iterative learning algorithms. However, current advancements are mostly restricted to average-case scenarios and necessitate the stringent bounded loss assumption, leaving a gap with regard to computationally tractable PAC generalization analysis, especially for long-tailed loss distributions. In this paper, we bridge this gap by introducing a novel class of PAC bounds through leveraging loss entropies. These bounds simplify the computation of key information metrics in previous PAC information-theoretic bounds to one-dimensional variables, thereby enhancing computational tractability. Moreover, our data-independent bounds provide novel insights into the generalization behavior of the minimum error entropy criterion, while our data-dependent bounds improve over previous results by alleviating the bounded loss assumption under both leave-one-out and supersample settings. Extensive numerical studies indicate strong correlations between the generalization error and the induced loss entropy, showing that the presented bounds adeptly capture the patterns of the true generalization gap under various learning scenarios.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/53XSX5HH/Dong et al. - 2023 - Rethinking Information-theoretic Generalization L.pdf}
}

@inproceedings{dortenzio_adaptive_2023,
  title = {Adaptive {{Mixture Model Reduction}} Based on the {{Composite Transportation Dissimilarity}}},
  booktitle = {2023 26th {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {D'Ortenzio, Alessandro and Manes, Costanzo and Iuliis, Vittorio De and Orguner, Umut},
  year = {2023},
  month = jun,
  pages = {1--8},
  doi = {10.23919/FUSION52260.2023.10224099},
  abstract = {Providing efficient yet accurate statistical models is a challenging problem in many applications. When elementary models are not sufficiently descriptive, mixtures of densities can be used. A complexity management issue arises when mixture models are employed: the number of components should be a trade-off between the complexity and the accuracy of the model. However, in general, it is not obvious how to determine the right number of mixture components for a specific application. In a previous work, theoretical foundations to address such a topic have been laid, grounded on the use of the Composite Transportation Dissimilarity between mixtures, and a preliminary criterion to manage the complexity of a mixture model has been proposed. In this paper, additional theoretical insights are provided that allow to formulate a novel adaptive mixture reduction algorithm. Numerical tests show that in most cases the new algorithm constitutes a significant improvement over the previous one.},
  keywords = {Complexity theory,Costs,Kullback-Leibler Divergence,Merging,Mixture models,Mixture Reduction,Model Selection,Optimal Transport Theory,Switches,Target tracking,Transportation},
  file = {/Users/kshitijgoel/Zotero/storage/4GXI2E6G/D’Ortenzio et al. - 2023 - Adaptive Mixture Model Reduction based on the Comp.pdf;/Users/kshitijgoel/Zotero/storage/UVAW9HBV/10224099.html}
}

@article{doss_optimal_2023,
  title = {Optimal Estimation of High-Dimensional {{Gaussian}} Location Mixtures},
  author = {Doss, Natalie and Wu, Yihong and Yang, Pengkun and Zhou, Harrison H.},
  year = {2023},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {51},
  number = {1},
  pages = {62--95},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/22-AOS2207},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-51/issue-1/Optimal-estimation-of-high-dimensional-Gaussian-location-mixtures/10.1214/22-AOS2207.full},
  urldate = {2023-08-15},
  abstract = {This paper studies the optimal rate of estimation in a finite Gaussian location mixture model in high dimensions without separation conditions. We assume that the number of components k is bounded and that the centers lie in a ball of bounded radius, while allowing the dimension d to be as large as the sample size n. Extending the one-dimensional result of Heinrich and Kahn (Ann. Statist. 46 (2018) 2844--2870), we show that the minimax rate of estimating the mixing distribution in Wasserstein distance is {$\Theta$}((d/n)1/4+n-1/(4k-2)), achieved by an estimator computable in time O(nd2+n5/4). Furthermore, we show that the mixture density can be estimated at the optimal parametric rate {$\Theta$}(d/n) in Hellinger distance and provide a computationally efficient algorithm to achieve this rate in the special case of k=2. Both the theoretical and methodological development rely on a careful application of the method of moments. Central to our results is the observation that the information geometry of finite Gaussian mixtures is characterized by the moment tensors of the mixing distribution, whose low-rank structure can be exploited to obtain a sharp local entropy bound.},
  keywords = {62C20,62G05,62G07,Finite mixture model,Gaussian mixture,high-dimensional density estimation,low-rank tensor,method of moments,Metric entropy,Minimax optimality},
  file = {/Users/kshitijgoel/Zotero/storage/ANMDNDK2/Doss et al. - 2023 - Optimal estimation of high-dimensional Gaussian lo.pdf}
}

@inproceedings{dou_trimformer_2025,
  title = {Trimformer: {{A Novel Sequence Compression Mechanism}} with {{Local Attention}}},
  shorttitle = {Trimformer},
  booktitle = {{{ICASSP}} 2025 - 2025 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Dou, Ran and Ru, Liyang and Principe, Jose},
  year = {2025},
  month = apr,
  pages = {1--5},
  issn = {2379-190X},
  doi = {10.1109/ICASSP49660.2025.10890757},
  url = {https://ieeexplore.ieee.org/document/10890757/},
  urldate = {2025-06-07},
  abstract = {Training on extremely long sequences poses significant challenges for attention mechanisms. In this paper, we introduce a novel trim attention mechanism that capitalizes on the inherent sparsity within attention processes. This mechanism effectively compresses the sequence length, thereby reducing the overall computational complexity without altering the number of trainable parameters. Our experimental results demonstrate that this approach not only decreases computational demands but also outperforms the Vision Transformer in image classification tasks. The trim attention mechanism can seamlessly replace any standard attention layer.},
  keywords = {attention mechanism,Attention mechanisms,Computational complexity,Computer architecture,image classification,Image coding,Natural language processing,sequence compression,Signal processing,Speech processing,Standards,Training,Transformers},
  file = {/Users/kshitijgoel/Zotero/storage/RNMPRRNY/Dou et al. - 2025 - Trimformer A Novel Sequence Compression Mechanism with Local Attention.pdf}
}

@article{downs_relationships_1967,
  title = {Some {{Relationships Between}} the {{Normal}} and {{Von Mises Distributions}}},
  author = {Downs, Thomas D. and Gould, A. Lawrence},
  year = {1967},
  journal = {Biometrika},
  volume = {54},
  number = {3/4},
  eprint = {2335068},
  eprinttype = {jstor},
  pages = {684--687},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2335068},
  url = {https://www.jstor.org/stable/2335068},
  urldate = {2024-11-01},
  abstract = {An n-flat has a hyperspherical normal distribution over its surface if, and only if, every m-ball in the n-flat has a conditional von Mises distribution on its surface, where m = 2,...,n.},
  file = {/Users/kshitijgoel/Zotero/storage/WJ5CVD7N/Downs and Gould - 1967 - Some Relationships Between the Normal and Von Mises Distributions.pdf}
}

@article{dowson_frechet_1982,
  title = {The {{Fr{\'e}chet}} Distance between Multivariate Normal Distributions},
  author = {Dowson, D. C and Landau, B. V},
  year = {1982},
  month = sep,
  journal = {Journal of Multivariate Analysis},
  volume = {12},
  number = {3},
  pages = {450--455},
  issn = {0047-259X},
  doi = {10.1016/0047-259X(82)90077-X},
  url = {https://www.sciencedirect.com/science/article/pii/0047259X8290077X},
  urldate = {2023-09-28},
  abstract = {The Fr{\'e}chet distance between two multivariate normal distributions having means {$\mu$}X, {$\mu$}Y and covariance matrices {$\Sigma$}X, {$\Sigma$}Y is shown to be given by d2 = {\textbar}{$\mu$}X - {$\mu$}Y{\textbar}2 + tr({$\Sigma$}X + {$\Sigma$}Y - 2({$\Sigma$}X{$\Sigma$}Y)12). The quantity d0 given by d02 = tr({$\Sigma$}X + {$\Sigma$}Y - 2({$\Sigma$}X{$\Sigma$}Y)12) is a natural metric on the space of real covariance matrices of given order.},
  keywords = {covariance matrices,Frechet distance,multivariate normal distributions},
  file = {/Users/kshitijgoel/Zotero/storage/2D64Z7WX/Dowson and Landau - 1982 - The Fréchet distance between multivariate normal d.pdf;/Users/kshitijgoel/Zotero/storage/4LEQ9LJJ/0047259X8290077X.html}
}

@inproceedings{dragiev_gaussian_2011,
  title = {Gaussian Process Implicit Surfaces for Shape Estimation and Grasping},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Dragiev, Stanimir and Toussaint, Marc and Gienger, Michael},
  year = {2011},
  month = may,
  pages = {2845--2850},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980395},
  abstract = {The choice of an adequate object shape representation is critical for efficient grasping and robot manipulation. A good representation has to account for two requirements: it should allow uncertain sensory fusion in a probabilistic way and it should serve as a basis for efficient grasp and motion generation. We consider Gaussian process implicit surface potentials as object shape representations. Sensory observations condition the Gaussian process such that its posterior mean defines an implicit surface which becomes an estimate of the object shape. Uncertain visual, haptic and laser data can equally be fused in the same Gaussian process shape estimate. The resulting implicit surface potential can then be used directly as a basis for a reach and grasp controller, serving as an attractor for the grasp end-effectors and steering the orientation of contact points. Our proposed controller results in a smooth reach and grasp trajectory without strict separation of phases. We validate the shape estimation using Gaussian processes in a simulation on randomly sampled shapes and the grasp controller on a real robot with 7DoF arm and 7DoF hand.},
  keywords = {Estimation,Gaussian processes,Grasping,Robot sensing systems,Shape,Surface treatment},
  file = {/Users/kshitijgoel/Zotero/storage/IPV5GIC9/Dragiev et al. - 2011 - Gaussian process implicit surfaces for shape estim.pdf}
}

@inproceedings{drews_fast_2013,
  title = {Fast and Adaptive {{3D}} Change Detection Algorithm for Autonomous Robots Based on {{Gaussian Mixture Models}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Drews, P. and {da Silva Filho}, S. C. and Marcolino, L. F. and N{\'u}{\~n}ez, P.},
  year = {2013},
  month = may,
  pages = {4685--4690},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6631244},
  abstract = {Nowadays, the advance of the technology allows robots to acquire dense point clouds decreasing the price and increasing the performance. However, it is a hard task to deal with due to the large amount of points, the redundancy and the noise. This paper proposes an adaptable system to build a 3D feature model of point clouds using Gaussian Mixture Models. These 3D models are used in order to detect changes in the autonomous robot's working environment. The presented work describes an efficient change detection system based on two consecutive stages. First, a top-down approach estimates features using Gaussian Mixture Models. The presented new approach improves the performance of previous related works in terms of computational load and robustness, nevertheless the system is selection criteria dependent. Thus, the efficiency of different selection criteria are evaluated and compared in this paper. Experimental results demonstrate that the Minimum Distance Length (MDL) criteria outperforms the other studied methods. In the second stage, a change detection method is performed using the previously estimate Mixture of Gaussians. The proposed full system is able to detect changes using Gaussian Mixture Models with a reduced computational cost in relation to state-of-art algorithms.},
  keywords = {Computational modeling,Navigation,Noise,Robots,Software,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/4R7SWMKL/Drews et al. - 2013 - Fast and adaptive 3D change detection algorithm fo.pdf;/Users/kshitijgoel/Zotero/storage/4HHPM62U/6631244.html}
}

@inproceedings{dryanovski_fast_2013,
  title = {Fast Visual Odometry and Mapping from {{RGB-D}} Data},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Dryanovski, Ivan and Valenti, Roberto G. and Xiao, Jizhong},
  year = {2013},
  month = may,
  pages = {2305--2310},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6630889},
  url = {https://ieeexplore.ieee.org/document/6630889/},
  urldate = {2025-07-17},
  abstract = {An RGB-D camera is a sensor which outputs color and depth and information about the scene it observes. In this paper, we present a real-time visual odometry and mapping system for RGB-D cameras. The system runs at frequencies of 30Hz and higher in a single thread on a desktop CPU with no GPU acceleration required. We recover the unconstrained 6-DoF trajectory of a moving camera by aligning sparse features observed in the current RGB-D image against a model of previous features. The model is persistent and dynamically updated from new observations using a Kalman Filter. We formulate a novel uncertainty measure for sparse RGD-B features based on a Gaussian mixture model for the filtering stage. Our registration algorithm is capable of closing small-scale loops in indoor environments online without any additional SLAM back-end techniques.},
  keywords = {Cameras,Data models,Iterative closest point algorithm,Robot vision systems,Trajectory,Uncertainty,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/2T7QBYQC/Dryanovski et al. - 2013 - Fast visual odometry and mapping from RGB-D data.pdf}
}

@phdthesis{du_learning_2024,
  title = {Learning {{Generalizable Systems}} by {{Learning Composable Energy Landscapes}}},
  author = {Du, Yilun},
  year = {2024},
  address = {Cambridge, MA},
  url = {https://yilundu.github.io/thesis.pdf},
  abstract = {How can we construct intelligent embodied agents in the physical world? Such agents should be able to autonomously solve tasks that have not been seen before, subject to external disturbances in the environment, as well as new combinations of factors such as lighting, varying sensor inputs, and unexpected interactions with agents and other objects.},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  file = {/Users/kshitijgoel/Zotero/storage/R84ZP9AT/Du - Learning Generalizable Systems by Learning Composable Energy Landscapes.pdf}
}

@article{duan_labels_2023,
  title = {Labels, {{Information}}, and {{Computation}}: {{Efficient Learning Using Sufficient Labels}}},
  shorttitle = {Labels, {{Information}}, and {{Computation}}},
  author = {Duan, Shiyu and Chang, Spencer and Principe, Jose C.},
  year = {2023},
  journal = {Journal of Machine Learning Research},
  volume = {24},
  number = {31},
  pages = {1--35},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v24/22-0019.html},
  urldate = {2024-02-23},
  abstract = {In supervised learning, obtaining a large set of fully-labeled training data is expensive. We show that we do not always need full label information on every single training example to train a competent classifier. Specifically, inspired by the principle of sufficiency in statistics, we present a statistic (a summary) of the fully-labeled training set that captures almost all the relevant information for classification but at the same time is easier to obtain directly. We call this statistic "sufficiently-labeled data" and prove its sufficiency and efficiency for finding the optimal hidden representations, on which competent classifier heads can be trained using as few as a single randomly-chosen fully-labeled example per class. Sufficiently-labeled data can be obtained from annotators directly without collecting the fully-labeled data first. And we prove that it is easier to directly obtain sufficiently-labeled data than obtaining fully-labeled data. Furthermore, sufficiently-labeled data is naturally more secure since it stores relative, instead of absolute, information. Extensive experimental results are provided to support our theory.},
  file = {/Users/kshitijgoel/Zotero/storage/LVVNGSCW/Duan et al. - 2023 - Labels, Information, and Computation Efficient Le.pdf}
}

@article{duberg_ufoexplorer_2022,
  title = {{{UFOExplorer}}: {{Fast}} and {{Scalable Sampling-Based Exploration With}} a {{Graph-Based Planning Structure}}},
  shorttitle = {{{UFOExplorer}}},
  author = {Duberg, Daniel and Jensfelt, Patric},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {2487--2494},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3142923},
  url = {https://ieeexplore.ieee.org/document/9681328},
  urldate = {2024-11-15},
  abstract = {We propose UFOExplorer, a fast and efficient exploration method that scales well with the environment size. An exploration paradigm driven by map updates is proposed to enable the robot to react quicker and to always move towards the optimal exploration goal. For each map update, a dense graph-based planning structure is updated and extended. The planning structure is then used to generate a path using a simple exploration heuristic, which guides the robot towards the closest exploration goal. The proposed method scales well with the environment size, as the planning cost is amortized when updating and extending the planning structure. The simple exploration heuristic performs on par with the most recent state-of-the-art methods in smaller environments and outperforms them in larger environments, both in terms of exploration speed and computational efficiency. The implementation of the method is made available for future research.},
  keywords = {Costs,mapping,Motion and path planning,Planning,Robots,Scalability,Search problems,Space exploration,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/87YIGNPZ/Duberg and Jensfelt - 2022 - UFOExplorer Fast and Scalable Sampling-Based Exploration With a Graph-Based Planning Structure.pdf;/Users/kshitijgoel/Zotero/storage/YW73XVCV/9681328.html}
}

@article{duberg_ufomap_2020,
  title = {{{UFOMap}}: {{An Efficient Probabilistic 3D Mapping Framework That Embraces}} the {{Unknown}}},
  shorttitle = {{{UFOMap}}},
  author = {Duberg, Daniel and Jensfelt, Patric},
  year = {2020},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {4},
  pages = {6411--6418},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.3013861},
  url = {https://ieeexplore.ieee.org/document/9158399},
  urldate = {2024-11-15},
  abstract = {3D models are an essential part of many robotic applications. In applications where the environment is unknown a-priori, or where only a part of the environment is known, it is important that the 3D model can handle the unknown space efficiently. Path planning, exploration, and reconstruction all fall into this category. In this letter we present an extension to OctoMap which we call UFOMap. UFOMap uses an explicit representation of all three states in the map, i.e., unknown, free, and occupied. This gives, surprisingly, a more memory efficient representation. We provide methods that allow for significantly faster insertions into the octree. Furthermore, UFOMap supports fast queries based on occupancy state using so called indicators and based on location by exploiting the octree structure and bounding volumes. This enables real-time colored octree mapping at high resolution (below 1 cm). UFOMap is contributed as a C++ library that can be used standalone but is also integrated into ROS.},
  keywords = {Collision avoidance,Mapping,motion and path planning,Octrees,Path planning,RGB-D perception,Robot sensing systems,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/MIIHDCIT/Duberg and Jensfelt - 2020 - UFOMap An Efficient Probabilistic 3D Mapping Framework That Embraces the Unknown.pdf;/Users/kshitijgoel/Zotero/storage/LFNWHV6J/9158399.html}
}

@book{duda_pattern_2001,
  title = {Pattern Classification},
  author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
  year = {2001},
  edition = {2nd ed},
  publisher = {Wiley},
  address = {New York},
  url = {https://www.wiley.com/en-us/Pattern+Classification%2C+2nd+Edition-p-9780471056690},
  isbn = {978-0-471-05669-0},
  lccn = {Q327 .D83 2001},
  keywords = {Pattern recognition systems,Statistical decision}
}

@article{duong_autonomous_2022,
  title = {Autonomous {{Navigation}} in {{Unknown Environments With Sparse Bayesian Kernel-Based Occupancy Mapping}}},
  author = {Duong, Thai and Yip, Michael and Atanasov, Nikolay},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--19},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3177950},
  abstract = {This article focuses on online occupancy mapping and real-time collision checking onboard an autonomous robot navigating in a large unknown environment. Commonly used voxel and octree map representations can be easily maintained in a small environment but have increasing memory requirements as the environment grows. We propose a fundamentally different approach for occupancy mapping, in which the boundary between occupied and free space is viewed as the decision boundary of a machine learning classifier. This work generalizes a kernel perceptron model which maintains a very sparse set of support vectors to represent the environment boundaries efficiently. We develop a probabilistic formulation based on relevance vector machines, handling measurement noise, and probabilistic occupancy classification, supporting autonomous navigation. We provide an online training algorithm, updating the sparse Bayesian map incrementally from streaming range data, and an efficient collision-checking method for general curves, representing potential robot trajectories. The effectiveness of our mapping and collision checking algorithms is evaluated in tasks requiring autonomous robot navigation and active mapping in unknown environments.},
  keywords = {Autonomous navigation,Bayes methods,collision avoidance,Collision avoidance,Kernel,kernel-based occupancy mapping,Navigation,relevance vector machine (RVM),sparse Bayesian classification,Support vector machines,Training,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/UJMRHLL5/Duong et al. - 2022 - Autonomous Navigation in Unknown Environments With.pdf;/Users/kshitijgoel/Zotero/storage/B8SQ9LY8/9798705.html}
}

@article{duplessis_quantification_2021,
  title = {Quantification of {{Kaolinite}} and {{Halloysite Using Machine Learning}} from {{FTIR}}, {{XRF}}, and {{Brightness Data}}},
  author = {Du Plessis, Pieter I. and Gazley, Michael F. and Tay, Stephanie L. and Trunfull, Eliza F. and Knorsch, Manuel and Branch, Thomas and Fourie, Louis F.},
  year = {2021},
  month = dec,
  journal = {Minerals},
  volume = {11},
  number = {12},
  pages = {1350},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2075-163X},
  doi = {10.3390/min11121350},
  url = {https://www.mdpi.com/2075-163X/11/12/1350},
  urldate = {2024-02-22},
  abstract = {Quantification of halloysite and kaolinite in clay deposits from X-ray diffraction (XRD) commonly requires extensive sample preparation to differentiate the two phyllosilicates. When assessing hundreds of samples for mineral resource estimations, XRD analyses may become unfeasible due to time and expense. Fourier transform infrared (FTIR) analysis is a fast and cost-effective method to discriminate between kaolinite and halloysite; however, few efforts have been made to use this technique for quantified analysis of these minerals. In this study, we trained machine- and deep-learning models on XRD data to predict the abundance of kaolinite and halloysite from FTIR, chemical composition, and brightness data. The case study is from the Cloud Nine kaolinite--halloysite deposit, Noombenberry Project, Western Australia. The residual clay deposit is hosted in the saprolitic and transition zone of the weathering profile above the basement granite on the southwestern portion of the Archean Yilgarn Craton. Compared with XRD quantification, the predicted models have an R2 of 0.97 for kaolinite and 0.96 for halloysite, demonstrating an excellent fit. Based on these results, we demonstrate that our methodology provides a cost-effective alternative to XRD to quantify kaolinite and halloysite abundances.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {clay,deep learning,kaolin,machine learning,quantification,XRD},
  file = {/Users/kshitijgoel/Zotero/storage/TNWM2WTN/Du Plessis et al. - 2021 - Quantification of Kaolinite and Halloysite Using M.pdf}
}

@incollection{durrant-whyte_multisensor_2016,
  title = {Multisensor {{Data Fusion}}},
  booktitle = {Springer {{Handbook}} of {{Robotics}}},
  author = {{Durrant-Whyte}, Hugh and Henderson, Thomas C.},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  year = {2016},
  pages = {867--896},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-32552-1_35},
  url = {https://doi.org/10.1007/978-3-319-32552-1_35},
  urldate = {2024-06-04},
  abstract = {Multisensor data fusionmultisensordata fusionis the process of combining observations from a~number of different sensors to provide a~robust and complete description of an environment or process of interest. Data fusion finds wide application in many areas of robotics such as object recognition, environment mapping, and localization.},
  isbn = {978-3-319-32552-1},
  langid = {english},
  keywords = {Data Fusion,Extended Kalman Filter,Kalman Filter,Monte Carlo,Observation Model},
  file = {/Users/kshitijgoel/Zotero/storage/FADJKMDA/Durrant-Whyte and Henderson - 2016 - Multisensor Data Fusion.pdf}
}

@article{dutoit_probabilistic_2011,
  title = {Probabilistic {{Collision Checking With Chance Constraints}}},
  author = {Du Toit, Noel E. and Burdick, J. W.},
  year = {2011},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {27},
  number = {4},
  pages = {809--815},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2011.2116190},
  url = {http://ieeexplore.ieee.org/document/5738354/},
  urldate = {2024-01-24},
  abstract = {Obstacle avoidance, and by extension collision checking, is a basic requirement for robot autonomy. Most classical approaches to collision-checking ignore the uncertainties associated with the robot and obstacle's geometry and position. It is natural to use a probabilistic description of the uncertainties. However, constraint satisfaction cannot be guaranteed, in this case, and collision constraints must instead be converted to chance constraints. Standard results for linear probabilistic constraint evaluation have been applied to probabilistic collision evaluation; however, this approach ignores the uncertainty associated with the sensed obstacle. An alternative formulation of probabilistic collision checking that accounts for robot and obstacle uncertainty is presented which allows for dependent object distributions (e.g., interactive robot-obstacle models). In order to efficiently enforce the resulting collision chance constraints, an approximation is proposed and the validity of this approximation is evaluated. The results presented here have been applied to robot-motion planning in dynamic, uncertain environments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ILXR7XWK/Du Toit and Burdick - 2011 - Probabilistic Collision Checking With Chance Const.pdf}
}

@inproceedings{ebadi_lamp_2020,
  title = {{{LAMP}}: {{Large-Scale Autonomous Mapping}} and {{Positioning}} for {{Exploration}} of {{Perceptually-Degraded Subterranean Environments}}},
  shorttitle = {{{LAMP}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ebadi, Kamak and Chang, Yun and Palieri, Matteo and Stephens, Alex and Hatteland, Alex and Heiden, Eric and Thakur, Abhishek and Funabiki, Nobuhiro and Morrell, Benjamin and Wood, Sally and Carlone, Luca and {Agha-mohammadi}, Ali-akbar},
  year = {2020},
  month = may,
  pages = {80--86},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9197082},
  abstract = {Simultaneous Localization and Mapping (SLAM) in large-scale, unknown, and complex subterranean environments is a challenging problem. Sensors must operate in off-nominal conditions; uneven and slippery terrains make wheel odometry inaccurate, while long corridors without salient features make exteroceptive sensing ambiguous and prone to drift; finally, spurious loop closures that are frequent in environments with repetitive appearance, such as tunnels and mines, could result in a significant distortion of the entire map. These challenges are in stark contrast with the need to build highly-accurate 3D maps to support a wide variety of applications, ranging from disaster response to the exploration of underground extraterrestrial worlds. This paper reports on the implementation and testing of a lidar-based multi-robot SLAM system developed in the context of the DARPA Subterranean Challenge. We present a system architecture to enhance subterranean operation, including an accurate lidar-based front-end, and a flexible and robust back-end that automatically rejects outlying loop closures. We present an extensive evaluation in large-scale, challenging subterranean environments, including the results obtained in the Tunnel Circuit of the DARPA Subterranean Challenge. Finally, we discuss potential improvements, limitations of the state of the art, and future research directions.},
  keywords = {Base stations,Laser radar,Simultaneous localization and mapping,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/XQ3BC92D/Ebadi et al. - 2020 - LAMP Large-Scale Autonomous Mapping and Positioni.pdf;/Users/kshitijgoel/Zotero/storage/ZMQSYS5U/stamp.html}
}

@misc{ebadi_present_2022,
  title = {Present and {{Future}} of {{SLAM}} in {{Extreme Underground Environments}}},
  author = {Ebadi, Kamak and Bernreiter, Lukas and Biggie, Harel and Catt, Gavin and Chang, Yun and Chatterjee, Arghya and Denniston, Christopher E. and Desch{\^e}nes, Simon-Pierre and Harlow, Kyle and Khattak, Shehryar and Nogueira, Lucas and Palieri, Matteo and Petr{\'a}{\v c}ek, Pavel and Petrl{\'i}k, Mat{\v e}j and Reinke, Andrzej and Kr{\'a}tk{\'y}, V{\'i}t and Zhao, Shibo and {Agha-mohammadi}, Ali-akbar and Alexis, Kostas and Heckman, Christoffer and Khosoussi, Kasra and Kottege, Navinda and Morrell, Benjamin and Hutter, Marco and Pauling, Fred and Pomerleau, Fran{\c c}ois and Saska, Martin and Scherer, Sebastian and Siegwart, Roland and Williams, Jason L. and Carlone, Luca},
  year = {2022},
  month = aug,
  number = {arXiv:2208.01787},
  eprint = {2208.01787},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2208.01787},
  urldate = {2022-08-07},
  abstract = {This paper reports on the state of the art in underground SLAM by discussing different SLAM strategies and results across six teams that participated in the three-year-long SubT competition. In particular, the paper has four main goals. First, we review the algorithms, architectures, and systems adopted by the teams; particular emphasis is put on lidar-centric SLAM solutions (the go-to approach for virtually all teams in the competition), heterogeneous multi-robot operation (including both aerial and ground robots), and real-world underground operation (from the presence of obscurants to the need to handle tight computational constraints). We do not shy away from discussing the dirty details behind the different SubT SLAM systems, which are often omitted from technical papers. Second, we discuss the maturity of the field by highlighting what is possible with the current SLAM systems and what we believe is within reach with some good systems engineering. Third, we outline what we believe are fundamental open problems, that are likely to require further research to break through. Finally, we provide a list of open-source SLAM implementations and datasets that have been produced during the SubT challenge and related efforts, and constitute a useful resource for researchers and practitioners.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/LVIEUKR8/Ebadi et al. - 2022 - Present and Future of SLAM in Extreme Underground .pdf;/Users/kshitijgoel/Zotero/storage/462CHIDR/2208.html}
}

@article{ebadi_present_2023,
  title = {Present and {{Future}} of {{SLAM}} in {{Extreme Environments}}: {{The DARPA SubT Challenge}}},
  shorttitle = {Present and {{Future}} of {{SLAM}} in {{Extreme Environments}}},
  author = {Ebadi, Kamak and Bernreiter, Lukas and Biggie, Harel and Catt, Gavin and Chang, Yun and Chatterjee, Arghya and Denniston, Christopher E. and Desch{\^e}nes, Simon-Pierre and Harlow, Kyle and Khattak, Shehryar and Nogueira, Lucas and Palieri, Matteo and Petr{\'a}{\v c}ek, Pavel and Petrl{\'i}k, Mat{\v e}j and Reinke, Andrzej and Kr{\'a}tk{\'y}, V{\'i}t and Zhao, Shibo and {Agha-mohammadi}, Ali-akbar and Alexis, Kostas and Heckman, Christoffer and Khosoussi, Kasra and Kottege, Navinda and Morrell, Benjamin and Hutter, Marco and Pauling, Fred and Pomerleau, Fran{\c c}ois and Saska, Martin and Scherer, Sebastian and Siegwart, Roland and Williams, Jason L. and Carlone, Luca},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3323938},
  url = {https://ieeexplore.ieee.org/document/10286080/},
  urldate = {2023-10-18},
  abstract = {This paper surveys recent progress and discusses future opportunities for Simultaneous Localization And Mapping (SLAM) in extreme underground environments. SLAM in subterranean environments, from tunnels, caves, and man-made underground structures on Earth, to lava tubes on Mars, is a key enabler for a range of applications, such as planetary exploration, search and rescue, disaster response, and automated mining, among others. SLAM in underground environments has recently received substantial attention, thanks to the DARPA Subterranean (SubT) Challenge, a global robotics competition aimed at assessing and pushing the state of the art in autonomous robotic exploration and mapping in complex underground environments. This paper reports on the state of the art in underground SLAM by discussing different SLAM strategies and results across six teams that participated in the three-year-long SubT competition. In particular, the paper has four main goals. First, we review the algorithms, architectures, and systems adopted by the teams; particular emphasis is put on LIDAR-centric SLAM solutions (the go-to approach for virtually all teams in the competition), heterogeneous multi-robot operation (including both aerial and ground robots), and real-world underground operation (from the presence of obscurants to the need to handle tight computational constraints). We do not shy away from discussing the ``dirty details'' behind the different SubT SLAM systems, which are often omitted from technical papers. Second, we discuss the maturity of the field by highlighting what is possible with the current SLAM systems and what we believe is within reach with some good systems engineering. Third, we outline what we believe are fundamental open problems, that are likely to require further research to break through. Finally, we provide a list of open-source SLAM implementations and datasets that have been produced during the SubT challenge and related efforts, and constitute a useful resource for researchers and practitioners.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/P4N2JPIX/Ebadi et al. - 2023 - Present and Future of SLAM in Extreme Environments.pdf}
}

@incollection{eberly_differential_1994,
  title = {A {{Differential Geometric Approach}} to {{Anisotropic Diffusion}}},
  booktitle = {Geometry-{{Driven Diffusion}} in {{Computer Vision}}},
  author = {Eberly, David},
  editor = {{ter Haar Romeny}, Bart M.},
  year = {1994},
  pages = {371--392},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-017-1699-4_14},
  url = {https://doi.org/10.1007/978-94-017-1699-4_14},
  urldate = {2024-04-29},
  abstract = {The necessity of using a multiscale analysis of images has clearly been established in the literature. The introduction of a continuous scale-space can be found in [187], [386], and [396]. The fundamental constraint on a continuous scale-space is that it be causal; that is, no spurious detail should be generated with increasing scale. Additional constraints involving linearity and symmetry lead to the fact that the Gaussian kernel is the unique scale-space filter. A detailed investigation of scale-space, including its natural differential operators and differential invariants is found in [358]. The issues of discretization of the operators are found in [213].},
  isbn = {978-94-017-1699-4},
  langid = {english},
  keywords = {Christoffel Symbol,Covariant Differentiation,Finite Difference Scheme,Principal Curvature,Unit Tangent Vector},
  file = {/Users/kshitijgoel/Zotero/storage/MF49FFAV/Eberly - 1994 - A Differential Geometric Approach to Anisotropic D.pdf}
}

@book{eberly_ridges_1996,
  title = {Ridges in {{Image}} and {{Data Analysis}}},
  author = {Eberly, David},
  editor = {Viergever, Max A.},
  year = {1996},
  series = {Computational {{Imaging}} and {{Vision}}},
  volume = {7},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-015-8765-5},
  url = {http://link.springer.com/10.1007/978-94-015-8765-5},
  urldate = {2024-04-29},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-90-481-4761-8 978-94-015-8765-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JTKQ84CL/Eberly - 1996 - Ridges in Image and Data Analysis.pdf}
}

@book{eberly_robust_2020,
  title = {Robust and Error-Free Geometric Computing},
  author = {Eberly, David},
  year = {2020},
  edition = {First edition},
  publisher = {CRC Press, Taylor \& Francis Group},
  address = {Boca Raton},
  abstract = {"This is a how-to book for solving problems in actual practice. The contents and accompanying source code are based on the feature requests and feedback received from industry and academics who want both the descriptions and source code for hard-to-find implementations of geometric algorithms. The code is robust, as required by the applications they work on"--},
  isbn = {978-0-367-35294-3 978-0-429-33050-6},
  lccn = {T57.825 .E24 2020},
  keywords = {Geometric programming},
  file = {/Users/kshitijgoel/Zotero/storage/QMHBWCDP/Eberly - Robust and Error-Free Geometric Computing.pdf}
}

@inproceedings{eckart_accelerated_2016,
  title = {Accelerated {{Generative Models}} for {{3D Point Cloud Data}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Eckart, Ben and Kim, Kihwan and Troccoli, Alejandro and Kelly, Alonzo and Kautz, Jan},
  year = {2016},
  month = jun,
  pages = {5497--5505},
  publisher = {IEEE},
  address = {Las Vegas, NV, USA},
  doi = {10.1109/CVPR.2016.593},
  url = {http://ieeexplore.ieee.org/document/7780962/},
  urldate = {2021-09-29},
  isbn = {978-1-4673-8851-1},
  file = {/Users/kshitijgoel/Zotero/storage/M7BAPXGJ/Eckart et al. - 2016 - Accelerated Generative Models for 3D Point Cloud D.pdf}
}

@phdthesis{eckart_compact_2017,
  title = {Compact {{Generative Models}} of {{Point Cloud Data}} for {{3D Perception}}},
  author = {Eckart, Benjamin},
  year = {2017},
  month = oct,
  address = {Pittsburgh, PA, USA},
  url = {https://www.ri.cmu.edu/app/uploads/2018/02/b_eckart_robotics_2017.pdf},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/7E58FVRA/Eckart - Compact Generative Models of Point Cloud Data for .pdf}
}

@inproceedings{eckart_eoe_2018,
  title = {{{EOE}}: {{Expected Overlap Estimation}} over {{Unstructured Point Cloud Data}}},
  shorttitle = {{{EOE}}},
  booktitle = {2018 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Eckart, Benjamin and Kim, Kihwan and Jan, Kautz},
  year = {2018},
  month = sep,
  pages = {747--755},
  issn = {2475-7888},
  doi = {10.1109/3DV.2018.00090},
  abstract = {We present an iterative overlap estimation technique to augment existing point cloud registration algorithms that can achieve high performance in difficult real-world situations where large pose displacement and non-overlapping geometry would otherwise cause traditional methods to fail. Our approach estimates overlapping regions through an iterative Expectation Maximization procedure that encodes the sensor field-of-view into the registration process. The proposed technique, Expected Overlap Estimation (EOE), is derived from the observation that differences in field-of-view violate the iid assumption implicitly held by all maximum likelihood based registration techniques. We demonstrate how our approach can augment many popular registration methods with minimal computational overhead. Through experimentation on both synthetic and real-world datasets, we find that adding an explicit overlap estimation step can aid robust outlier handling and increase the accuracy of both ICP-based and GMM-based registration methods, especially in large unstructured domains and where the amount of overlap between point clouds is very small.},
  keywords = {Data models,Estimation,Geometry,Iterative closest point algorithm,overlap estimation,point cloud,registration,Three-dimensional displays,Two dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/HY7S2C2C/Eckart et al. - 2018 - EOE Expected Overlap Estimation over Unstructured.pdf}
}

@inproceedings{eckart_hgmr_2018,
  title = {{{HGMR}}: {{Hierarchical Gaussian Mixtures}} for {{Adaptive 3D Registration}}},
  shorttitle = {{{HGMR}}},
  booktitle = {Proceedings of the {{European Conference}} on {{Computer Vision}} ({{ECCV}})},
  author = {Eckart, B. and Kim, K. and Kautz, J.},
  year = {2018},
  pages = {705--721},
  url = {https://openaccess.thecvf.com/content_ECCV_2018/html/Benjamin_Eckart_Fast_and_Accurate_ECCV_2018_paper.html},
  urldate = {2022-09-20},
  file = {/Users/kshitijgoel/Zotero/storage/44PF3LEF/Eckart et al. - 2018 - HGMR Hierarchical Gaussian Mixtures for Adaptive .pdf}
}

@inproceedings{eckart_selfsupervised_2021,
  title = {Self-{{Supervised Learning}} on {{3D Point Clouds}} by {{Learning Discrete Generative Models}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Eckart, Benjamin and Yuan, Wentao and Liu, Chao and Kautz, Jan},
  year = {2021},
  pages = {8248--8257},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Eckart_Self-Supervised_Learning_on_3D_Point_Clouds_by_Learning_Discrete_Generative_CVPR_2021_paper.html},
  urldate = {2022-09-20},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7UKVBD3U/Eckart et al. - 2021 - Self-Supervised Learning on 3D Point Clouds by Lea.pdf}
}

@article{edgeworth_law_1892,
  title = {The Law of Error and Correlated Averages},
  author = {Edgeworth, F. Y.},
  year = {1892},
  month = nov,
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume = {34},
  number = {210},
  pages = {429--438},
  issn = {1941-5982, 1941-5990},
  doi = {10.1080/14786449208620355},
  url = {https://www.tandfonline.com/doi/full/10.1080/14786449208620355},
  urldate = {2024-07-24},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KBD5BA8T/Edgeworth - 1892 - L. The law of error and correlated averages.pdf}
}

@article{eilers_unimodal_2005,
  title = {Unimodal Smoothing},
  author = {Eilers, Paul H. C.},
  year = {2005},
  journal = {Journal of Chemometrics},
  volume = {19},
  number = {5-7},
  pages = {317--328},
  issn = {1099-128X},
  doi = {10.1002/cem.935},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cem.935},
  urldate = {2025-08-03},
  abstract = {In many applications it is expected from theory that a signal should be non-negative and unimodal, that is, show only one peak. If the data are noisy, standard smoothing algorithms will not always give the desired result: peaks may be rounded and negative lobes may occur in the tails. Positive unimodal fits can be obtained by modeling the logarithm of a curve and combining a standard roughness penalty with a specialized asymmetric penalty. The theoretical basis and implementation in Matlab are presented, as well as performance on real and simulated data. Copyright {\copyright} 2006 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2006 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {asymmetric penalty,log-concave,monotone,P-splines},
  file = {/Users/kshitijgoel/Zotero/storage/67C6XCXZ/Eilers - 2005 - Unimodal smoothing.pdf;/Users/kshitijgoel/Zotero/storage/SIYCMEP6/cem.html}
}

@inproceedings{einhorn_finding_2011,
  title = {Finding the Adequate Resolution for Grid Mapping - {{Cell}} Sizes Locally Adapting on-the-Fly},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Einhorn, Erik and Schr{\"o}ter, Christof and Gross, Horst-Michael},
  year = {2011},
  month = may,
  pages = {1843--1848},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980084},
  abstract = {For robot mapping occupancy grid maps are the most common representation of the environment. However, most existing algorithms for creating such maps assume a fixed resolution of the grid cells. In this paper we present a novel mapping technique that chooses the resolution of each cell adaptively by merging and splitting cells depending on the measurements. The splitting of the cells is based on a statistical measure that we derive in this paper. In contrast to other approaches the adaption of the resolution is done online during the mapping process itself. Additionally, we introduce the Nd-Tree, a generalization of quadtrees and octrees that allows to subdivide any d-dimensional volume recursively with Nd children per node. Using this data structure our approach can be implemented in a very generic way and allows the creation of 2D, 3D and even higher dimensional maps using the same algorithm. Finally, we show results of our proposed method for 2D and 3D mapping using different kinds of range sensors.},
  keywords = {Histograms,Octrees,Robots,Sensors,Three dimensional displays,Volume measurement},
  file = {/Users/kshitijgoel/Zotero/storage/AJMWWH5X/Einhorn et al. - 2011 - Finding the adequate resolution for grid mapping -.pdf;/Users/kshitijgoel/Zotero/storage/XWCQYV4K/5980084.html}
}

@article{elbrachter_deep_2021,
  title = {Deep {{Neural Network Approximation Theory}}},
  author = {Elbrachter, Dennis and Perekrestenko, Dmytro and Grohs, Philipp and Bolcskei, Helmut},
  year = {2021},
  month = may,
  journal = {IEEE Transactions on Information Theory},
  volume = {67},
  number = {5},
  pages = {2581--2623},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2021.3062161},
  url = {https://ieeexplore.ieee.org/document/9363169/},
  urldate = {2024-04-23},
  abstract = {This paper develops fundamental limits of deep neural network learning by characterizing what is possible if no constraints are imposed on the learning algorithm and on the amount of training data. Concretely, we consider Kolmogorovoptimal approximation through deep neural networks with the guiding theme being a relation between the complexity of the function (class) to be approximated and the complexity of the approximating network in terms of connectivity and memory requirements for storing the network topology and the associated quantized weights. The theory we develop establishes that deep networks are Kolmogorov-optimal approximants for markedly different function classes, such as unit balls in Besov spaces and modulation spaces. In addition, deep networks provide exponential approximation accuracy---i.e., the approximation error decays exponentially in the number of nonzero weights in the network---of the multiplication operation, polynomials, sinusoidal functions, and certain smooth functions. Moreover, this holds true even for one-dimensional oscillatory textures and the Weierstrass function---a fractal function, neither of which has previously known methods achieving exponential approximation accuracy. We also show that in the approximation of sufficiently smooth functions finite-width deep networks require strictly smaller connectivity than finite-depth wide networks.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JDLTWVJS/Elbrachter et al. - 2021 - Deep Neural Network Approximation Theory.pdf}
}

@article{elfes_using_1989,
  title = {Using Occupancy Grids for Mobile Robot Perception and Navigation},
  author = {Elfes, A.},
  year = {1989},
  month = jun,
  journal = {Computer},
  volume = {22},
  number = {6},
  pages = {46--57},
  issn = {1558-0814},
  doi = {10.1109/2.30720},
  url = {https://ieeexplore.ieee.org/document/30720},
  urldate = {2024-01-27},
  abstract = {An approach to robot perception and world modeling that uses a probabilistic tesselated representation of spatial information called the occupancy grid is reviewed. The occupancy grid is a multidimensional random field that maintains stochastic estimates of the occupancy state of the cells in a spatial lattice. To construct a sensor-derived map of the robot's world, the cell state estimates are obtained by interpreting the incoming range readings using probabilistic sensor models. Bayesian estimation procedures allow the incremental updating of the occupancy grid, using readings taken from several sensors over multiple points of view. The use of occupancy grids from mapping and for navigation is examined. Operations on occupancy grids and extensions of the occupancy grid framework are briefly considered.{$<>$}},
  keywords = {Decision making,Mobile robots,Navigation,Path planning,Remotely operated vehicles,Robot kinematics,Robot sensing systems,Robustness,Service robots,State estimation},
  file = {/Users/kshitijgoel/Zotero/storage/9V9NNEMM/Elfes - 1989 - Using occupancy grids for mobile robot perception .pdf;/Users/kshitijgoel/Zotero/storage/JFY4B25I/30720.html}
}

@misc{elsayed_streaming_2024,
  title = {Streaming {{Deep Reinforcement Learning Finally Works}}},
  author = {Elsayed, Mohamed and Vasan, Gautham and Mahmood, A. Rupam},
  year = {2024},
  month = dec,
  number = {arXiv:2410.14606},
  eprint = {2410.14606},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.14606},
  url = {http://arxiv.org/abs/2410.14606},
  urldate = {2025-02-04},
  abstract = {Natural intelligence processes experience as a continuous stream, sensing, acting, and learning moment-by-moment in real time. Streaming learning, the modus operandi of classic reinforcement learning (RL) algorithms like Q-learning and TD, mimics natural learning by using the most recent sample without storing it. This approach is also ideal for resource-constrained, communication-limited, and privacy-sensitive applications. However, in deep RL, learners almost always use batch updates and replay buffers, making them computationally expensive and incompatible with streaming learning. Although the prevalence of batch deep RL is often attributed to its sample efficiency, a more critical reason for the absence of streaming deep RL is its frequent instability and failure to learn, which we refer to as stream barrier. This paper introduces the stream-x algorithms, the first class of deep RL algorithms to overcome stream barrier for both prediction and control and match sample efficiency of batch RL. Through experiments in Mujoco Gym, DM Control Suite, and Atari Games, we demonstrate stream barrier in existing algorithms and successful stable learning with our stream-x algorithms: stream Q, stream AC, and stream TD, achieving the best model-free performance in DM Control Dog environments. A set of common techniques underlies the stream-x algorithms, enabling their success with a single set of hyperparameters and allowing for easy extension to other algorithms, thereby reviving streaming RL.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/KIL5ZBQ6/Elsayed et al. - 2024 - Streaming Deep Reinforcement Learning Finally Works.pdf;/Users/kshitijgoel/Zotero/storage/XQCYBRH4/2410.html}
}

@article{elsken_neural_2019,
  title = {Neural {{Architecture Search}}: {{A Survey}}},
  shorttitle = {Neural {{Architecture Search}}},
  author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  year = {2019},
  journal = {Journal of Machine Learning Research},
  volume = {20},
  number = {55},
  pages = {1--21},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v20/18-598.html},
  urldate = {2024-02-04},
  abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated {\textbackslash}emph\{neural architecture search\} methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
  file = {/Users/kshitijgoel/Zotero/storage/HYCFTY38/Elsken et al. - 2019 - Neural Architecture Search A Survey.pdf}
}

@misc{endo_benchnav_2024,
  title = {{{BenchNav}}: {{Simulation Platform}} for {{Benchmarking Off-road Navigation Algorithms}} with {{Probabilistic Traversability}}},
  shorttitle = {{{BenchNav}}},
  author = {Endo, Masafumi and Honda, Kohei and Ishigami, Genya},
  year = {2024},
  month = may,
  number = {arXiv:2405.13318},
  eprint = {2405.13318},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.13318},
  urldate = {2024-05-24},
  abstract = {As robotic navigation techniques in perception and planning advance, mobile robots increasingly venture into offroad environments involving complex traversability. However, selecting suitable planning methods remains a challenge due to their algorithmic diversity, as each offers unique benefits. To aid in algorithm design, we introduce BenchNav, an open-source PyTorch-based simulation platform for benchmarking off-road navigation with uncertain traversability. Built upon Gymnasium, BenchNav provides three key features: 1) a data generation pipeline for preparing synthetic natural environments, 2) built-in machine learning models for traversability prediction, and 3) consistent execution of path and motion planning across different algorithms. We show BenchNav's versatility through simulation examples in off-road environments, employing three representative planning algorithms from different domains.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/PE4RAUN7/Endo et al. - 2024 - BenchNav Simulation Platform for Benchmarking Off-road Navigation Algorithms with Probabilistic Tra.pdf}
}

@inproceedings{engel_concept_2010,
  title = {Concept {{Formation Using Incremental Gaussian Mixture Models}}},
  booktitle = {Progress in {{Pattern Recognition}}, {{Image Analysis}}, {{Computer Vision}}, and {{Applications}}},
  author = {Engel, Paulo Martins and Heinen, Milton Roberto},
  editor = {Bloch, Isabelle and Cesar, Roberto M.},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {128--135},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-16687-7_21},
  abstract = {This paper presents a new algorithm for incremental concept formation based on a Bayesian framework. The algorithm, called IGMM (for Incremental Gaussian Mixture Model), uses a probabilistic approach for modeling the environment, and so, it can rely on solid arguments to handle this issue. IGMM creates and continually adjusts a probabilistic model consistent to all sequentially presented data without storing or revisiting previous training data. IGMM is particularly useful for incremental clustering of data streams, as encountered in the domain of moving object trajectories and mobile robotics. It creates an incremental knowledge model of the domain consisting of primitive concepts involving all observed variables. Experiments with simulated data streams of sonar readings of a mobile robot shows that IGMM can efficiently segment trajectories detecting higher order concepts like ``wall at right'' and ``curve at left''.},
  isbn = {978-3-642-16687-7},
  langid = {english},
  keywords = {Bayesian Methods,Clustering,Concept Formation,EM Algorithm,Finite Mixtures,Incremental Learning,Unsupervised Learning},
  file = {/Users/kshitijgoel/Zotero/storage/AP6ALTKS/Engel and Heinen - 2010 - Concept Formation Using Incremental Gaussian Mixtu.pdf}
}

@inproceedings{engel_incremental_2010,
  title = {Incremental {{Learning}} of {{Multivariate Gaussian Mixture Models}}},
  booktitle = {Advances in {{Artificial Intelligence}} -- {{SBIA}} 2010},
  author = {Engel, Paulo Martins and Heinen, Milton Roberto},
  editor = {{da Rocha Costa}, Ant{\^o}nio Carlos and Vicari, Rosa Maria and Tonidandel, Flavio},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {82--91},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-16138-4_9},
  abstract = {This paper presents a new algorithm for unsupervised incremental learning based on a Bayesian framework. The algorithm, called IGMM (for Incremental Gaussian Mixture Model), creates and continually adjusts a Gaussian Mixture Model consistent to all sequentially presented data. IGMM is particularly useful for on-line incremental clustering of data streams, as encountered in the domain of mobile robotics and animats. It creates an incremental knowledge model of the domain consisting of primitive concepts involving all observed variables. We present some preliminary results obtained using synthetic data and also consider practical issues as convergence properties discuss future developments.},
  isbn = {978-3-642-16138-4},
  langid = {english},
  keywords = {Bayesian Methods,Clustering,Expectation-Maximization Algorithm,Finite Mixtures,Incremental Learning,Unsupervised Learning},
  file = {/Users/kshitijgoel/Zotero/storage/VI227B98/Engel and Heinen - 2010 - Incremental Learning of Multivariate Gaussian Mixt.pdf}
}

@inproceedings{engin_active_2021,
  title = {Active {{Localization}} of {{Multiple Targets}} from {{Noisy Relative Measurements}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIV}}},
  author = {Engin, Selim and Isler, Volkan},
  editor = {LaValle, Steven M. and Lin, Ming and Ojala, Timo and Shell, Dylan and Yu, Jingjin},
  year = {2021},
  pages = {398--413},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-66723-8_24},
  abstract = {Consider a mobile robot tasked with localizing targets at unknown locations by obtaining relative measurements. The observations can be bearing or range measurements. How should the robot move so as to localize the targets and minimize the uncertainty in their locations as quickly as possible? This is a difficult optimization problem for which existing approaches are either greedy in nature or they rely on accurate initial estimates.},
  isbn = {978-3-030-66723-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/N3J7VR5N/Engin and Isler - 2021 - Active Localization of Multiple Targets from Noisy.pdf}
}

@article{erdmann_understanding_1995,
  title = {Understanding {{Action}} and {{Sensing}} by {{Designing Action-Based Sensors}}},
  author = {Erdmann, Michael},
  year = {1995},
  month = oct,
  journal = {The International Journal of Robotics Research},
  volume = {14},
  number = {5},
  pages = {483--509},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/027836499501400506},
  url = {https://doi.org/10.1177/027836499501400506},
  urldate = {2022-10-24},
  abstract = {This article proposes a method for automatically designing sensors from the specification of a robot's task, its actions, and its uncertainty in control. The sensors provide the information required by the robot to perform its task, despite uncertainty in sensing and control. The key idea is to generate a strategy for a robot task by using a backchaining planner that assumes perfect sensing while taking careful account of control uncer tainty. The resulting plan indirectly specifies a sensor that tells the robot when to execute which action. Although the planner assumes perfect sensing information, the sensor need not ac tually provide perfect information. Instead, the sensor provides only the information required for the plan to function correctly.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QH25UUP8/Erdmann - 1995 - Understanding Action and Sensing by Designing Acti.pdf}
}

@inproceedings{espiau_formal_1996,
  title = {Formal {{Verification}} in {{Robotics}}: {{Why}} and {{How}}?},
  shorttitle = {Formal {{Verification}} in {{Robotics}}},
  booktitle = {Robotics {{Research}}},
  author = {Espiau, B. and Kapellos, K. and Jourdan, M.},
  editor = {Giralt, Georges and Hirzinger, Gerhard},
  year = {1996},
  pages = {225--236},
  publisher = {Springer},
  address = {London},
  doi = {10.1007/978-1-4471-1021-7_26},
  abstract = {A mobile robot aimed to operate in an hazardous environment is a typical example of critical system. We mean here that, for such a system, like for a satellite, any repairing or recovery operation, even a mission reconfiguration, which would involve the intervention of a human operator is always costly, often difficult and sometimes impossible. This is why such systems should be at least provided with capacities of on-line adaption, like self replanning or sensor-based control. However, this is not sufficient and we have to be sure, as far as possible, that the system will behave correctly, before launching. More precisely, once a mission has been defined, we would like to verify that:its specifications are correct, i.e. that they correspond to the desired goals,its programming conforms to specifications,the constraints induced by real-time and implementation issues do not disturb its behavior.},
  isbn = {978-1-4471-1021-7},
  langid = {english},
  keywords = {Formal Verification,Mobile Robot,Temporal Logic,Verification Method,Verification Tool},
  file = {/Users/kshitijgoel/Zotero/storage/FJYTAF7E/Espiau et al. - 1996 - Formal Verification in Robotics Why and How.pdf}
}

@phdthesis{eysenbach_probabilistic_2023,
  type = {Thesis},
  title = {Probabilistic {{Reinforcement Learning}}: {{Using Data}} to {{Define Desired Outcomes}} and {{Inferring How}} to {{Get There}}},
  shorttitle = {Probabilistic {{Reinforcement Learning}}},
  author = {Eysenbach, Benjamin},
  year = {2023},
  month = oct,
  doi = {10.1184/R1/24234052.v1},
  url = {https://kilthub.cmu.edu/articles/thesis/Probabilistic_Reinforcement_Learning_Using_Data_to_Define_Desired_Outcomes_and_Inferring_How_to_Get_There/24234052/1},
  urldate = {2024-06-18},
  abstract = {This thesis studies algorithms for teaching autonomous agents to complete tasks through trial and error learning. Typically, this problem is posed as a reinforcement learning (RL) problem, wherein agents attempt to maximize a user-provided reward function. The algorithms studied here take a different approach, largely eschewing the reward function and instead learning to achieve desired outcomes directly from data. This approach allows users to employ algorithmic tools from the supervised and unsupervised learning, while also surfacing an interface that allows non-expert users to teach agents new tasks....},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/4MYCVSXW/Eysenbach - 2023 - Probabilistic Reinforcement Learning Using Data to Define Desired Outcomes and Inferring How to Get.pdf}
}

@article{fabisch_gmr_2021,
  title = {Gmr: {{Gaussian Mixture Regression}}},
  shorttitle = {Gmr},
  author = {Fabisch, Alexander},
  year = {2021},
  month = jun,
  journal = {Journal of Open Source Software},
  volume = {6},
  number = {62},
  pages = {3054},
  issn = {2475-9066},
  doi = {10.21105/joss.03054},
  url = {https://joss.theoj.org/papers/10.21105/joss.03054},
  urldate = {2023-03-21},
  abstract = {Fabisch, A., (2021). gmr: Gaussian Mixture Regression. Journal of Open Source Software, 6(62), 3054, https://doi.org/10.21105/joss.03054},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/U2X7IH4T/Fabisch - 2021 - gmr Gaussian Mixture Regression.pdf}
}

@inproceedings{faessler_automatic_2015,
  title = {Automatic Re-Initialization and Failure Recovery for Aggressive Flight with a Monocular Vision-Based Quadrotor},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Faessler, Matthias and Fontana, Flavio and Forster, Christian and Scaramuzza, Davide},
  year = {2015},
  month = may,
  pages = {1722--1729},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7139420},
  url = {https://ieeexplore.ieee.org/document/7139420},
  urldate = {2024-12-17},
  abstract = {Autonomous, vision-based quadrotor flight is widely regarded as a challenging perception and control problem since the accuracy of a flight maneuver is strongly influenced by the quality of the on-board state estimate. In addition, any vision-based state estimator can fail due to the lack of visual information in the scene or due to the loss of feature tracking after an aggressive maneuver. When this happens, the robot should automatically re-initialize the state estimate to maintain its autonomy and, thus, guarantee the safety for itself and the environment. In this paper, we present a system that enables a monocular-vision-based quadrotor to automatically recover from any unknown, initial attitude with significant velocity, such as after loss of visual tracking due to an aggressive maneuver. The recovery procedure consists of multiple stages, in which the quadrotor, first, stabilizes its attitude and altitude, then, re-initializes its visual state-estimation pipeline before stabilizing fully autonomously. To experimentally demonstrate the performance of our system, we aggressively throw the quadrotor in the air by hand and have it recover and stabilize all by itself. We chose this example as it simulates conditions similar to failure recovery during aggressive flight. Our system was able to recover successfully in several hundred throws in both indoor and outdoor environments.},
  keywords = {Acceleration,Attitude control,Current measurement,Pipelines,Quaternions,State estimation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/HTEW32UC/Faessler et al. - 2015 - Automatic re-initialization and failure recovery for aggressive flight with a monocular vision-based.pdf}
}

@article{faessler_differential_2018,
  title = {Differential {{Flatness}} of {{Quadrotor Dynamics Subject}} to {{Rotor Drag}} for {{Accurate Tracking}} of {{High-Speed Trajectories}}},
  author = {Faessler, Matthias and Franchi, Antonio and Scaramuzza, Davide},
  year = {2018},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {2},
  pages = {620--626},
  issn = {2377-3766},
  doi = {10.1109/LRA.2017.2776353},
  abstract = {In this letter, we prove that the dynamical model of a quadrotor subject to linear rotor drag effects is differentially flat in its position and heading. We use this property to compute feedforward control terms directly from a reference trajectory to be tracked. The obtained feedforward terms are then used in a cascaded, nonlinear feedback control law that enables accurate agile flight with quadrotors. Compared to the state-of-the-art control methods, which treat the rotor drag as an unknown disturbance, our method reduces the trajectory tracking error significantly. Finally, we present a method based on a gradient-free optimization to identify the rotor drag coefficients, which are required to compute the feedforward control terms. The new theoretical results are thoroughly validated trough extensive comparative experiments.},
  keywords = {Acceleration,Aerial systems,Aerodynamics,Computational modeling,differential flatness,Drag,dynamics,mechanics and control,quadrotor control,Rotors,Trajectory,Trajectory tracking},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/books/1712.02402.pdf;/Users/kshitijgoel/Zotero/storage/T4U3HID4/Faessler et al. - 2018 - Differential Flatness of Quadrotor Dynamics Subjec.pdf;/Users/kshitijgoel/Zotero/storage/4JW8BWW4/stamp.html}
}

@inproceedings{fairfield_active_2010,
  title = {Active {{SLAM}} and {{Loop Prediction}} with the {{Segmented Map Using Simplified Models}}},
  booktitle = {Field and {{Service Robotics}}},
  author = {Fairfield, Nathaniel and Wettergreen, David},
  editor = {Howard, Andrew and Iagnemma, Karl and Kelly, Alonzo},
  year = {2010},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {173--182},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-13408-1_16},
  abstract = {We previously introduced the SegSLAM algorithm, an approach to the simultaneous localization and mapping (SLAM) problem that divides the environment up into segments, or submaps, using heuristic methods.We investigate a realtime method for Active SLAM with SegSLAM, in which actions are selected in order to reduce uncertainty in both the local metric submap and the global topological map. Recent work in the area of Active SLAM has been built on the theoretical basis of information entropy. Due to the complexity of the SegSLAM belief state, as encoded in the SegMap representation, it is not feasible to estimate the expected entropy of the full belief state. Instead, we use a simplified model to heuristically select entropy-reducing actions without explicitly evaluating the full belief state.We discuss the relation of this heuristic method to the full entropy estimation method, and present results from applying our planning method in real-time onboard a mobile robot.},
  isbn = {978-3-642-13408-1},
  langid = {english},
  keywords = {Belief State,Center Tunnel,Information Entropy,Loop Prediction,Mobile Robot},
  file = {/Users/kshitijgoel/Zotero/storage/I29S3678/Fairfield and Wettergreen - 2010 - Active SLAM and Loop Prediction with the Segmented.pdf}
}

@inproceedings{fakoorian_rose_2023,
  title = {{{ROSE}}: {{Robust State Estimation}} via~{{Online Covariance Adaption}}},
  shorttitle = {{{ROSE}}},
  booktitle = {Robotics {{Research}}},
  author = {Fakoorian, Seyed and Otsu, Kyohei and Khattak, Shehryar and Palieri, Matteo and {Agha-mohammadi}, Ali-akbar},
  editor = {Billard, Aude and Asfour, Tamim and Khatib, Oussama},
  year = {2023},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {452--467},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-25555-7_31},
  abstract = {Robust state estimation is critical for enabling reliable autonomous robot operations in challenging environments. To estimate the state, heterogeneous sensor fusion is commonly employed to enhance the reliability against perceptual failure. However, most known methods for sensor-fusion are brittle to dynamic perceptual condition changes due to the use of hand-tuned and time-constant error models. This paper introduces ROSE, a Robust Online-adaptive State Estimator, capable of adapting uncertainty statistics for individual multi-modal estimates in real-time to perform reliable sensor-fusion for robot state estimation. The proposed method leverages theory from adaptive Kalman filtering and extends it to optimization-based methods, to improve estimation accuracy while enabling integration of delayed heterogeneous sensor inputs. ROSE has been thoroughly evaluated by simulation studies and real-world demonstrations using a high-speed off-road vehicle navigating complex unstructured terrains and performing aggressive motions.},
  isbn = {978-3-031-25555-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GLLA8QJQ/Fakoorian et al. - 2023 - ROSE Robust State Estimation via Online Covarianc.pdf}
}

@inproceedings{falanga_aggressive_2017,
  title = {Aggressive Quadrotor Flight through Narrow Gaps with Onboard Sensing and Computing Using Active Vision},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Falanga, Davide and Mueggler, Elias and Faessler, Matthias and Scaramuzza, Davide},
  year = {2017},
  month = may,
  pages = {5774--5781},
  doi = {10.1109/ICRA.2017.7989679},
  abstract = {We address one of the main challenges towards autonomous quadrotor flight in complex environments, which is flight through narrow gaps. While previous works relied on off-board localization systems or on accurate prior knowledge of the gap position and orientation in the world reference frame, we rely solely on onboard sensing and computing and estimate the full state by fusing gap detection from a single onboard camera with an IMU. This problem is challenging for two reasons: (i) the quadrotor pose uncertainty with respect to the gap increases quadratically with the distance from the gap; (ii) the quadrotor has to actively control its orientation towards the gap to enable state estimation (i.e., active vision). We solve this problem by generating a trajectory that considers geometric, dynamic, and perception constraints: during the approach maneuver, the quadrotor always faces the gap to allow state estimation, while respecting the vehicle dynamics; during the traverse through the gap, the distance of the quadrotor to the edges of the gap is maximized. Furthermore, we replan the trajectory during its execution to cope with the varying uncertainty of the state estimate. We successfully evaluate and demonstrate the proposed approach in many real experiments, achieving a success rate of 80\% and gap orientations up to 45{$^\circ$}. To the best of our knowledge, this is the first work that addresses and achieves autonomous, aggressive flight through narrow gaps using only onboard sensing and computing and without prior knowledge of the pose of the gap.},
  keywords = {Cameras,Planning,Robot sensing systems,State estimation,Trajectory,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/5GVUF6T2/Falanga et al. - 2017 - Aggressive quadrotor flight through narrow gaps wi.pdf;/Users/kshitijgoel/Zotero/storage/W6BBMUCR/7989679.html}
}

@article{falanga_how_2019,
  title = {How {{Fast Is Too Fast}}? {{The Role}} of {{Perception Latency}} in {{High-Speed Sense}} and {{Avoid}}},
  shorttitle = {How {{Fast Is Too Fast}}?},
  author = {Falanga, Davide and Kim, Suseong and Scaramuzza, Davide},
  year = {2019},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {2},
  pages = {1884--1891},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2898117},
  url = {https://ieeexplore.ieee.org/document/8636976},
  urldate = {2024-11-15},
  abstract = {In this letter, we study the effects that perception latency has on the maximum speed a robot can reach to safely navigate through an unknown cluttered environment. We provide a general analysis that can serve as a baseline for future quantitative reasoning for design tradeoffs in autonomous robot navigation. We consider the case where the robot is modeled as a linear second-order system with bounded input and navigates through static obstacles. Also, we focus on a scenario where the robot wants to reach a target destination in as little time as possible, and therefore cannot change its longitudinal velocity to avoid obstacles. We show how the maximum latency that the robot can tolerate to guarantee safety is related to the desired speed, the range of its sensing pipeline, and the actuation limitations of the platform (i.e., the maximum acceleration it can produce). As a particular case study, we compare monocular and stereo frame-based cameras against novel, low-latency sensors, such as event cameras, in the case of quadrotor flight. To validate our analysis, we conduct experiments on a quadrotor platform equipped with an event camera to detect and avoid obstacles thrown towards the robot. To the best of our knowledge, this is the first theoretical work in which perception and actuation limitations are jointly considered to study the performance of a robotic platform in high-speed navigation.},
  keywords = {aerial systems: perception and autonomy,Cameras,Collision avoidance,Navigation,Robot vision systems,visual-based navigation},
  file = {/Users/kshitijgoel/Zotero/storage/YGNZCKDT/Falanga et al. - 2019 - How Fast Is Too Fast The Role of Perception Latency in High-Speed Sense and Avoid.pdf;/Users/kshitijgoel/Zotero/storage/BDZ8KN7I/8636976.html}
}

@inproceedings{falanga_pampc_2018,
  title = {{{PAMPC}}: {{Perception-Aware Model Predictive Control}} for {{Quadrotors}}},
  shorttitle = {{{PAMPC}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Falanga, Davide and Foehn, Philipp and Lu, Peng and Scaramuzza, Davide},
  year = {2018},
  month = oct,
  pages = {1--8},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8593739},
  url = {https://ieeexplore.ieee.org/document/8593739/?arnumber=8593739},
  urldate = {2025-02-03},
  abstract = {We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sensing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, together with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the conflict between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.},
  keywords = {Cameras,Optimization,Planning,Predictive control,Robot vision systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/CKB3RKUY/Falanga et al. - 2018 - PAMPC Perception-Aware Model Predictive Control for Quadrotors.pdf;/Users/kshitijgoel/Zotero/storage/9CC2DLRR/8593739.html}
}

@article{fan_threefilterstonormal_2021,
  title = {Three-{{Filters-to-Normal}}: {{An Accurate}} and {{Ultrafast Surface Normal Estimator}}},
  shorttitle = {Three-{{Filters-to-Normal}}},
  author = {Fan, Rui and Wang, Hengli and Xue, Bohuan and Huang, Huaiyang and Wang, Yuan and Liu, Ming and Pitas, Ioannis},
  year = {2021},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {5405--5412},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3067308},
  url = {https://ieeexplore.ieee.org/document/9381580},
  urldate = {2024-06-03},
  abstract = {This letter proposes three-filters-to-normal (3F2N), an accurate and ultrafast surface normal estimator (SNE), which is designed for structured range sensor data, e.g., depth/disparity images. 3F2N SNE computes surface normals by simply performing three filtering operations (two image gradient filters in horizontal and vertical directions, respectively, and a mean/median filter) on an inverse depth image or a disparity image. Despite the simplicity of 3F2N SNE, no similar method already exists in the literature. To evaluate the performance of our proposed SNE, we created three large-scale synthetic datasets (easy, medium and hard) using 24 3D mesh models, each of which is used to generate 1800-2500 pairs of depth images (resolution: 480 {\texttimes} 640 pixels) and the corresponding ground-truth surface normal maps from different views. 3F2N SNE demonstrates the state-of-the-art performance, outperforming all other existing geometry-based SNEs, where the average angular errors with respect to the easy, medium and hard datasets are 1.66{$^\circ$}, 5.69{$^\circ$} and 15.31{$^\circ$}, respectively. Furthermore, our C++ and CUDA implementations achieve a processing speed of over 260 Hz and 21 kHz, respectively. Our datasets and source code are publicly available at sites.google.com/view/3f2n.},
  keywords = {Computer vision,Datasets,Estimation,Fans,range sensor data,Robot sensing systems,Solid modeling,surface normal,Surface treatment,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/L3XJFBTQ/Fan et al. - 2021 - Three-Filters-to-Normal An Accurate and Ultrafast Surface Normal Estimator.pdf;/Users/kshitijgoel/Zotero/storage/6846F49P/9381580.html}
}

@inproceedings{fang_3dac_2022,
  title = {{{3DAC}}: {{Learning Attribute Compression}} for {{Point Clouds}}},
  shorttitle = {{{3DAC}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Fang, Guangchi and Hu, Qingyong and Wang, Hanyun and Xu, Yiling and Guo, Yulan},
  year = {2022},
  pages = {14819--14828},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.html},
  urldate = {2022-09-02},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BBBAJBXC/Fang et al. - 2022 - 3DAC Learning Attribute Compression for Point Clo.pdf}
}

@article{faubel_split_2009,
  title = {The {{Split}} and {{Merge Unscented Gaussian Mixture Filter}}},
  author = {Faubel, F. and McDonough, J. and Klakow, D.},
  year = {2009},
  month = sep,
  journal = {IEEE Signal Processing Letters},
  volume = {16},
  number = {9},
  pages = {786--789},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2009.2024859},
  url = {http://ieeexplore.ieee.org/document/5071279/},
  urldate = {2023-10-30},
  abstract = {In this work we present a novel approach to nonlinear, non-Gaussian tracking problems based on splitting and merging Gaussian filters in order to increase the level of detail of the filtering density in likely regions of the state space and reduce it in unlikely ones. As this is only effective in the presence of nonlinearities, we describe a split control technique that prevents filters from being split if they operate in linear regions of state space. In simulations with polar measurements, the new algorithm reduced the mean square error by nearly 50\% compared to the unscented Kalman filter.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/T824Z8TQ/Faubel et al. - 2009 - The Split and Merge Unscented Gaussian Mixture Fil.pdf}
}

@techreport{fefferman_existence_2023,
  title = {{{EXISTENCE AND SMOOTHNESS OF THE NAVIER}}--{{STOKES EQUATION}}},
  author = {Fefferman, Charles L},
  year = {2023},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2KET8PZJ/Fefferman - EXISTENCE AND SMOOTHNESS OF THE NAVIER–STOKES EQUA.pdf}
}

@article{fei_3d_2024,
  title = {{{3D Gaussian Splatting}} as {{New Era}}: {{A Survey}}},
  shorttitle = {{{3D Gaussian Splatting}} as {{New Era}}},
  author = {Fei, Ben and Xu, Jingyi and Zhang, Rui and Zhou, Qingyuan and Yang, Weidong and He, Ying},
  year = {2024},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  pages = {1--20},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2024.3397828},
  url = {https://ieeexplore.ieee.org/abstract/document/10521791},
  urldate = {2024-05-10},
  abstract = {3D Gaussian Splatting (3D-GS) has emerged as a significant advancement in the field of Computer Graphics, offering explicit scene representation and novel view synthesis without the reliance on neural networks, such as Neural Radiance Fields (NeRF). This technique has found diverse applications in areas such as robotics, urban mapping, autonomous navigation, and virtual reality/augmented reality, just name a few. Given the growing popularity and expanding research in 3D Gaussian Splatting, this paper presents a comprehensive survey of relevant papers from the past year. We organize the survey into taxonomies based on characteristics and applications, providing an introduction to the theoretical underpinnings of 3D Gaussian Splatting. Our goal through this survey is to acquaint new researchers with 3D Gaussian Splatting, serve as a valuable reference for seminal works in the field, and inspire future research directions, as discussed in our concluding section.},
  keywords = {3D Gaussian Splatting,computer graphics,generation,Image color analysis,Image reconstruction,manipulation,perception,reconstruction,rendering,Rendering (computer graphics),Reviews,Surveys,Three-dimensional displays,Videos,virtual humans},
  file = {/Users/kshitijgoel/Zotero/storage/8HSXQ75G/Fei et al. - 2024 - 3D Gaussian Splatting as New Era A Survey.pdf;/Users/kshitijgoel/Zotero/storage/MGW89YR3/10521791.html}
}

@article{feng_heat_2024,
  title = {A {{Heat Method}} for {{Generalized Signed Distance}}},
  author = {Feng, Nicole and Crane, Keenan},
  year = {2024},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {4},
  pages = {92:1--92:19},
  issn = {0730-0301},
  doi = {10.1145/3658220},
  url = {https://doi.org/10.1145/3658220},
  urldate = {2024-07-26},
  abstract = {We introduce a method for approximating the signed distance function (SDF) of geometry corrupted by holes, noise, or self-intersections. The method implicitly defines a completed version of the shape, rather than explicitly repairing the given input. Our starting point is a modified version of the heat method for geodesic distance, which diffuses normal vectors rather than a scalar distribution. This formulation provides robustness akin to generalized winding numbers (GWN), but provides distance function rather than just an inside/outside classification. Our formulation also offers several features not common to classic distance algorithms, such as the ability to simultaneously fit multiple level sets, a notion of distance for geometry that does not topologically bound any region, and the ability to mix and match signed and unsigned distance. The method can be applied in any dimension and to any spatial discretization, including triangle meshes, tet meshes, point clouds, polygonal meshes, voxelized surfaces, and regular grids. We evaluate the method on several challenging examples, implementing normal offsets and other morphological operations directly on imperfect curve and surface data. In many cases we also obtain an inside/outside classification dramatically more robust than the one obtained provided by GWN.},
  file = {/Users/kshitijgoel/Zotero/storage/HAL3ALZF/Feng and Crane - 2024 - A Heat Method for Generalized Signed Distance.pdf}
}

@article{feng_terrainmesh_2024,
  title = {{{TerrainMesh}}: {{Metric-Semantic Terrain Reconstruction From Aerial Images Using Joint}} 2-{{D-3-D Learning}}},
  shorttitle = {{{TerrainMesh}}},
  author = {Feng, Qiaojun and Atanasov, Nikolay},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {1457--1475},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3353073},
  url = {https://ieeexplore.ieee.org/document/10388460},
  urldate = {2024-02-22},
  abstract = {This article considers outdoor terrain mapping using RGB images obtained from an aerial vehicle. While feature-based localization and mapping techniques deliver real-time vehicle odometry and sparse keypoint depth reconstruction, a dense model of the environment geometry and semantics (vegetation, buildings, etc.) is usually recovered offline with significant computation and storage. This article develops a joint 2-D-3-D learning approach to reconstruct a local metric-semantic mesh at each camera keyframe maintained by a visual odometry algorithm. Given the estimated camera trajectory, the local meshes can be assembled into a global environment model to capture the terrain topology and semantics during online operation. A local mesh is reconstructed using an initialization and refinement stage. In the initialization stage, we estimate the mesh vertex elevation by solving a least squares problem relating the vertex barycentric coordinates to the sparse keypoint depth measurements. In the refinement stage, we associate 2-D image and semantic features with the 3-D mesh vertices using camera projection and apply graph convolution to refine the mesh vertex spatial coordinates and semantic features based on joint 2-D and 3-D supervision. Quantitative and qualitative evaluation using real aerial images show the potential of our method to support environmental monitoring and surveillance applications.},
  keywords = {Aerial systems: Perception and autonomy,Cameras,Convolution,graph convolution for mesh reconstruction,Image reconstruction,mapping,Robots,semantic scene understanding,Semantics,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/IVYMU5YK/Feng and Atanasov - 2024 - TerrainMesh Metric-Semantic Terrain Reconstructio.pdf}
}

@article{figueiredo_unsupervised_2002,
  title = {Unsupervised Learning of Finite Mixture Models},
  author = {Figueiredo, M.A.T. and Jain, A.K.},
  year = {2002},
  month = mar,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {3},
  pages = {381--396},
  issn = {1939-3539},
  doi = {10.1109/34.990138},
  abstract = {This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective "unsupervised" is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.},
  keywords = {Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/VUYH2CA5/Figueiredo and Jain - 2002 - Unsupervised learning of finite mixture models.pdf;/Users/kshitijgoel/Zotero/storage/B52B8ZQU/990138.html}
}

@inproceedings{fioraio_largescale_2015,
  title = {Large-Scale and Drift-Free Surface Reconstruction Using Online Subvolume Registration},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Fioraio, Nicola and Taylor, Jonathan and Fitzgibbon, Andrew and Di Stefano, Luigi and Izadi, Shahram},
  year = {2015},
  month = jun,
  pages = {4475--4483},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2015.7299077},
  abstract = {Depth cameras have helped commoditize 3D digitization of the real-world. It is now feasible to use a single Kinect-like camera to scan in an entire building or other large-scale scenes. At large scales, however, there is an inherent challenge of dealing with distortions and drift due to accumulated pose estimation errors. Existing techniques suffer from one or more of the following: a) requiring an expensive offline global optimization step taking hours to compute; b) needing a full second pass over the input depth frames to correct for accumulated errors; c) relying on RGB data alongside depth data to optimize poses; or d) requiring the user to create explicit loop closures to allow gross alignment errors to be resolved. In this paper, we present a method that addresses all of these issues. Our method supports online model correction, without needing to reprocess or store any input depth data. Even while performing global correction of a large 3D model, our method takes only minutes rather than hours to compute. Our model does not require any explicit loop closures to be detected and, finally, relies on depth data alone, allowing operation in low-lighting conditions. We show qualitative results on many large scale scenes, highlighting the lack of error and drift in our reconstructions. We compare to state of the art techniques and demonstrate large-scale dense surface reconstruction ``in the dark'', a capability not offered by RGB-D techniques.},
  keywords = {Cameras,Image reconstruction,Optimization,Solid modeling,Surface reconstruction,Three-dimensional displays,Volume measurement},
  file = {/Users/kshitijgoel/Zotero/storage/GMQFVKMH/Fioraio et al. - 2015 - Large-scale and drift-free surface reconstruction .pdf;/Users/kshitijgoel/Zotero/storage/C4HU88DZ/stamp.html}
}

@article{firoozi_foundation_2025,
  title = {Foundation Models in Robotics: {{Applications}}, Challenges, and the Future},
  shorttitle = {Foundation Models in Robotics},
  author = {Firoozi, Roya and Tucker, Johnathan and Tian, Stephen and Majumdar, Anirudha and Sun, Jiankai and Liu, Weiyu and Zhu, Yuke and Song, Shuran and Kapoor, Ashish and Hausman, Karol and Ichter, Brian and Driess, Danny and Wu, Jiajun and Lu, Cewu and Schwager, Mac},
  year = {2025},
  month = apr,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {5},
  pages = {701--739},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241281508},
  url = {https://doi.org/10.1177/02783649241281508},
  urldate = {2025-04-16},
  abstract = {We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LE92IMIA/Firoozi et al. - 2025 - Foundation models in robotics Applications, challenges, and the future.pdf}
}

@article{fisher_dispersion_1953,
  title = {Dispersion on a {{Sphere}}},
  author = {Fisher, Ronald},
  year = {1953},
  journal = {Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences},
  volume = {217},
  number = {1130},
  eprint = {99186},
  eprinttype = {jstor},
  pages = {295--305},
  publisher = {The Royal Society},
  issn = {0080-4630},
  url = {https://www.jstor.org/stable/99186},
  urldate = {2024-06-27},
  abstract = {Any topological framework requires the development of a theory of errors of characteristic and appropriate mathematical form. The paper develops a form of theory which appears to be appropriate to measurements of position on a sphere. The primary problems of estimation as applied to the true direction, and the precision of observations, are discussed in the subcases which arise. The simultaneous distribution of the amplitude and direction of the vector sum of a number of random unit vectors of given precision, is demonstrated. From this is derived the test of significance appropriate to a worker whose knowledge of precision lies entirely in the internal evidence of the sample. This is the analogue of 'Student's' test in the Gaussian theory of errors. The general formulae obtained are illustrated using measurements of the direction of remanent magnetization in the directly and inversely magnetized lava flows obtained in Iceland by Mr J. Hospers.},
  file = {/Users/kshitijgoel/Zotero/storage/BXAMG2RK/Fisher - 1953 - Dispersion on a Sphere.pdf}
}

@inproceedings{florea_survey_2022,
  title = {Survey on {{Monocular Depth Estimation}} for {{Unmanned Aerial Vehicles}} Using {{Deep Learning}}},
  booktitle = {2022 {{IEEE}} 18th {{International Conference}} on {{Intelligent Computer Communication}} and {{Processing}} ({{ICCP}})},
  author = {Florea, Horatiu and Nedevschi, Sergiu},
  year = {2022},
  month = sep,
  pages = {319--326},
  issn = {2766-8495},
  doi = {10.1109/ICCP56966.2022.10053950},
  url = {https://ieeexplore.ieee.org/document/10053950/?arnumber=10053950&tag=1},
  urldate = {2024-12-17},
  abstract = {Deep learning-based solutions for the ill-posed problem of Monocular Depth Estimation (MDE) from 2D color images have shown potential in recent years, spurring a very active field of research. Most state-of-the-art proposals focus on solving the problem in the context of automotive advanced driver assistance and/or autonomous driving systems. While presenting their own complexities and challenges, the vast majority of road environments exhibit a number of commonalities amongst themselves. The aerial domain in which modern Unmanned Aerial Vehicles (UAVs) operate is significantly different and features a large variety of possible scenes based on the specific mission carried out. The increasing number of applications for UAVs could benefit from more advanced learning-based MDE solutions for recovering 3D geometric information from the scene. In this paper, we conduct a study of existing research on the topic of MDE specifically tailored for aerial views, as well as presenting the datasets and tools currently supporting such research, high-lighting the challenges that remain. To the best of our knowledge, this is the first survey covering this field.},
  keywords = {Autonomous aerial vehicles,Complexity theory,deep learning,Deep learning,Estimation,monocular depth estimation,Roads,self-supervised learning,Technological innovation,Three-dimensional displays,unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/X37Z8ISF/Florea and Nedevschi - 2022 - Survey on Monocular Depth Estimation for Unmanned Aerial Vehicles using Deep Learning.pdf;/Users/kshitijgoel/Zotero/storage/FWAFL23W/10053950.html}
}

@phdthesis{florence_integrated_2017,
  title = {Integrated {{Perception}} and {{Control}} at {{High Speed}}},
  author = {Florence, Peter R},
  year = {2017},
  abstract = {We present a method for robust high-speed quadrotor {\'r}ight through unknown cluttered environments using integrated perception and control. Motivated by experiments in which the diiculty of accurate state estimation was a primary limitation on speed, our method forgoes maintaining a map in favor of using only instantaneous depth information in the local frame. This provides robustness in the presence of signi{\H o}cant state estimate uncertainty. We compare the method against a benchmark approach using a simulated quadrotor race through a forest at high speeds in the presence of increasing state estimate noise. We then present hardware validation experiments in both indoor and outdoor environments, performing robust obstacle avoidance at speeds of up to 10 m/s, including sustained {\'r}ight through a forest at 6 m/s. Finally, we add to the memoryless method, and develop a robust obstacle avoidance approach that uses memory without resorting to a maximum-likelihood mapping framework.},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  file = {/Users/kshitijgoel/Zotero/storage/39DP8Z6D/Florence - Integrated Perception and Control at High Speed.pdf}
}

@incollection{florence_integrated_2020,
  title = {Integrated {{Perception}} and {{Control}} at {{High Speed}}: {{Evaluating Collision Avoidance Maneuvers Without Maps}}},
  shorttitle = {Integrated {{Perception}} and {{Control}} at {{High Speed}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XII}}: {{Proceedings}} of the {{Twelfth Workshop}} on the {{Algorithmic Foundations}} of {{Robotics}}},
  author = {Florence, Pete and Carter, John and Tedrake, Russ},
  editor = {Goldberg, Ken and Abbeel, Pieter and Bekris, Kostas and Miller, Lauren},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {304--319},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-43089-4_20},
  url = {https://doi.org/10.1007/978-3-030-43089-4_20},
  urldate = {2024-01-09},
  abstract = {We present a method for robust high-speed quadrotor flight through unknown cluttered environments using integrated perception and control. Motivated by experiments in which the difficulty of accurate state estimation was a primary limitation on speed, our method forgoes maintaining a map in favor of using only instantaneous depth information in the local frame. This provides robustness in the presence of significant state estimate uncertainty. Additionally, we present approximation methods augmented with spatial partitioning data structures that enable low-latency, real-time reactive control. The probabilistic formulation provides a natural way to integrate reactive obstacle avoidance with arbitrary navigation objectives. We validate the method using a simulated quadrotor race through a forest at high speeds in the presence of increasing state estimate noise. We pair our method with a motion primitive library and compare with a global path-generation and pathfollowing approach.},
  isbn = {978-3-030-43089-4},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9VLA42U3/Florence et al. - 2020 - Integrated Perception and Control at High Speed E.pdf}
}

@inproceedings{florence_nanomap_2018,
  title = {{{NanoMap}}: {{Fast}}, {{Uncertainty-Aware Proximity Queries}} with {{Lazy Search Over Local 3D Data}}},
  shorttitle = {{{NanoMap}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Florence, Peter R. and Carter, John and Ware, Jake and Tedrake, Russ},
  year = {2018},
  month = may,
  pages = {7631--7638},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8463195},
  url = {https://ieeexplore.ieee.org/document/8463195},
  urldate = {2024-01-28},
  abstract = {We would like robots to be able to safely navigate at high speed, efficiently use local 3D information, and robustly plan motions that consider pose uncertainty of measurements in a local map structure. This is hard to do with previously existing mapping approaches, like occupancy grids, that are focused on incrementally fusing 3D data into a common world frame. In particular, both their fragile sensitivity to state estimation errors and computational cost can be limiting. We develop an alternative framework, NanoMap, which alleviates the need for global map fusion and enables a motion planner to efficiently query pose-uncertainty-aware local 3D geometric information. The key idea of NanoMap is to store a history of noisy relative pose transforms and search over a corresponding set of depth sensor measurements for the minimum-uncertainty view of a queried point in space. This approach affords a variety of capabilities not offered by traditional mapping techniques: (a) the pose uncertainty associated with 3D data can be incorporated in motion planning, (b) poses can be updated (i.e., from loop closures) with minimal computational effort, and (c) 3D data can be fused lazily for the purpose of planning. We provide an open-source implementation of NanoMap, and analyze its capabilities and computational efficiency in simulation experiments. Finally, we demonstrate in hardware its effectiveness for fast 3D obstacle avoidance onboard a quadrotor flying up to 10 m/s.},
  keywords = {Collision avoidance,Current measurement,History,Planning,Robot sensing systems,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/46DMP6EV/Florence et al. - 2018 - NanoMap Fast, Uncertainty-Aware Proximity Queries.pdf;/Users/kshitijgoel/Zotero/storage/CU7VN4VL/8463195.html}
}

@article{foehn_agilicious_2022,
  title = {Agilicious: {{Open-source}} and Open-Hardware Agile Quadrotor for Vision-Based Flight},
  shorttitle = {Agilicious},
  author = {Foehn, Philipp and Kaufmann, Elia and Romero, Angel and Penicka, Robert and Sun, Sihao and Bauersfeld, Leonard and Laengle, Thomas and Cioffi, Giovanni and Song, Yunlong and Loquercio, Antonio and Scaramuzza, Davide},
  year = {2022},
  month = jun,
  journal = {Science Robotics},
  volume = {7},
  number = {67},
  pages = {eabl6259},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abl6259},
  url = {https://www.science.org/doi/10.1126/scirobotics.abl6259},
  urldate = {2023-03-15},
  abstract = {Autonomous, agile quadrotor flight raises fundamental challenges for robotics research in terms of perception, planning, learning, and control. A versatile and standardized platform is needed to accelerate research and let practitioners focus on the core problems. To this end, we present Agilicious, a codesigned hardware and software framework tailored to autonomous, agile quadrotor flight. It is completely open source and open hardware and supports both model-based and neural network--based controllers. Also, it provides high thrust-to-weight and torque-to-inertia ratios for agility, onboard vision sensors, graphics processing unit (GPU)--accelerated compute hardware for real-time perception and neural network inference, a real-time flight controller, and a versatile software stack. In contrast to existing frameworks, Agilicious offers a unique combination of flexible software stack and high-performance hardware. We compare Agilicious with prior works and demonstrate it on different agile tasks, using both model-based and neural network--based controllers. Our demonstrators include trajectory tracking at up to 5               g               and 70 kilometers per hour in a motion capture system, and vision-based acrobatic flight and obstacle avoidance in both structured and unstructured environments using solely onboard perception. Last, we demonstrate its use for hardware-in-the-loop simulation in virtual reality environments. Because of its versatility, we believe that Agilicious supports the next generation of scientific and industrial quadrotor research.                        ,              We provide a codesigned hardware and software framework tailored to autonomous, agile quadrotor flight.},
  langid = {english},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/to_read_for_sure/scirobotics.abl6259.pdf}
}

@article{forbes_hidden_2003,
  title = {Hidden {{Markov}} Random Field Model Selection Criteria Based on Mean Field-like Approximations},
  author = {Forbes, F. and Peyrard, N.},
  year = {2003},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {25},
  number = {9},
  pages = {1089--1101},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2003.1227985},
  abstract = {Hidden Markov random fields appear naturally in problems such as image segmentation, where an unknown class assignment has to be estimated from the observations at each pixel. Choosing the probabilistic model that best accounts for the observations is an important first step for the quality of the subsequent estimation and analysis. A commonly used selection criterion is the Bayesian Information Criterion (BIC) of Schwarz (1978), but for hidden Markov random fields, its exact computation is not tractable due to the dependence structure induced by the Markov model. We propose approximations of BIC based on the mean field principle of statistical physics. The mean field theory provides approximations of Markov random fields by systems of independent variables leading to tractable computations. Using this principle, we first derive a class of criteria by approximating the Markov distribution in the usual BIC expression as a penalized likelihood. We then rewrite BIC in terms of normalizing constants, also called partition functions, instead of Markov distributions. It enables us to use finer mean field approximations and to derive other criteria using optimal lower bounds for the normalizing constants. To illustrate the performance of our partition function-based approximation of BIC as a model selection criterion, we focus on the preliminary issue of choosing the number of classes before the segmentation task. Experiments on simulated and real data point out our criterion as promising: It takes spatial information into account through the Markov model and improves the results obtained with BIC for independent mixture models.},
  keywords = {Bayesian methods,Context modeling,Hidden Markov models,Image analysis,Image segmentation,Integral equations,Markov random fields,Multidimensional systems,Physics,Pixel},
  file = {/Users/kshitijgoel/Zotero/storage/UTT7HCYG/Forbes and Peyrard - 2003 - Hidden Markov random field model selection criteri.pdf}
}

@article{fox_active_1998,
  title = {Active {{Markov}} Localization for Mobile Robots},
  author = {Fox, Dieter and Burgard, Wolfram and Thrun, Sebastian},
  year = {1998},
  month = nov,
  journal = {Robotics and Autonomous Systems},
  series = {Autonomous {{Mobile Robots}}},
  volume = {25},
  number = {3},
  pages = {195--207},
  issn = {0921-8890},
  doi = {10.1016/S0921-8890(98)00049-9},
  url = {https://www.sciencedirect.com/science/article/pii/S0921889098000499},
  urldate = {2023-10-25},
  abstract = {Localization is the problem of determining the position of a mobile robot from sensor data. Most existing localization approaches are passive, i.e., they do not exploit the opportunity to control the robot's effectors during localization. This paper proposes an active localization approach. The approach is based on Markov localization and provides rational criteria for (1) setting the robot's motion direction (exploration), and (2) determining the pointing direction of the sensors so as to most efficiently localize the robot. Furthermore, it is able to deal with noisy sensors and approximative world models. The appropriateness of our approach is demonstrated empirically using a mobile robot in a structured office environment.},
  keywords = {Autonomous service robots,Robot position estimation},
  file = {/Users/kshitijgoel/Zotero/storage/E63PHZ5A/Fox et al. - 1998 - Active Markov localization for mobile robots.pdf;/Users/kshitijgoel/Zotero/storage/KM3PQ6JR/S0921889098000499.html}
}

@inproceedings{fraichard_short_2007,
  title = {A {{Short Paper}} about {{Motion Safety}}},
  booktitle = {Proceedings 2007 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Fraichard, Thierry},
  year = {2007},
  month = apr,
  pages = {1140--1145},
  publisher = {IEEE},
  address = {Rome, Italy},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2007.363138},
  url = {http://ieeexplore.ieee.org/document/4209242/},
  urldate = {2024-01-24},
  abstract = {Motion safety for robotic systems operating in the real world is critical (especially when their size and dynamics make them potentially harmful for themselves or their environment). Motion safety is a taken-for-granted and ill-defined notion in the Robotics literature and the primary contribution of this paper is to propose three safety criteria that helps in understanding a number of key aspects related to the motion safety issue. A number of navigation schemes used by robotic systems operating in the real-world are then evaluated with respect to these safety criteria. It is established that, in all cases, they violate one or several of them. Accordingly, motion safety, especially in the presence of moving objects, cannot be guaranteed (in the sense that these robotic systems may end up in a situation where a collision inevitably occurs later in the future). Finally, it is shown that the concept of Inevitable Collision States introduced in [1] does respect the three above-mentioned safety criteria and therefore offers a theoretical answer to the motion safety issue.},
  isbn = {978-1-4244-0602-9 978-1-4244-0601-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5CPDXI6K/Fraichard - 2007 - A Short Paper about Motion Safety.pdf}
}

@article{franchi_encoding_2024,
  title = {Encoding the {{Latent Posterior}} of {{Bayesian Neural Networks}} for {{Uncertainty Quantification}}},
  author = {Franchi, Gianni and Bursuc, Andrei and Aldea, Emanuel and Dubuisson, Severine and Bloch, Isabelle},
  year = {2024},
  month = apr,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {46},
  number = {04},
  pages = {2027--2040},
  publisher = {IEEE Computer Society},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2023.3328829},
  url = {https://www.computer.org/csdl/journal/tp/2024/04/10302334/1RHghk2QNsQ},
  urldate = {2024-03-29},
  abstract = {Bayesian Neural Networks (BNNs) have long been considered an ideal, yet unscalable solution for improving the robustness and the predictive uncertainty of deep neural networks. While they could capture more accurately the posterior distribution of the network parameters, most BNN approaches are either limited to small networks or rely on constraining assumptions, e.g., parameter independence. These drawbacks have enabled prominence of simple, but computationally heavy approaches such as Deep Ensembles, whose training and testing costs increase linearly with the number of networks. In this work we aim for efficient deep BNNs amenable to complex computer vision architectures, e.g., ResNet-50 DeepLabv3+, and tasks, e.g., semantic segmentation and image classification, with fewer assumptions on the parameters. We achieve this by leveraging variational autoencoders (VAEs) to learn the interaction and the latent distribution of the parameters at each network layer. Our approach, called Latent-Posterior BNN (LP-BNN), is compatible with the recent BatchEnsemble method, leading to highly efficient (in terms of computation and memory during both training and testing) ensembles. LP-BNNs attain competitive results across multiple metrics in several challenging benchmarks for image classification, semantic segmentation, and out-of-distribution detection.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z2I63YG6/Franchi et al. - 2024 - Encoding the Latent Posterior of Bayesian Neural N.pdf}
}

@inproceedings{francis_functional_2020,
  title = {Functional {{Path Optimisation}} for {{Exploration}} in {{Continuous Occupancy Maps}}},
  booktitle = {Robotics {{Research}}},
  author = {Francis, Gilad and Ott, Lionel and Ramos, Fabio},
  editor = {Amato, Nancy M. and Hager, Greg and Thomas, Shawna and {Torres-Torriti}, Miguel},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {859--875},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-28619-4_59},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-28619-4_59},
  abstract = {Autonomous exploration is a complex task where the robot moves through an unknown environment with the goal of mapping it. The desired output of such a process is a sequence of paths that efficiently and safely minimise the uncertainty of the resulting map. However, optimising over the entire space of possible paths is computationally intractable. Therefore, most exploration methods relax the general problem by optimising a simpler one, for example finding the single next best view. In this work, we formulate exploration as a variational problem which allows us to directly optimise in the space of trajectories using functional gradient methods, searching for the Next Best Path (NBP). We take advantage of the recently introduced Hilbert maps to devise an information-based functional that can be computed in closed-form. The resulting trajectories are continuous and maximise safety as well as mutual information. In experiments we verify the ability of the proposed method to find smooth and safe paths and compare these results with other exploration methods.},
  isbn = {978-3-030-28619-4},
  langid = {english},
  keywords = {Functional Gradient,Path Planning,Robotic Exploration},
  file = {/Users/kshitijgoel/Zotero/storage/L35FXV9I/Francis et al. - 2020 - Functional Path Optimisation for Exploration in Co.pdf}
}

@article{frank_theoretical_2009,
  title = {Theoretical and Experimental Error Analysis of Continuous-Wave Time-of-Flight Range Cameras},
  author = {Frank, Mario and Plaue, Matthias and Rapp, Holger and Koethe, Ullrich and J{\"a}hne, Bernd and Hamprecht, Fred A.},
  year = {2009},
  month = jan,
  journal = {Optical Engineering},
  volume = {48},
  number = {1},
  pages = {013602},
  publisher = {SPIE},
  issn = {0091-3286, 1560-2303},
  doi = {10.1117/1.3070634},
  url = {https://www.spiedigitallibrary.org/journals/optical-engineering/volume-48/issue-1/013602/Theoretical-and-experimental-error-analysis-of-continuous-wave-time-of/10.1117/1.3070634.full},
  urldate = {2024-07-26},
  abstract = {We offer a formal investigation of the measurement principle of time-of-flight 3-D cameras using correlation of amplitude-modulated continuous-wave signals. These sensors can provide both depth maps and IR intensity pictures simultaneously and in real time. We examine the theory of the data acquisition in detail. The variance of the range measurements is derived in a concise way and we show that the computed range follows an offset normal distribution. The impact of quantization of that distribution is discussed. All theoretically investigated errors like the behavior of the variance, depth bias, saturation and quantization effects are supported by experimental results.},
  file = {/Users/kshitijgoel/Zotero/storage/GU28WYIL/Frank et al. - 2009 - Theoretical and experimental error analysis of continuous-wave time-of-flight range cameras.pdf}
}

@misc{freeman_brax_2021,
  title = {Brax -- {{A Differentiable Physics Engine}} for {{Large Scale Rigid Body Simulation}}},
  author = {Freeman, C. Daniel and Frey, Erik and Raichuk, Anton and Girgin, Sertan and Mordatch, Igor and Bachem, Olivier},
  year = {2021},
  month = jun,
  number = {arXiv:2106.13281},
  eprint = {2106.13281},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.13281},
  url = {http://arxiv.org/abs/2106.13281},
  urldate = {2025-08-12},
  abstract = {We present Brax, an open source library for rigid body simulation with a focus on performance and parallelism on accelerators, written in JAX. We present results on a suite of tasks inspired by the existing reinforcement learning literature, but remade in our engine. Additionally, we provide reimplementations of PPO, SAC, ES, and direct policy optimization in JAX that compile alongside our environments, allowing the learning algorithm and the environment processing to occur on the same device, and to scale seamlessly on accelerators. Finally, we include notebooks that facilitate training of performant policies on common OpenAI Gym MuJoCo-like tasks in minutes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/KNMMEKDH/Freeman et al. - 2021 - Brax -- A Differentiable Physics Engine for Large Scale Rigid Body Simulation.pdf;/Users/kshitijgoel/Zotero/storage/YCWIMIJ7/2106.html}
}

@inproceedings{fresk_full_2013,
  title = {Full Quaternion Based Attitude Control for a Quadrotor},
  booktitle = {2013 {{European Control Conference}} ({{ECC}})},
  author = {Fresk, Emil and Nikolakopoulos, George},
  year = {2013},
  month = jul,
  pages = {3864--3869},
  doi = {10.23919/ECC.2013.6669617},
  abstract = {The aim of this article is to present a novel quaternion based control scheme for the attitude control problem of a quadrotor. A quaternion is a hyper complex number of rank 4 that can be utilized to avoid the inherent geometrical singularity when representing rigid body dynamics with Euler angles or the complexity of having coupled differential equations with the Direction Cosine Matrix (DCM). In the presented approach both the quadrotor's attitude model and the proposed non-linear Proportional squared (P2) control algorithm have been implemented in the quaternion space, without any transformations and calculations in the Euler's angle space or DCM. Throughout the article, the merits of the proposed novel approach are being analyzed and discussed, while the efficacy of the suggested novel quaternion based controller are being evaluated by extended simulation results.},
  keywords = {Aerospace electronics,Attitude control,Equations,Mathematical model,Noise,Quaternions,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/QVQQQA7F/Fresk and Nikolakopoulos - 2013 - Full quaternion based attitude control for a quadr.pdf;/Users/kshitijgoel/Zotero/storage/8JJKSD5I/stamp.html}
}

@inproceedings{fridovich-keil_planning_2018,
  title = {Planning, {{Fast}} and {{Slow}}: {{A Framework}} for {{Adaptive Real-Time Safe Trajectory Planning}}},
  shorttitle = {Planning, {{Fast}} and {{Slow}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {{Fridovich-Keil}, David and Herbert, Sylvia L. and Fisac, Jaime F. and Deglurkar, Sampada and Tomlin, Claire J.},
  year = {2018},
  month = may,
  pages = {387--394},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8460863},
  abstract = {Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of ``meta-planning'' in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.},
  keywords = {Computational modeling,Navigation,Planning,Real-time systems,Robustness,Safety,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/FFHRWSK2/Fridovich-Keil et al. - 2018 - Planning, Fast and Slow A Framework for Adaptive .pdf;/Users/kshitijgoel/Zotero/storage/FX6DXF68/8460863.html}
}

@inproceedings{fridovich-keil_plenoxels_2022,
  title = {Plenoxels: {{Radiance Fields Without Neural Networks}}},
  shorttitle = {Plenoxels},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {{Fridovich-Keil}, Sara and Yu, Alex and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  year = {2022},
  pages = {5501--5510},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.html},
  urldate = {2022-09-02},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LPQ327ZF/Fridovich-Keil et al. - 2022 - Plenoxels Radiance Fields Without Neural Networks.pdf}
}

@article{friendly_elliptical_2013,
  title = {Elliptical {{Insights}}: {{Understanding Statistical Methods}} through {{Elliptical Geometry}}},
  shorttitle = {Elliptical {{Insights}}},
  author = {Friendly, Michael and Monette, Georges and Fox, John},
  year = {2013},
  journal = {Statistical Science},
  volume = {28},
  number = {1},
  eprint = {43288410},
  eprinttype = {jstor},
  pages = {1--39},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237},
  url = {https://www.jstor.org/stable/43288410},
  urldate = {2024-04-29},
  abstract = {Visual insights into a wide variety of statistical methods, for both didactic and data analytic purposes, can often be achieved through geometric diagrams and geometrically based statistical graphs. This paper extols and illustrates the virtues of the ellipse and her higher-dimensional cousins for both these purposes in a variety of contexts, including linear models, multivariate linear models and mixed-effect models. We emphasize the strong relationships among statistical methods, matrix-algebraic solutions and geometry that can often be easily understood in terms of ellipses.},
  file = {/Users/kshitijgoel/Zotero/storage/6LEGEN6R/Friendly et al. - 2013 - Elliptical Insights Understanding Statistical Met.pdf}
}

@article{fu_dectrain_2025,
  title = {{{DecTrain}}: {{Deciding When}} to {{Train}} a {{Monocular Depth DNN Online}}},
  shorttitle = {{{DecTrain}}},
  author = {Fu, Zih-Sing and Sudhakar, Soumya and Karaman, Sertac and Sze, Vivienne},
  year = {2025},
  month = mar,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {3},
  eprint = {2410.02980},
  primaryclass = {cs},
  pages = {2822--2829},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2025.3536206},
  url = {http://arxiv.org/abs/2410.02980},
  urldate = {2025-02-20},
  abstract = {Deep neural networks (DNNs) can deteriorate in accuracy when deployment data differs from training data. While performing online training at all timesteps can improve accuracy, it is computationally expensive. We propose DecTrain, a new algorithm that decides when to train a monocular depth DNN online using self-supervision with low overhead. To make the decision at each timestep, DecTrain compares the cost of training with the predicted accuracy gain. We evaluate DecTrain on out-of-distribution data, and find DecTrain maintains accuracy compared to online training at all timesteps, while training only 44\% of the time on average. We also compare the recovery of a low inference cost DNN using DecTrain and a more generalizable high inference cost DNN on various sequences. DecTrain recovers the majority (97\%) of the accuracy gain of online training at all timesteps while reducing computation compared to the high inference cost DNN which recovers only 66\%. With an even smaller DNN, we achieve 89\% recovery while reducing computation by 56\%. DecTrain enables low-cost online training for a smaller DNN to have competitive accuracy with a larger, more generalizable DNN at a lower overall computational cost.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/SX6CEFYP/Fu et al. - 2025 - DecTrain Deciding When to Train a Monocular Depth DNN Online.pdf;/Users/kshitijgoel/Zotero/storage/HGXEPR2Y/2410.html}
}

@inproceedings{fu_radvio_2019,
  title = {{{RaD-VIO}}: {{Rangefinder-aided Downward Visual-Inertial Odometry}}},
  shorttitle = {{{RaD-VIO}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Fu, Bo and Shankar, Kumar Shaurya and Michael, Nathan},
  year = {2019},
  month = may,
  pages = {1841--1847},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8793741},
  abstract = {State-of-the-art forward facing monocular visual-inertial odometry algorithms are often brittle in practice, especially whilst dealing with initialisation and motion in directions that render the state unobservable. In such cases having a reliable complementary odometry algorithm enables robust and resilient flight. Using the common local planarity assumption, we present a fast, dense, and direct frame-to-frame visual-inertial odometry algorithm for downward facing cameras that minimises a joint cost function involving a homography based photometric cost and an IMU regularisation term. Via extensive evaluation in a variety of scenarios we demonstrate superior performance than existing state-of-the-art downward facing odometry algorithms for Micro Aerial Vehicles (MAVs).},
  keywords = {Angular velocity,Cameras,Laser beams,Optimization,Reliability,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/NWPQ94A9/Fu et al. - 2019 - RaD-VIO Rangefinder-aided Downward Visual-Inertia.pdf;/Users/kshitijgoel/Zotero/storage/8EXMWV63/8793741.html}
}

@article{fu_robust_2022,
  title = {Robust {{Task Scheduling}} for {{Heterogeneous Robot Teams Under Capability Uncertainty}}},
  author = {Fu, Bo and Smith, William and Rizzo, Denise M. and Castanier, Matthew and Ghaffari, Maani and Barton, Kira},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--19},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3216068},
  abstract = {This article develops a stochastic programming framework for multiagent systems, where task decomposition, assignment, and scheduling problems are simultaneously optimized. The framework can be applied to heterogeneous mobile robot teams with distributed subtasks. Examples include pandemic robotic service coordination, explore and rescue, and delivery systems with heterogeneous vehicles. Owing to their inherent flexibility and robustness, multiagent systems are applied in a growing range of real-world problems that involve heterogeneous tasks and uncertain information. Most previous works assume one fixed way to decompose a task into roles that can later be assigned to the agents. This assumption is not valid for a complex task where the roles can vary and multiple decomposition structures exist. Meanwhile, it is unclear how uncertainties in task requirements and agent capabilities can be systematically quantified and optimized under a multiagent system setting. A representation for complex tasks is proposed: agent capabilities are represented as a vector of random distributions, and task requirements are verified by a generalizable binary function. The conditional value at risk is chosen as a metric in the objective function to generate robust plans. An efficient algorithm is described to solve the model, and the whole framework is evaluated in two different practical test cases: capture-the-flag and robotic service coordination during a pandemic (e.g., COVID-19). Results demonstrate that the framework is generalizable, is scalable up to 140 agents and 40 tasks for the example test cases, and provides low-cost plans that ensure a high probability of success.},
  keywords = {Heterogeneous multiagent systems,Multi-robot systems,pandemic robotic services,Resource management,Robot kinematics,Robot sensing systems,Routing,scheduling and coordination,stochastic vehicle routing problem,task allocation,Task analysis,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/VMKN4XDX/Fu et al. - 2022 - Robust Task Scheduling for Heterogeneous Robot Tea.pdf;/Users/kshitijgoel/Zotero/storage/LPIV39TT/9942275.html}
}

@article{funk_multiresolution_2021,
  title = {Multi-{{Resolution 3D Mapping With Explicit Free Space Representation}} for {{Fast}} and {{Accurate Mobile Robot Motion Planning}}},
  author = {Funk, Nils and Tarrio, Juan and Papatheodorou, Sotiris and Popovi{\'c}, Marija and Alcantarilla, Pablo F. and Leutenegger, Stefan},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {3553--3560},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3061989},
  url = {https://ieeexplore.ieee.org/document/9362165},
  urldate = {2024-11-15},
  abstract = {With the aim of bridging the gap between high quality reconstruction and robot motion planning, we propose an efficient system that leverages the concept of adaptive-resolution volumetric mapping, which naturally integrates with the hierarchical decomposition of space in an octree data structure. Instead of a Truncated Signed Distance Function (TSDF), we adopt mapping of occupancy probabilities in log-odds representation, which allows to represent both surfaces, as well as the entire free, i.e. observed space, as opposed to unobserved space. We introduce a method for choosing resolution -on the fly- in real-time by means of a multi-scale max-min pooling of the input depth image. The notion of explicit free space mapping paired with the spatial hierarchy in the data structure, as well as map resolution, allows for collision queries, as needed for robot motion planning, at unprecedented speed. We quantitatively evaluate mapping accuracy, memory, runtime performance, and planning performance showing improvements over the state of the art, particularly in cases requiring high resolution maps.},
  keywords = {Cameras,Image reconstruction,Mapping,motion and path planning,Octrees,Planning,Real-time systems,Robot sensing systems,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/7NGDLIVA/Funk et al. - 2021 - Multi-Resolution 3D Mapping With Explicit Free Space Representation for Fast and Accurate Mobile Rob.pdf;/Users/kshitijgoel/Zotero/storage/B2SRQ3IZ/9362165.html}
}

@article{funk_orientationaware_2023,
  title = {Orientation-{{Aware Hierarchical}}, {{Adaptive-Resolution A}}* {{Algorithm}} for {{UAV Trajectory Planning}}},
  author = {Funk, Nils and Tarrio, Juan and Papatheodorou, Sotiris and Alcantarilla, Pablo F. and Leutenegger, Stefan},
  year = {2023},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {10},
  pages = {6723--6730},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3308490},
  url = {https://ieeexplore.ieee.org/abstract/document/10229171},
  urldate = {2024-02-25},
  abstract = {Successful path planning for Unmanned Aerial Vehicles (UAVs) in challenging environments with narrow openings, such as disaster areas, requires attitude to be considered. State-of-the-art methods incorporate attitude only in the refinement stage. We introduce a first-of-a-kind global minimum cost path search method based on A* that considers attitude along the path. To make the problem tractable, our method exploits an adaptive and coarse-to-fine approach using global and local A* runs, plus an efficient method to introduce the UAV attitude in the process. We integrate our method with an SE(3) trajectory optimisation method based on a safe-flight-corridor, yielding a complete path planning pipeline. Extensive evaluation is undertaken using the AirSim flight simulator under closed loop control in a set of randomised maps, allowing us to quantitatively assess our method. We show that it achieves significantly higher success rates than the baselines, at a reduced computational burden.},
  keywords = {Aircraft navigation,Autonomous aerial vehicles,Collision avoidance,Costs,motion planning,Octrees,path planning,Pipelines,Robots,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/H3UGJH9G/Funk et al. - 2023 - Orientation-Aware Hierarchical, Adaptive-Resolutio.pdf;/Users/kshitijgoel/Zotero/storage/PTLKD5WP/10229171.html}
}

@inproceedings{gal_dropout_2016,
  title = {Dropout as a {{Bayesian Approximation}}: {{Representing Model Uncertainty}} in {{Deep Learning}}},
  shorttitle = {Dropout as a {{Bayesian Approximation}}},
  booktitle = {Proceedings of {{The}} 33rd {{International Conference}} on {{Machine Learning}}},
  author = {Gal, Yarin and Ghahramani, Zoubin},
  year = {2016},
  month = jun,
  pages = {1050--1059},
  publisher = {PMLR},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v48/gal16.html},
  urldate = {2024-01-27},
  abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KA7CY3F6/Gal and Ghahramani - 2016 - Dropout as a Bayesian Approximation Representing .pdf}
}

@inproceedings{gala_probabilistic_2024,
  title = {Probabilistic {{Integral Circuits}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Gala, Gennaro and de Campos, Cassio and Peharz, Robert and Vergari, Antonio and Quaeghebeur, Erik},
  year = {2024},
  month = apr,
  pages = {2143--2151},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/gala24a.html},
  urldate = {2024-04-30},
  abstract = {Continuous latent variables (LVs) are a key ingredient of many generative models, as they allow modelling expressive mixtures with an uncountable number of components. In contrast, probabilistic circuits (PCs) are hierarchical discrete mixtures represented as computational graphs composed of input, sum and product units. Unlike continuous LV models, PCs provide tractable inference but are limited to discrete LVs with categorical (i.e. unordered) states. We bridge these model classes by introducing probabilistic integral circuits (PICs), a new language of computational graphs that extends PCs with integral units representing continuous LVs. In the first place, PICs are symbolic computational graphs and are fully tractable in simple cases where analytical integration is possible. In practice, we parameterise PICs with light-weight neural nets delivering an intractable hierarchical continuous mixture that can be approximated arbitrarily well with large PCs using numerical quadrature. On several distribution estimation benchmarks, we show that such PIC-approximating PCs systematically outperform PCs commonly learned via expectation-maximization or SGD.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UJSB5U4C/Gala et al. - 2024 - Probabilistic Integral Circuits.pdf}
}

@article{gander_constrained_1989,
  title = {A Constrained Eigenvalue Problem},
  author = {Gander, Walter and Golub, Gene H. and {von Matt}, Urs},
  year = {1989},
  month = mar,
  journal = {Linear Algebra and its Applications},
  series = {Special {{Issue Dedicated}} to {{Alan J}}. {{Hoffman}}},
  volume = {114--115},
  pages = {815--839},
  issn = {0024-3795},
  doi = {10.1016/0024-3795(89)90494-1},
  url = {https://www.sciencedirect.com/science/article/pii/0024379589904941},
  urldate = {2025-07-11},
  abstract = {Let A be a real symmetric matrix. In order to find the eigenvector corresponding to the smallest eigenvalue of A, we find the minimizer of the expression xTAx subject to xTx= 1. In many applications, however, it is necessary to introduced linear constraints: NTitx= t. In this paper we first show how to eliminate these linear constraints. Then the minimization is tackled by employing Lagrange equations. An analysis of the solvability of the problem and the sensitivity of the solution x is given. We show how the problem can be reduced to a so-called secular equation that we solve by a conventional zero-finding process. Alternatively, we present a second method which transforms the Lagrange equations into a quadratic eigenvalue problem. The two approaches are compared to each other.},
  file = {/Users/kshitijgoel/Zotero/storage/UZ3CFXB7/Gander et al. - 1989 - A constrained eigenvalue problem.pdf;/Users/kshitijgoel/Zotero/storage/FDJQZ679/0024379589904941.html}
}

@article{gander_least_1980,
  title = {Least Squares with a Quadratic Constraint},
  author = {Gander, Walter},
  year = {1980},
  month = sep,
  journal = {Numerische Mathematik},
  volume = {36},
  number = {3},
  pages = {291--307},
  issn = {0945-3245},
  doi = {10.1007/BF01396656},
  url = {https://doi.org/10.1007/BF01396656},
  urldate = {2025-07-11},
  abstract = {We present the theory of the linear least squares problem with a quadratic constraint. New theorems characterizing properties of the solutions are given. A numerical application is discussed.},
  langid = {english},
  keywords = {AMS(MOS): 65F20,Calculus of Variations and Optimization,Control and Systems Theory,CR: 5.14,Discrete Optimization,Linear Algebra,Linear Models and Regression,Stochastic Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/MWDUZC2C/Gander - 1980 - Least squares with a quadratic constraint.pdf}
}

@phdthesis{ganesh_robust_2017,
  type = {{{CMU-RI-TR-17-32}}},
  title = {Robust {{Distributed 3D Mapping With Communication Constraints}}},
  author = {Ganesh, Vibhav Nagaraj},
  year = {2017},
  month = jun,
  address = {Pittsburgh, PA, USA},
  url = {https://www.ri.cmu.edu/publications/robust-distributed-3d-mapping-with-communication-constraints/},
  urldate = {2022-04-19},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/47XE69YH/Ganesh - Robust Distributed 3D Mapping With Communication C.pdf}
}

@article{gao_adaptive_2024,
  title = {Adaptive {{Tracking}} and {{Perching}} for {{Quadrotor}} in {{Dynamic Scenarios}}},
  author = {Gao, Yuman and Ji, Jialin and Wang, Qianhao and Jin, Rui and Lin, Yi and Shang, Zhimeng and Cao, Yanjun and Shen, Shaojie and Xu, Chao and Gao, Fei},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {499--519},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3335670},
  url = {https://ieeexplore.ieee.org/document/10328688/},
  urldate = {2025-05-12},
  abstract = {Perching on the moving platforms is a promising solution to enhance the endurance and operational range of quadrotors, which could benefit the efficiency of a variety of air ground cooperative tasks. To ensure robust perching, tracking with a steady relative state and reliable perception is a prerequisite. This paper presents an adaptive dynamic tracking and perching scheme for autonomous quadrotors to achieve tight integration with moving platforms. For reliable perception of dynamic targets, we introduce elastic visibility aware planning to actively avoid occlusion and target loss. Additionally, we propose a flexible terminal adjustment method that adapts the changes in flight duration and the couple d terminal states, ensuring full state synchronization with the time varying perching surface at various angles. A relaxation strategy is developed by optimizing the tangential relative speed to address the dynamics and safety violations brought by hard bo undary conditions. Moreover, we take SE(3) motion planning into account to ensure no collision until the contact moment. Furthermore, we propose an efficient spatiotemporal trajectory optimization framework considerin g full state dynamics The proposed method is extensively tested through benchmark comparisons and ablation studies. To facilitate the application of academic research to industry and to validate the efficiency under strictly limited computational resources, we deploy our system on a commercial drone (DJI MAVIC3) with a full size sport utility vehicle (SUV). We conduct extensive real world experiments, where the drone successfully tracks and perches at 30 km/h (8.3 m/ s) on the top of the SUV, and at 3.5{$\sim$}m/s with 60{$^\circ$} inclined into the trunk of the SUV.},
  keywords = {Aerial system,Drones,motion and path planning,perception and autonomy,Planning,Quadrotors,Safety,Target tracking,Trajectory,trajectory optimization,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/TYL7K867/Gao et al. - 2024 - Adaptive Tracking and Perching for Quadrotor in Dynamic Scenarios.pdf}
}

@article{gao_gaussian_2022,
  title = {Gaussian {{Mixture Model}} for {{Multivariate Wind Power Based}} on {{Kernel Density Estimation}} and {{Component Number Reduction}}},
  author = {Gao, Yuanhai and Xu, Xiaoyuan and Yan, Zheng and Shahidehpour, Mohammad},
  year = {2022},
  month = jul,
  journal = {IEEE Transactions on Sustainable Energy},
  volume = {13},
  number = {3},
  pages = {1853--1856},
  issn = {1949-3037},
  doi = {10.1109/TSTE.2022.3159391},
  abstract = {The Gaussian mixture model (GMM) is a powerful tool to establish the probability distributions of random variables in power system analyses. GMM can model arbitrary probability distributions by increasing the number of its Gaussian components, but the commonly used expectation-maximization (EM) algorithm fails to obtain accurate GMM for large component numbers, which limits the application of GMM to multivariate wind power modeling. In this letter, a parameter estimation method for GMM with large component numbers is proposed based on kernel density estimation (KDE) and the improved density-preserving hierarchical EM algorithm. Then, the closed-form solution to probabilistic power flow (PPF) calculation is derived based on piecewise linearization and GMM, which validates the importance of large component numbers. Finally, the proposed uncertainty modeling method is compared with EM-based GMM, Copula functions, KDE, k-nearest neighbors and block neural autoregressive flow on actual wind speed data to validate its superiority in describing the details of probability densities of wind power. PPF calculation is performed to show the efficiency and accuracy of the proposed uncertainty analysis method.},
  keywords = {Estimation,Gaussian mixture model,Load flow,parameter estimation,probabilistic power flow,Probability density function,Probability distribution,uncertainty,Uncertainty,wind power,Wind power generation,Wind speed},
  file = {/Users/kshitijgoel/Zotero/storage/44YHYQ93/Gao et al. - 2022 - Gaussian Mixture Model for Multivariate Wind Power.pdf;/Users/kshitijgoel/Zotero/storage/FGFM3YEG/9735366.html}
}

@misc{gao_gevo_2024,
  title = {{{GEVO}}: {{Memory-Efficient Monocular Visual Odometry Using Gaussians}}},
  shorttitle = {{{GEVO}}},
  author = {Gao, Dasong and Li, Peter Zhi Xuan and Sze, Vivienne and Karaman, Sertac},
  year = {2024},
  month = sep,
  number = {arXiv:2409.09295},
  eprint = {2409.09295},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.09295},
  urldate = {2024-11-18},
  abstract = {Constructing a high-fidelity representation of the 3D scene using a monocular camera can enable a wide range of applications on mobile devices, such as micro-robots, smartphones, and AR/VR headsets. On these devices, memory is often limited in capacity and its access often dominates the consumption of compute energy. Although Gaussian Splatting (GS) allows for high-fidelity reconstruction of 3D scenes, current GS-based SLAM is not memory efficient as a large number of past images is stored to retrain Gaussians for reducing catastrophic forgetting. These images often require two-orders-of-magnitude higher memory than the map itself and thus dominate the total memory usage. In this work, we present GEVO, a GS-based monocular SLAM framework that achieves comparable fidelity as prior methods by rendering (instead of storing) them from the existing map. Novel Gaussian initialization and optimization techniques are proposed to remove artifacts from the map and delay the degradation of the rendered images over time. Across a variety of environments, GEVO achieves comparable map fidelity while reducing the memory overhead to around 58 MBs, which is up to 94x lower than prior works.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/CEZW2MDS/Gao et al. - 2024 - GEVO Memory-Efficient Monocular Visual Odometry Using Gaussians.pdf;/Users/kshitijgoel/Zotero/storage/67YPVCPR/2409.html}
}

@phdthesis{gao_information_2022,
  title = {An {{Information Geometric Picture}} of the {{Space}} of {{Tasks}}},
  author = {Gao, Yansong},
  year = {2022},
  address = {Philadelphia, PA, USA},
  langid = {english},
  school = {University of Pennsylvania},
  file = {/Users/kshitijgoel/Zotero/storage/7BD33T7C/Gao - AN INFORMATION GEOMETRIC PICTURE OF THE SPACE OF TASKS.pdf}
}

@inproceedings{gao_informationgeometric_2021,
  title = {An {{Information-Geometric Distance}} on the {{Space}} of {{Tasks}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Gao, Yansong and Chaudhari, Pratik},
  year = {2021},
  month = jul,
  pages = {3553--3563},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/gao21a.html},
  urldate = {2024-06-26},
  abstract = {This paper prescribes a distance between learning tasks modeled as joint distributions on data and labels. Using tools in information geometry, the distance is defined to be the length of the shortest weight trajectory on a Riemannian manifold as a classifier is fitted on an interpolated task. The interpolated task evolves from the source to the target task using an optimal transport formulation. This distance, which we call the "coupled transfer distance" can be compared across different classifier architectures. We develop an algorithm to compute the distance which iteratively transports the marginal on the data of the source task to that of the target task while updating the weights of the classifier to track this evolving data distribution. We develop theory to show that our distance captures the intuitive idea that a good transfer trajectory is the one that keeps the generalization gap small during transfer, in particular at the end on the target task. We perform thorough empirical validation and analysis across diverse image classification datasets to show that the coupled transfer distance correlates strongly with the difficulty of fine-tuning.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/66XC8A4W/Gao and Chaudhari - 2021 - An Information-Geometric Distance on the Space of Tasks.pdf;/Users/kshitijgoel/Zotero/storage/VY9RMEWK/Gao and Chaudhari - 2021 - An Information-Geometric Distance on the Space of Tasks.pdf}
}

@article{gao_integrated_2023,
  title = {An {{Integrated Hierarchical Approach}} for {{Real-Time Mapping With Gaussian Mixture Model}}},
  author = {Gao, Yuan and Dong, Wei},
  year = {2023},
  month = nov,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {11},
  pages = {6891--6898},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3313945},
  url = {https://ieeexplore.ieee.org/abstract/document/10246367},
  urldate = {2024-02-29},
  abstract = {To achieve effective collaboration of multiple robots, it requires efficient exchanges of map information. As directly exchanging generally used depth map requires high communication bandwidth, it is practical to enhance the efficiency using map compression techniques based on Gaussian mixture models. Currently, parameters of the Gaussian mixture model are mostly computed using the expectation-maximization algorithm. It is time consuming as it has to iteratively update parameters by traversing all points in a point cloud converted from the depth map, and it is not suitable for real-time applications. Other methods directly segment the point cloud into grids and then perform a single Gaussian parameter estimation for each grid. They achieve real-time compression but generate parameter sensitive results. To tackle issues above, we improve compression methods with an integrated hierarchical approach. First, the points are clustered hierarchically and efficiently by K-means, generating coarse clusters. Then, each cluster is further hierarchically clustered by expectation-maximization algorithm for accuracy enhancement. After each clustering process, an evaluation index for ensuring accuracy and preventing over-fitting is calculated to determine whether pruning or retention of newly generated clusters is appropriate. At last, parameters of each Gaussian distribution in the model are estimated by points in a corresponding cluster. Experiments conducted in various environments demonstrate that our approach improves computing efficiency by over 79 times compared to the state-of-the-art approach.},
  keywords = {Clustering algorithms,Depth map compression,expectation-maximization algorithm,Gaussian distribution,Gaussian mixture model,K-means,Optimization,Real-time systems,Robots,Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/DU7TK9YJ/Gao and Dong - 2023 - An Integrated Hierarchical Approach for Real-Time .pdf}
}

@inproceedings{gao_meetingmergingmission_2022,
  title = {Meeting-{{Merging-Mission}}: {{A Multi-robot Coordinate Framework}} for {{Large-Scale Communication-Limited Exploration}}},
  shorttitle = {Meeting-{{Merging-Mission}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Gao, Yuman and Wang, Yingjian and Zhong, Xingguang and Yang, Tiankai and Wang, Mingyang and Xu, Zhixiong and Wang, Yongchao and Lin, Yi and Xu, Chao and Gao, Fei},
  year = {2022},
  month = oct,
  pages = {13700--13707},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981544},
  url = {https://ieeexplore.ieee.org/document/9981544/},
  urldate = {2025-08-06},
  abstract = {This letter presents a complete framework Meeting-Merging-Mission for multi-robot exploration under communication restriction. Considering communication is limited in both bandwidth and range in the real world, we propose a lightweight environment presentation method and an efficient cooperative exploration strategy. For lower bandwidth, each robot uses specific polytopes to maintain free space and to generate Super Frontier Information (SFI), which serves as the source for exploration decision-making. To reduce repeated exploration, we develop a mission-based protocol that drives robots to share collected information in stable rendezvous. We also design a complete path planning scheme for both centralized and decentralized cases. To validate that our framework is practical and generic, we present an extensive benchmark and deploy our system into multi-UGV and multi-UAV platforms.},
  keywords = {Bandwidth,Benchmark testing,Decision making,Location awareness,Path planning,Protocols,Robot kinematics},
  file = {/Users/kshitijgoel/Zotero/storage/RAMBNCIF/Gao et al. - 2022 - Meeting-Merging-Mission A Multi-robot Coordinate Framework for Large-Scale Communication-Limited Ex.pdf}
}

@article{garcia-portugues_kernel_2013,
  title = {Kernel Density Estimation for Directional--Linear Data},
  author = {{Garc{\'i}a-Portugu{\'e}s}, Eduardo and Crujeiras, Rosa M. and {Gonz{\'a}lez-Manteiga}, Wenceslao},
  year = {2013},
  month = oct,
  journal = {Journal of Multivariate Analysis},
  volume = {121},
  pages = {152--175},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2013.06.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0047259X13001309},
  urldate = {2024-07-08},
  abstract = {A nonparametric kernel density estimator for directional--linear data is introduced. The proposal is based on a product kernel accounting for the different nature of both (directional and linear) components of the random vector. Expressions for the bias, variance, and mean integrated square error (MISE) are derived, jointly with an asymptotic normality result for the proposed estimator. For some particular distributions, an explicit formula for the MISE is obtained and compared with its asymptotic version, both for directional and directional--linear kernel density estimators. In this same setting, a closed expression for the bootstrap MISE is also derived.},
  keywords = {Directional-linear data,Kernel density estimator,Nonparametric statistics},
  file = {/Users/kshitijgoel/Zotero/storage/65ASQE77/García-Portugués et al. - 2013 - Kernel density estimation for directional–linear data.pdf;/Users/kshitijgoel/Zotero/storage/BWFDD8LA/S0047259X13001309.html}
}

@misc{garg_advances_2023,
  title = {Advances in the {{Theory}} of {{Control Barrier Functions}}: {{Addressing Practical Challenges}} in {{Safe Control Synthesis}} for {{Autonomous}} and {{Robotic Systems}}},
  shorttitle = {Advances in the {{Theory}} of {{Control Barrier Functions}}},
  author = {Garg, Kunal and Usevitch, James and Breeden, Joseph and Black, Mitchell and Agrawal, Devansh and Parwana, Hardik and Panagou, Dimitra},
  year = {2023},
  month = dec,
  number = {arXiv:2312.16719},
  eprint = {2312.16719},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.16719},
  url = {http://arxiv.org/abs/2312.16719},
  urldate = {2024-12-09},
  abstract = {This tutorial paper presents recent work of the authors that extends the theory of Control Barrier Functions (CBFs) to address practical challenges in the synthesis of safe controllers for autonomous systems and robots. We present novel CBFs and methods that handle safety constraints (i) with time and input constraints under disturbances, (ii) with high-relative degree under disturbances and input constraints, and (iii) that are affected by adversarial inputs and sampled-data effects. We then present novel CBFs and adaptation methods that prevent loss of validity of the CBF, as well as methods to tune the parameters of the CBF online to reduce conservatism in the system response. We also address the pointwise-only optimal character of CBF-induced control inputs by introducing a CBF formulation that accounts for future trajectories, as well as implementation challenges such as how to preserve safety when using output feedback control and zero-order-hold control. Finally we consider how to synthesize non-smooth CBFs when discontinuous inputs and multiple constraints are present.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
  file = {/Users/kshitijgoel/Zotero/storage/VD4LNQND/Garg et al. - 2023 - Advances in the Theory of Control Barrier Functions Addressing Practical Challenges in Safe Control.pdf;/Users/kshitijgoel/Zotero/storage/2JB9ETI9/2312.html}
}

@inproceedings{garg_information_2023,
  title = {Information Theoretic Clustering via Divergence Maximization among Clusters},
  booktitle = {Proceedings of the {{Thirty-Ninth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Garg, Sahil and Dalirrooyfard, Mina and Schneider, Anderson and Adler, Yeshaya and Nevmyvaka, Yuriy and Chen, Yu and Li, Fengpei and Cecchi, Guillermo},
  year = {2023},
  month = jul,
  pages = {624--634},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v216/garg23a.html},
  urldate = {2024-04-28},
  abstract = {Information-theoretic clustering is one of the most promising and principled approaches to finding clusters with minimal apriori assumptions. The key criterion therein is to maximize the mutual information between the data points and their cluster labels. Such an approach, however, does not explicitly promote any type of inter-cluster behavior. We instead propose to maximize the Kullback-Leibler divergence between the underlying data distributions associated to clusters (referred to as cluster distributions). We show it to entail the mutual information criterion along with maximizing cross entropy between the cluster distributions. For practical efficiency, we propose to empirically estimate the objective of KL-D between clusters in its dual form leveraging deep neural nets as a dual function approximator. Remarkably, our theoretical analysis establishes that estimating the divergence measure in its dual form simplifies the problem of clustering to one of optimally finding k-1 cut points for k clusters in the 1-D dual functional space. Overall, our approach enables linear-time clustering algorithms with theoretical guarantees of near-optimality, owing to the submodularity of the objective. We show the empirical superiority of our approach w.r.t. current state-of-the-art methods on the challenging task of clustering noisy timeseries as observed in domains such as neuroscience, healthcare, financial markets, spatio-temporal environmental dynamics, etc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6478ZS4U/Garg et al. - 2023 - Information theoretic clustering via divergence ma.pdf;/Users/kshitijgoel/Zotero/storage/CFQ5CQXF/Garg et al. - 2023 - Information theoretic clustering via divergence ma.pdf}
}

@inproceedings{gautam_method_2022,
  title = {A {{Method}} for {{Designing Autonomous Robots}} That {{Know Their Limits}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Gautam, Alvika and Whiting, Tim and Cao, Xuan and Goodrich, Michael A. and Crandall, Jacob W.},
  year = {2022},
  month = may,
  pages = {121--127},
  doi = {10.1109/ICRA46639.2022.9812030},
  abstract = {While the design of autonomous robots often emphasizes developing proficient robots, another important attribute of autonomous robot systems is their ability to evaluate their own proficiency and limitations. A robot should be able to assess how well it can perform a task before, during, and after it attempts the task. Thus, we consider the following question: How can we design autonomous robots that know their own limits? Toward this end, this paper presents an approach, called assumption-alignment tracking (AAT), for designing autonomous robots that can effectively evaluate their own limits. In AAT, the robot combines (a) measures of how well its decision-making algorithms align with its environment and hardware systems with (b) its past experiences to assess its ability to succeed at a given task. The effectiveness of AAT in assessing a robot's limits are illustrated in a robot navigation task.},
  keywords = {Automation,Autonomous robots,Decision making,Hardware,Navigation,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/BF4NM3D3/Gautam et al. - 2022 - A Method for Designing Autonomous Robots that Know.pdf;/Users/kshitijgoel/Zotero/storage/QVARQZWG/9812030.html}
}

@article{gavaskar_fast_2019,
  title = {Fast {{Adaptive Bilateral Filtering}}},
  author = {Gavaskar, Ruturaj G. and Chaudhury, Kunal N.},
  year = {2019},
  month = feb,
  journal = {IEEE Transactions on Image Processing},
  volume = {28},
  number = {2},
  pages = {779--790},
  issn = {1941-0042},
  doi = {10.1109/TIP.2018.2871597},
  url = {https://ieeexplore.ieee.org/document/8469064},
  urldate = {2024-07-08},
  abstract = {In the classical bilateral filter, a fixed Gaussian range kernel is used along with a spatial kernel for edge-preserving smoothing. We consider a generalization of this filter, the so-called adaptive bilateral filter, where the center and width of the Gaussian range kernel are allowed to change from pixel to pixel. Though this variant was originally proposed for sharpening and noise removal, it can also be used for other applications, such as artifact removal and texture filtering. Similar to the bilateral filter, the brute-force implementation of its adaptive counterpart requires intense computations. While several fast algorithms have been proposed in the literature for bilateral filtering, most of them work only with a fixed range kernel. In this paper, we propose a fast algorithm for adaptive bilateral filtering, whose complexity does not scale with the spatial filter width. This is based on the observation that the concerned filtering can be performed purely in range space using an appropriately defined local histogram. We show that by replacing the histogram with a polynomial and the finite range-space sum with an integral, we can approximate the filter using analytic functions. In particular, an efficient algorithm is derived using the following innovations: the polynomial is fitted by matching its moments to those of the target histogram (this is done using fast convolutions), and the analytic functions are recursively computed using integration-by-parts. Our algorithm can accelerate the brute-force implementation by at least 20 {\textbackslash}times , without perceptible distortions in the visual quality. We demonstrate the effectiveness of our algorithm for sharpening, JPEG deblocking, and texture filtering.},
  keywords = {Acceleration,adaptive,approximation,Approximation algorithms,Bilateral filtering,Complexity theory,fast algorithm,histogram,Histograms,Image edge detection,Kernel,Smoothing methods},
  file = {/Users/kshitijgoel/Zotero/storage/EX2WK8FI/Gavaskar and Chaudhury - 2019 - Fast Adaptive Bilateral Filtering.pdf}
}

@inproceedings{ge_visionbased_2022,
  title = {Vision-Based {{Relative Detection}} and {{Tracking}} for {{Teams}} of {{Micro Aerial Vehicles}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ge, Rundong and Lee, Moonyoung and Radhakrishnan, Vivek and Zhou, Yang and Li, Guanrui and Loianno, Giuseppe},
  year = {2022},
  month = oct,
  pages = {380--387},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981115},
  url = {https://ieeexplore.ieee.org/document/9981115/},
  urldate = {2025-05-13},
  abstract = {In this paper, we address the vision-based detection and tracking problems of multiple aerial vehicles using a single camera and Inertial Measurement Unit (IMU) as well as the corresponding perception consensus problem (i.e., uniqueness and identical IDs across all observing agents). We design several vision-based decentralized Bayesian multi-tracking filtering strategies to resolve the association between the incoming unsorted measurements obtained by a visual detector algorithm and the tracked agents. We compare their accuracy in different operating conditions as well as their scalability according to the number of agents in the team. This analysis provides useful insights about the most appropriate design choice for the given task. We further show that the proposed perception and inference pipeline which includes a Deep Neural Network (DNN) as visual target detector is lightweight and capable of concurrently running control and planning with Size, Weight, and Power (SWaP) constrained robots on-board. Experimental results show the effective tracking of multiple drones in various challenging scenarios such as heavy occlusions.},
  keywords = {Detectors,Filtering,Pipelines,Robustness,Scalability,Target tracking,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/KDW8DHHW/Ge et al. - 2022 - Vision-based Relative Detection and Tracking for Teams of Micro Aerial Vehicles.pdf;/Users/kshitijgoel/Zotero/storage/7TFTNESB/9981115.html}
}

@article{gemerek_directional_2022,
  title = {Directional {{Sensor Planning}} for {{Occlusion Avoidance}}},
  author = {Gemerek, Jake and Fu, Bo and Chen, Yucheng and Liu, Zeyu and Zheng, Min and {van Wijk}, David and Ferrari, Silvia},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {6},
  pages = {3713--3733},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3180628},
  abstract = {Directional sensors, such as video cameras, have become ubiquitous to many autonomous robots applications, such as monitoring and surveillance. The performance of these sensors and processing algorithms, however, may be hindered by the presence of objects that block visibility. This article presents a novel approach for planning the path of a mobile directional sensor deployed to observe multiple targets distributed in an environment populated with multiple obstacles and occlusions. Unlike existing art gallery or watchman's route methods, the visibility theory and motion planners developed in this article account for both line-of-sight visibility and bounded field-of-view constraints, and can provide obstacle avoidance based on robot geometry and kinodynamic constraints. The computational complexity analysis and experiments on a camera-equipped drone demonstrate that, despite the challenging geometric characteristics of directional C-targets, the approach scales to real-world problems. Furthermore, when compared to algorithms inspired by traveling salesman and target coverage approaches, the directional visibility planners presented in this article are significantly more effective both at guaranteeing complete target visibility and at minimizing distance traveled.},
  keywords = {Aerospace electronics,Avoidance,camera,Cameras,coverage,directional,Geometry,line of sight (LOS),obstacle,occlusion,path planning,Path planning,Robot control,Robot sensing systems,Robot vision systems,sensor,target,visibility},
  file = {/Users/kshitijgoel/Zotero/storage/V8CIFXFX/Gemerek et al. - 2022 - Directional Sensor Planning for Occlusion Avoidanc.pdf;/Users/kshitijgoel/Zotero/storage/DV4Z2L8I/9893394.html}
}

@inproceedings{geneva_openvins_2020,
  title = {{{OpenVINS}}: {{A Research Platform}} for {{Visual-Inertial Estimation}}},
  shorttitle = {{{OpenVINS}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Geneva, Patrick and Eckenhoff, Kevin and Lee, Woosik and Yang, Yulin and Huang, Guoquan},
  year = {2020},
  month = may,
  pages = {4666--4672},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196524},
  abstract = {In this paper, we present an open platform, termed OpenVINS, for visual-inertial estimation research for both the academic community and practitioners from industry. The open sourced codebase provides a foundation for researchers and engineers to quickly start developing new capabilities for their visual-inertial systems. This codebase has out of the box support for commonly desired visual-inertial estimation features, which include: (i) on-manifold sliding window Kalman filter, (ii) online camera intrinsic and extrinsic calibration, (iii) camera to inertial sensor time offset calibration, (iv) SLAM landmarks with different representations and consistent First-Estimates Jacobian (FEJ) treatments, (v) modular type system for state management, (vi) extendable visual-inertial system simulator, and (vii) extensive toolbox for algorithm evaluation. Moreover, we have also focused on detailed documentation and theoretical derivations to support rapid development and research, which are greatly lacked in the current open sourced algorithms. Finally, we perform comprehensive validation of the proposed OpenVINS against state-of-the-art open sourced algorithms, showing its competing estimation performance.},
  keywords = {Calibration,Cameras,Current measurement,Documentation,Estimation,Jacobian matrices,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/P43XPRUM/Geneva et al. - 2020 - OpenVINS A Research Platform for Visual-Inertial .pdf;/Users/kshitijgoel/Zotero/storage/G3FXRNXX/9196524.html}
}

@article{genewein_bounded_2015,
  title = {Bounded {{Rationality}}, {{Abstraction}}, and {{Hierarchical Decision-Making}}: {{An Information-Theoretic Optimality Principle}}},
  shorttitle = {Bounded {{Rationality}}, {{Abstraction}}, and {{Hierarchical Decision-Making}}},
  author = {Genewein, Tim and Leibfried, Felix and {Grau-Moya}, Jordi and Braun, Daniel Alexander},
  year = {2015},
  month = nov,
  journal = {Frontiers in Robotics and AI},
  volume = {2},
  publisher = {Frontiers},
  issn = {2296-9144},
  doi = {10.3389/frobt.2015.00027},
  url = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2015.00027/full},
  urldate = {2025-02-14},
  abstract = {{$<$}p{$>$}Abstraction and hierarchical information processing are hallmarks of human and animal intelligence underlying the unrivaled flexibility of behavior in biological systems. Achieving such flexibility in artificial systems is challenging, even with more and more computational power. Here, we investigate the hypothesis that abstraction and hierarchical information processing might in fact be the consequence of limitations in information-processing power. In particular, we study an information-theoretic framework of bounded rational decision-making that trades off utility maximization against information-processing costs. We apply the basic principle of this framework to perception-action systems with multiple information-processing nodes and derive bounded-optimal solutions. We show how the formation of abstractions and decision-making hierarchies depends on information-processing costs. We illustrate the theoretical ideas with example simulations and conclude by formalizing a mathematically unifying optimization principle that could potentially be extended to more complex systems.{$<$}/p{$>$}},
  langid = {english},
  keywords = {bounded rationality,computational rationality,decision-making,Hierarchical Architecture,Information Theory,Lossy compression,perception-action system,Rate distortion},
  file = {/Users/kshitijgoel/Zotero/storage/9DY5D2QJ/Genewein et al. - 2015 - Bounded Rationality, Abstraction, and Hierarchical Decision-Making An Information-Theoretic Optimal.pdf}
}

@misc{geng_mean_2025,
  title = {Mean {{Flows}} for {{One-step Generative Modeling}}},
  author = {Geng, Zhengyang and Deng, Mingyang and Bai, Xingjian and Kolter, J. Zico and He, Kaiming},
  year = {2025},
  month = may,
  number = {arXiv:2505.13447},
  eprint = {2505.13447},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.13447},
  url = {http://arxiv.org/abs/2505.13447},
  urldate = {2025-08-07},
  abstract = {We propose a principled and effective framework for one-step generative modeling. We introduce the notion of average velocity to characterize flow fields, in contrast to instantaneous velocity modeled by Flow Matching methods. A well-defined identity between average and instantaneous velocities is derived and used to guide neural network training. Our method, termed the MeanFlow model, is self-contained and requires no pre-training, distillation, or curriculum learning. MeanFlow demonstrates strong empirical performance: it achieves an FID of 3.43 with a single function evaluation (1-NFE) on ImageNet 256x256 trained from scratch, significantly outperforming previous state-of-the-art one-step diffusion/flow models. Our study substantially narrows the gap between one-step diffusion/flow models and their multi-step predecessors, and we hope it will motivate future research to revisit the foundations of these powerful models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/YQTPJEYW/Geng et al. - 2025 - Mean Flows for One-step Generative Modeling.pdf;/Users/kshitijgoel/Zotero/storage/4J9BI9KY/2505.html}
}

@article{gennery_traversability_1999,
  title = {Traversability {{Analysis}} and {{Path Planning}} for a {{Planetary Rover}}},
  author = {Gennery, Donald B.},
  year = {1999},
  month = apr,
  journal = {Autonomous Robots},
  volume = {6},
  number = {2},
  pages = {131--146},
  issn = {1573-7527},
  doi = {10.1023/A:1008831426966},
  url = {https://doi.org/10.1023/A:1008831426966},
  urldate = {2024-02-28},
  abstract = {A method of analyzing three-dimensional data such as might be produced by stereo vision or a laser range finder in order to plan a path for a vehicle such as a Mars rover is described. In order to produce robust results from data that is sparse and of varying accuracy, the method takes into account the accuracy of each data point, as represented by its covariance matrix. It computes estimates of smoothed and interpolated height, slope, and roughness at equally spaced horizontal intervals, as well as accuracy estimates of these quantities. From this data, a cost function is computed that takes into account both the distance traveled and the probability that each region is traversable. A parallel search algorithm that finds the path of minimum cost also is described. Examples using real data are presented.},
  langid = {english},
  keywords = {mobile robots,obstacle avoidance,sensor fusion,terrain mapping,uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/W4KW2HZU/Gennery - 1999 - Traversability Analysis and Path Planning for a Pl.pdf}
}

@article{genovese_nonparametric_2014,
  title = {Nonparametric {{Ridge Estimation}}},
  author = {Genovese, Christopher R. and {Perone-Pacifico}, Marco and Verdinelli, Isabella and Wasserman, Larry},
  year = {2014},
  journal = {The Annals of Statistics},
  volume = {42},
  number = {4},
  eprint = {43556332},
  eprinttype = {jstor},
  pages = {1511--1545},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/43556332},
  urldate = {2024-04-25},
  abstract = {We study the problem of estimating the ridges of a density function. Ridge estimation is an extension of mode finding and is useful for understanding the structure of a density. It can also be used to find hidden structure in point cloud data. We show that, under mild regularity conditions, the ridges of the kernel density estimator consistently estimate the ridges of the true density. When the data are noisy measurements of a manifold, we show that the ridges are close and topologically similar to the hidden manifold. To find the estimated ridges in practice, we adapt the modified mean-shift algorithm proposed by Ozertem and Erdogmus [J. Mach. Learn. Res. 12 (2011) 1249-1286]. Some numerical experiments verify that the algorithm is accurate.},
  file = {/Users/kshitijgoel/Zotero/storage/Z9H42QCV/Genovese et al. - 2014 - Nonparametric Ridge Estimation.pdf}
}

@book{gentle_matrix_2017,
  title = {Matrix {{Algebra}}},
  author = {Gentle, James E.},
  year = {2017},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-64867-5},
  url = {http://link.springer.com/10.1007/978-3-319-64867-5},
  urldate = {2024-06-08},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-319-64866-8 978-3-319-64867-5},
  keywords = {determinant,eigenvalue,eigenvector,generalized inverse,geometry,graph theory,inner product,linear algebra,linear model,linear system,linear transformation,matrix,numerical analysis,optimization,positive definite,R software,singular value decomposition,vector,vector space},
  file = {/Users/kshitijgoel/Zotero/storage/PPRWZQGL/Gentle - 2017 - Matrix Algebra.pdf}
}

@book{gentle_matrix_2024,
  title = {Matrix {{Algebra}}: {{Theory}}, {{Computations}} and {{Applications}} in {{Statistics}}},
  shorttitle = {Matrix {{Algebra}}},
  author = {Gentle, James E.},
  year = {2024},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-42144-0},
  url = {https://link.springer.com/10.1007/978-3-031-42144-0},
  urldate = {2024-06-08},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-42143-3 978-3-031-42144-0},
  langid = {english},
  keywords = {computer arithmetic,determinant,eigenvalue,eigenvector,generalized inverse,graph theory,inner product,linear algebra,linear model,linear system,linear transformation,matrix,numerical analysis,optimization,positive definite,R software,singular value decomposition,statistics,vector,vector space},
  file = {/Users/kshitijgoel/Zotero/storage/LC5LU7CW/Gentle - 2024 - Matrix Algebra Theory, Computations and Applications in Statistics.pdf}
}

@incollection{gentle_real_2024,
  title = {Real {{Analysis}} and {{Probability Distributions}} of {{Vectors}} and {{Matrices}}},
  booktitle = {Matrix {{Algebra}}: {{Theory}}, {{Computations}} and {{Applications}} in {{Statistics}}},
  author = {Gentle, James E.},
  editor = {Gentle, James E.},
  year = {2024},
  pages = {323--364},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-42144-0_7},
  url = {https://doi.org/10.1007/978-3-031-42144-0_7},
  urldate = {2024-06-08},
  abstract = {The earlier chapters in Part I have been in the area of mathematics generally called ``algebra.'' It includes the study of the familiar structures such as groups, fields, vector spaces or linear algebra, and so on. Another important area of mathematics is called ``analysis.'' It includes the ordinary calculus, with differentiation and integration usually based in measure theory. If the objects are real numbers or are composed of real numbers, the area is called ``real analysis.''},
  isbn = {978-3-031-42144-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/S45GPESH/Gentle - 2024 - Real Analysis and Probability Distributions of Vectors and Matrices.pdf}
}

@inproceedings{georgakis_uncertaintydriven_2022,
  title = {Uncertainty-Driven {{Planner}} for {{Exploration}} and {{Navigation}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Georgakis, Georgios and Bucher, Bernadette and Arapin, Anton and Schmeckpeper, Karl and Matni, Nikolai and Daniilidis, Kostas},
  year = {2022},
  month = may,
  pages = {11295--11302},
  doi = {10.1109/ICRA46639.2022.9812423},
  abstract = {We consider the problems of exploration and pointgoal navigation in previously unseen environments, where the spatial complexity of indoor scenes and partial observability constitute these tasks challenging. We argue that learning occupancy priors over indoor maps provides significant advantages towards addressing these problems. To this end, we present a novel planning framework that first learns to generate occupancy maps beyond the field-of-view of the agent, and second leverages the model uncertainty over the generated areas to formulate path selection policies for each task of interest. For pointgoal navigation the policy chooses paths with an upper confidence bound policy for efficient and traversable paths, while for exploration the policy maximizes model uncertainty over candidate paths. We perform experiments in the visually realistic environments of Matterport3D using the Habitat simulator and demonstrate: 1) Improved results on exploration and map quality metrics over competitive methods, and 2) The effectiveness of our planning module when paired with the state-of-the-art DD-PPO method for the point-goal navigation task.},
  keywords = {Automation,Complexity theory,Measurement,Navigation,Planning,Task analysis,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/DJ5L6MP5/Georgakis et al. - 2022 - Uncertainty-driven Planner for Exploration and Nav.pdf}
}

@inproceedings{gepperth_generalizing_2024,
  title = {Generalizing {{Self-organizing Maps}}: {{Large-Scale Training}} of~{{GMMs}} and~{{Applications}} in~{{Data Science}}},
  shorttitle = {Generalizing {{Self-organizing Maps}}},
  booktitle = {Advances in {{Self-Organizing Maps}}, {{Learning Vector Quantization}}, {{Interpretable Machine Learning}}, and {{Beyond}}},
  author = {Gepperth, Alexander},
  editor = {Villmann, Thomas and Kaden, Marika and Geweniger, Tina and Schleif, Frank-Michael},
  year = {2024},
  pages = {53--62},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-67159-3_7},
  abstract = {This contribution shows that Gaussian Mixture Models can be considered generalizations of self-organizing maps. More precisely, we demonstrate that the training of self-organizing maps is an approximation to the training of Gaussian Mixture Models by gradient descent. As a consequence, the scores of a trained SOM can be treated as log-likelihoods of a GMM with tied, spherical covariance and used, e.g., for outlier detection, whereas sampling from trained SOMs is not well-defined. Furthermore, we outline how SGD-trained GMMs can be generalized to diagonal and more expressive covariance matrices and how this benefits typical data science applications such as outlier detection, sampling and generative classification. Source codes are available on the author's web site or upon request.},
  isbn = {978-3-031-67159-3},
  langid = {english},
  keywords = {Gaussian Mixture Models,Self-Organizing Maps,Stochastic Gradient Descent},
  file = {/Users/kshitijgoel/Zotero/storage/KS7WX7NJ/Gepperth - 2024 - Generalizing Self-organizing Maps Large-Scale Training of GMMs and Applications in Data Science.pdf}
}

@article{gepperth_gradientbased_2021,
  title = {Gradient-{{Based Training}} of {{Gaussian Mixture Models}} for {{High-Dimensional Streaming Data}}},
  author = {Gepperth, Alexander and Pf{\"u}lb, Benedikt},
  year = {2021},
  month = dec,
  journal = {Neural Processing Letters},
  volume = {53},
  number = {6},
  pages = {4331--4348},
  issn = {1573-773X},
  doi = {10.1007/s11063-021-10599-3},
  url = {https://doi.org/10.1007/s11063-021-10599-3},
  urldate = {2025-06-11},
  abstract = {We present an approach for efficiently training Gaussian Mixture Model (GMM) by Stochastic Gradient Descent (SGD) with non-stationary, high-dimensional streaming data. Our training scheme does not require data-driven parameter initialization (e.g., k-means) and can thus be trained based on a random initial state. Furthermore, the approach allows mini-batch sizes as low as 1, which are typical for streaming-data settings. Major problems in such settings are undesirable local optima during early training phases and numerical instabilities due to high data dimensionalities. We introduce an adaptive annealing procedure to address the first problem, whereas numerical instabilities are eliminated by an exponential-free approximation to the standard GMM log-likelihood. Experiments on a variety of visual and non-visual benchmarks show that our SGD approach can be trained completely without, for instance, k-means based centroid initialization. It also compares favorably to an online variant of Expectation-Maximization (EM)---stochastic EM (sEM), which it outperforms by a large margin for very high-dimensional data.},
  langid = {english},
  keywords = {Gaussian Mixture Model,High-Dimensional Streaming Data,Machine Learning,Mastery Learning,Statistical Learning,Stochastic Gradient Descent,Stochastic Learning and Adaptive Control,Stochastic Modelling,Stochastic Modelling in Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/5T9VNMYU/Gepperth and Pfülb - 2021 - Gradient-Based Training of Gaussian Mixture Models for High-Dimensional Streaming Data.pdf}
}

@inproceedings{gepperth_rigorous_2020,
  title = {A {{Rigorous Link Between Self-Organizing Maps}} and {{Gaussian Mixture Models}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} -- {{ICANN}} 2020},
  author = {Gepperth, Alexander and Pf{\"u}lb, Benedikt},
  editor = {Farka{\v s}, Igor and Masulli, Paolo and Wermter, Stefan},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {863--872},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-61616-8_69},
  abstract = {This work presents a mathematical treatment of the relation between Self-Organizing Maps (SOMs) and Gaussian Mixture Models (GMMs). We show that energy-based SOM models can be interpreted as performing gradient descent, minimizing an approximation to the GMM log-likelihood that is particularly valid for high data dimensionalities. The SOM-like decrease of the neighborhood radius can be understood as an annealing procedure ensuring that gradient descent does not get stuck in undesirable local minima. This link allows to treat SOMs as generative probabilistic models, giving a formal justification for using SOMs, e.g., to detect outliers, or for sampling.},
  isbn = {978-3-030-61616-8},
  langid = {english},
  keywords = {Gaussian Mixture Models,Self-Organizing Maps,Stochastic Gradient Descent},
  file = {/Users/kshitijgoel/Zotero/storage/72EIVG6J/Gepperth and Pfülb - 2020 - A Rigorous Link Between Self-Organizing Maps and G.pdf}
}

@article{gergal_drone_2021,
  title = {Drone {{Swarming Tactics Using Reinforcement Learning}} and {{Policy Optimization}}},
  author = {Gergal, Elizabeth K.},
  year = {2021},
  month = jul,
  url = {https://apps.dtic.mil/sti/html/trecms/AD1149672/},
  urldate = {2025-08-12},
  abstract = {This project aims to develop defensive drone swarming tactics using reinforcement learning (RL). Swarming is a military tactic where many individually operated units maneuver as one mass to attack an enemy. Defensive swarm tactics are current topics of interest for the US military as other countries and non-state actors are gaining advantages because swarm agents are usually simple, inexpensive, and easy to implement. Current work has already developed the means of flying (drones), communicating, and swarming. However, swarms do not yet have the ability to coordinate an attack against an enemy swarm. We simulated drone battles between two swarms of military fixed wings drones using pre-programmed tactics. Even when outnumbered by up to 100\%, there were effective tactics that could overcome the difference in size. When used in defense of a ship, these programmed tactics, on average, allowed between 0 and 0.5 drones to pass the defense and hit the ship which outperforms the current defenses on an Arleigh Burke Class Destroyer and other researched drone swarm defenses. This research shows that it is possible to gain a tactical advantage over an enemy swarm using certain maneuvers and tactics. In order to develop even more effective tactics, we trained an "Agent" tactic using RL. RL is a branch of machine learning that allows an agent to learn an environment, train, and learn which actions that will result in success. The "Agent" tactic does not exhibit emergent behavior yet, but it does kill some enemy drones and outperform other researched RL trained drone swarm tactics.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7E2AVJSM/Gergal - 2021 - Drone Swarming Tactics Using Reinforcement Learning and Policy Optimization.pdf}
}

@misc{geshkovski_mathematical_2024,
  title = {A Mathematical Perspective on {{Transformers}}},
  author = {Geshkovski, Borjan and Letrouit, Cyril and Polyanskiy, Yury and Rigollet, Philippe},
  year = {2024},
  month = aug,
  number = {arXiv:2312.10794},
  eprint = {2312.10794},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10794},
  url = {http://arxiv.org/abs/2312.10794},
  urldate = {2025-01-21},
  abstract = {Transformers play a central role in the inner workings of large language models. We develop a mathematical framework for analyzing Transformers based on their interpretation as interacting particle systems, which reveals that clusters emerge in long time. Our study explores the underlying theory and offers new perspectives for mathematicians as well as computer scientists.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Analysis of PDEs,Mathematics - Dynamical Systems},
  file = {/Users/kshitijgoel/Zotero/storage/PWTGI44Z/Geshkovski et al. - 2024 - A mathematical perspective on Transformers.pdf;/Users/kshitijgoel/Zotero/storage/79WBRL83/2312.html}
}

@article{ghaffarijadidi_gaussian_2018,
  title = {Gaussian Processes Autonomous Mapping and Exploration for Range-Sensing Mobile Robots},
  author = {Ghaffari~Jadidi, Maani and Valls~Miro, Jaime and Dissanayake, Gamini},
  year = {2018},
  month = feb,
  journal = {Autonomous Robots},
  volume = {42},
  number = {2},
  pages = {273--290},
  issn = {1573-7527},
  doi = {10.1007/s10514-017-9668-3},
  url = {https://doi.org/10.1007/s10514-017-9668-3},
  urldate = {2023-10-23},
  abstract = {Most of the existing robotic exploration schemes use occupancy grid representations and geometric targets known as frontiers. The occupancy grid representation relies on the assumption of independence between grid cells and ignores structural correlations present in the environment. We develop a Gaussian processes (GPs) occupancy mapping technique that is computationally tractable for online map building due to its incremental formulation and provides a continuous model of uncertainty over the map spatial coordinates. The standard way to represent geometric frontiers extracted from occupancy maps is to assign binary values to each grid cell. We extend this notion to novel probabilistic frontier maps computed efficiently using the gradient of the GP occupancy map. We also propose a mutual information-based greedy exploration technique built on that representation that takes into account all possible future observations. A major advantage of high-dimensional map inference is the fact that such techniques require fewer observations, leading to a faster map entropy reduction during exploration for map building scenarios. Evaluations using the publicly available datasets show the effectiveness of the proposed framework for robotic mapping and exploration tasks.},
  langid = {english},
  keywords = {Autonomous navigation,Exploration,Gaussian processes,Mapping,Mutual information},
  file = {/Users/kshitijgoel/Zotero/storage/GQ55RWLR/Ghaffari Jadidi et al. - 2018 - Gaussian processes autonomous mapping and explorat.pdf}
}

@phdthesis{ghassabeh_convergence_2013,
  title = {On the Convergence and Applications of Mean Shift Type Algorithms},
  author = {Ghassabeh, Youness},
  year = {2013},
  address = {Canada -- Ontario, CA},
  url = {https://www.proquest.com/docview/1512225946/abstract/F8467BFE833B4148PQ/1},
  urldate = {2024-07-11},
  abstract = {Mean shift (MS) and subspace constrained mean shift (SCMS) algorithms are non-parametric, iterative methods to find a representation of a high dimensional data set on a principal curve or surface embedded in a high dimensional space. The representation of high dimensional data on a principal curve or surface, the class of mean shift type algorithms and their properties, and applications of these algorithms are the main focus of this dissertation. Although MS and SCMS algorithms have been used in many applications, a rigorous study of their convergence is still missing. This dissertation aims to fill some of the gaps between theory and practice by investigating some convergence properties of these algorithms. In particular, we propose a sufficient condition for a kernel density estimate with a Gaussian kernel to have isolated stationary points to guarantee the convergence of the MS algorithm. We also show that the SCMS algorithm inherits some of the important convergence properties of the MS algorithm. In particular, the monotonicity and convergence of the density estimate values along the sequence of output values of the algorithm are shown. We also show that the distance between consecutive points of the output sequence converges to zero, as does the projection of the gradient vector onto the subspace spanned by the D-d eigenvectors corresponding to the D-d largest eigenvalues of the local inverse covariance matrix. Furthermore, three new variations of the SCMS algorithm are proposed and the running times and performance of the resulting algorithms are compared with original SCMS algorithm. We also propose an adaptive version of the SCMS algorithm to consider the effect of new incoming samples without running the algorithm on the whole data set. As well, we develop some new potential applications of the MS and SCMS algorithm. These applications involve finding straight lines in digital images; pre-processing data before applying locally linear embedding (LLE) and ISOMAP for dimensionality reduction; noisy source vector quantization where the clean data need to be estimated before the quanization step; improving the performance of kernel regression in certain situations; and skeletonization of digitally stored handwritten characters.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780499279620},
  langid = {english},
  school = {Queen's University (Canada)},
  keywords = {Convergence,Dimensionality reduction,Mean shift algorithms,Principal curve,Principal surface,Pure sciences,Source vector quantization,Subspace constrained algorithm,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/QRFFTR5X/Aliyari Ghassabeh - On the convergence and applications of mean shift type algorithms.pdf}
}

@phdthesis{gillespie_evolving_2024,
  type = {Thesis},
  title = {Evolving {{Intrinsic Triangulations}}},
  author = {Gillespie, Mark},
  year = {2024},
  month = jun,
  doi = {10.1184/R1/25898782.v1},
  url = {https://kilthub.cmu.edu/articles/thesis/Evolving_Intrinsic_Triangulations/25898782/1},
  urldate = {2025-01-18},
  abstract = {This thesis presents algorithms and data structures for performing robust computation on surfaces that evolve over time. Throughout scientific and geometric computing, surfaces are often modeled as triangle meshes. However, finding high-quality meshes remains a challenge because meshes play two distinct and often-conflicting roles: defining both the surface geometry and a space of functions on that surface. One solution to this dilemma, which has proven quite powerful in recent years, is the use of intrinsic triangulations to decouple these two concerns. The key idea is that given a triangle mesh representing an input surface, one can find many alternative triangulations which encode the exact same intrinsic geometry but offer alternative function spaces to work in. This technique makes it easy to find high-quality intrinsic triangle meshes, sidestepping the tradeoffs of classical mesh construction. However, the fact that intrinsic triangulations exactly preserve the input geometry---one of the central benefits of the technique---also makes it challenging to apply to surfaces whose geometry changes over time. In this thesis we relax the assumption of exact geometry preservation, allowing the intrinsic perspective to be applied to time-evolving surfaces. We take as examples the problems of mesh simplification and surface parameterization. In the case of mesh simplification, we provide a general-purpose data structure for intrinsic triangulations which share only the topological class of the input surface, but may feature different geometry. In the case of surface parameterization, we build more efficient data structures and algorithms for the special case where the geometry changes conformally, using a connection between discrete conformal maps and hyperbolic geometry. In both cases, we find that the intrinsic perspective leads to simple algorithms which are still robust and efficient on a variety of examples.},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/6W98AQDH/Gillespie - 2024 - Evolving Intrinsic Triangulations.pdf}
}

@article{gillespie_ray_2024,
  title = {Ray {{Tracing Harmonic Functions}}},
  author = {Gillespie, Mark and Yang, Denise and Botsch, Mario and Crane, Keenan},
  year = {2024},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {4},
  pages = {99:1--99:18},
  issn = {0730-0301},
  doi = {10.1145/3658201},
  url = {https://doi.org/10.1145/3658201},
  urldate = {2024-07-26},
  abstract = {Sphere tracing is a fast and high-quality method for visualizing surfaces encoded by signed distance functions (SDFs). We introduce a similar method for a completely different class of surfaces encoded by harmonic functions, opening up rich new possibilities for visual computing. Our starting point is similar in spirit to sphere tracing: using conservative Harnack bounds on the growth of harmonic functions, we develop a Harnack tracing algorithm for visualizing level sets of harmonic functions, including those that are angle-valued and exhibit singularities. The method takes much larger steps than na{\"i}ve ray marching, avoids numerical issues common to generic root finding methods and, like sphere tracing, needs only perform pointwise evaluation of the function at each step. For many use cases, the method is fast enough to run real time in a shader program. We use it to visualize smooth surfaces directly from point clouds (via Poisson surface reconstruction) or polygon soup (via generalized winding numbers) without linear solves or mesh extraction. We also use it to visualize nonplanar polygons (possibly with holes), surfaces from architectural geometry, mesh "exoskeletons", and key mathematical objects including knots, links, spherical harmonics, and Riemann surfaces. Finally we show that, at least in theory, Harnack tracing provides an alternative mechanism for visualizing arbitrary implicit surfaces.},
  file = {/Users/kshitijgoel/Zotero/storage/GN9T9MDD/Gillespie et al. - 2024 - Ray Tracing Harmonic Functions.pdf}
}

@phdthesis{gimbogyeong_fast_2022,
  type = {Thesis},
  title = {Fast {{Incremental Density-Based Clustering}} over {{Sliding Windows}}},
  author = {김보경},
  year = {2022},
  url = {https://s-space.snu.ac.kr/handle/10371/187775},
  urldate = {2025-07-31},
  abstract = {Given the prevalence of mobile and IoT devices, continuous clustering against streaming data has become an essential tool of increasing importance for data analytics. Among many clustering approaches, density-based clustering has garnered much attention due to its unique advantage that it can detect clusters of an arbitrary shape when noise exists. However, when the clusters need to be updated continuously along with an evolving input dataset, a relatively high computational cost is required. Particularly, deleting data points from the clusters causes severe performance degradation. In this dissertation, the performance limits of the incremental density-based clustering over sliding windows are addressed. Ultimately, two algorithms, DISC and DenForest, are proposed. The first algorithm DISC is an incremental density-based clustering algorithm that efficiently produces the same clustering results as DBSCAN over sliding windows. It focuses on redundancy issues that occur when updating clusters. When multiple data points are inserted or deleted individually, surrounding data points are explored and retrieved redundantly. DISC addresses these issues and improves the performance by updating multiple points in a batch. It also presents several optimization techniques. The second algorithm DenForest is an incremental density-based clustering algorithm that primarily focuses on the deletion process. Unlike previous methods that manage clusters as a graph, DenForest manages clusters as a group of spanning trees, which contributes to very efficient deletion performance. Moreover, it provides a batch-optimized technique to improve the insertion performance. To prove the effectiveness of the two algorithms, extensive evaluations were conducted, and it is demonstrated that DISC and DenForest outperform the state-of-the-art density-based clustering algorithms significantly.},
  langid = {english},
  school = {서울대학교 대학원},
  annotation = {Accepted: 2022-12-29T07:44:29Z},
  file = {/Users/kshitijgoel/Zotero/storage/Z43YNCTZ/김보경 - 2022 - Fast Incremental Density-Based Clustering over Sliding Windows.pdf}
}

@inproceedings{ginting_capabilityaware_2022,
  title = {Capability-{{Aware Task Allocation}} and {{Team Formation Analysis}} for {{Cooperative Exploration}} of {{Complex Environments}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ginting, Muhammad Fadhil and Otsu, Kyohei and Kochenderfer, Mykel J. and {Agha-mohammadi}, Ali-akbar},
  year = {2022},
  month = oct,
  pages = {7145--7152},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981631},
  abstract = {To achieve autonomy in complex real-world exploration missions, we consider deployment strategies for a team of robots with heterogeneous capabilities. We formulate a multi-robot exploration mission and compute an operation policy to maintain robot team productivity and maximize mission success. The environment description, robot capability, and mission outcome are modeled as a Markov decision process (MDP). We also include constraints, such as sensor failures, limited communication coverage, and mobility-stressing elements. The proposed operation model is applied to the DARPA Subterranean (SubT) Challenge. The deployment policy is also compared against the human-based operation strategy in the final competition of the SubT Challenge.},
  keywords = {Computational modeling,Markov processes,Multi-robot systems,Productivity,Resource management,Robot sensing systems,Robustness},
  file = {/Users/kshitijgoel/Zotero/storage/N24M9I8T/Ginting et al. - 2022 - Capability-Aware Task Allocation and Team Formatio.pdf;/Users/kshitijgoel/Zotero/storage/HLG3HFIN/9981631.html}
}

@article{ginting_chord_2021,
  title = {{{CHORD}}: {{Distributed Data-Sharing}} via {{Hybrid ROS}} 1 and 2 for {{Multi-Robot Exploration}} of {{Large-Scale Complex Environments}}},
  shorttitle = {{{CHORD}}},
  author = {Ginting, Muhammad Fadhil and Otsu, Kyohei and Edlund, Jeffrey A. and Gao, Jay and {Agha-Mohammadi}, Ali-Akbar},
  year = {2021},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {5064--5071},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3061393},
  abstract = {A well-structured and reliable communication system is key to the successful operations of multi-robot systems. In this letter, we present our design and implementation of a multi-robot communication architecture CHORD (Collaborative High-bandwidth Operations with Radio Droppables) based on two popular robotics middleware, ROS 1 and ROS 2. We discuss the benefit and best practices of combining two different frameworks that share the same spirit and show its performance from large-scale real-world experiments. The proposed system is developed as part of Team CoSTAR's effort for the DARPA Subterranean (SubT) Challenge. The system has been field-proved and demonstrated in the Urban Circuit event, where team CoSTAR won first place. To our knowledge, this work is the first real-world demonstration of a ROS 2-based multi-robot system in such large-scale extreme environments. From the significant improvement of the communication performance and the ease of transition from existing ROS 1 systems, this work encourages wider adoption of ROS 2 in field robotics applications.},
  keywords = {Bridges,Collaboration,Communication systems,field robots,multi-robot systems,Multi-robot systems,Networked robots,Quality of service,Reliability,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/73K64LEP/Ginting et al. - 2021 - CHORD Distributed Data-Sharing via Hybrid ROS 1 a.pdf;/Users/kshitijgoel/Zotero/storage/UKSGRR8R/9364680.html}
}

@inproceedings{gionis_similarity_1999,
  title = {Similarity {{Search}} in {{High Dimensions}} via {{Hashing}}},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Very Large Data Bases}}},
  author = {Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev},
  year = {1999},
  month = sep,
  series = {{{VLDB}} '99},
  pages = {518--529},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  urldate = {2024-07-18},
  isbn = {978-1-55860-615-9}
}

@incollection{glomb_surface_2014,
  title = {Surface {{Mixture Models}} for the {{Optimization}} of {{Object Boundary Representation}}},
  booktitle = {Artificial {{Intelligence}} and {{Soft Computing}}},
  author = {G{\l}omb, Przemys{\l}aw and Sochan, Arkadiusz},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Rutkowski, Leszek and Korytkowski, Marcin and Scherer, Rafa{\l} and Tadeusiewicz, Ryszard and Zadeh, Lotfi A. and Zurada, Jacek M.},
  year = {2014},
  volume = {8467},
  pages = {703--714},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-07173-2_60},
  url = {http://link.springer.com/10.1007/978-3-319-07173-2_60},
  urldate = {2022-11-02},
  abstract = {We explore an original approach to represent boundaries of objects based on mixture of densities in parametrized submanifolds embedded in Rn. This method combines representation of boundary by `patchwork' of surfaces and traditional mixture models to represent point distributions within the surfaces. Specifically, this method could be used for lossy compression/storage of point clouds, with significant data compression factor. We present method description and experiments with scanned objects.},
  isbn = {978-3-319-07172-5 978-3-319-07173-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/L6ZNQDBI/Głomb and Sochan - 2014 - Surface Mixture Models for the Optimization of Obj.pdf}
}

@misc{goel_distance_2024,
  title = {Distance and {{Collision Probability Estimation}} from {{Gaussian Surface Models}}},
  author = {Goel, Kshitij and Tabib, Wennie},
  year = {2024},
  month = apr,
  number = {arXiv:2402.00186},
  eprint = {2402.00186},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2402.00186},
  urldate = {2024-07-21},
  abstract = {This paper describes continuous-space methodologies to estimate the collision probability, Euclidean distance and gradient between an ellipsoidal robot model and an environment surface modeled as a set of Gaussian distributions. Continuousspace collision probability estimation is critical for uncertaintyaware motion planning. Most collision detection and avoidance approaches assume the robot is modeled as a sphere, but ellipsoidal representations provide tighter approximations and enable navigation in cluttered and narrow spaces. State-of-theart methods derive the Euclidean distance and gradient by processing raw point clouds, which is computationally expensive for large workspaces. Recent advances in Gaussian surface modeling (e.g. mixture models, splatting) enable compressed and high-fidelity surface representations. Few methods exist to estimate continuous-space occupancy from such models. They require Gaussians to model free space and are unable to estimate the collision probability, Euclidean distance and gradient for an ellipsoidal robot. The proposed methods bridge this gap by extending prior work in ellipsoid-to-ellipsoid Euclidean distance and collision probability estimation to Gaussian surface models. A geometric blending approach is also proposed to improve collision probability estimation. The approaches are evaluated with numerical 2D and 3D experiments using real-world point cloud data. Methods for efficient calculation of these quantities are demonstrated to execute within a few microseconds per ellipsoid pair using a single-thread on low-power CPUs of modern embedded computers.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computational Geometry,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/7XHU5TD2/Goel and Tabib - 2024 - Distance and Collision Probability Estimation from Gaussian Surface Models.pdf}
}

@inproceedings{goel_fast_2021,
  title = {Fast {{Exploration Using Multirotors}}: {{Analysis}}, {{Planning}}, and {{Experimentation}}},
  shorttitle = {Fast {{Exploration Using Multirotors}}},
  booktitle = {Field and {{Service Robotics}}},
  author = {Goel, Kshitij and Corah, Micah and Boirum, Curtis and Michael, Nathan},
  editor = {Ishigami, Genya and Yoshida, Kazuya},
  year = {2021},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {291--305},
  publisher = {Springer},
  address = {Singapore},
  doi = {10.1007/978-981-15-9460-1_21},
  url = {https://link.springer.com/chapter/10.1007/978-981-15-9460-1_21},
  copyright = {All rights reserved},
  isbn = {978-981-15-9460-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2BRE3UD8/Goel et al. - 2021 - Fast Exploration Using Multirotors Analysis, Plan.pdf}
}

@inproceedings{goel_gira_2024,
  title = {{{GIRA}}: {{Gaussian Mixture Models}} for {{Inference}} and {{Robot Autonomy}}},
  shorttitle = {{{GIRA}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Goel, Kshitij and Tabib, Wennie},
  year = {2024},
  month = may,
  pages = {6212--6218},
  doi = {10.1109/ICRA57147.2024.10611216},
  url = {https://ieeexplore.ieee.org/abstract/document/10611216},
  urldate = {2024-09-29},
  abstract = {This paper introduces the open-source framework, GIRA, which implements fundamental robotics algorithms for reconstruction, pose estimation, and occupancy modeling using compact generative models. Compactness enables perception in the large by ensuring that the perceptual models can be communicated through low-bandwidth channels during large-scale mobile robot deployments. The generative property enables perception in the small by providing high-resolution reconstruction capability. These properties address perception needs for diverse robotic applications, including multi-robot exploration and dexterous manipulation. State-of-the-art perception systems construct perceptual models via multiple disparate pipelines that reuse the same underlying sensor data, which leads to increased computation, redundancy, and complexity. GIRA bridges this gap by providing a unified perceptual modeling framework using Gaussian mixture models (GMMs) as well as a novel systems contribution, which consists of GPUaccelerated functions to learn GMMs 10-100x faster compared to existing CPU implementations. Because few GMM-based frameworks are open-sourced, this work seeks to accelerate innovation and broaden adoption of these techniques.},
  keywords = {Adaptation models,Computational modeling,Point cloud compression,Pose estimation,Robot sensing systems,Software,Technological innovation},
  file = {/Users/kshitijgoel/Zotero/storage/YQUF5V3Z/Goel and Tabib - 2024 - GIRA Gaussian Mixture Models for Inference and Robot Autonomy.pdf;/Users/kshitijgoel/Zotero/storage/Q8GWXN6H/10611216.html}
}

@inproceedings{goel_hierarchical_2022,
  title = {Hierarchical {{Collision Avoidance}} for {{Adaptive-Speed Multirotor Teleoperation}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Goel, Kshitij and Daoud, Yves Georgy and Michael, Nathan and Tabib, Wennie},
  year = {2022},
  month = nov,
  pages = {20--27},
  issn = {2475-8426},
  doi = {10.1109/SSRR56537.2022.10018782},
  url = {https://ieeexplore.ieee.org/document/10018782},
  urldate = {2024-11-15},
  abstract = {This paper improves safe motion primitives-based teleoperation of a multirotor by developing a hierarchical collision avoidance method that modulates maximum speed based on environment complexity and perceptual constraints. Safe speed modulation is challenging in environments that exhibit varying clutter. Existing methods fix maximum speed and map resolution, which prevents vehicles from accessing tight spaces and places the cognitive load for changing speed on the operator. We address these gaps by proposing a high-rate (10 Hz) teleoperation approach that modulates the maximum vehicle speed through hierarchical collision checking. The hierarchical collision checker simultaneously adapts the local map's voxel size and maximum vehicle speed to ensure motion planning safety. The proposed methodology is evaluated in simulation and real-world experiments and compared to a non-adaptive motion primitives-based teleoperation approach. The results demonstrate the advantages of the proposed teleoperation approach both in time taken and the ability to complete the task without requiring the user to specify a maximum vehicle speed.},
  keywords = {Adaptation models,Cognitive load,Collision avoidance,Complexity theory,Modulation,Safety,Space vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/2G3MJW8G/Goel et al. - 2022 - Hierarchical Collision Avoidance for Adaptive-Speed Multirotor Teleoperation.pdf}
}

@article{goel_incremental_2023,
  title = {Incremental {{Multimodal Surface Mapping}} via {{Self-Organizing Gaussian Mixture Models}}},
  author = {Goel, Kshitij and Tabib, Wennie},
  year = {2023},
  month = dec,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {12},
  pages = {8358--8365},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3327670},
  url = {https://ieeexplore.ieee.org/document/10295571/},
  urldate = {2023-11-20},
  abstract = {This letter describes an incremental multimodal surface mapping methodology, which represents the environment as a continuous probabilistic model. This model enables high-resolution reconstruction while simultaneously compressing spatial and intensity point cloud data. The strategy employed in this work utilizes Gaussian mixture models (GMMs) to represent the environment. While prior GMM-based mapping works have developed methodologies to determine the number of mixture components using information-theoretic techniques, these approaches either operate on individual sensor observations, making them unsuitable for incremental mapping, or are not real-time viable, especially for applications where high-fidelity modeling is required. To bridge this gap, this letter introduces a spatial hash map for rapid GMM submap extraction combined with an approach to determine relevant and redundant data in a point cloud. These contributions increase computational speed by an order of magnitude compared to state-of-the-art incremental GMM-based mapping. In addition, the proposed approach yields a superior tradeoff in map accuracy and size when compared to state-of-the-art mapping methodologies (both GMM- and not GMM-based). Evaluations are conducted using both simulated and real-world data. The software is released open-source to benefit the robotics community.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M8RQWSIU/Goel and Tabib - 2023 - Incremental Multimodal Surface Mapping via Self-Or.pdf}
}

@article{goel_probabilistic_2023,
  title = {Probabilistic {{Point Cloud Modeling}} via {{Self-Organizing Gaussian Mixture Models}}},
  author = {Goel, Kshitij and Michael, Nathan and Tabib, Wennie},
  year = {2023},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {5},
  pages = {2526--2533},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3256923},
  url = {https://ieeexplore.ieee.org/abstract/document/10068771},
  urldate = {2024-01-27},
  abstract = {This letter presents a continuous probabilistic modeling methodology for spatial point cloud data using finite Gaussian Mixture Models (GMMs) where the number of components are adapted based on the scene complexity. Few hierarchical and adaptive methods have been proposed to address the challenge of balancing model fidelity with size. Instead, state-of-the-art mapping approaches require tuning parameters for specific use cases, but do not generalize across diverse environments. To address this gap, we utilize a self-organizing principle from information-theoretic learning to automatically adapt the complexity of the GMM model based on the relevant information in the sensor data. The approach is evaluated against existing point cloud modeling techniques on real-world data with varying degrees of scene complexity.},
  keywords = {Adaptation models,Complexity theory,Computational modeling,Data models,field robots,Mapping,Point cloud compression,Probabilistic logic,RGB-D perception,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/AALNRT26/Goel et al. - 2023 - Probabilistic Point Cloud Modeling via Self-Organi.pdf;/Users/kshitijgoel/Zotero/storage/Q6F4GX86/10068771.html}
}

@phdthesis{goel_rapid_2021,
  title = {Rapid {{Subsurface Exploration}} with {{Multiple Aerial Robots}}},
  author = {Goel, Kshitij},
  year = {2021},
  month = aug,
  address = {Pittsburgh, PA, USA},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/RRBFVCGC/Goel - Rapid Subsurface Exploration with Multiple Aerial .pdf}
}

@inproceedings{goel_rapid_2021a,
  title = {Rapid and {{High-Fidelity Subsurface Exploration}} with {{Multiple Aerial Robots}}},
  booktitle = {Experimental {{Robotics}}},
  author = {Goel, Kshitij and Tabib, Wennie and Michael, Nathan},
  editor = {Siciliano, Bruno and Laschi, Cecilia and Khatib, Oussama},
  year = {2021},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {436--448},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-71151-1_39},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-71151-1_39},
  copyright = {All rights reserved},
  isbn = {978-3-030-71151-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/H67WISHV/Goel et al. - 2021 - Rapid and High-Fidelity Subsurface Exploration wit.pdf}
}

@article{gokcay_information_2002,
  title = {Information Theoretic Clustering},
  author = {Gokcay, E. and Principe, J.C.},
  year = {2002},
  month = feb,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {2},
  pages = {158--171},
  issn = {1939-3539},
  doi = {10.1109/34.982897},
  url = {https://ieeexplore.ieee.org/abstract/document/982897},
  urldate = {2024-04-28},
  abstract = {Clustering is an important topic in pattern recognition. Since only the structure of the data dictates the grouping (unsupervised learning), information theory is an obvious criteria to establish the clustering rule. The paper describes a novel valley seeking clustering algorithm using an information theoretic measure to estimate the cost of partitioning the data set. The information theoretic criteria developed here evolved from a Renyi entropy estimator (A. Renyi, 1960) that was proposed recently and has been successfully applied to other machine learning applications (J.C. Principe et al., 2000). An improved version of the k-change algorithm is used in optimization because of the stepwise nature of the cost function and existence of local minima. Even when applied to nonlinearly separable data, the new algorithm performs well, and was able to find nonlinear boundaries between clusters. The algorithm is also applied to the segmentation of magnetic resonance imaging data (MRI) with very promising results.},
  keywords = {Clustering algorithms,Costs,Entropy,Estimation theory,Information theory,Machine learning algorithms,Magnetic resonance imaging,Partitioning algorithms,Pattern recognition,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/23H7QR3N/Gokcay and Principe - 2002 - Information theoretic clustering.pdf;/Users/kshitijgoel/Zotero/storage/33RFYEW6/982897.html}
}

@inproceedings{golla_realtime_2015,
  title = {Real-Time Point Cloud Compression},
  booktitle = {2015 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Golla, Tim and Klein, Reinhard},
  year = {2015},
  month = sep,
  pages = {5087--5092},
  publisher = {IEEE},
  address = {Hamburg, Germany},
  doi = {10.1109/IROS.2015.7354093},
  url = {http://ieeexplore.ieee.org/document/7354093/},
  urldate = {2024-04-18},
  abstract = {With today's advanced 3D scanner technology, huge amounts of point cloud data can be generated in short amounts of time. Data compression is thus necessary for storage and especially for transmission, e.g., via wireless networks. While previous approaches delivered good compression ratios and interesting theoretical insights, they are either computationally expensive or do not support incrementally acquired data and locally decompressing the data, two requirements we found necessary in many applications. We present a compression approach that is efficient in storage requirements as well as in computational cost, as it can compress and decompress point cloud data in real-time. Furthermore, it is capable of compressing incrementally acquired data, local decompression and of decompressing a subsampled representation of the original data. Our method is based on local 2D parameterizations of surface point cloud data, for which we describe an efficient approach. We suggest the usage of standard image compression techniques for the compression of local details. While exhibiting state-of-the-art compression ratios, our approach remains easy to implement. In our evaluation, we compare our approach to previous ones and discuss the choice of parameters. Due to our algorithm's efficiency, we consider it as a reference concerning speed and compression rates.},
  isbn = {978-1-4799-9994-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/P92IFI85/Golla and Klein - 2015 - Real-time point cloud compression.pdf}
}

@book{goodfellow_deep_2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {MIT Press},
  url = {http://www.deeplearningbook.org}
}

@inproceedings{gordon_applying_2003,
  title = {Applying the Information Bottleneck Principle to Unsupervised Clustering of Discrete and Continuous Image Representations},
  booktitle = {Proceedings {{Ninth IEEE International Conference}} on {{Computer Vision}}},
  author = {{Gordon} and {Greenspan} and {Goldberger}},
  year = {2003},
  month = oct,
  pages = {370-377 vol.1},
  doi = {10.1109/ICCV.2003.1238368},
  abstract = {We present a method for unsupervised clustering of image databases. The method is based on a recently introduced information-theoretic principle, the information bottleneck (IB) principle. Image archives are clustered such that the mutual information between the clusters and the image content is maximally preserved. The IB principle is applied to both discrete and continuous image representations, using discrete image histograms and probabilistic continuous image modeling based on mixture of Gaussian densities, respectively. Experimental results demonstrate the performance of the proposed method for image clustering on a large image database. Several clustering algorithms derived from the IB principle are explored and compared.},
  keywords = {Clustering algorithms,Clustering methods,Histograms,Image databases,Image representation,Image retrieval,Jacobian matrices,Mutual information,Pixel,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/38WAZRQJ/Gordon et al. - 2003 - Applying the information bottleneck principle to u.pdf;/Users/kshitijgoel/Zotero/storage/LMSYTZ3X/getPDF.html}
}

@inproceedings{goretkin_look_2020,
  title = {Look {{Before You Sweep}}: {{Visibility-Aware Motion Planning}}},
  shorttitle = {Look {{Before You Sweep}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIII}}},
  author = {Goretkin, Gustavo and Kaelbling, Leslie Pack and {Lozano-P{\'e}rez}, Tom{\'a}s},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {373--388},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-44051-0_22},
  abstract = {This paper addresses the problem of planning for a robot with a directional obstacle-detection sensor that must move through a cluttered environment. The planning objective is to remain safe by finding a path for the complete robot, including sensor, that guarantees that the robot will not move into any part of the workspace before it has been seen by the sensor. Although a great deal of work has addressed a version of this problem in which the ``field of view'' of the sensor is a sphere around the robot, there is very little work addressing robots with a narrow or occluded field of view. We give a formal definition of the problem, several solution methods with different computational trade-offs, and experimental results in illustrative domains.},
  isbn = {978-3-030-44051-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LPV565IT/Goretkin et al. - 2020 - Look Before You Sweep Visibility-Aware Motion Pla.pdf}
}

@article{gottipati_deep_2019,
  title = {Deep {{Active Localization}}},
  author = {Gottipati, Sai Krishna and Seo, Keehong and Bhatt, Dhaivat and Mai, Vincent and Murthy, Krishna and Paull, Liam},
  year = {2019},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {4},
  pages = {4394--4401},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2932575},
  url = {https://ieeexplore.ieee.org/document/8784238},
  urldate = {2023-10-26},
  abstract = {Active localization consists of generating robot actions that allow it to maximally disambiguate its pose within a reference map. Traditional approaches use an information-theoretic criterion for action selection and hand-crafted perceptual models. In this work we propose an end-to-end differentiable method for learning to take informative actions that is trainable entirely in simulation and then transferable to real robot hardware with zero refinement. The system is composed of two learned modules: a convolutional neural network for perception, and a deep reinforcement learned planning module. We leverage a multi-scale approach in the perceptual model since the accuracy needed to take actions using reinforcement learning is much less than the accuracy needed for robot control. We demonstrate that the resulting system outperforms traditional approach for either perception or planning. We also demonstrate our approach's robustness to different map configurations and other nuisance parameters through the use of domain randomization in training. The code has been released: https://github.com/montrealrobotics/dal and is compatible with the OpenAI gym framework, as well as the Gazebo simulator.},
  file = {/Users/kshitijgoel/Zotero/storage/GW2IWG7T/Gottipati et al. - 2019 - Deep Active Localization.pdf}
}

@misc{govindarajan_radiant_2025,
  title = {Radiant {{Foam}}: {{Real-Time Differentiable Ray Tracing}}},
  shorttitle = {Radiant {{Foam}}},
  author = {Govindarajan, Shrisudhan and Rebain, Daniel and Yi, Kwang Moo and Tagliasacchi, Andrea},
  year = {2025},
  month = feb,
  number = {arXiv:2502.01157},
  eprint = {2502.01157},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.01157},
  url = {http://arxiv.org/abs/2502.01157},
  urldate = {2025-02-04},
  abstract = {Research on differentiable scene representations is consistently moving towards more efficient, real-time models. Recently, this has led to the popularization of splatting methods, which eschew the traditional ray-based rendering of radiance fields in favor of rasterization. This has yielded a significant improvement in rendering speeds due to the efficiency of rasterization algorithms and hardware, but has come at a cost: the approximations that make rasterization efficient also make implementation of light transport phenomena like reflection and refraction much more difficult. We propose a novel scene representation which avoids these approximations, but keeps the efficiency and reconstruction quality of splatting by leveraging a decades-old efficient volumetric mesh ray tracing algorithm which has been largely overlooked in recent computer vision research. The resulting model, which we name Radiant Foam, achieves rendering speed and quality comparable to Gaussian Splatting, without the constraints of rasterization. Unlike ray traced Gaussian models that use hardware ray tracing acceleration, our method requires no special hardware or APIs beyond the standard features of a programmable GPU.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/TUDND3CT/Govindarajan et al. - 2025 - Radiant Foam Real-Time Differentiable Ray Tracing.pdf;/Users/kshitijgoel/Zotero/storage/T6DWISQN/2502.html}
}

@book{graf_foundations_2000,
  title = {Foundations of {{Quantization}} for {{Probability Distributions}}},
  author = {Graf, Siegfried and Luschgy, Harald},
  year = {2000},
  series = {Lecture {{Notes}} in {{Mathematics}}},
  volume = {1730},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/BFb0103945},
  url = {http://link.springer.com/10.1007/BFb0103945},
  urldate = {2024-07-17},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-540-67394-1 978-3-540-45577-6},
  keywords = {Cluster analysis,data compression,image processing,information,information theory,Measure,operations research,Pattern Recognition,Probability distribution,Probability theory,sets},
  file = {/Users/kshitijgoel/Zotero/storage/S27LZBRT/Graf and Luschgy - 2000 - Foundations of Quantization for Probability Distributions.pdf}
}

@article{greggio_efficient_2014,
  title = {Efficient Greedy Estimation of Mixture Models through a Binary Tree Search},
  author = {Greggio, Nicola and Bernardino, Alexandre and Dario, Paolo and {Santos-Victor}, Jos{\'e}},
  year = {2014},
  month = oct,
  journal = {Robotics and Autonomous Systems},
  volume = {62},
  number = {10},
  pages = {1440--1452},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2014.05.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0921889014001110},
  urldate = {2023-01-05},
  abstract = {Unsupervised data clustering can be addressed by the estimation of mixture models, where the mixture components are associated to clusters in data space. In this paper we present a novel unsupervised classification algorithm based on the simultaneous estimation of the mixture's parameters and the number of components (complexity). Its distinguishing aspect is the way the data space is searched. Our algorithm starts from a single component covering all the input space and iteratively splits components according to breadth first search on a binary tree structure that provides an efficient exploration of the possible solutions. The proposed scheme demonstrates important computational savings with respect to other state-of-the-art algorithms, making it particularly suited to scenarios where the performance time is an issue, such as in computer and robot vision applications. The initialization procedure is unique, allowing a deterministic evolution of the algorithm, while the parameter estimation is performed with a modification of the Expectation Maximization algorithm. To compare models with different complexity we use the Minimum Message Length information criteria that implement the trade-off between the number of components and data fit log-likelihood. We validate our new approach with experiments on synthetic data, and we test and compare to related approaches its computational efficiency in data-intensive image segmentation applications.},
  langid = {english},
  keywords = {Expectation Maximization,Image processing,Machine vision,Robotics,Unsupervised clustering},
  file = {/Users/kshitijgoel/Zotero/storage/M2WZL899/Greggio et al. - 2014 - Efficient greedy estimation of mixture models thro.pdf;/Users/kshitijgoel/Zotero/storage/82HVY35D/S0921889014001110.html}
}

@article{greggio_fast_2012,
  title = {Fast Estimation of {{Gaussian}} Mixture Models for Image Segmentation},
  author = {Greggio, Nicola and Bernardino, Alexandre and Laschi, Cecilia and Dario, Paolo and {Santos-Victor}, Jos{\'e}},
  year = {2012},
  month = jul,
  journal = {Machine Vision and Applications},
  volume = {23},
  number = {4},
  pages = {773--789},
  issn = {1432-1769},
  doi = {10.1007/s00138-011-0320-5},
  url = {https://doi.org/10.1007/s00138-011-0320-5},
  urldate = {2023-01-05},
  abstract = {The expectation maximization algorithm has been classically used to find the maximum likelihood estimates of parameters in probabilistic models with unobserved data, for instance, mixture models. A key issue in such problems is the choice of the model complexity. The higher the number of components in the mixture, the higher will be the data likelihood, but also the higher will be the computational burden and data overfitting. In this work, we propose a clustering method based on the expectation maximization algorithm that adapts online the number of components of a finite Gaussian mixture model from multivariate data or method estimates the number of components and their means and covariances sequentially, without requiring any careful initialization. Our methodology starts from a single mixture component covering the whole data set and sequentially splits it incrementally during expectation maximization steps. The coarse to fine nature of the algorithm reduce the overall number of computations to achieve a solution, which makes the method particularly suited to image segmentation applications whenever computational time is an issue. We show the effectiveness of the method in a series of experiments and compare it with a state-of-the-art alternative technique both with synthetic data and real images, including experiments with images acquired from the iCub humanoid robot.},
  langid = {english},
  keywords = {Clustering,Expectation maximization,Image processing,Machine learning,Self-adapting Gaussians mixtures,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/T29Y3I4C/Greggio et al. - 2012 - Fast estimation of Gaussian mixture models for ima.pdf}
}

@article{greggio_unsupervised_2024,
  title = {Unsupervised Incremental Estimation of {{Gaussian}} Mixture Models with {{1D}} Split Moves},
  author = {Greggio, Nicola and Bernardino, Alexandre},
  year = {2024},
  month = feb,
  journal = {Pattern Recognition},
  pages = {110306},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2024.110306},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320324000578},
  urldate = {2024-02-11},
  abstract = {In this paper, we propose a new type of split rule for incremental estimation of Gaussian Mixture Models with model selection. Split-based methods typically start with a mixture composed of a single component representing all data, and successively split and optimize components for a given model selection criterion. These algorithms are typically faster than alternatives, but depend critically on the component splitting method, since a good split rule promotes a faster convergence of the mixture optimization phase. We propose a new efficient and robust split rule that projects mixture components onto a 1D subspace and fits a two-component model to the projected data with the Expectation Maximization algorithm. The proposed approach is fast and robust to parameter tuning, being the ideal choice for applications that favor speed while still maintaining an acceptable accuracy. We illustrate the validity of the method through a series of experiments on synthetic and real datasets comparing the proposed method to alternatives of the state-of-the-art in terms of efficiency, accuracy, and sensitivity to parameter tuning.},
  keywords = {Gaussian mixture models,Model selection,Split and merge methods,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/47LG94RW/Greggio and Bernardino - 2024 - Unsupervised incremental estimation of Gaussian mi.pdf}
}

@article{grillenzoni_detection_2014,
  title = {Detection of Tectonic Faults by Spatial Clustering of Earthquake Hypocenters},
  author = {Grillenzoni, Carlo},
  year = {2014},
  month = feb,
  journal = {Spatial Statistics},
  volume = {7},
  pages = {62--78},
  issn = {2211-6753},
  doi = {10.1016/j.spasta.2013.11.003},
  url = {https://www.sciencedirect.com/science/article/pii/S2211675313000687},
  urldate = {2024-04-29},
  abstract = {Identification of the structure of tectonic faults from seismic data is mainly performed with clustering and principal curves techniques. In this paper we follow an approach based on the detection of the ridges of kernel densities estimated on earthquake epicenters. We use an iterative method based on the mean-shift algorithm for mode seeking, in which each step is made orthogonal to the principal direction of the local Hessian matrix. We carry out an extensive application to the historical data of San Francisco Bay area, and we compare the performance of similar methods with simulation experiments.},
  keywords = {Density ridges,Kernel smoothing,Local Hessian,Mean shift,Point data,Principal curves},
  file = {/Users/kshitijgoel/Zotero/storage/9FW94L6I/S2211675313000687.html}
}

@article{grillenzoni_local_2019,
  title = {Local Curve and Surface Detection in Spatial Data Using {{Gaussian}} Mixtures},
  author = {Grillenzoni, Carlo},
  year = {2019},
  month = dec,
  journal = {GEM - International Journal on Geomathematics},
  volume = {10},
  number = {1},
  pages = {19},
  issn = {1869-2672, 1869-2680},
  doi = {10.1007/s13137-019-0131-9},
  url = {http://link.springer.com/10.1007/s13137-019-0131-9},
  urldate = {2024-04-29},
  abstract = {Discovering the intrinsic surfaces in noisy spatial data is widely used in object detection and recognition in geoscience. Typical examples are identification of tectonic faults from seismic catalogs, volume smoothing from laser reliefs and tracking the path of landslides from GPS data. This paper aims to detect curves and surfaces in noisy point clouds represented by Gaussian mixture models (GMM). The number of components of the model is selected with information criteria and the parameters are estimated with likelihood and clustering methods. By using the concept of surface ridges of differential geometry, local curves and surfaces can be identified with the major axes of the GMM system. Next, by applying the mean shift algorithm and projection matrices of the local Hessian, an efficient estimator can be derived. Finally, a sliced 2D approach for 3D point clouds is applied to simulated and seismic data (Data and Matlab software are provided in the supplementary material).},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CK8GGAA4/Grillenzoni - 2019 - Local curve and surface detection in spatial data .pdf}
}

@book{grohs_mathematical_2022,
  title = {Mathematical {{Aspects}} of {{Deep Learning}}},
  editor = {Grohs, Philipp and Kutyniok, Gitta},
  year = {2022},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/9781009025096},
  url = {https://www.cambridge.org/core/books/mathematical-aspects-of-deep-learning/8D9B41D1E9BB8CA515E93412EECC2A7E},
  urldate = {2024-06-25},
  abstract = {In recent years the development of new classification and regression algorithms based on deep learning has led to a revolution in the fields of artificial intelligence, machine learning, and data analysis. The development of a theoretical foundation to guarantee the success of these algorithms constitutes one of the most active and exciting research topics in applied mathematics. This book presents the current mathematical understanding of deep learning methods from the point of view of the leading experts in the field. It serves both as a starting point for researchers and graduate students in computer science, mathematics, and statistics trying to get into the field and as an invaluable reference for future research.},
  isbn = {978-1-316-51678-2},
  file = {/Users/kshitijgoel/Zotero/storage/F8KXZMAQ/Grohs and Kutyniok - 2022 - Mathematical Aspects of Deep Learning.pdf;/Users/kshitijgoel/Zotero/storage/775K2Q78/8D9B41D1E9BB8CA515E93412EECC2A7E.html}
}

@book{grotschel_geometric_1993,
  title = {Geometric {{Algorithms}} and {{Combinatorial Optimization}}},
  author = {Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  year = {1993},
  series = {Algorithms and {{Combinatorics}}},
  volume = {2},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-78240-4},
  url = {http://link.springer.com/10.1007/978-3-642-78240-4},
  urldate = {2024-01-24},
  isbn = {978-3-642-78242-8 978-3-642-78240-4},
  keywords = {algorithms,Basis Reduction in Lattices,Basisreduktion bei Gittern,combinatorial optimization,combinatorics,Convexity,Ellipsoid Method,Ellipsoidmethode,Kombinatorische Optimierung,Konvexitat,Lattice,Linear Programming,Lineares Programmieren,operations resear},
  file = {/Users/kshitijgoel/Zotero/storage/WIDMUBGC/Grötschel et al. - 1993 - Geometric Algorithms and Combinatorial Optimizatio.pdf}
}

@misc{gu_mrcographs_2024,
  title = {{{MR-COGraphs}}: {{Communication-efficient Multi-Robot Open-vocabulary Mapping System}} via {{3D Scene Graphs}}},
  shorttitle = {{{MR-COGraphs}}},
  author = {Gu, Qiuyi and Ye, Zhaocheng and Yu, Jincheng and Tang, Jiahao and Yi, Tinghao and Dong, Yuhan and Wang, Jian and Cui, Jinqiang and Chen, Xinlei and Wang, Yu},
  year = {2024},
  month = dec,
  number = {arXiv:2412.18381},
  eprint = {2412.18381},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.18381},
  url = {http://arxiv.org/abs/2412.18381},
  urldate = {2024-12-27},
  abstract = {Collaborative perception in unknown environments is crucial for multi-robot systems. With the emergence of foundation models, robots can now not only perceive geometric information but also achieve open-vocabulary scene understanding. However, existing map representations that support open-vocabulary queries often involve large data volumes, which becomes a bottleneck for multi-robot transmission in communication-limited environments. To address this challenge, we develop a method to construct a graph-structured 3D representation called COGraph, where nodes represent objects with semantic features and edges capture their spatial relationships. Before transmission, a data-driven feature encoder is applied to compress the feature dimensions of the COGraph. Upon receiving COGraphs from other robots, the semantic features of each node are recovered using a decoder. We also propose a feature-based approach for place recognition and translation estimation, enabling the merging of local COGraphs into a unified global map. We validate our framework using simulation environments built on Isaac Sim and real-world datasets. The results demonstrate that, compared to transmitting semantic point clouds and 512-dimensional COGraphs, our framework can reduce the data volume by two orders of magnitude, without compromising mapping and query performance. For more details, please visit our website at https://github.com/efc-robot/MR-COGraphs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/LNKGWAU7/Gu et al. - 2024 - MR-COGraphs Communication-efficient Multi-Robot Open-vocabulary Mapping System via 3D Scene Graphs.pdf;/Users/kshitijgoel/Zotero/storage/NWK3YTV9/2412.html}
}

@article{guigui_introduction_2023,
  title = {Introduction to {{Riemannian Geometry}} and {{Geometric Statistics}}: {{From Basic Theory}} to {{Implementation}} with {{Geomstats}}},
  shorttitle = {Introduction to {{Riemannian Geometry}} and {{Geometric Statistics}}},
  author = {Guigui, Nicolas and Miolane, Nina and Pennec, Xavier},
  year = {2023},
  month = feb,
  journal = {Foundations and Trends{\textregistered} in Machine Learning},
  volume = {16},
  number = {3},
  pages = {329--493},
  publisher = {Now Publishers, Inc.},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000098},
  url = {https://www.nowpublishers.com/article/Details/MAL-098},
  urldate = {2024-07-13},
  abstract = {Introduction to Riemannian Geometry and Geometric Statistics: From Basic Theory to Implementation with Geomstats},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LABRFIB2/Guigui et al. - 2023 - Introduction to Riemannian Geometry and Geometric Statistics From Basic Theory to Implementation wi.pdf}
}

@inproceedings{guizilini_largescale_2016,
  title = {Large-Scale {{3D}} Scene Reconstruction with {{Hilbert Maps}}},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Guizilini, Vitor and Ramos, Fabio},
  year = {2016},
  month = oct,
  pages = {3247--3254},
  issn = {2153-0866},
  doi = {10.1109/IROS.2016.7759501},
  abstract = {3D scene reconstruction involves the volumetric modeling of space, and it is a fundamental step in a wide variety of robotic applications, including grasping, obstacle avoidance, path planning, mapping and many others. Nowadays, sensors are able to quickly collect vast amounts of data, and the challenge has become one of storing and processing all this information in a timely manner, especially if real-time performance is required. Recently, a novel technique for the stochastic learning of discriminative models through continuous occupancy maps was proposed: Hilbert Maps [18], that is able to represent the input space at an arbitrary resolution while capturing statistical relationships between measurements. The original framework was proposed for 2D environments, and here we extend it to higher-dimensional spaces, addressing some of the challenges brought by the curse of dimensionality. Namely, we propose a method for the automatic selection of feature coordinate locations, and introduce the concept of localized automatic relevance determination (LARD) to the Hilbert Maps framework, in which different dimensions in the projected Hilbert space operate within independent length-scale values. The proposed technique was tested against other state-of-the-art 3D scene reconstruction tools in three different datasets: a simulated indoors environment, RIEGL laser scans and dense LSD-SLAM pointclouds. The results testify to the proposed framework's ability to model complex structures and correctly interpolate over unobserved areas of the input space while achieving real-time training and querying performances.},
  keywords = {Adaptation models,Clustering algorithms,Hilbert space,Stochastic processes,Three-dimensional displays,Training,Two dimensional displays},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/to_read_for_sure/Large-scale_3D_scene_reconstruction_with_Hilbert_Maps.pdf}
}

@misc{guizilini_zeroshot_2023,
  title = {Towards {{Zero-Shot Scale-Aware Monocular Depth Estimation}}},
  author = {Guizilini, Vitor and Vasiljevic, Igor and Chen, Dian and Ambrus, Rares and Gaidon, Adrien},
  year = {2023},
  month = jun,
  number = {arXiv:2306.17253},
  eprint = {2306.17253},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.17253},
  url = {http://arxiv.org/abs/2306.17253},
  urldate = {2024-12-17},
  abstract = {Monocular depth estimation is scale-ambiguous, and thus requires scale supervision to produce metric predictions. Even so, the resulting models will be geometry-specific, with learned scales that cannot be directly transferred across domains. Because of that, recent works focus instead on relative depth, eschewing scale in favor of improved up-to-scale zero-shot transfer. In this work we introduce ZeroDepth, a novel monocular depth estimation framework capable of predicting metric scale for arbitrary test images from different domains and camera parameters. This is achieved by (i) the use of input-level geometric embeddings that enable the network to learn a scale prior over objects; and (ii) decoupling the encoder and decoder stages, via a variational latent representation that is conditioned on single frame information. We evaluated ZeroDepth targeting both outdoor (KITTI, DDAD, nuScenes) and indoor (NYUv2) benchmarks, and achieved a new state-of-the-art in both settings using the same pre-trained model, outperforming methods that train on in-domain data and require test-time scaling to produce metric estimates.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/GZEPU8E5/Guizilini et al. - 2023 - Towards Zero-Shot Scale-Aware Monocular Depth Estimation.pdf;/Users/kshitijgoel/Zotero/storage/8SG58MAK/2306.html}
}

@book{gundlach_designing_2014,
  title = {Designing {{Unmanned Aircraft Systems}}: {{A Comprehensive Approach}}, {{Second Edition}}},
  shorttitle = {Designing {{Unmanned Aircraft Systems}}},
  author = {Gundlach, Jay},
  year = {2014},
  month = jul,
  publisher = {{American Institute of Aeronautics and Astronautics, Inc.}},
  address = {Washington, DC},
  doi = {10.2514/4.102615},
  url = {https://arc.aiaa.org/doi/book/10.2514/4.102615},
  urldate = {2023-03-16},
  isbn = {978-1-62410-261-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3M6CCLZA/Gundlach - 2014 - Designing Unmanned Aircraft Systems A Comprehensi.pdf}
}

@inproceedings{guo_autonomous_2021,
  title = {Autonomous {{Navigation}} in {{Dynamic Environments}} with {{Multi-Modal Perception Uncertainties}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Guo, Hongliang and Huang, Zefan and Ho, Qiheng and Ang, Marcelo and Rus, Daniela},
  year = {2021},
  month = may,
  pages = {9255--9261},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561965},
  abstract = {This paper addresses the safe path planning problem for autonomous mobility with multi-modal perception uncertainties. Specifically, we assume that different sensor inputs lead to different Gaussian process regulated perception uncertainties (named as multi-modal perception uncertainties). We implement a Bayesian inference algorithm, which merges the multi-modal GP-regulated uncertainties into a unified one and translates the unified uncertainty into a dynamic risk map. With the safe path planner taking the risk map as input, we are able to plan a safe path for the autonomous vehicle to follow. Experimental results on an autonomous golf cart testbed validate the applicability and efficiency of the proposed algorithm.},
  keywords = {autonomous mobility,Conferences,Gaussian processes,Heuristic algorithms,Inference algorithms,multi-modal perception uncertainties,Path planning,Robot sensing systems,safe path planning,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/SW7PFDAD/Guo et al. - 2021 - Autonomous Navigation in Dynamic Environments with.pdf;/Users/kshitijgoel/Zotero/storage/R5FN9PQJ/9561965.html}
}

@misc{guo_gaussian_2023,
  title = {Gaussian {{Mixture Solvers}} for {{Diffusion Models}}},
  author = {Guo, Hanzhong and Lu, Cheng and Bao, Fan and Pang, Tianyu and Yan, Shuicheng and Du, Chao and Li, Chongxuan},
  year = {2023},
  month = nov,
  number = {arXiv:2311.00941},
  eprint = {2311.00941},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2311.00941},
  urldate = {2024-11-18},
  abstract = {Recently, diffusion models have achieved great success in generative tasks. Sampling from diffusion models is equivalent to solving the reverse diffusion stochastic differential equations (SDEs) or the corresponding probability flow ordinary differential equations (ODEs). In comparison, SDE-based solvers can generate samples of higher quality and are suited for image translation tasks like stroke-based synthesis. During inference, however, existing SDE-based solvers are severely constrained by the efficiency-effectiveness dilemma. Our investigation suggests that this is because the Gaussian assumption in the reverse transition kernel is frequently violated (even in the case of simple mixture data) given a limited number of discretization steps. To overcome this limitation, we introduce a novel class of SDE-based solvers called {\textbackslash}emph\{Gaussian Mixture Solvers (GMS)\} for diffusion models. Our solver estimates the first three-order moments and optimizes the parameters of a Gaussian mixture transition kernel using generalized methods of moments in each step during sampling. Empirically, our solver outperforms numerous SDE-based solvers in terms of sample quality in image generation and stroke-based synthesis in various diffusion models, which validates the motivation and effectiveness of GMS. Our code is available at https://github.com/Guohanzhong/GMS.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/WWA49IEN/Guo et al. - 2023 - Gaussian Mixture Solvers for Diffusion Models.pdf;/Users/kshitijgoel/Zotero/storage/HPJ3RVTI/2311.html}
}

@misc{guo_marginalizing_2025,
  title = {Marginalizing and {{Conditioning Gaussians}} onto {{Linear Approximations}} of {{Smooth Manifolds}} with {{Applications}} in {{Robotics}}},
  author = {Guo, Zi Cong and Forbes, James R. and Barfoot, Timothy D.},
  year = {2025},
  month = may,
  number = {arXiv:2409.09871},
  eprint = {2409.09871},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.09871},
  url = {http://arxiv.org/abs/2409.09871},
  urldate = {2025-06-02},
  abstract = {We present closed-form expressions for marginalizing and conditioning Gaussians onto linear manifolds, and demonstrate how to apply these expressions to smooth nonlinear manifolds through linearization. Although marginalization and conditioning onto axis-aligned manifolds are well-established procedures, doing so onto non-axis-aligned manifolds is not as well understood. We demonstrate the utility of our expressions through three applications: 1) approximation of the projected normal distribution, where the quality of our linearized approximation increases as problem nonlinearity decreases; 2) covariance extraction in Koopman SLAM, where our covariances are shown to be consistent on a real-world dataset; and 3) covariance extraction in constrained GTSAM, where our covariances are shown to be consistent in simulation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/G7LEEY8R/Guo et al. - 2025 - Marginalizing and Conditioning Gaussians onto Linear Approximations of Smooth Manifolds with Applica.pdf;/Users/kshitijgoel/Zotero/storage/K8J88RTH/2409.html}
}

@article{guo_resourceaware_2018,
  title = {Resource-{{Aware Large-Scale Cooperative Three-Dimensional Mapping Using Multiple Mobile Devices}}},
  author = {Guo, Chao X. and Sartipi, Kourosh and DuToit, Ryan C. and Georgiou, Georgios A. and Li, Ruipeng and O'Leary, John and Nerurkar, Esha D. and Hesch, Joel A. and Roumeliotis, Stergios I.},
  year = {2018},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {34},
  number = {5},
  pages = {1349--1369},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2858229},
  abstract = {In this paper, we address the problem of cooperative mapping (CM) using datasets collected by multiple users at different times, when the transformation between the users' starting poses is unknown. Specifically, we formulate CM as a constrained optimization problem, in which each user's independently estimated trajectory and map are merged together by imposing geometric constraints between commonly observed point and line features. Additionally, we provide an algorithm for efficiently solving the CM problem, by taking advantage of its structure. The proposed solution is proven to be batch-least-squares (BLS) optimal over all users' datasets, while it is less memory demanding and lends itself to parallel implementations. In particular, our solution is shown to be faster than the standard BLS solution, when the overlap between the users' data is small. Furthermore, our algorithm is resource-aware as it is able to consistently trade accuracy for lower processing cost, by retaining only an informative subset of the common-feature constraints. Experimental results based on visual and inertial measurements collected from multiple users within large buildings are used to assess the performance of the proposed CM algorithm.},
  keywords = {Buildings,Cameras,constrained optimization problem,Cooperative mapping (CM),Mobile handsets,resource-aware system,Robots,Servers,three-dimensional (3-D) mapping,Trajectory,visual and inertial sensor fusion,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/G34DKQ36/Guo et al. - 2018 - Resource-Aware Large-Scale Cooperative Three-Dimen.pdf;/Users/kshitijgoel/Zotero/storage/TBGP9AKL/8430569.html}
}

@article{gupta_ndt6d_2023,
  title = {{{NDT-6D}} for Color Registration in Agri-Robotic Applications},
  author = {Gupta, Himanshu and Lilienthal, Achim J. and Andreasson, Henrik and Kurtser, Polina},
  year = {2023},
  journal = {Journal of Field Robotics},
  volume = {40},
  number = {6},
  pages = {1603--1619},
  issn = {1556-4967},
  doi = {10.1002/rob.22194},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22194},
  urldate = {2024-05-24},
  abstract = {Registration of point cloud data containing both depth and color information is critical for a variety of applications, including in-field robotic plant manipulation, crop growth modeling, and autonomous navigation. However, current state-of-the-art registration methods often fail in challenging agricultural field conditions due to factors such as occlusions, plant density, and variable illumination. To address these issues, we propose the NDT-6D registration method, which is a color-based variation of the Normal Distribution Transform (NDT) registration approach for point clouds. Our method computes correspondences between pointclouds using both geometric and color information and minimizes the distance between these correspondences using only the three-dimensional (3D) geometric dimensions. We evaluate the method using the GRAPES3D data set collected with a commercial-grade RGB-D sensor mounted on a mobile platform in a vineyard. Results show that registration methods that only rely on depth information fail to provide quality registration for the tested data set. The proposed color-based variation outperforms state-of-the-art methods with a root mean square error (RMSE) of 1.1--1.6 cm for NDT-6D compared with 1.1--2.3 cm for other color-information-based methods and 1.2--13.7 cm for noncolor-information-based methods. The proposed method is shown to be robust against noises using the TUM RGBD data set by artificially adding noise present in an outdoor scenario. The relative pose error (RPE) increased {\textbackslash}unicodex0007E{\textbackslash}14\% for our method compared to an increase of {\textbackslash}unicodex0007E{\textbackslash}75\% for the best-performing registration method. The obtained average accuracy suggests that the NDT-6D registration methods can be used for in-field precision agriculture applications, for example, crop detection, size-based maturity estimation, and growth modeling.},
  copyright = {{\copyright} 2023 The Authors. Journal of Field Robotics published by Wiley Periodicals LLC.},
  langid = {english},
  keywords = {agricultural robotics,color pointcloud,in-field sensing,machine perception,RGB-D registration,stereo IR,vineyard},
  file = {/Users/kshitijgoel/Zotero/storage/QNBSADJR/Gupta et al. - 2023 - NDT-6D for color registration in agri-robotic applications.pdf;/Users/kshitijgoel/Zotero/storage/XAID2XYQ/rob.html}
}

@article{gutierrez_bayesian_2019,
  title = {A {{Bayesian Approach}} to {{Statistical Shape Analysis}} via the {{Projected Normal Distribution}}},
  author = {Guti{\'e}rrez, Luis and {Guti{\'e}rrez-Pe{\~n}a}, Eduardo and Mena, Rams{\'e}s H.},
  year = {2019},
  month = jun,
  journal = {Bayesian Analysis},
  volume = {14},
  number = {2},
  pages = {427--447},
  publisher = {International Society for Bayesian Analysis},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/18-BA1113},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-14/issue-2/A-Bayesian-Approach-to-Statistical-Shape-Analysis-via-the-Projected/10.1214/18-BA1113.full},
  urldate = {2024-07-26},
  abstract = {This work presents a Bayesian predictive approach to statistical shape analysis. A modeling strategy that starts with a Gaussian distribution on the configuration space, and then removes the effects of location, rotation and scale, is studied. This boils down to an application of the projected normal distribution to model the configurations in the shape space, which together with certain identifiability constraints, facilitates parameter interpretation. Having better control over the parameters allows us to generalize the model to a regression setting where the effect of predictors on shapes can be considered. The methodology is illustrated and tested using both simulated scenarios and a real data set concerning eight anatomical landmarks on a sagittal plane of the corpus callosum in patients with autism and in a group of controls.},
  keywords = {62F15,62H35,62J05,Bookstein coordinates,Identifiability,medical image,shape regression},
  file = {/Users/kshitijgoel/Zotero/storage/QWJ8GKF4/Gutiérrez et al. - 2019 - A Bayesian Approach to Statistical Shape Analysis via the Projected Normal Distribution.pdf}
}

@phdthesis{gutierrez-barragan_compressive_2022,
  title = {Compressive {{Representations}} for {{Single-Photon 3D Cameras}}},
  author = {{Gutierrez-Barragan}, Felipe},
  year = {2022},
  address = {United States -- Wisconsin},
  url = {https://www.proquest.com/docview/2735859546/abstract/6F09217E3D4D4D93PQ/1},
  urldate = {2025-01-21},
  abstract = {This dissertation proposes a compression framework to deal with the extreme data rates that are output by high-resolution single-photon cameras (SPCs) based on single-photon avalanche diodes (SPADs). SPADs are an emerging pixel technology for time-of-flight (ToF) 3D cameras that can capture the time-of-arrival of individual photons at picosecond resolution. Moreover, SPAD-based SPCs are compatible with the complementary metal-oxide semiconductor (CMOS) photolithography process which can enable fabrication of kilo-to-mega-pixel resolution SPAD arrays at low costs. Due to these capabilities SPAD-based 3D cameras can enable real-time megapixel 3D imaging with millimeter and even sub-millimeter accuracy. However, as the spatial and time resolution of SPAD cameras increase, their output data rates far exceed the capacity of existing data transfer technologies. The thesis of this dissertation is that the in-sensor memory and output data rates of high-resolution single-photon 3D cameras can be reduced to practical levels without reducing 3D imaging quality, by building compressive representations of photon data in an online fashion where we see each photon (and its timing information) only once. To prove this thesis we begin by introducing an online compression framework for single-photon camera ToF data. The compressed representation of the photon data is built on-the-fly, as each photon is detected, by applying a linear spatiotemporal projection of each photon timestamp (i.e., time-of-arrival). Therefore, instead of storing or transferring large arrays of photon timestamps in-sensor, a compressive representation is stored in-sensor and then transferred off-sensor to the compute module (e.g., FPGA, ISP, embedded computer) for processing. Not only the output data rates are reduced by only transferring the compressed representation, but also the required in-sensor memory is also reduced since we only have to store the compressive representation. The remainder of the dissertation focuses on demonstrating the proposed framework in the context of single-photon 3D imaging. First, we introduce multiple physics-based priors about the temporal dimension of the photon timestamp data. Using this domain knowledge we ``hand-design'' temporal compressive represen- xv tations that are 10-100x smaller than the original photon data representation, and from which 3D information can be computed reliably in a wide range of signal, noise, and illumination scenarios. Next, we show that the proposed compression framework can be integrated with learning-based models based on convolutional neural networks (CNNs). This integration enables the joint end-to-end learning/optimization of the compressive representation and a 3D imaging CNN model. We find that the learned compressive representations can further improve 3D imaging performance over the hand-designed representations while continuing to reduce data rates by 1-2 orders of magnitude. In other words, the proposed compressive representations can reduce the data rates of a megapixel single-photon 3D camera from over 100GB/sec down to a practical 1GB/sec rate which can be managed by current data transfer technologies (e.g., USB 3.2).},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798357544223},
  langid = {english},
  school = {The University of Wisconsin - Madison},
  keywords = {Compressive representations,Computer science,Online compression,Single-photon 3D imaging,Single-photon avalanche diodes,Single-photon cameras,Time-of-flight imaging},
  file = {/Users/kshitijgoel/Zotero/storage/YHY2SA63/Gutierrez-Barragan - 2022 - Compressive Representations for Single-Photon 3D Cameras.pdf}
}

@article{guttman_rtrees_1984,
  title = {R-Trees: A Dynamic Index Structure for Spatial Searching},
  shorttitle = {R-Trees},
  author = {Guttman, Antonin},
  year = {1984},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {14},
  number = {2},
  pages = {47--57},
  issn = {0163-5808},
  doi = {10.1145/971697.602266},
  url = {https://dl.acm.org/doi/10.1145/971697.602266},
  urldate = {2024-02-21},
  abstract = {In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications},
  file = {/Users/kshitijgoel/Zotero/storage/AMRNDUC5/Guttman - 1984 - R-trees a dynamic index structure for spatial sea.pdf}
}

@article{habibian_survey_2025,
  title = {A Survey of Communicating Robot Learning during Human-Robot Interaction},
  author = {Habibian, Soheil and Alvarez Valdivia, Antonio and Blumenschein, Laura H. and Losey, Dylan P.},
  year = {2025},
  month = apr,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {4},
  pages = {665--698},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241281369},
  url = {https://doi.org/10.1177/02783649241281369},
  urldate = {2025-04-16},
  abstract = {For robots to seamlessly interact with humans, we first need to make sure that humans and robots understand one another. Diverse algorithms have been developed to enable robots to learn from humans (i.e., transferring information from humans to robots). In parallel, visual, haptic, and auditory communication interfaces have been designed to convey the robot's internal state to the human (i.e., transferring information from robots to humans). Prior research often separates these two directions of information transfer, and focuses primarily on either learning algorithms or communication interfaces. By contrast, in this survey we take an interdisciplinary approach to identify common themes and emerging trends that close the loop between learning and communication. Specifically, we survey state-of-the-art methods and outcomes for communicating a robot's learning back to the human teacher during human-robot interaction. This discussion connects human-in-the-loop learning methods and explainable robot learning with multimodal feedback systems and measures of human-robot interaction. We find that---when learning and communication are developed together---the resulting closed-loop system can lead to improved human teaching, increased human trust, and human-robot co-adaptation. The paper includes a perspective on several of the interdisciplinary research themes and open questions that could advance how future robots communicate their learning to everyday operators. Finally, we implement a selection of the reviewed methods in a case study where participants kinesthetically teach a robot arm. This case study documents and tests an integrated approach for learning in ways that can be communicated, conveying this learning across multimodal interfaces, and measuring the resulting changes in human and robot behavior.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/WYMUYXGK/Habibian et al. - 2025 - A survey of communicating robot learning during human-robot interaction.pdf}
}

@inproceedings{hahn_heat_2011,
  title = {Heat Mapping for Improved Victim Detection},
  booktitle = {2011 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}}},
  author = {Hahn, Ruwen and Lang, Dagmar and H{\"a}selich, Marcel and Paulus, Dietrich},
  year = {2011},
  month = nov,
  pages = {116--121},
  issn = {2374-3247},
  doi = {10.1109/SSRR.2011.6106769},
  abstract = {Disasters, such as earthquakes or tsunamis, result in destroyed buildings and other dangerous scenarios for human rescuers. Remotely controlled robots are often used to aid humans. Since those robots require steady communication, they are limited to a certain range and might get stuck in case the connection is interrupted. To augment remote controlled robots, autonomous robots are needed. These robots are able to navigate in devastated areas to detect victims while creating a map of the environment at the same time. Victim detection based on thermal sensors is the most widely used approach. In this paper we present a novel approach based on low-cost thermal sensors, using the global heat distribution. Therefore we developed a 2D heat map, which is created by the combination of thermal and laser information during continuous autonomous exploration. The map is build from the history of all sensor readings over time resulting in a heat distribution. The main contribution of this paper is the introduction of a 2D heat map accumulating thermal sensor readings over time for improved victim detection.},
  keywords = {Heating,Lasers,mapping,Measurement by laser beam,Navigation,Robots,Thermal sensors,victim detection,victim verification},
  file = {/Users/kshitijgoel/Zotero/storage/62BPL7KT/Hahn et al. - 2011 - Heat mapping for improved victim detection.pdf;/Users/kshitijgoel/Zotero/storage/BVCZYSK7/6106769.html}
}

@article{haider_what_2022,
  title = {What {{Can We Learn}} from {{Depth Camera Sensor Noise}}?},
  author = {Haider, Azmi and {Hel-Or}, Hagit},
  year = {2022},
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {14},
  pages = {5448},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s22145448},
  url = {https://www.mdpi.com/1424-8220/22/14/5448},
  urldate = {2025-07-06},
  abstract = {Although camera and sensor noise are often disregarded, assumed negligible or dealt with in the context of denoising, in this paper we show that significant information can actually be deduced from camera noise about the captured scene and the objects within it. Specifically, we deal with depth cameras and their noise patterns. We show that from sensor noise alone, the object's depth and location in the scene can be deduced. Sensor noise can indicate the source camera type, and within a camera type the specific device used to acquire the images. Furthermore, we show that noise distribution on surfaces provides information about the light direction within the scene as well as allows to distinguish between real and masked faces. Finally, we show that the size of depth shadows (missing depth data) is a function of the object's distance from the background, its distance from the camera and the object's size. Hence, can be used to authenticate objects location in the scene. This paper provides tools and insights into what can be learned from depth camera sensor noise.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {depth camera,depth sensors,noise},
  file = {/Users/kshitijgoel/Zotero/storage/649DKV3B/Haider and Hel-Or - 2022 - What Can We Learn from Depth Camera Sensor Noise.pdf}
}

@book{haines_ray_2019,
  title = {Ray {{Tracing Gems}}: {{High-Quality}} and {{Real-Time Rendering}} with {{DXR}} and {{Other APIs}}},
  shorttitle = {Ray {{Tracing Gems}}},
  editor = {Haines, Eric and {Akenine-M{\"o}ller}, Tomas},
  year = {2019},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/978-1-4842-4427-2},
  url = {http://link.springer.com/10.1007/978-1-4842-4427-2},
  urldate = {2024-04-22},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0},
  isbn = {978-1-4842-4426-5 978-1-4842-4427-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/RVKJ3MZC/Haines and Akenine-Möller - 2019 - Ray Tracing Gems High-Quality and Real-Time Rende.pdf}
}

@article{hakobyan_wasserstein_2022,
  title = {Wasserstein {{Distributionally Robust Motion Control}} for {{Collision Avoidance Using Conditional Value-at-Risk}}},
  author = {Hakobyan, Astghik and Yang, Insoon},
  year = {2022},
  month = apr,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {2},
  pages = {939--957},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2021.3106827},
  url = {https://ieeexplore.ieee.org/document/9547384/},
  urldate = {2023-10-17},
  abstract = {In this article, a risk-aware motion control scheme is considered for mobile robots to avoid randomly moving obstacles when the true probability distribution of uncertainty is unknown. We propose a novel model-predictive control (MPC) method for limiting the risk of unsafety even when the true distribution of the obstacles' movements deviates, within an ambiguity set, from the empirical distribution obtained using a limited amount of sample data. By choosing the ambiguity set as a statistical ball with its radius measured by the Wasserstein metric, we achieve a probabilistic guarantee of the out-of-sample risk, evaluated using new sample data generated independently of the training data. To resolve the infinite-dimensionality issue inherent in the distributionally robust MPC problem, we reformulate it as a finite-dimensional nonlinear program using modern distributionally robust optimization techniques based on the Kantorovich duality principle. To find a globally optimal solution in the case of affine dynamics and output equations, a spatial branch-and-bound algorithm is designed using McCormick relaxation. The performance of the proposed method is demonstrated and analyzed through simulation studies using nonlinear dynamic and kinematic vehicle models and a linearized quadrotor model. The simulation results indicate that, even when the sample size is small, the proposed method can successfully avoid randomly moving obstacles with a guarantee of out-of-sample risk, while its sample average approximation counterpart fails to do so.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/I6U4SDTC/Hakobyan and Yang - 2022 - Wasserstein Distributionally Robust Motion Control.pdf}
}

@inproceedings{halder_parameterized_2018,
  title = {On the {{Parameterized Computation}} of {{Minimum Volume Outer Ellipsoid}} of {{Minkowski Sum}} of {{Ellipsoids}}},
  booktitle = {2018 {{IEEE Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Halder, Abhishek},
  year = {2018},
  month = dec,
  pages = {4040--4045},
  publisher = {IEEE},
  address = {Miami Beach, FL},
  doi = {10.1109/CDC.2018.8619508},
  url = {https://ieeexplore.ieee.org/document/8619508/},
  urldate = {2024-01-20},
  abstract = {We consider the problem of computing certain parameterized minimum volume outer ellipsoidal (MVOE) approximation of the Minkowski sum of a finite number of ellipsoids. We clarify connections among several parameterizations available in the literature, obtain novel analysis results regarding the conditions of optimality, and based on the same, propose two new algorithms for computing the parameterized MVOE. Numerical results reveal faster runtime for the proposed algorithms than the standard semidefinite programming approach for computing the same.},
  isbn = {978-1-5386-1395-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6C845Q5Q/Halder - 2018 - On the Parameterized Computation of Minimum Volume.pdf}
}

@article{hall_improved_1995,
  title = {Improved {{Variable Window Kernel Estimates}} of {{Probability Densities}}},
  author = {Hall, Peter and Hu, Tien Chung and Marron, J. S.},
  year = {1995},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {23},
  number = {1},
  pages = {1--10},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176324451},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-23/issue-1/Improved-Variable-Window-Kernel-Estimates-of-Probability-Densities/10.1214/aos/1176324451.full},
  urldate = {2024-07-10},
  abstract = {Variable window width kernel density estimators, with the width varying proportionally to the square root of the density, have been thought to have superior asymptotic properties. The rate of convergence has been claimed to be as good as those typical for higher-order kernels, which makes the variable width estimators more attractive because no adjustment is needed to handle the negativity usually entailed by the latter. However, in a recent paper, Terrell and Scott show that these results can fail in important cases. In this paper, we characterize situations where the fast rate is valid, and also give rates for a variety of cases where they are slower. In addition, a modification of the usual variable window width estimator is proposed, which does have the earlier claimed rates of convergence.},
  keywords = {62G05,Adaptive methods,Bandwidth choice,Curve estimation,nonparametric estimation,smoothing},
  file = {/Users/kshitijgoel/Zotero/storage/PNUFCZAY/Hall et al. - 1995 - Improved Variable Window Kernel Estimates of Probability Densities.pdf}
}

@article{hall_kernel_1987,
  title = {Kernel {{Density Estimation}} with {{Spherical Data}}},
  author = {Hall, Peter and Watson, G. S. and Cabrera, Javier},
  year = {1987},
  journal = {Biometrika},
  volume = {74},
  number = {4},
  eprint = {2336469},
  eprinttype = {jstor},
  pages = {751--762},
  publisher = {[Oxford University Press, Biometrika Trust]},
  issn = {0006-3444},
  doi = {10.2307/2336469},
  url = {https://www.jstor.org/stable/2336469},
  urldate = {2024-06-27},
  abstract = {We study two natural classes of kernel density estimators for use with spherical data. Members of both classes have already been used in practice. The classes have an element in common, but for the most part they are disjoint. However, all members of the first class are asymptotically equivalent to one another, and to a single element of the second class. In this sense the second class `contains' the first. It includes some estimators which out-perform all those in the first class, if loss is measured in either squared-error or Kullback-Leibler senses. Explicit formulae are given for bias, variance and loss, and large-sample properties of these quantities are described. Numerical illustrations are presented.},
  file = {/Users/kshitijgoel/Zotero/storage/SVHZ6Y98/Hall et al. - 1987 - Kernel Density Estimation with Spherical Data.pdf}
}

@inproceedings{han_fiesta_2019,
  title = {{{FIESTA}}: {{Fast Incremental Euclidean Distance Fields}} for {{Online Motion Planning}} of {{Aerial Robots}}},
  shorttitle = {{{FIESTA}}},
  booktitle = {2019 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Han, Luxin and Gao, Fei and Zhou, Boyu and Shen, Shaojie},
  year = {2019},
  month = nov,
  pages = {4423--4430},
  issn = {2153-0866},
  doi = {10.1109/IROS40897.2019.8968199},
  url = {https://ieeexplore.ieee.org/abstract/document/8968199},
  urldate = {2024-01-27},
  abstract = {Euclidean Signed Distance Field (ESDF) is useful for online motion planning of aerial robots since it can easily query the distance and gradient information against obstacles. Fast incrementally built ESDF map is the bottleneck for conducting real-time motion planning. In this paper, we investigate this problem and propose a mapping system called FIESTA to build global ESDF map incrementally. By introducing two independent updating queues for inserting and deleting obstacles separately, and using Indexing Data Structures and Doubly Linked Lists for map maintenance, our algorithm updates as few as possible nodes using a BFS framework. Our ESDF map has high computational performance and produces near-optimal results. We show our method outperforms other up-to-date methods in term of performance and accuracy by both theory and experiments. We integrate FIESTA into a completed quadrotor system and validate it by both simulation and onboard experiments. We release our method as open-source software for the community.},
  file = {/Users/kshitijgoel/Zotero/storage/76NCP4G6/Han et al. - 2019 - FIESTA Fast Incremental Euclidean Distance Fields.pdf;/Users/kshitijgoel/Zotero/storage/2PQWL83W/8968199.html}
}

@inproceedings{han_incremental_2004,
  title = {Incremental Density Approximation and Kernel-Based {{Bayesian}} Filtering for Object Tracking},
  booktitle = {Proceedings of the 2004 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}, 2004. {{CVPR}} 2004.},
  author = {Han, Bohyung and Comaniciu, D. and Zhu, Ying and Davis, L.},
  year = {2004},
  month = jun,
  volume = {1},
  pages = {I-I},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2004.1315092},
  url = {https://ieeexplore.ieee.org/document/1315092},
  urldate = {2024-02-21},
  abstract = {Statistical density estimation techniques are used in many computer vision applications such as object tracking, background subtraction, motion estimation and segmentation. The particle filter (condensation) algorithm provides a general framework for estimating the probability density functions (pdf) of general non-linear and non-Gaussian systems. However, since this algorithm is based on a Monte Carlo approach, where the density is represented by a set of random samples, the number of samples is problematic, especially for high dimensional problems. In this paper, we propose an alternative to the classical particle filter in which the underlying pdf is represented with a semi-parametric method based on a mode finding algorithm using mean-shift. A mode propagation technique is designed for this new representation for tracking applications. A quasi-random sampling method in the measurement stage is used to improve performance, and sequential density approximation for the measurements distribution is performed for efficient computation. We apply our algorithm to a high dimensional color-based tracking problem, and demonstrate its performance by showing competitive results with other trackers.},
  keywords = {Application software,Bayesian methods,Computer vision,Density measurement,Filtering,Monte Carlo methods,Motion estimation,Particle filters,Probability density function,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/TLADGENQ/Han et al. - 2004 - Incremental density approximation and kernel-based.pdf}
}

@article{han_sequential_2008,
  title = {Sequential {{Kernel Density Approximation}} and {{Its Application}} to {{Real-Time Visual Tracking}}},
  author = {Han, Bohyung and Comaniciu, D. and {Ying Zhu} and Davis, L.S.},
  year = {2008},
  month = jul,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {30},
  number = {7},
  pages = {1186--1197},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2007.70771},
  url = {http://ieeexplore.ieee.org/document/4359371/},
  urldate = {2024-03-14},
  abstract = {Visual features are commonly modeled with probability density functions in computer vision problems, but current methods such as a mixture of Gaussians and kernel density estimation suffer from either the lack of flexibility by fixing or limiting the number of Gaussian components in the mixture or large memory requirement by maintaining a nonparametric representation of the density. These problems are aggravated in real-time computer vision applications since density functions are required to be updated as new data becomes available. We present a novel kernel density approximation technique based on the mean-shift mode finding algorithm and describe an efficient method to sequentially propagate the density modes over time. Although the proposed density representation is memory efficient, which is typical for mixture densities, it inherits the flexibility of nonparametric methods by allowing the number of components to be variable. The accuracy and compactness of the sequential kernel density approximation technique is illustrated by both simulations and experiments. Sequential kernel density approximation is applied to online target appearance modeling for visual tracking, and its performance is demonstrated on a variety of videos.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BC2N4JRQ/Bohyung Han et al. - 2008 - Sequential Kernel Density Approximation and Its Ap.pdf}
}

@article{han_visual_2009,
  title = {Visual {{Tracking}} by {{Continuous Density Propagation}} in {{Sequential Bayesian Filtering Framework}}},
  author = {Han, Bohyung and {Ying Zhu} and Comaniciu, D. and Davis, L.S.},
  year = {2009},
  month = may,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {31},
  number = {5},
  pages = {919--930},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2008.134},
  url = {http://ieeexplore.ieee.org/document/4531747/},
  urldate = {2024-03-14},
  abstract = {Particle filtering is frequently used for visual tracking problems since it provides a general framework for estimating and propagating probability density functions for nonlinear and non-Gaussian dynamic systems. However, this algorithm is based on a Monte Carlo approach and the cost of sampling and measurement is a problematic issue, especially for high-dimensional problems. We describe an alternative to the classical particle filter in which the underlying density function has an analytic representation for better approximation and effective propagation. The techniques of density interpolation and density approximation are introduced to represent the likelihood and the posterior densities with Gaussian mixtures, where all relevant parameters are automatically determined. The proposed analytic approach is shown to perform more efficiently in sampling in high-dimensional space. We apply the algorithm to real-time tracking problems and demonstrate its performance on real video sequences as well as synthetic examples.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Q4ZU3B72/Bohyung Han et al. - 2009 - Visual Tracking by Continuous Density Propagation .pdf}
}

@inproceedings{handa_benchmark_2014,
  title = {A Benchmark for {{RGB-D}} Visual Odometry, {{3D}} Reconstruction and {{SLAM}}},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Handa, Ankur and Whelan, Thomas and McDonald, John and Davison, Andrew J.},
  year = {2014},
  month = may,
  pages = {1524--1531},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2014.6907054},
  abstract = {We introduce the Imperial College London and National University of Ireland Maynooth (ICL-NUIM) dataset for the evaluation of visual odometry, 3D reconstruction and SLAM algorithms that typically use RGB-D data. We present a collection of handheld RGB-D camera sequences within synthetically generated environments. RGB-D sequences with perfect ground truth poses are provided as well as a ground truth surface model that enables a method of quantitatively evaluating the final map or surface reconstruction accuracy. Care has been taken to simulate typically observed real-world artefacts in the synthetic imagery by modelling sensor noise in both RGB and depth data. While this dataset is useful for the evaluation of visual odometry and SLAM trajectory estimation, our main focus is on providing a method to benchmark the surface reconstruction accuracy which to date has been missing in the RGB-D community despite the plethora of ground truth RGB-D datasets available.},
  keywords = {Cameras,Image reconstruction,Iterative closest point algorithm,Noise,Surface reconstruction,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/BFCVE93C/Handa et al. - 2014 - A benchmark for RGB-D visual odometry, 3D reconstr.pdf}
}

@inproceedings{hansen_analyzing_2024,
  title = {Analyzing the {{Effectiveness}} of {{Neural Radiance Fields}} for {{Geometric Modeling}} of {{Lunar Terrain}}},
  booktitle = {2024 {{IEEE Aerospace Conference}}},
  author = {Hansen, Margaret and Adams, Caleb and Fong, Terrence and Wettergreen, David},
  year = {2024},
  month = mar,
  pages = {1--12},
  issn = {1095-323X},
  doi = {10.1109/AERO58975.2024.10521163},
  url = {https://ieeexplore.ieee.org/document/10521163/?arnumber=10521163},
  urldate = {2024-10-13},
  abstract = {The geometric accuracy of digital elevation models built from neural radiance fields (NeRFs) is assessed using stereo pairs collected during a simulated rover traverse under lunar polar lighting conditions by comparison to multi-view stereo reconstruction. While NeRF-based methods are more sensitive to the viewpoints in the training data and produce more artifacts on the edges of the scene, they are capable of producing denser models in occluded regions with limited additional error when the light source is not visible in the cameras. With a visible light source, the NeRF models are incapable of correctly learning scene geometry, though rendered images still appear to be decent. This trend is mitigated somewhat by using depth supervision, though this method elsewhere produces higher amounts of error. Since the volumetric rendering used by NeRF relies on probabilistic reasoning along the ray used to observe the scene, the standard deviation and gradient of the cumulative distribution function can be used as indicators of how sharply a NeRF model resolves a surface and are correlated with height error.},
  keywords = {Cameras,Geometry,Lighting,Moon,Noise,Rendering (computer graphics),Runtime},
  file = {/Users/kshitijgoel/Zotero/storage/FJIHG8AT/Hansen et al. - 2024 - Analyzing the Effectiveness of Neural Radiance Fields for Geometric Modeling of Lunar Terrain.pdf;/Users/kshitijgoel/Zotero/storage/3M4JCA2N/10521163.html}
}

@article{hansen_model_2001,
  title = {Model {{Selection}} and the {{Principle}} of {{Minimum Description Length}}},
  author = {Hansen, Mark H and Yu, Bin},
  year = {2001},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {454},
  pages = {746--774},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1198/016214501753168398},
  url = {https://doi.org/10.1198/016214501753168398},
  urldate = {2023-02-17},
  abstract = {This article reviews the principle of minimum description length (MDL) for problems of model selection. By viewing statistical modeling as a means of generating descriptions of observed data, the MDL framework discriminates between competing models based on the complexity of each description. This approach began with Kolmogorov's theory of algorithmic complexity, matured in the literature on information theory, and has recently received renewed attention within the statistics community. Here we review both the practical and the theoretical aspects of MDL as a tool for model selection, emphasizing the rich connections between information theory and statistics. At the boundary between these two disciplines we find many interesting interpretations of popular frequentist and Bayesian procedures. As we show, MDL provides an objective umbrella under which rather disparate approaches to statistical modeling can coexist and be compared. We illustrate the MDL principle by considering problems in regression, nonparametric curve estimation, cluster analysis, and time series analysis. Because model selection in linear regression is an extremely common problem that arises in many applications, we present detailed derivations of several MDL criteria in this context and discuss their properties through a number of examples. Our emphasis is on the practical application of MDL, and hence we make extensive use of real datasets. In writing this review, we tried to make the descriptive philosophy of MDL natural to a statistics audience by examining classical problems in model selection. In the engineering literature, however, MDL is being applied to ever more exotic modeling situations. As a principle for statistical modeling in general, one strength of MDL is that it can be intuitively extended to provide useful tools for new problems.},
  keywords = {Aic,Bayes information criterion,Bayesian methods,Cluster analysis,Code length,Coding redundancy,Information theory,Model selection,Pointwise and minimax lower bounds,Regression,Time series},
  file = {/Users/kshitijgoel/Zotero/storage/YXZIT9AD/Hansen and Yu - 2001 - Model Selection and the Principle of Minimum Descr.pdf}
}

@inproceedings{hansen_rangebased_2023,
  title = {Range-Based {{GP Maps}}: {{Local Surface Mapping}} for {{Mobile Robots}} Using {{Gaussian Process Regression}} in {{Range Space}}},
  shorttitle = {Range-Based {{GP Maps}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Hansen, Margaret and Wettergreen, David},
  year = {2023},
  month = oct,
  pages = {7241--7248},
  publisher = {IEEE},
  address = {Detroit, MI, USA},
  doi = {10.1109/IROS55552.2023.10341949},
  url = {https://ieeexplore.ieee.org/document/10341949/},
  urldate = {2024-02-28},
  abstract = {This work introduces range-based GP maps, which directly represent terrain by modeling the range from a LiDAR sensor as a Gaussian process (GP) in spherical space. Such a model aligns the predicted uncertainty from the GP regression with the uncertainty in the underlying sensor observations. Experimental evaluation on simulated natural terrain indicates that local range-based GP maps perform comparably to elevation-based methods when predicting terrain height, with the former producing more stable parameters and providing a better uncertainty representation. An aggregation method is proposed using the pose as an additional input to the GP. Unlike their elevation-based counterparts, range-based GP maps are capable of modeling overhangs and vertical obstacles with ease, demonstrated with examples of maps built on realworld data from a fully 3D subterranean environment.},
  isbn = {978-1-6654-9190-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MXSUPEVH/Hansen and Wettergreen - 2023 - Range-based GP Maps Local Surface Mapping for Mob.pdf}
}

@article{hardouin_multirobot_2023,
  title = {A {{Multirobot System}} for 3-{{D Surface Reconstruction With Centralized}} and {{Distributed Architectures}}},
  author = {Hardouin, Guillaume and Moras, Julien and Morbidi, Fabio and Marzat, Julien and Mouaddib, El Mustapha},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--16},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3258641},
  abstract = {In this article, we propose an original solution to the problem of surface reconstruction of large-scale unknown environments, with multiple cooperative robots. As they progress through the 3-D environment, the robots rely on volumetric maps obtained via a TSDF representation to extract discrete incomplete surface elements (ISEs), and a list of candidate viewpoints is generated to cover them. A next-best-view planning approach, which approximately solves a traveling salesman problem (TSP) via greedy allocation, is then used to iteratively assign these viewpoints to the robots. Two multiagent architectures, a centralized one (TSP-Greedy Allocation or TSGA) and a distributed one (dist-TSGA), in which the robots locally compute their maps and share them, are developed and compared. Extensive numerical and real-world experiments with multiple aerial and ground robots in challenging 3-D environments show the flexibility and effectiveness of our surface representation of a volumetric map. The experiments also shed light on the nexus between reconstruction accuracy and surface completeness, and between total distance traveled and execution time.},
  keywords = {Multirobot system,next-best-view (NBV) planning,Planning,Robot sensing systems,Robots,sampling-based motion planning,Sea surface,Surface reconstruction,Surface treatment,three-dimensional (3-D) reconstruction,Three-dimensional displays,truncated signed distance function (TSDF)},
  file = {/Users/kshitijgoel/Zotero/storage/JE69I4L8/Hardouin et al. - 2023 - A Multirobot System for 3-D Surface Reconstruction.pdf;/Users/kshitijgoel/Zotero/storage/2V2DMKBP/stamp.html}
}

@inproceedings{hardouin_nextbestview_2020,
  title = {Next-{{Best-View}} Planning for Surface Reconstruction of Large-Scale {{3D}} Environments with Multiple {{UAVs}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Hardouin, Guillaume and Moras, Julien and Morbidi, Fabio and Marzat, Julien and Mouaddib, El Mustapha},
  year = {2020},
  month = oct,
  pages = {1567--1574},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9340897},
  abstract = {In this paper, we propose a novel cluster-based Next-Best-View path planning algorithm to simultaneously explore and inspect large-scale unknown environments with multiple Unmanned Aerial Vehicles (UAVs). In the majority of existing informative path-planning methods, a volumetric criterion is used for the exploration of unknown areas, and the presence of surfaces is only taken into account indirectly. Unfortunately, this approach may lead to inaccurate 3D models, with no guarantee of global surface coverage. To perform accurate 3D reconstructions and minimize runtime, we extend our previous online planner based on TSDF (Truncated Signed Distance Function) mapping, to a fleet of UAVs. Sensor configurations to be visited are directly extracted from the map and assigned greedily to the aerial vehicles, in order to maximize the global utility at the fleet level. The performances of the proposed TSGA (TSP-Greedy Allocation) planner and of a nearest neighbor planner have been compared via realistic numerical experiments in two challenging environments (a power plant and the Statue of Liberty) with up to five quadrotor UAVs equipped with stereo cameras.},
  keywords = {Resource management,Robot vision systems,Runtime,Solid modeling,Surface reconstruction,Three-dimensional displays,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/66DCVHZ7/Hardouin et al. - 2020 - Next-Best-View planning for surface reconstruction.pdf}
}

@inproceedings{harithas_ccovoxel_2022,
  title = {{{CCO-VOXEL}}: {{Chance Constrained Optimization}} over {{Uncertain Voxel-Grid Representation}} for {{Safe Trajectory Planning}}},
  shorttitle = {{{CCO-VOXEL}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Harithas, Sudarshan S and Yadav, Rishabh Dev and Singh, Deepak and Singh, Arun Kumar and Krishna, K Madhava},
  year = {2022},
  month = may,
  pages = {11087--11093},
  publisher = {IEEE},
  address = {Philadelphia, PA, USA},
  doi = {10.1109/ICRA46639.2022.9812250},
  url = {https://ieeexplore.ieee.org/document/9812250/},
  urldate = {2024-04-01},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-7281-9681-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LJ9R6CRU/Harithas et al. - 2022 - CCO-VOXEL Chance Constrained Optimization over Un.pdf}
}

@article{harris_array_2020,
  title = {Array Programming with {{NumPy}}},
  author = {Harris, Charles R. and Millman, K. Jarrod and {van der Walt}, St{\'e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and {van Kerkwijk}, Marten H. and Brett, Matthew and Haldane, Allan and {del R{\'i}o}, Jaime Fern{\'a}ndez and Wiebe, Mark and Peterson, Pearu and {G{\'e}rard-Marchant}, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  year = {2020},
  month = sep,
  journal = {Nature},
  volume = {585},
  number = {7825},
  pages = {357--362},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2649-2},
  url = {https://www.nature.com/articles/s41586-020-2649-2},
  urldate = {2023-05-06},
  abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Computational neuroscience,Computational science,Computer science,Software,Solar physics},
  file = {/Users/kshitijgoel/Zotero/storage/JLARGITX/Harris et al. - 2020 - Array programming with NumPy.pdf}
}

@book{hartley_multiple_2004,
  title = {Multiple {{View Geometry}} in {{Computer Vision}}},
  author = {Hartley, Richard and Zisserman, Andrew},
  year = {2004},
  month = mar,
  edition = {2},
  publisher = {Cambridge University Press},
  doi = {10.1017/CBO9780511811685},
  url = {https://www.cambridge.org/core/product/identifier/9780511811685/type/book},
  urldate = {2023-03-16},
  isbn = {978-0-521-54051-3 978-0-511-81168-5},
  file = {/Users/kshitijgoel/Zotero/storage/9YBRB73H/Hartley and Zisserman - 2004 - Multiple View Geometry in Computer Vision.pdf}
}

@phdthesis{harvey_fractional_1965,
  title = {Fractional {{Moments}} of a {{Quadratic Form}} in {{Noncentral Normal Random Variables}}},
  author = {Harvey, James Raymond},
  year = {1965},
  address = {United States -- North Carolina},
  url = {https://www.proquest.com/docview/302199870/citation/7DE9744FD5804F5DPQ/1},
  urldate = {2023-10-20},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9781084278912},
  langid = {english},
  school = {North Carolina State University},
  keywords = {Pure sciences},
  file = {/Users/kshitijgoel/Zotero/storage/6D4FZNHW/HARVEY - Fractional Moments of a Quadratic Form in Noncentr.pdf}
}

@inproceedings{hasanbelliu_robust_2011,
  title = {A Robust Point Matching Algorithm for Non-Rigid Registration Using the {{Cauchy-Schwarz}} Divergence},
  booktitle = {2011 {{IEEE International Workshop}} on {{Machine Learning}} for {{Signal Processing}}},
  author = {Hasanbelliu, Erion and Giraldo, Luis Sanchez and Pr{\'i}ncipe, Jos{\'e} C.},
  year = {2011},
  month = sep,
  pages = {1--6},
  issn = {2378-928X},
  doi = {10.1109/MLSP.2011.6064593},
  abstract = {In this paper, we describe an algorithm that provides both rigid and non-rigid point-set registration. The point sets are represented as probability density functions and the registration problem is treated as distribution alignment. Using the PDFs instead of the points provides a more robust way of dealing with outliers and noise, and it mitigates the need to establish a correspondence between the points in the two sets. The algorithm operates on the distance between the two PDFs to recover the spatial transformation function needed to register the two point sets. The distance measure used is the Cauchy-Schwarz divergence. The algorithm is robust to noise and outliers, and performswell in varying degrees of transformations and noise.},
  keywords = {Algorithm design and analysis,Bandwidth,Cauchy-Schwarz divergence,Feature extraction,information theoretic learning,Kernel,Noise,non-rigid registration,Robustness,Shape,shape matching},
  file = {/Users/kshitijgoel/Zotero/storage/JEAVWWWT/Hasanbelliu et al. - 2011 - A robust point matching algorithm for non-rigid re.pdf;/Users/kshitijgoel/Zotero/storage/CZ9H3VMC/stamp.html}
}

@article{hasnat_joint_2016,
  title = {Joint {{Color-Spatial-Directional Clustering}} and {{Region Merging}} ({{JCSD-RM}}) for {{Unsupervised RGB-D Image Segmentation}}},
  author = {Hasnat, Md. Abul and Alata, Olivier and Tr{\'e}meau, Alain},
  year = {2016},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {38},
  number = {11},
  pages = {2255--2268},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2015.2513407},
  url = {https://ieeexplore.ieee.org/abstract/document/7368926},
  urldate = {2023-12-12},
  abstract = {Recent advances in depth imaging sensors provide easy access to the synchronized depth with color, called RGB-D image. In this paper, we propose an unsupervised method for indoor RGB-D image segmentation and analysis. We consider a statistical image generation model based on the color and geometry of the scene. Our method consists of a joint color-spatial-directional clustering method followed by a statistical planar region merging method. We evaluate our method on the NYU depth database and compare it with existing unsupervised RGB-D segmentation methods. Results show that, it is comparable with the state of the art methods and it needs less computation time. Moreover, it opens interesting perspectives to fuse color and geometry in an unsupervised manner.},
  file = {/Users/kshitijgoel/Zotero/storage/37LWHJYH/Hasnat et al. - 2016 - Joint Color-Spatial-Directional Clustering and Reg.pdf;/Users/kshitijgoel/Zotero/storage/H62C3DLL/7368926.html}
}

@inproceedings{hasnat_unsupervised_2014,
  title = {Unsupervised {{Clustering}} of {{Depth Images Using Watson Mixture Model}}},
  booktitle = {2014 22nd {{International Conference}} on {{Pattern Recognition}}},
  author = {Hasnat, Md. Abul and Alata, Olivier and Tr{\'e}meau, Alain},
  year = {2014},
  month = aug,
  pages = {214--219},
  issn = {1051-4651},
  doi = {10.1109/ICPR.2014.46},
  url = {https://ieeexplore.ieee.org/document/6976757},
  urldate = {2024-06-09},
  abstract = {In this paper, we propose an unsupervised clustering method for axially symmetric directional unit vectors. Our method exploits the Watson distribution and Bregman Divergence within a Model Based Clustering framework. The main objectives of our method are: (a) provide efficient solution to estimate the parameters of a Watson Mixture Model (WMM), (b) generate a set of WMMs and (b) select the optimal model. To this aim, we develop: (a) an efficient soft clustering method, (b) a hierarchical clustering approach in parameter space and (c) a model selection strategy by exploiting information criteria and an evaluation graph. We empirically validate the proposed method using synthetic data. Next, we apply the method for clustering image normals and demonstrate that the proposed method is a potential tool for analyzing the depth image.},
  keywords = {Clustering methods,Computational modeling,Data models,Depth Image Analysis,Image analysis,Integrated circuit modeling,Mathematical model,Mixture Model,Model Based Clustering,Unsupervised Clustering,Vectors,Watson Distribution},
  file = {/Users/kshitijgoel/Zotero/storage/JKLGBW9E/Hasnat et al. - 2014 - Unsupervised Clustering of Depth Images Using Watson Mixture Model.pdf;/Users/kshitijgoel/Zotero/storage/SWNS284I/6976757.html}
}

@book{hastie_elements_2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-84858-7},
  url = {http://link.springer.com/10.1007/978-0-387-84858-7},
  urldate = {2025-08-01},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/YS8X3LRP/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf}
}

@inproceedings{hauberg_directional_2018,
  title = {Directional {{Statistics}} with the {{Spherical Normal Distribution}}},
  booktitle = {2018 21st {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Hauberg, S{\o}ren},
  year = {2018},
  month = jul,
  pages = {704--711},
  doi = {10.23919/ICIF.2018.8455242},
  url = {https://ieeexplore.ieee.org/document/8455242},
  urldate = {2024-07-12},
  abstract = {A well-known problem in directional statistics - the study of data distributed on the unit sphere - is that current models disregard the curvature of the underlying sample space. This ensures computationally efficiency, but can influence results. To investigate this, we develop efficient inference techniques for data distributed by the curvature-aware spherical normal distribution. We derive closed-form expressions for the normalization constant when the distribution is isotropic, and a fast and accurate approximation for the anisotropic case on the two-sphere. We further develop approximate posterior inference techniques for the mean and concentration of the distribution, and propose a fast sampling algorithm for simulating the distribution. Combined, this provides the tools needed for practical inference on the unit sphere in a manner that respects the curvature of the underlying sample space.},
  keywords = {Bayes methods,Closed-form solutions,Distributed databases,Euclidean distance,Gaussian distribution,Tools},
  file = {/Users/kshitijgoel/Zotero/storage/KHLDAWD7/Hauberg - 2018 - Directional Statistics with the Spherical Normal Distribution.pdf;/Users/kshitijgoel/Zotero/storage/X757888Z/hauberg_fusion2018_supplements.pdf;/Users/kshitijgoel/Zotero/storage/7QR7JM2Y/8455242.html}
}

@article{hauberg_scalable_2016,
  title = {Scalable {{Robust Principal Component Analysis Using Grassmann Averages}}},
  author = {Hauberg, S{\o}ren and Feragen, Aasa and Enficiaud, Raffi and Black, Michael J.},
  year = {2016},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {38},
  number = {11},
  pages = {2298--2311},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2015.2511743},
  url = {https://ieeexplore.ieee.org/document/7364267/?arnumber=7364267},
  urldate = {2024-07-25},
  abstract = {In large datasets, manual data verification is impossible, and we must expect the number of outliers to increase with data size. While principal component analysis (PCA) can reduce data size, and scalable solutions exist, it is well-known that outliers can arbitrarily corrupt the results. Unfortunately, state-of-the-art approaches for robust PCA are not scalable. We note that in a zero-mean dataset, each observation spans a one-dimensional subspace, giving a point on the Grassmann manifold. We show that the average subspace corresponds to the leading principal component for Gaussian data. We provide a simple algorithm for computing this Grassmann Average (GA), and show that the subspace estimate is less sensitive to outliers than PCA for general distributions. Because averages can be efficiently computed, we immediately gain scalability. We exploit robust averaging to formulate the Robust Grassmann Average (RGA) as a form of robust PCA. The resulting Trimmed Grassmann Average (TGA) is appropriate for computer vision because it is robust to pixel outliers. The algorithm has linear computational complexity and minimal memory requirements. We demonstrate TGA for background modeling, video restoration, and shadow removal. We show scalability by performing robust PCA on the entire Star Wars IV movie; a task beyond any current method. Source code is available online.},
  keywords = {Approximation methods,Complexity theory,Computer vision,Dimensionality reduction,Estimation,Manifolds,Principal component analysis,robust principal component analysis,Robustness,subspace estimation},
  file = {/Users/kshitijgoel/Zotero/storage/79B39ALS/Hauberg et al. - 2016 - Scalable Robust Principal Component Analysis Using Grassmann Averages.pdf;/Users/kshitijgoel/Zotero/storage/TF9VWYQG/7364267.html}
}

@book{hazan_introduction_2022,
  title = {Introduction to Online Convex Optimization},
  author = {Hazan, Elad},
  year = {2022},
  series = {Adaptive {{Computation}} and {{Machine Learning}}},
  edition = {Second edition},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts London, England},
  isbn = {978-0-262-04698-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZWUVWJM5/Hazan - 2023 - Introduction to Online Convex Optimization.pdf}
}

@inproceedings{he_guided_2010,
  title = {Guided {{Image Filtering}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2010},
  author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
  editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
  year = {2010},
  pages = {1--14},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15549-9_1},
  abstract = {In this paper, we propose a novel type of explicit image filter - guided filter. Derived from a local linear model, the guided filter generates the filtering output by considering the content of a guidance image, which can be the input image itself or another different image. The guided filter can perform as an edge-preserving smoothing operator like the popular bilateral filter [1], but has better behavior near the edges. It also has a theoretical connection with the matting Laplacian matrix [2], so is a more generic concept than a smoothing operator and can better utilize the structures in the guidance image. Moreover, the guided filter has a fast and non-approximate linear-time algorithm, whose computational complexity is independent of the filtering kernel size. We demonstrate that the guided filter is both effective and efficient in a great variety of computer vision and computer graphics applications including noise reduction, detail smoothing/enhancement, HDR compression, image matting/feathering, haze removal, and joint upsampling.},
  isbn = {978-3-642-15549-9},
  langid = {english},
  keywords = {Alpha Matte,Bilateral Filter,Dark Channel,Detail Layer,Local Linear Model},
  file = {/Users/kshitijgoel/Zotero/storage/CHFIBVYJ/He et al. - 2010 - Guided Image Filtering.pdf}
}

@misc{he_hover_2024,
  title = {{{HOVER}}: {{Versatile Neural Whole-Body Controller}} for {{Humanoid Robots}}},
  shorttitle = {{{HOVER}}},
  author = {He, Tairan and Xiao, Wenli and Lin, Toru and Luo, Zhengyi and Xu, Zhenjia and Jiang, Zhenyu and Kautz, Jan and Liu, Changliu and Shi, Guanya and Wang, Xiaolong and Fan, Linxi and Zhu, Yuke},
  year = {2024},
  month = oct,
  number = {arXiv:2410.21229},
  eprint = {2410.21229},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.21229},
  urldate = {2024-11-18},
  abstract = {Humanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control. For example, navigation relies on root velocity tracking, while tabletop manipulation prioritizes upper-body joint angle tracking. Existing approaches typically train individual policies tailored to a specific command space, limiting their transferability across modes. We present the key insight that full-body kinematic motion imitation can serve as a common abstraction for all these tasks and provide general-purpose motor skills for learning multiple modes of whole-body control. Building on this, we propose HOVER (Humanoid Versatile Controller), a multi-mode policy distillation framework that consolidates diverse control modes into a unified policy. HOVER enables seamless transitions between control modes while preserving the distinct advantages of each, offering a robust and scalable solution for humanoid control across a wide range of modes. By eliminating the need for policy retraining for each control mode, our approach improves efficiency and flexibility for future humanoid applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/FJLPIJCX/He et al. - 2024 - HOVER Versatile Neural Whole-Body Controller for Humanoid Robots.pdf;/Users/kshitijgoel/Zotero/storage/UZWAPXAA/2410.html}
}

@inproceedings{he_robust_2022,
  title = {Towards {{Robust Visual-Inertial Odometry}} with {{Multiple Non-Overlapping Monocular Cameras}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {He, Yao and Yu, Huai and Yang, Wen and Scherer, Sebastian},
  year = {2022},
  month = oct,
  pages = {9452--9458},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981664},
  url = {https://ieeexplore.ieee.org/document/9981664/?arnumber=9981664},
  urldate = {2025-01-21},
  abstract = {We present a Visual-Inertial Odometry (VIO) algorithm with multiple non-overlapping monocular cameras aiming at improving the robustness of the VIO algorithm. An initialization scheme and tightly-coupled bundle adjustment for multiple non-overlapping monocular cameras are proposed. With more stable features captured by multiple cameras, VIO can maintain stable state estimation, especially when one of the cameras tracked unstable or limited features. We also address the high CPU usage rate brought by multiple cameras by proposing a GPU-accelerated frontend. Finally, we use our pedestrian carried system to evaluate the robustness of the VIO algorithm in several challenging environments. The results show that the multi-camera setup yields significantly higher estimation robustness than a monocular system while not increasing the CPU usage rate (reducing the CPU resource usage rate and computational latency by 40.4\% and 50.6\% on each camera). A demo video can be found at https://youtu.be/r7QvPth1m10.},
  keywords = {Cameras,Feature extraction,Pose estimation,Redundancy,Robot vision systems,Robustness,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/JADAQYG4/He et al. - 2022 - Towards Robust Visual-Inertial Odometry with Multiple Non-Overlapping Monocular Cameras.pdf;/Users/kshitijgoel/Zotero/storage/AMC5NX2Q/9981664.html}
}

@misc{heeg_learning_2024,
  title = {Learning {{Quadrotor Control From Visual Features Using Differentiable Simulation}}},
  author = {Heeg, Johannes and Song, Yunlong and Scaramuzza, Davide},
  year = {2024},
  month = oct,
  number = {arXiv:2410.15979},
  eprint = {2410.15979},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.15979},
  url = {http://arxiv.org/abs/2410.15979},
  urldate = {2025-02-18},
  abstract = {The sample inefficiency of reinforcement learning (RL) remains a significant challenge in robotics. RL requires large-scale simulation and, still, can cause long training times, slowing down research and innovation. This issue is particularly pronounced in vision-based control tasks where reliable state estimates are not accessible. Differentiable simulation offers an alternative by enabling gradient back-propagation through the dynamics model, providing low-variance analytical policy gradients and, hence, higher sample efficiency. However, its usage for real-world robotic tasks has yet been limited. This work demonstrates the great potential of differentiable simulation for learning quadrotor control. We show that training in differentiable simulation significantly outperforms model-free RL in terms of both sample efficiency and training time, allowing a policy to learn to recover a quadrotor in seconds when providing vehicle state and in minutes when relying solely on visual features. The key to our success is two-fold. First, the use of a simple surrogate model for gradient computation greatly accelerates training without sacrificing control performance. Second, combining state representation learning with policy learning enhances convergence speed in tasks where only visual features are observable. These findings highlight the potential of differentiable simulation for real-world robotics and offer a compelling alternative to conventional RL approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/QKEG7CPQ/Heeg et al. - 2024 - Learning Quadrotor Control From Visual Features Using Differentiable Simulation.pdf;/Users/kshitijgoel/Zotero/storage/KDTIHXD5/2410.html}
}

@inproceedings{hegde_hyperppo_2024,
  title = {{{HyperPPO}}: {{A}} Scalable Method for Finding Small Policies for Robotic Control},
  shorttitle = {{{HyperPPO}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Hegde, Shashank and Huang, Zhehui and Sukhatme, Gaurav S.},
  year = {2024},
  month = may,
  pages = {10821--10828},
  doi = {10.1109/ICRA57147.2024.10610861},
  url = {https://ieeexplore.ieee.org/document/10610861/},
  urldate = {2025-08-12},
  abstract = {Models with fewer parameters are necessary for the neural control of memory-limited, performant robots. Finding these smaller neural network architectures can be time-consuming. We propose HyperPPO, an on-policy reinforcement learning algorithm that utilizes graph hypernetworks to estimate the weights of multiple neural architectures simultaneously. Our method estimates weights for networks that are much smaller than those in common-use networks yet encode highly performant policies. We obtain multiple trained policies at the same time while maintaining sample efficiency and provide the user the choice of picking a network architecture that satisfies their computational constraints. We show that our method scales well - more training resources produce faster convergence to higher-performing architectures. We demonstrate that the neural policies estimated by HyperPPO are capable of decentralized control of a Crazyflie2.1 quadrotor. Website: https://sites.google.com/usc.edu/hyperppo},
  keywords = {Computational efficiency,Computer architecture,Decentralized control,Network architecture,Neural networks,Reinforcement learning,Training},
  file = {/Users/kshitijgoel/Zotero/storage/UWLJIVD9/Hegde et al. - 2024 - HyperPPO A scalable method for finding small policies for robotic control.pdf}
}

@inproceedings{heiden_planning_2017,
  title = {Planning High-Speed Safe Trajectories in Confidence-Rich Maps},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Heiden, Eric and Hausman, Karol and Sukhatme, Gaurav S. and {Agha-mohammadi}, Ali-akbar},
  year = {2017},
  month = sep,
  pages = {2880--2886},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8206120},
  url = {https://ieeexplore.ieee.org/document/8206120},
  urldate = {2024-01-27},
  abstract = {Planning safe, high-speed trajectories in unknown environments remains a major roadblock on the way toward achieving fast autonomous flight. Current state-of-the-art planning approaches use sampling-based methods or trajectory optimization to obtain fast trajectories, whose safety is evaluated by taking into account the current state estimate of the environment. In unknown environments, however, this leads to numerous stops caused by the need for re-planning the trajectory due to unexpected obstacles. In this paper, we propose to use an active perception paradigm for planning. We predict the future uncertainty of the map and optimize trajectories to minimize re-planning risk. This leads to faster and safer trajectories. We evaluate the proposed planning approach in a series of simulation experiments, which show that we are able to achieve safer trajectories with a smaller number of re-planning stops and faster speeds.},
  keywords = {Optimization,Planning,Probabilistic logic,Robots,Sensors,Trajectory,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/5AY679DV/Heiden et al. - 2017 - Planning high-speed safe trajectories in confidenc.pdf;/Users/kshitijgoel/Zotero/storage/MMAWWU62/8206120.html}
}

@book{hempel_call_2001,
  title = {On {{Call}}: {{A Complete Reference}} for {{Cave Rescue}}},
  author = {Hempel, John C. and {Fregeau-Conover}, Annette},
  year = {2001},
  publisher = {National Speleological Society},
  isbn = {978-1-879961-16-6},
  langid = {english}
}

@inproceedings{henderson_efficient_2020,
  title = {An {{Efficient}} and {{Continuous Approach}} to {{Information-Theoretic Exploration}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Henderson, Theia and Sze, Vivienne and Karaman, Sertac},
  year = {2020},
  month = may,
  pages = {8566--8572},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196592},
  abstract = {Exploration of unknown environments is embedded and essential in many robotics applications. Traditional algorithms, that decide where to explore by computing the expected information gain of an incomplete map from future sensor measurements, are limited to very powerful computational platforms. In this paper, we describe a novel approach for computing this expected information gain efficiently, as principally derived via mutual information. The key idea behind the proposed approach is a continuous occupancy map framework and the recursive structure it reveals. This structure makes it possible to compute the expected information gain of sensor measurements across an entire map much faster than computing each measurements' expected gain independently. Specifically, for an occupancy map composed of {\textbar}M{\textbar} cells and a range sensor that emits {\textbar}{$\Theta\vert$} measurement beams, the algorithm (titled FCMI) computes the information gain corresponding to measurements made at each cell in O({\textbar}{$\Theta\vert\vert$}M{\textbar}) steps. To the best of our knowledge, this complexity bound is better than all existing methods for computing information gain. In our experiments, we observe that this novel, continuous approach is two orders of magnitude faster than the state-of-the-art FSMI algorithm.},
  keywords = {Distortion measurement,Gain measurement,Mutual information,Robot sensing systems,Time measurement},
  file = {/Users/kshitijgoel/Zotero/storage/CNTCS2X3/Henderson et al. - 2020 - An Efficient and Continuous Approach to Informatio.pdf}
}

@phdthesis{hernandez-lobato_balancing_2010,
  title = {Balancing {{Flexibility}} and {{Robustness}} in {{Machine Learning}}: {{Semi-parametric Methods}} and {{Sparse Linear Models}}},
  author = {{Hern{\'a}ndez-Lobato}, Jos{\'e} Miguel},
  year = {2010},
  month = nov,
  langid = {english},
  school = {UNIVERSIDAD AUT{\'O}NOMA DE MADRID},
  file = {/Users/kshitijgoel/Zotero/storage/ZHNT5E4X/Hernández-Lobato - Balancing Flexibility and Robustness in Machine Learning Semi-parametric Methods and Sparse Linear.pdf}
}

@article{hernandez-stumpfhauser_general_2017,
  title = {The {{General Projected Normal Distribution}} of {{Arbitrary Dimension}}: {{Modeling}} and {{Bayesian Inference}}},
  shorttitle = {The {{General Projected Normal Distribution}} of {{Arbitrary Dimension}}},
  author = {{Hernandez-Stumpfhauser}, Daniel and Breidt, F. Jay and van der Woerd, Mark J.},
  year = {2017},
  month = mar,
  journal = {Bayesian Analysis},
  volume = {12},
  number = {1},
  pages = {113--133},
  publisher = {International Society for Bayesian Analysis},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/15-BA989},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-12/issue-1/The-General-Projected-Normal-Distribution-of-Arbitrary-Dimension--Modeling/10.1214/15-BA989.full},
  urldate = {2024-07-24},
  abstract = {The general projected normal distribution is a simple and intuitive model for directional data in any dimension: a multivariate normal random vector divided by its length is the projection of that vector onto the surface of the unit hypersphere. Observed data consist of the projections, but not the lengths. Inference for this model has been restricted to the two-dimensional (circular) case, using Bayesian methods with data augmentation to generate the latent lengths and a Metropolis-within-Gibbs algorithm to sample from the posterior. We describe a new parameterization of the general projected normal distribution that makes inference in any dimension tractable, including the important three-dimensional (spherical) case, which has not previously been considered. Under this new parameterization, the full conditionals of the unknown parameters have closed forms, and we propose a new slice sampler to draw the latent lengths without the need for rejection. Gibbs sampling with this new scheme is fast and easy, leading to improved Bayesian inference; for example, it is now feasible to conduct model selection among complex mixture and regression models for large data sets. Our parameterization also allows straightforward incorporation of covariates into the covariance matrix of the multivariate normal, increasing the ability of the model to explain directional data as a function of independent regressors. Circular and spherical cases are considered in detail and illustrated with scientific applications. For the circular case, seasonal variation in time-of-day departures of anglers from recreational fishing sites is modeled using covariates in both the mean vector and covariance matrix. For the spherical case, we consider paired angles that describe the relative positions of carbon atoms along the backbone chain of a protein. We fit mixtures of general projected normals to these data, with the best-fitting mixture accurately describing biologically meaningful structures including helices, {$\beta$}-sheets, and coils and turns. Finally, we show via simulation that our methodology has satisfactory performance in some 10-dimensional and 50-dimensional problems.},
  keywords = {Circular data,directional data,Gibbs sampler,Markov chain Monte Carlo,protein structure analysis,spherical data},
  file = {/Users/kshitijgoel/Zotero/storage/MVTFW3MJ/Hernandez-Stumpfhauser et al. - 2017 - The General Projected Normal Distribution of Arbitrary Dimension Modeling and Bayesian Inference.pdf;/Users/kshitijgoel/Zotero/storage/SKDZGTCW/suppdf_1.pdf}
}

@misc{herrera-esposito_projected_2025,
  title = {Projected {{Normal Distribution}}: {{Moment Approximations}} and {{Generalizations}}},
  shorttitle = {Projected {{Normal Distribution}}},
  author = {{Herrera-Esposito}, Daniel and Burge, Johannes},
  year = {2025},
  month = jun,
  number = {arXiv:2506.17461},
  eprint = {2506.17461},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2506.17461},
  url = {http://arxiv.org/abs/2506.17461},
  urldate = {2025-08-05},
  abstract = {The projected normal distribution, also known as the angular Gaussian distribution, is obtained by dividing a multivariate normal random variable \${\textbackslash}mathbf\{x\}\$ by its norm \${\textbackslash}sqrt\{{\textbackslash}mathbf\{x\}{\textasciicircum}T {\textbackslash}mathbf\{x\}\}\$. The resulting random variable follows a distribution on the unit sphere. No closed-form formulas for the moments of the projected normal distribution are known, which can limit its use in some applications. In this work, we derive analytic approximations to the first and second moments of the projected normal distribution using Taylor expansions and using results from the theory of quadratic forms of Gaussian random variables. Then, motivated by applications in systems neuroscience, we present generalizations of the projected normal distribution that divide the variable \${\textbackslash}mathbf\{x\}\$ by a denominator of the form \${\textbackslash}sqrt\{{\textbackslash}mathbf\{x\}{\textasciicircum}T {\textbackslash}mathbf\{B\} {\textbackslash}mathbf\{x\} + c\}\$, where \${\textbackslash}mathbf\{B\}\$ is a symmetric positive definite matrix and \$c\$ is a non-negative number. We derive moment approximations as well as the density function for these other projected distributions. We show that the moments approximations are accurate for a wide range of dimensionalities and distribution parameters. Furthermore, we show that the moments approximations can be used to fit these distributions to data through moment matching. These moment matching methods should be useful for analyzing data across a range of applications where the projected normal distribution is used, and for applying the projected normal distribution and its generalizations to model data in neuroscience.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition,Statistics - Methodology},
  file = {/Users/kshitijgoel/Zotero/storage/ZU7RVXE9/Herrera-Esposito and Burge - 2025 - Projected Normal Distribution Moment Approximations and Generalizations.pdf;/Users/kshitijgoel/Zotero/storage/7AMACSYG/2506.html}
}

@inproceedings{hertz_pointgmm_2020,
  title = {{{PointGMM}}: {{A Neural GMM Network}} for {{Point Clouds}}},
  shorttitle = {{{PointGMM}}},
  booktitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Hertz, Amir and Hanocka, Rana and Giryes, Raja and {Cohen-Or}, Daniel},
  year = {2020},
  month = jun,
  pages = {12051--12060},
  publisher = {IEEE},
  address = {Seattle, WA, USA},
  doi = {10.1109/CVPR42600.2020.01207},
  url = {https://ieeexplore.ieee.org/document/9156692/},
  urldate = {2023-03-17},
  abstract = {Point clouds are a popular representation for 3D shapes. However, they encode a particular sampling without accounting for shape priors or non-local information. We advocate for the use of a hierarchical Gaussian mixture model (hGMM), which is a compact, adaptive and lightweight representation that probabilistically defines the underlying 3D surface. We present PointGMM, a neural network that learns to generate hGMMs which are characteristic of the shape class, and also coincide with the input point cloud. PointGMM is trained over a collection of shapes to learn a class-specific prior. The hierarchical representation has two main advantages: (i) coarse-to-fine learning, which avoids converging to poor local-minima; and (ii) (an unsupervised) consistent partitioning of the input shape. We show that as a generative model, PointGMM learns a meaningful latent space which enables generating consistent interpolations between existing shapes, as well as synthesizing novel shapes. We also present a novel framework for rigid registration using PointGMM, that learns to disentangle orientation from structure of an input shape.},
  isbn = {978-1-7281-7168-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VJUPB697/Hertz et al. - 2020 - PointGMM A Neural GMM Network for Point Clouds.pdf}
}

@article{hibbard_safely_2023,
  title = {Safely: {{Safe Stochastic Motion Planning Under Constrained Sensing}} via {{Duality}}},
  shorttitle = {Safely},
  author = {Hibbard, Michael and Vinod, Abraham P. and Quattrociocchi, Jesse and Topcu, Ufuk},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {3464--3478},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3297018},
  url = {https://ieeexplore.ieee.org/document/10225441},
  urldate = {2023-10-17},
  abstract = {Consider a robot operating in an uncertain environment with stochastic, dynamic obstacles. Despite the clear benefits for trajectory optimization, it is often hard to keep track of each obstacle at every time step due to sensing and hardware limitations. We introduce the {\textbackslash}mathtt Safely motion planner, a receding-horizon control framework, that simultaneously synthesizes both a trajectory for the robot to follow as well as a sensor selection strategy that prescribes trajectory-relevant obstacles to measure at each time step while respecting the sensing constraints of the robot. We perform the motion planning using sequential quadratic programming, and prescribe obstacles to sense based on a novel connection between the duality information associated with the convex subproblems and the effect of uncertainty reduction through Kalman filter updates. We guarantee safety by ensuring that the probability of the robot colliding with any of the obstacles is below a prescribed threshold at every time step of the planned robot trajectory. We demonstrate the efficacy of the {\textbackslash}mathtt Safely motion planner through software and hardware experiments.},
  file = {/Users/kshitijgoel/Zotero/storage/LALKXB9E/Hibbard et al. - 2023 - Safely Safe Stochastic Motion Planning Under Cons.pdf}
}

@article{hilf_commercial_2015,
  title = {The {{Commercial Use}} of {{Drones}}},
  author = {Hilf, Juliane and Umbach, Klaus},
  year = {2015},
  journal = {Computer Law Review International},
  volume = {16},
  number = {3},
  pages = {65--71},
  publisher = {Walter de Gruyter GmbH},
  address = {Cologne, Germany},
  issn = {16107608},
  doi = {http://dx.doi.org/10.9785/cri-2015-0302},
  url = {https://www.proquest.com/docview/1858170450/citation/A4D7791A9E2745FEPQ/1},
  urldate = {2022-04-08},
  abstract = {The commercial use of drones is widely expected to take off in the very near future. While still in a more or less experimental phase today, the technology will soon most likely have an immense impact on a number of businesses. Global investment in drone technology is estimated at about \$ 90 billion for the next decade. But as of today, a regulatory framework that would provide a reliable basis for the industry to invest at such a scale is not yet in place; neither in the United States of America (US) nor in the European Union (EU). However, important regulatory decisions regarding the future commercial use of drones are due this year from the regulators in Brussels and Washington, DC. This might be decisive for the question which region of the world will have a competitive advantage in introducing the new technology on a wider scale. Following an introduction (I.) this article first describes the current status of the relevant regulatory regime in the EU and the US respectively (II.) and then turns to the likely new developments in both jurisdictions (III.). It finishes by comparing the approaches (IV.).},
  copyright = {Copyright Walter de Gruyter GmbH 2015},
  langid = {english},
  keywords = {Computers},
  file = {/Users/kshitijgoel/Zotero/storage/PYMYBHTP/2015 - The Commercial Use of Drones.pdf}
}

@article{hillen_moments_2017,
  title = {Moments of von Mises and Fisher Distributions and Applications},
  author = {Hillen, Thomas and J. Painter, Kevin and C. Swan, Amanda and D. Murtha, Albert and {1. University of Alberta, Centre for Mathematical Biology, Edmonton, Alberta, T6G2G1, Canada} and {2. Department of Mathematics, Heriot-Watt University, Edinburgh, EH14 4AS, UK} and {3. Cross Cancer Institute, 11560-University Ave NW, Edmonton, Alberta, T6G 1Z2, Canada}},
  year = {2017},
  journal = {Mathematical Biosciences and Engineering},
  volume = {14},
  number = {3},
  pages = {673--694},
  issn = {1551-0018},
  doi = {10.3934/mbe.2017038},
  url = {http://www.aimspress.com/article/10.3934/mbe.2017038},
  urldate = {2024-07-12},
  abstract = {The von Mises and Fisher distributions are spherical analogues to the Normal distribution on the unit circle and unit sphere, respectively. The computation of their moments, and in particular the second moment, usually involves solving tedious trigonometric integrals. Here we present a new method to compute the moments of spherical distributions, based on the divergence theorem. This method allows a clear derivation of the second moments and can be easily generalized to higher dimensions. In particular we note that, to our knowledge, the variance-covariance matrix of the three dimensional Fisher distribution has not previously been explicitly computed. While the emphasis of this paper lies in calculating the moments of spherical distributions, their usefulness is motivated by their relationship to population statistics in animal/cell movement models and demonstrated in applications to the modelling of sea turtle navigation, wolf movement and brain tumour growth.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z4AH8J9D/Hillen et al. - 2017 - Moments of von mises and fisher distributions and applications.pdf}
}

@article{hinton_deep_2012,
  title = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}: {{The Shared Views}} of {{Four Research Groups}}},
  shorttitle = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}},
  author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  year = {2012},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {29},
  number = {6},
  pages = {82--97},
  issn = {1558-0792},
  doi = {10.1109/MSP.2012.2205597},
  abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
  keywords = {Acoustics,Automatic speech recognition,Data models,Gaussian processes,Hidden Markov models,Neural networks,Speech recognition,Training},
  file = {/Users/kshitijgoel/Zotero/storage/JVNB9XLI/Hinton et al. - 2012 - Deep Neural Networks for Acoustic Modeling in Spee.pdf;/Users/kshitijgoel/Zotero/storage/WDQ5RQMT/6296526.html}
}

@inproceedings{hirayama_robust_2022,
  title = {Robust {{Localization}} for~{{Multi-robot Formations}}: {{An Experimental Evaluation}} of~an~{{Extended GM-PHD Filter}}},
  shorttitle = {Robust {{Localization}} for~{{Multi-robot Formations}}},
  booktitle = {Distributed {{Autonomous Robotic Systems}}},
  author = {Hirayama, Michiaki and Wasik, Alicja and Kamezaki, Mitsuhiro and Martinoli, Alcherio},
  editor = {Matsuno, Fumitoshi and Azuma, Shun-ichi and Yamamoto, Masahito},
  year = {2022},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {148--162},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-92790-5_12},
  abstract = {This paper presents a thorough experimental evaluation of an extended Gaussian Mixture Probability Hypothesis Density filter which is able to provide state estimates for the maintenance of a multi-robot formation, even when the communication fails and the tracking data are insufficient for maintaining a stable formation. The filter incorporates, firstly, absolute poses exchanged by the robots, and secondly, the geometry of the desired formation. By combining communicated data, information about the formation, and sensory detections, the resulting algorithm preserves accuracy in the state estimates despite frequent occurrences of long-duration sensing occlusions, and provides the necessary state information when the communication is sporadic or suffers from short-term outage. Differently from our previous contributions, in which the tracking strategy has only been tested in simulation, in this paper we present the results of experiments with a real multi-robot system. The results confirm that the algorithm enables robust formation maintenance in cluttered environments, under conditions affected by sporadic communication and high measurement uncertainty.},
  isbn = {978-3-030-92790-5},
  langid = {english},
  keywords = {Cooperative localization,Formation control,Multi-robot tracking,Probability hypothesis density filter},
  file = {/Users/kshitijgoel/Zotero/storage/ZP97TEWK/Hirayama et al. - 2022 - Robust Localization for Multi-robot Formations An.pdf}
}

@inproceedings{ho_denoising_2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  year = {2020},
  volume = {33},
  pages = {6840--6851},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
  urldate = {2024-03-05},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
  file = {/Users/kshitijgoel/Zotero/storage/78F4MPZK/Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf}
}

@misc{ho_mapex_2024,
  title = {{{MapEx}}: {{Indoor Structure Exploration}} with {{Probabilistic Information Gain}} from {{Global Map Predictions}}},
  shorttitle = {{{MapEx}}},
  author = {Ho, Cherie and Kim, Seungchan and Moon, Brady and Parandekar, Aditya and Harutyunyan, Narek and Wang, Chen and Sycara, Katia and Best, Graeme and Scherer, Sebastian},
  year = {2024},
  month = sep,
  number = {arXiv:2409.15590},
  eprint = {2409.15590},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.15590},
  urldate = {2024-09-29},
  abstract = {Exploration is a critical challenge in robotics, centered on understanding unknown environments. In this work, we focus on robots exploring structured indoor environments which are often predictable and composed of repeating patterns. Most existing approaches, such as conventional frontier approaches, have difficulty leveraging the predictability and explore with simple heuristics such as `closest first'. Recent works use deep learning techniques to predict unknown regions of the map, using these predictions for information gain calculation. However, these approaches are often sensitive to the predicted map quality or do not reason over sensor coverage. To overcome these issues, our key insight is to jointly reason over what the robot can observe and its uncertainty to calculate probabilistic information gain. We introduce MapEx, a new exploration framework that uses predicted maps to form probabilistic sensor model for information gain estimation. MapEx generates multiple predicted maps based on observed information, and takes into consideration both the computed variances of predicted maps and estimated visible area to estimate the information gain of a given viewpoint. Experiments on the real-world KTH dataset showed on average 12.4\% improvement than representative map-prediction based exploration and 25.4\% improvement than nearest frontier approach.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/F89VULWA/Ho et al. - 2024 - MapEx Indoor Structure Exploration with Probabilistic Information Gain from Global Map Predictions.pdf}
}

@book{hofmann-wellenhof_global_2001,
  title = {Global {{Positioning System}}},
  author = {{Hofmann-Wellenhof}, Bernhard and Lichtenegger, Herbert and Collins, James},
  year = {2001},
  publisher = {Springer},
  address = {Vienna},
  doi = {10.1007/978-3-7091-6199-9},
  url = {http://link.springer.com/10.1007/978-3-7091-6199-9},
  urldate = {2025-03-13},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-211-83534-0 978-3-7091-6199-9},
  langid = {english},
  keywords = {altitude determination,coordinate computation,global navigation,GNSS,GNSS/Kartographie,GPS,Hohenstimmung,Koordinatenberechnung,mapping,Navigation,Orbit,satellite,satellite systems,surveying,Vermessung},
  file = {/Users/kshitijgoel/Zotero/storage/M3U2E83J/Hofmann-Wellenhof et al. - 2001 - Global Positioning System.pdf}
}

@book{hogg_introduction_2019,
  title = {Introduction to Mathematical Statistics},
  author = {Hogg, Robert V. and McKean, Joseph W. and Craig, Allen T.},
  year = {2019},
  edition = {Eighth edition},
  publisher = {Pearson},
  address = {Boston},
  isbn = {978-0-13-468699-8},
  langid = {english},
  lccn = {QA276 .H59 2019},
  keywords = {Mathematical statistics},
  file = {/Users/kshitijgoel/Zotero/storage/NXJH2FB9/Hogg et al. - 2019 - Introduction to mathematical statistics.pdf}
}

@article{hollinger_active_2013,
  title = {Active Planning for Underwater Inspection and the Benefit of Adaptivity},
  author = {Hollinger, Geoffrey A and Englot, Brendan and Hover, Franz S and Mitra, Urbashi and Sukhatme, Gaurav S},
  year = {2013},
  month = jan,
  journal = {The International Journal of Robotics Research},
  volume = {32},
  number = {1},
  pages = {3--18},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364912467485},
  url = {https://doi.org/10.1177/0278364912467485},
  urldate = {2023-09-22},
  abstract = {We discuss the problem of inspecting an underwater structure, such as a submerged ship hull, with an autonomous underwater vehicle (AUV). Unlike a large body of prior work, we focus on planning the views of the AUV to improve the quality of the inspection, rather than maximizing the accuracy of a given data stream. We formulate the inspection planning problem as an extension to Bayesian active learning, and we show connections to recent theoretical guarantees in this area. We rigorously analyze the benefit of adaptive re-planning for such problems, and we prove that the potential benefit of adaptivity can be reduced from an exponential to a constant factor by changing the problem from cost minimization with a constraint on information gain to variance reduction with a constraint on cost. Such analysis allows the use of robust, non-adaptive planning algorithms that perform competitively with adaptive algorithms. Based on our analysis, we propose a method for constructing 3D meshes from sonar-derived point clouds, and we introduce uncertainty modeling through non-parametric Bayesian regression. Finally, we demonstrate the benefit of active inspection planning using sonar data from ship hull inspections with the Bluefin-MIT Hovering AUV.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9LBVQ32D/Hollinger et al. - 2013 - Active planning for underwater inspection and the .pdf}
}

@inproceedings{holz_realtime_2012,
  title = {Real-{{Time Plane Segmentation Using RGB-D Cameras}}},
  booktitle = {{{RoboCup}} 2011: {{Robot Soccer World Cup XV}}},
  author = {Holz, Dirk and Holzer, Stefan and Rusu, Radu Bogdan and Behnke, Sven},
  editor = {R{\"o}fer, Thomas and Mayer, N. Michael and Savage, Jesus and Saranl{\i}, Ulu{\k c}},
  year = {2012},
  pages = {306--317},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-32060-6_26},
  abstract = {Real-time 3D perception of the surrounding environment is a crucial precondition for the reliable and safe application of mobile service robots in domestic environments. Using a RGB-D camera, we present a system for acquiring and processing 3D (semantic) information at frame rates of up to 30Hz that allows a mobile robot to reliably detect obstacles and segment graspable objects and supporting surfaces as well as the overall scene geometry. Using integral images, we compute local surface normals. The points are then clustered, segmented, and classified in both normal space and spherical coordinates. The system is tested in different setups in a real household environment.},
  isbn = {978-3-642-32060-6},
  langid = {english},
  keywords = {Collision Avoidance,Distance Space,Integral Image,Latent Dirichlet Allocation,Point Cloud},
  file = {/Users/kshitijgoel/Zotero/storage/IEBNSSPJ/Holz et al. - 2012 - Real-Time Plane Segmentation Using RGB-D Cameras.pdf}
}

@misc{hong_gslivo_2025,
  title = {{{GS-LIVO}}: {{Real-Time LiDAR}}, {{Inertial}}, and {{Visual Multi-sensor Fused Odometry}} with {{Gaussian Mapping}}},
  shorttitle = {{{GS-LIVO}}},
  author = {Hong, Sheng and Zheng, Chunran and Shen, Yishu and Li, Changze and Zhang, Fu and Qin, Tong and Shen, Shaojie},
  year = {2025},
  month = jan,
  number = {arXiv:2501.08672},
  eprint = {2501.08672},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.08672},
  url = {http://arxiv.org/abs/2501.08672},
  urldate = {2025-01-16},
  abstract = {In recent years, 3D Gaussian splatting (3D-GS) has emerged as a novel scene representation approach. However, existing vision-only 3D-GS methods often rely on hand-crafted heuristics for point-cloud densification and face challenges in handling occlusions and high GPU memory and computation consumption. LiDAR-Inertial-Visual (LIV) sensor configuration has demonstrated superior performance in localization and dense mapping by leveraging complementary sensing characteristics: rich texture information from cameras, precise geometric measurements from LiDAR, and high-frequency motion data from IMU. Inspired by this, we propose a novel real-time Gaussian-based simultaneous localization and mapping (SLAM) system. Our map system comprises a global Gaussian map and a sliding window of Gaussians, along with an IESKF-based odometry. The global Gaussian map consists of hash-indexed voxels organized in a recursive octree, effectively covering sparse spatial volumes while adapting to different levels of detail and scales. The Gaussian map is initialized through multi-sensor fusion and optimized with photometric gradients. Our system incrementally maintains a sliding window of Gaussians, significantly reducing GPU computation and memory consumption by only optimizing the map within the sliding window. Moreover, we implement a tightly coupled multi-sensor fusion odometry with an iterative error state Kalman filter (IESKF), leveraging real-time updating and rendering of the Gaussian map. Our system represents the first real-time Gaussian-based SLAM framework deployable on resource-constrained embedded systems, demonstrated on the NVIDIA Jetson Orin NX platform. The framework achieves real-time performance while maintaining robust multi-sensor fusion capabilities. All implementation algorithms, hardware designs, and CAD models will be publicly available.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/QUAD7QDC/Hong et al. - 2025 - GS-LIVO Real-Time LiDAR, Inertial, and Visual Multi-sensor Fused Odometry with Gaussian Mapping.pdf;/Users/kshitijgoel/Zotero/storage/N978IZXA/2501.html}
}

@article{honig_trajectory_2018,
  title = {Trajectory {{Planning}} for {{Quadrotor Swarms}}},
  author = {H{\"o}nig, Wolfgang and Preiss, James A. and Kumar, T. K. Satish and Sukhatme, Gaurav S. and Ayanian, Nora},
  year = {2018},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {34},
  number = {4},
  pages = {856--869},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2853613},
  url = {https://ieeexplore.ieee.org/document/8424034/?arnumber=8424034},
  urldate = {2024-10-26},
  abstract = {We describe a method for multirobot trajectory planning in known, obstacle-rich environments. We demonstrate our approach on a quadrotor swarm navigating in a warehouse setting. Our method consists of following three stages: 1) roadmap generation that generates sparse roadmaps annotated with possible interrobot collisions; 2) discrete planning that finds valid execution schedules in discrete time and space; 3) continuous refinement that creates smooth trajectories. We account for the downwash effect of quadrotors, allowing safe flight in dense formations. We demonstrate computational efficiency in simulation with up to 200 robots and physical plausibility with an experiment on 32 nano-quadrotors. Our approach can compute safe and smooth trajectories for hundreds of quadrotors in dense environments with obstacles in a few minutes.},
  keywords = {Collision avoidance,Multirobot systems,quadrotor,Robots,Schedules,swarm,Trajectory optimization,unmanned aerial vehicle (UAV),Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/6WLETVML/Hönig et al. - 2018 - Trajectory Planning for Quadrotor Swarms.pdf;/Users/kshitijgoel/Zotero/storage/PEA58E7C/8424034.html}
}

@article{hook_swarms_2022,
  title = {Swarms of {{Pirates}}: {{Red Team Exercises}} Using {{Autonomous High-Speed Maneuvering Surface Vessels}}},
  shorttitle = {Swarms of {{Pirates}}},
  author = {Hook, Joshua Vander and Seto, William and Nguyen, Viet and Hasnain, Zaki and Lee, Carlyn-Ann and Gallagher, Liam and {Halpin-Chan}, Tyler and Varahamurthy, Varun and Angulo, Moises},
  year = {2022},
  month = may,
  journal = {Field Robotics},
  volume = {2},
  pages = {872--909},
  issn = {2771-3989},
  doi = {10.55417/fr.2022029},
  url = {https://ieeexplore.ieee.org/document/10876010/?arnumber=10876010},
  urldate = {2025-03-10},
  abstract = {We present a final overview of the efforts by the Naval Air Warfare Center Weapons Division (NAWCWD) and the Jet Propulsion Laboratory to automate the operation of the largest fleet of autonomous maritime vehicles. The vehicles are intended for large-scale demonstrations and tests of US Navy systems or tactics. This review covers a preexisting distributed architecture for human-in-the-loop control of several autonomous high-speed boats with a main focus on the planning, formation assignment, and formation switching pipeline. Algorithm capabilities are described and validated in simulation and field tests using real-world vehicles. Theoretical lower bounds on the time required to change formations are also derived and used to bound our experimental performance. We are able to present data from the 2019 ``final exam'' that pitted this architecture in a head-to-head competition, which was won after a perfect run with no hazardous maneuvers recorded under autonomous control. The effort concluded successfully on December 31, 2020, with the delivery of code and documentation after successful integration and testing exercises in 2019 and 2020. We conclude the paper with discussions of limitations, extensions, and suggestions for future work.},
  keywords = {agriculture,Boats,Collision avoidance,Controller area networks,Human in the loop,navigation,obstacle avoidance,Pipelines,Planning,Propulsion,Robot sensing systems,Sea surface,Trajectory,wheeled robots},
  file = {/Users/kshitijgoel/Zotero/storage/HCLPB4DA/Hook et al. - 2022 - Swarms of Pirates Red Team Exercises using Autonomous High-Speed Maneuvering Surface Vessels.pdf;/Users/kshitijgoel/Zotero/storage/8N9FIVEM/10876010.html}
}

@article{horn_extended_1984,
  title = {Extended {{Gaussian}} Images},
  author = {Horn, B.K.P.},
  year = {1984},
  month = dec,
  journal = {Proceedings of the IEEE},
  volume = {72},
  number = {12},
  pages = {1671--1686},
  issn = {1558-2256},
  doi = {10.1109/PROC.1984.13073},
  url = {https://ieeexplore.ieee.org/document/1457341/?arnumber=1457341},
  urldate = {2024-07-16},
  abstract = {This is a primer on extended Gaussian images. Extended Gaussian images are useful for representing the shapes of surfaces. They can be computed easily from: 1. needle maps obtained using photometric stereo; or 2. depth maps generated by ranging devices or binocular stereo. Importantly, they can also be determined simply from geometric models of the objects. Extended Gaussian images can be of use in at least two of the tasks facing a machine vision system: 1. recognition, and 2. determining the attitude in space of an object. Here, the extended Gaussian image is defined and some of its properties discussed. An elaboration for nonconvex objects is presented and several examples are shown.},
  keywords = {Artificial intelligence,Image sampling,Image sensors,Interpolation,Machine vision,Needles,Photometry,Position measurement,Shape,Solid modeling},
  file = {/Users/kshitijgoel/Zotero/storage/ZWYF9KAY/Horn - 1984 - Extended Gaussian images.pdf;/Users/kshitijgoel/Zotero/storage/4DYRNYK8/1457341.html}
}

@article{hornik_multilayer_1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  year = {1989},
  month = jan,
  journal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  urldate = {2024-02-02},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation}
}

@article{hornung_octomap_2013,
  title = {{{OctoMap}}: An Efficient Probabilistic {{3D}} Mapping Framework Based on Octrees},
  shorttitle = {{{OctoMap}}},
  author = {Hornung, Armin and Wurm, Kai M. and Bennewitz, Maren and Stachniss, Cyrill and Burgard, Wolfram},
  year = {2013},
  month = apr,
  journal = {Autonomous Robots},
  volume = {34},
  number = {3},
  pages = {189--206},
  issn = {1573-7527},
  doi = {10.1007/s10514-012-9321-0},
  url = {https://doi.org/10.1007/s10514-012-9321-0},
  urldate = {2021-12-22},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9E4GCPYE/Hornung et al. - 2013 - OctoMap an efficient probabilistic 3D mapping fra.pdf}
}

@phdthesis{horvitz_computation_1991,
  title = {Computation and Action under Bounded Resources},
  author = {Horvitz, Eric Joel},
  year = {1991},
  address = {United States -- California},
  url = {https://www.proquest.com/docview/303932222/abstract/C63CAC48DC734398PQ/1},
  urldate = {2025-02-14},
  abstract = {We define and implement a model of rational action for automated reasoning systems that makes use of flexible approximation methods and inexpensive decision-theoretic procedures to determine how best to solve a problem under bounded computational resources. The model provides metareasoning techniques which enable a reasoning system to balance the costs of increased delays with the benefits of better results in a decision context. The decision-theoretic metareasoning techniques can be applied to a variety of computational tasks. We focus on the use of metalevel decision procedures to control complex probabilistic reasoning at the base level. The approach extends traditional decision analyses to autoepistemic models that represent knowledge about problem solving, in addition to knowledge about distinctions and relationships in the world. We found that it can be valuable to allocate a portion of costly reasoning resources to metalevel deliberation about the best way to use additional resources to solve a decision problem. After reviewing principles for applying multiattribute utility theory to the control of basic computational procedures, we describe how these principles can be used to control probabilistic reasoning. In particular, we examine techniques for controlling, at run time, the tradeoff between the complexity of detailed, accurate analyses and the tractability of less complex, yet less accurate probabilistic inference. We present the architecture and functionality of a system named Protos that embodies these principles for making high-stakes decisions under time pressure. We study the behavior of Protos on decision problems in critical-care medicine. Finally, we move beyond our focus on time constraints to consider the constraints on decision-theoretic reasoning posed by the cognitive limitations of people seeking insight from automated decision systems.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798207037509},
  langid = {english},
  school = {Stanford University},
  keywords = {Applied sciences,Computer science,Philosophy,Philosophy religion and theology,Psychology},
  file = {/Users/kshitijgoel/Zotero/storage/9T2RIVHL/Horvitz - 1991 - Computation and action under bounded resources.pdf}
}

@misc{hossain_covernav_2023,
  title = {{{CoverNav}}: {{Cover Following Navigation Planning}} in {{Unstructured Outdoor Environment}} with {{Deep Reinforcement Learning}}},
  shorttitle = {{{CoverNav}}},
  author = {Hossain, Jumman and Faridee, Abu-Zaher and Roy, Nirmalya and Basak, Anjan and Asher, Derrik E.},
  year = {2023},
  month = aug,
  number = {arXiv:2308.06594},
  eprint = {2308.06594},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.06594},
  url = {http://arxiv.org/abs/2308.06594},
  urldate = {2024-12-10},
  abstract = {Autonomous navigation in offroad environments has been extensively studied in the robotics field. However, navigation in covert situations where an autonomous vehicle needs to remain hidden from outside observers remains an underexplored area. In this paper, we propose a novel Deep Reinforcement Learning (DRL) based algorithm, called CoverNav, for identifying covert and navigable trajectories with minimal cost in offroad terrains and jungle environments in the presence of observers. CoverNav focuses on unmanned ground vehicles seeking shelters and taking covers while safely navigating to a predefined destination. Our proposed DRL method computes a local cost map that helps distinguish which path will grant the maximal covertness while maintaining a low cost trajectory using an elevation map generated from 3D point cloud data, the robot's pose, and directed goal information. CoverNav helps robot agents to learn the low elevation terrain using a reward function while penalizing it proportionately when it experiences high elevation. If an observer is spotted, CoverNav enables the robot to select natural obstacles (e.g., rocks, houses, disabled vehicles, trees, etc.) and use them as shelters to hide behind. We evaluate CoverNav using the Unity simulation environment and show that it guarantees dynamically feasible velocities in the terrain when fed with an elevation map generated by another DRL based navigation algorithm. Additionally, we evaluate CoverNav's effectiveness in achieving a maximum goal distance of 12 meters and its success rate in different elevation scenarios with and without cover objects. We observe competitive performance comparable to state of the art (SOTA) methods without compromising accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/2HYXF8PY/Hossain et al. - 2023 - CoverNav Cover Following Navigation Planning in Unstructured Outdoor Environment with Deep Reinforc.pdf;/Users/kshitijgoel/Zotero/storage/FLIICJSV/2308.html}
}

@inproceedings{hossain_encomp_2024,
  title = {{{EnCoMP}}: {{Enhanced Covert Maneuver Planning}} with {{Adaptive Target-Aware Visibility Estimation}} Using {{Offline Reinforcement Learning}}},
  shorttitle = {{{EnCoMP}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Autonomic Computing}} and {{Self-Organizing Systems}} ({{ACSOS}})},
  author = {Hossain, Jumman and Faridee, Abu-Zaher and Roy, Nirmalya and Asher, Derrik E. and Freeman, Jade and Gregory, Timothy and Trout, Theron},
  year = {2024},
  month = sep,
  pages = {51--60},
  doi = {10.1109/ACSOS61780.2024.00023},
  url = {https://ieeexplore.ieee.org/document/10771229},
  urldate = {2024-12-10},
  abstract = {Autonomous robots operating in complex environments face the critical challenge of identifying and utilizing environmental cover for covert navigation to minimize exposure to potentially harmful targets. We propose EnCoMP, an enhanced navigation framework that integrates offline reinforcement learning and our novel Adaptive Target-Aware Visibility Estimation (ATAVE) algorithm to enable robots to navigate covertly and efficiently in diverse outdoor settings. ATAVE is a dynamic probabilistic target modeling technique that we designed to continuously assess and mitigate potential targets in real-time, enhancing the robot's ability to navigate covertly by adapting to evolving environmental and target conditions. Moreover, our approach generates high-fidelity multi-map representations, including cover maps, potential target maps, height maps, and goal maps from LiDAR point clouds, providing a comprehensive understanding of the environment. These multi-maps offer detailed environmental insights, helping in strategic navigation decisions. The goal map encodes the relative distance and direction to the target location, guiding the robot's navigation. We train a Conservative Q-Learning (CQL) model on a large-scale dataset collected from real-world environments, learning a robust policy that maximizes cover utilization, minimizes target exposure, and maintains efficient navigation. We demonstrate our method's capabilities on a physical Jackal robot, showing extensive experiments across diverse terrains. These experiments demonstrate EnCoMP's superior performance compared to state-of-the-art methods, achieving a 95 \% success rate, 85 \% cover utilization, and reducing target exposure to 10.5 \%, while significantly outperforming baselines in navigation efficiency and robustness.},
  keywords = {Covert Map,Covert Navigation,Estimation,Height Map,Heuristic algorithms,Laser radar,Navigation,Offline reinforcement learning,Planning,Point cloud compression,Probabilistic logic,Q-learning,Real-time systems,Reinforcement learning,Robustness,Target Map},
  file = {/Users/kshitijgoel/Zotero/storage/XES9I6AV/Hossain et al. - 2024 - EnCoMP Enhanced Covert Maneuver Planning with Adaptive Target-Aware Visibility Estimation using Off.pdf}
}

@inproceedings{hosseini_matrix_2015,
  title = {Matrix {{Manifold Optimization}} for {{Gaussian Mixtures}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hosseini, Reshad and Sra, Suvrit},
  year = {2015},
  volume = {28},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2015/hash/dbe272bab69f8e13f14b405e038deb64-Abstract.html},
  urldate = {2024-03-27},
  abstract = {We take a new look at parameter estimation for Gaussian Mixture Model (GMMs). Specifically, we advance Riemannian manifold optimization (on the manifold of positive definite matrices) as a potential replacement for Expectation Maximization (EM), which has been the de facto standard for decades. An out-of-the-box invocation of Riemannian optimization, however, fails spectacularly: it obtains the same solution as EM, but vastly slower. Building on intuition from geometric convexity, we propose a simple reformulation that has remarkable consequences: it makes Riemannian optimization not only match EM (a nontrivial result on its own, given the poor record nonlinear programming has had against EM), but also outperform it in many settings. To bring our ideas to fruition, we develop a well-tuned Riemannian LBFGS method that proves superior to known competing methods (e.g., Riemannian conjugate gradient). We hope that our results encourage a wider consideration of manifold optimization in machine learning and statistics.},
  file = {/Users/kshitijgoel/Zotero/storage/2Y2PNY3K/Hosseini and Sra - 2015 - Matrix Manifold Optimization for Gaussian Mixtures.pdf}
}

@misc{hou_learning_2024,
  title = {Learning {{Camera Movement Control}} from {{Real-World Drone Videos}}},
  author = {Hou, Yunzhong and Zheng, Liang and Torr, Philip},
  year = {2024},
  month = dec,
  number = {arXiv:2412.09620},
  eprint = {2412.09620},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.09620},
  url = {http://arxiv.org/abs/2412.09620},
  urldate = {2025-01-30},
  abstract = {This study seeks to automate camera movement control for filming existing subjects into attractive videos, contrasting with the creation of non-existent content by directly generating the pixels. We select drone videos as our test case due to their rich and challenging motion patterns, distinctive viewing angles, and precise controls. Existing AI videography methods struggle with limited appearance diversity in simulation training, high costs of recording expert operations, and difficulties in designing heuristic-based goals to cover all scenarios. To avoid these issues, we propose a scalable method that involves collecting real-world training data to improve diversity, extracting camera trajectories automatically to minimize annotation costs, and training an effective architecture that does not rely on heuristics. Specifically, we collect 99k high-quality trajectories by running 3D reconstruction on online videos, connecting camera poses from consecutive frames to formulate 3D camera paths, and using Kalman filter to identify and remove low-quality data. Moreover, we introduce DVGFormer, an auto-regressive transformer that leverages the camera path and images from all past frames to predict camera movement in the next frame. We evaluate our system across 38 synthetic natural scenes and 7 real city 3D scans. We show that our system effectively learns to perform challenging camera movements such as navigating through obstacles, maintaining low altitude to increase perceived speed, and orbiting towers and buildings, which are very useful for recording high-quality videos. Data and code are available at dvgformer.github.io.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/JKR3Y82V/Hou et al. - 2024 - Learning Camera Movement Control from Real-World Drone Videos.pdf;/Users/kshitijgoel/Zotero/storage/7UCBD8HM/2412.html}
}

@article{hou_primitiveswarm_2025,
  title = {Primitive-{{Swarm}}: {{An Ultra-Lightweight}} and {{Scalable Planner}} for {{Large-Scale Aerial Swarms}}},
  shorttitle = {Primitive-{{Swarm}}},
  author = {Hou, Jialiang and Zhou, Xin and Pan, Neng and Li, Ang and Guan, Yuxiang and Xu, Chao and Gan, Zhongxue and Gao, Fei},
  year = {2025},
  journal = {IEEE Transactions on Robotics},
  volume = {41},
  pages = {3629--3648},
  issn = {1941-0468},
  doi = {10.1109/TRO.2025.3573667},
  url = {https://ieeexplore.ieee.org/document/11015263/},
  urldate = {2025-08-06},
  abstract = {Achieving large-scale aerial swarms is challenging due to the inherent contradictions in balancing computational efficiency and scalability. This article introduces primitive-swarm, an ultra-lightweight and scalable planner designed specifically for large-scale autonomous aerial swarms. The proposed approach adopts a decentralized and asynchronous replanning strategy. Within it is a novel motion primitive library consisting of time-optimal and dynamically feasible trajectories. They are generated utilizing a novel time-optimal path parameterization algorithm based on reachability analysis. Then, a rapid collision checking mechanism is developed by associating the motion primitives with the discrete surrounding space according to conflicts. By considering both spatial and temporal conflicts, the mechanism handles robot-obstacle and robot--robot collisions simultaneously. Then, during a replanning process, each robot selects the safe and minimum cost trajectory from the library based on user-defined requirements. Both the time-optimal motion primitive library and the occupancy information are computed offline, turning a time-consuming optimization problem into a linear-complexity selection problem. This enables the planner to comprehensively explore the nonconvex, discontinuous 3-D safe space filled with numerous obstacles and robots, effectively identifying the best hidden path. Benchmark comparisons demonstrate that our method achieves the shortest flight time and traveled distance with a computation time of less than 1 ms in dense environments. Super large-scale swarm simulations, involving up to 1000 robots, running in real time, verify the scalability of our method. Real-world experiments validate the feasibility and robustness of our approach. The code will be released to foster community collaboration.},
  keywords = {Autonomous aerial vehicles,collision avoidance,Collision avoidance,Computational efficiency,Drones,Heuristic algorithms,Libraries,motion planning,Planning,Robot sensing systems,Robots,Scalability,swarm robotics,Trajectory,trajectory optimization},
  file = {/Users/kshitijgoel/Zotero/storage/MLTSIRWJ/Hou et al. - 2025 - Primitive-Swarm An Ultra-Lightweight and Scalable Planner for Large-Scale Aerial Swarms.pdf}
}

@inproceedings{howard_3d_2004,
  title = {Towards {{3D}} Mapping in Large Urban Environments},
  booktitle = {2004 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}}) ({{IEEE Cat}}. {{No}}.{{04CH37566}})},
  author = {Howard, A. and Wolf, D.F. and Sukhatme, G.S.},
  year = {2004},
  month = sep,
  volume = {1},
  pages = {419-424 vol.1},
  doi = {10.1109/IROS.2004.1389388},
  abstract = {This paper describes work-in-progress aimed at generating dense 3D maps of urban environments using laser range data acquired from a moving platform. These maps display both fine-scale detail (resolving features only a few centimeters across) and large-scale consistency (typical maps are approximately 0.5 km on a side). In this paper, we sketch a basic 3D mapping algorithm (paying particular attention to practical engineering details) and present preliminary results acquired on the USC University Park campus using a Segway RMP vehicle.},
  keywords = {Automotive engineering,Computer displays,Computer science,Global Positioning System,Indoor environments,Large-scale systems,Laser theory,Maximum likelihood estimation,Robots,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/94PXY4R7/Howard et al. - 2004 - Towards 3D mapping in large urban environments.pdf}
}

@inproceedings{hu_1dlrf_2022,
  title = {{{1D-LRF Aided Visual-Inertial Odometry}} for {{High-Altitude MAV Flight}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Hu, Jiaxin and Hu, Jun and Shen, Yunjun and Lang, Xiaoming and Zang, Bo and Huang, Guoquan and Mao, Yinian},
  year = {2022},
  month = may,
  pages = {5858--5864},
  doi = {10.1109/ICRA46639.2022.9811757},
  abstract = {This paper addresses the problem of visual-inertial odometry (VIO) with a downward facing monocular camera when a micro aerial vehicle (MAV) flying at high altitude (over 100 meters). It is important to note that large scene depth causes visual motion constraints significantly less informative than that in near-sighted scenarios as considered in most existing VIO methods. To cope with this challenge, we develop an efficient MSCKF-based VIO algorithm aided by a single 1D laser range finder (LRF), termed LRF-VIO, which runs in real time on an embedded system. The key idea of the proposed LRF-VIO is to fully exploit the limited metric distance information provided by the 1D LRF to disambiguate the scale during visual feature tracking, thus improving the VIO performance at high altitude. Specifically, during the MSCKF visual measurement update, we deliberately constrain the depth of those SLAM features co-planar with the single LRF measuring point. Additionally, delayed initialization of features utilizes the LRF measurements whenever possible, and online extrinsic calibration between the LRF and monocular camera is performed to further improve estimation accuracy and robustness. The proposed LRF-VIO is extensively validated in both indoor and outdoor real-world experiments, outperforming the state-of-the-art methods.},
  keywords = {Estimation,Lasers,Measurement,Meters,Robot vision systems,Simultaneous localization and mapping,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/SPN29WHD/Hu et al. - 2022 - 1D-LRF Aided Visual-Inertial Odometry for High-Alt.pdf;/Users/kshitijgoel/Zotero/storage/Y8JIKTCF/9811757.html}
}

@misc{hu_generalpurpose_2024,
  title = {Toward {{General-Purpose Robots}} via {{Foundation Models}}: {{A Survey}} and {{Meta-Analysis}}},
  shorttitle = {Toward {{General-Purpose Robots}} via {{Foundation Models}}},
  author = {Hu, Yafei and Xie, Quanting and Jain, Vidhi and Francis, Jonathan and Patrikar, Jay and Keetha, Nikhil and Kim, Seungchan and Xie, Yaqi and Zhang, Tianyi and Fang, Hao-Shu and Zhao, Shibo and Omidshafiei, Shayegan and Kim, Dong-Ki and {Agha-mohammadi}, Ali-akbar and Sycara, Katia and {Johnson-Roberson}, Matthew and Batra, Dhruv and Wang, Xiaolong and Scherer, Sebastian and Wang, Chen and Kira, Zsolt and Xia, Fei and Bisk, Yonatan},
  year = {2024},
  month = oct,
  number = {arXiv:2312.08782},
  eprint = {2312.08782},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.08782},
  url = {http://arxiv.org/abs/2312.08782},
  urldate = {2024-11-11},
  abstract = {Building general-purpose robots that operate seamlessly in any environment, with any object, and utilizing various skills to complete diverse tasks has been a long-standing goal in Artificial Intelligence. However, as a community, we have been constraining most robotic systems by designing them for specific tasks, training them on specific datasets, and deploying them within specific environments. These systems require extensively-labeled data and task-specific models. When deployed in real-world scenarios, such systems face several generalization issues and struggle to remain robust to distribution shifts. Motivated by the impressive open-set performance and content generation capabilities of web-scale, large-capacity pre-trained models (i.e., foundation models) in research fields such as Natural Language Processing (NLP) and Computer Vision (CV), we devote this survey to exploring (i) how these existing foundation models from NLP and CV can be applied to the field of general-purpose robotics, and also exploring (ii) what a robotics-specific foundation model would look like. We begin by providing a generalized formulation of how foundation models are used in robotics, and the fundamental barriers to making generalist robots universally applicable. Next, we establish a taxonomy to discuss current work exploring ways to leverage existing foundation models for robotics and develop ones catered to robotics. Finally, we discuss key challenges and promising future directions in using foundation models for enabling general-purpose robotic systems. We encourage readers to view our living GitHub repository 2 of resources, including papers reviewed in this survey, as well as related projects and repositories for developing foundation models for robotics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/PC77MHTJ/Hu et al. - 2024 - Toward General-Purpose Robots via Foundation Models A Survey and Meta-Analysis.pdf;/Users/kshitijgoel/Zotero/storage/FB4K8CHR/2312.html}
}

@article{hu_mapeval_2025,
  title = {{{MapEval}}: {{Towards Unified}}, {{Robust}} and {{Efficient SLAM Map Evaluation Framework}}},
  shorttitle = {{{MapEval}}},
  author = {Hu, Xiangcheng and Wu, Jin and Jia, Mingkai and Yan, Hongyu and Jiang, Yi and Jiang, Binqian and Zhang, Wei and He, Wei and Tan, Ping},
  year = {2025},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {5},
  pages = {4228--4235},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3548441},
  url = {https://ieeexplore.ieee.org/document/10910156/},
  urldate = {2025-04-16},
  abstract = {Evaluating massive-scale point cloud maps in Simultaneous Localization and Mapping (SLAM) still remains challenging due to three limitations: lack of unified standards, poor robustness to noise, and computational inefficiency. We propose MapEval, a novel framework for point cloud map assessment. Our key innovation is a voxelized Gaussian approximation method that enables efficient Wasserstein distance computation while maintaining physical meaning. This leads to two complementary metrics: Voxelized Average Wasserstein Distance (AWD) for global geometry and Spatial Consistency Score (SCS) for local consistency. Extensive experiments demonstrate that MapEval achieves 100- 500 times speedup while maintaining evaluation performance compared to traditional metrics like Chamfer Distance (CD) and Mean Map Entropy (MME). Our framework shows robust performance across both simulated and real-world datasets with million-scale point clouds.},
  keywords = {Accuracy,Benchmarking,evaluation metrics,Geometry,Measurement,Pipelines,Point cloud compression,point cloud evaluation,Quality assessment,Robustness,Simultaneous localization and mapping,SLAM,Standards,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/2HGM9ISH/Hu et al. - 2025 - MapEval Towards Unified, Robust and Efficient SLA.pdf}
}

@misc{hu_metric3d_2024,
  title = {{{Metric3D}} v2: {{A Versatile Monocular Geometric Foundation Model}} for {{Zero-shot Metric Depth}} and {{Surface Normal Estimation}}},
  shorttitle = {{{Metric3D}} V2},
  author = {Hu, Mu and Yin, Wei and Zhang, Chi and Cai, Zhipeng and Long, Xiaoxiao and Chen, Hao and Wang, Kaixuan and Yu, Gang and Shen, Chunhua and Shen, Shaojie},
  year = {2024},
  month = mar,
  number = {arXiv:2404.15506},
  eprint = {2404.15506},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2404.15506},
  urldate = {2024-06-20},
  abstract = {We introduce Metric3D v2, a geometric foundation model for zero-shot metric depth and surface normal estimation from a single image, which is crucial for metric 3D recovery. While depth and normal are geometrically related and highly complimentary, they present distinct challenges. State-of-the-art (SoTA) monocular depth methods achieve zero-shot generalization by learning affine-invariant depths, which cannot recover real-world metrics. Meanwhile, SoTA normal estimation methods have limited zero-shot performance due to the lack of large-scale labeled data. To tackle these issues, we propose solutions for both metric depth estimation and surface normal estimation. For metric depth estimation, we show that the key to a zero-shot single-view model lies in resolving the metric ambiguity from various camera models and large-scale data training. We propose a canonical camera space transformation module, which explicitly addresses the ambiguity problem and can be effortlessly plugged into existing monocular models. For surface normal estimation, we propose a joint depth-normal optimization module to distill diverse data knowledge from metric depth, enabling normal estimators to learn beyond normal labels. Equipped with these modules, our depth-normal models can be stably trained with over 16 million of images from thousands of camera models with different-type annotations, resulting in zero-shot generalization to in-the-wild images with unseen camera settings. Our method current ranks the 1st on various zero-shot and non-zero-shot benchmarks for metric depth, affine-invariant-depth as well as surface-normal prediction, shown in Fig. 1. Notably, we surpassed the ultra-recent MarigoldDepth and DepthAnything on various depth benchmarks including NYUv2 and KITTI. Our method enables the accurate recovery of metric 3D structures on randomly collected internet images, paving the way for plausible single-image metrology. The potential benefits extend to downstream tasks, which can be significantly improved by simply plugging in our model. For example, our model relieves the scale drift issues of monocular-SLAM (Fig. 3), leading to high-quality metric scale dense mapping. These applications highlight the versatility of Metric3D v2 models as geometric foundation models. Our project page is at https://JUGGHM.github.io/Metric3Dv2.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/I9Q3G8NU/Hu et al. - 2024 - Metric3D v2 A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface.pdf}
}

@article{hu_taichi_2019,
  title = {Taichi: A Language for High-Performance Computation on Spatially Sparse Data Structures},
  shorttitle = {Taichi},
  author = {Hu, Yuanming and Li, Tzu-Mao and Anderson, Luke and {Ragan-Kelley}, Jonathan and Durand, Fr{\'e}do},
  year = {2019},
  month = dec,
  journal = {ACM Transactions on Graphics},
  volume = {38},
  number = {6},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3355089.3356506},
  url = {https://dl.acm.org/doi/10.1145/3355089.3356506},
  urldate = {2023-04-13},
  abstract = {3D visual computing data are often spatially sparse. To exploit such sparsity, people have developed hierarchical sparse data structures, such as multi-level sparse voxel grids, particles, and 3D hash tables. However, developing and using these high-performance sparse data structures is challenging, due to their intrinsic complexity and overhead. We propose               Taichi               , a new data-oriented programming language for efficiently authoring, accessing, and maintaining such data structures. The language offers a high-level, data structure-agnostic interface for writing computation code. The user independently specifies the data structure. We provide several elementary components with different sparsity properties that can be arbitrarily composed to create a wide range of multi-level sparse data structures. This               decoupling               of data structures from computation makes it easy to experiment with different data structures without changing computation code, and allows users to write computation as if they are working with a dense array. Our compiler then uses the semantics of the data structure and index analysis to automatically optimize for locality, remove redundant operations for coherent accesses, maintain sparsity and memory allocations, and generate efficient parallel and vectorized instructions for CPUs and GPUs.                                         Our approach yields competitive performance on common computational kernels such as stencil applications, neighbor lookups, and particle scattering. We demonstrate our language by implementing simulation, rendering, and vision tasks including a material point method simulation, finite element analysis, a multigrid Poisson solver for pressure projection, volumetric path tracing, and 3D convolution on sparse grids. Our computation-data structure decoupling allows us to quickly experiment with different data arrangements, and to develop high-performance data structures tailored for specific computational tasks. With               1               {$<$}u{$>$}               1               {$<$}/u{$>$}               0               th as many lines of code, we achieve 4.55{\texttimes} higher performance on average, compared to hand-optimized reference implementations.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z3P5RG4I/Hu et al. - 2019 - Taichi a language for high-performance computatio.pdf}
}

@phdthesis{hu_taichi_2021,
  title = {The {{Taichi High-Performance}} and {{Differentiable Programming Language}} for {{Sparse}} and {{Quantized Visual Computing}}},
  author = {Hu, Yuanming},
  year = {2021},
  month = jun,
  abstract = {Using traditional programming languages such as C++ and CUDA, writing highperformance visual computing code is often laborious and requires deep expertise in performance engineering. This implies an undesirable trade-off between performance and productivity. Emerging visual computing workloads such as sparse data structure operations, differentiable programming, and quantized computation, lead to further development difficulties with existing programming systems. To address these issues, we propose Taichi, an imperative and parallel programming language, tailored for developing high-performance visual computing systems. Taichi leverages domain-specific features of visual computing tasks, providing first-class abstraction and support for spatially sparse computation, differentiable programming, and quantization. With Taichi's optimizing compiler that has a high-level understanding of these domain-specific language constructs and automatically optimizes Taichi programs, we achieve performance and productivity simultaneously in various visual computing tasks, especially physical simulation. For example, with Taichi we can easily achieve 4.55{\texttimes} higher performance using 1/10 lines of code on sparse computations, effortlessly develop 10 differentiable physical simulators, and simulate unprecedented 235 million material point method (MPM) particles on a single GPU.},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  file = {/Users/kshitijgoel/Zotero/storage/U3GWKQCL/Hu - The Taichi High-Performance and Differentiable Pro.pdf}
}

@misc{huang_2d_2024,
  title = {{{2D Gaussian Splatting}} for {{Geometrically Accurate Radiance Fields}}},
  author = {Huang, Binbin and Yu, Zehao and Chen, Anpei and Geiger, Andreas and Gao, Shenghua},
  year = {2024},
  month = mar,
  number = {arXiv:2403.17888},
  eprint = {2403.17888},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.17888},
  urldate = {2024-05-22},
  abstract = {3D Gaussian Splatting (3DGS) has recently revolutionized radiance field reconstruction, achieving high quality novel view synthesis and fast rendering speed without baking. However, 3DGS fails to accurately represent surfaces due to the multi-view inconsistent nature of 3D Gaussians. We present 2D Gaussian Splatting (2DGS), a novel approach to model and reconstruct geometrically accurate radiance fields from multi-view images. Our key idea is to collapse the 3D volume into a set of 2D oriented planar Gaussian disks. Unlike 3D Gaussians, 2D Gaussians provide view-consistent geometry while modeling surfaces intrinsically. To accurately recover thin surfaces and achieve stable optimization, we introduce a perspective-accurate 2D splatting process utilizing ray-splat intersection and rasterization. Additionally, we incorporate depth distortion and normal consistency terms to further enhance the quality of the reconstructions. We demonstrate that our differentiable renderer allows for noise-free and detailed geometry reconstruction while maintaining competitive appearance quality, fast training speed, and real-time rendering. Our code will be made publicly available.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/L47G48FR/Huang et al. - 2024 - 2D Gaussian Splatting for Geometrically Accurate Radiance Fields.pdf}
}

@inproceedings{huang_collision_2024,
  title = {Collision {{Avoidance}} and {{Navigation}} for a {{Quadrotor Swarm Using End-to-end Deep Reinforcement Learning}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Huang, Zhehui and Yang, Zhaojing and Krupani, Rahul and {\c S}enba{\c s}lar, Bask{\i}n and Batra, Sumeet and Sukhatme, Gaurav S.},
  year = {2024},
  month = may,
  pages = {300--306},
  doi = {10.1109/ICRA57147.2024.10611499},
  url = {https://ieeexplore.ieee.org/document/10611499/},
  urldate = {2025-08-12},
  abstract = {End-to-end deep reinforcement learning (DRL) for quadrotor control promises many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our work is the first work that demonstrates the possibility of learning neighbor-avoiding and obstacle-avoiding control policies trained with end-to-end DRL that transfers zero-shot to real quadrotors. Our approach scales to 32 robots with 80\% obstacle density in simulation and 8 robots with 20\% obstacle density in physical deployment. Website: https://sites.google.com/view/obst-avoid-swarm-rl},
  keywords = {Collision avoidance,Deep reinforcement learning,Hardware,Navigation,Planning,Real-time systems,Training},
  file = {/Users/kshitijgoel/Zotero/storage/86U2I2Y2/Huang et al. - 2024 - Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learnin.pdf}
}

@misc{huang_error_2024,
  title = {On the {{Error Analysis}} of {{3D Gaussian Splatting}} and an {{Optimal Projection Strategy}}},
  author = {Huang, Letian and Bai, Jiayang and Guo, Jie and Li, Yuanqi and Guo, Yanwen},
  year = {2024},
  month = feb,
  number = {arXiv:2402.00752},
  eprint = {2402.00752},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2402.00752},
  urldate = {2024-07-23},
  abstract = {3D Gaussian Splatting has garnered extensive attention and application in real-time neural rendering. Concurrently, concerns have been raised about the limitations of this technology in aspects such as point cloud storage, performance, and robustness in sparse viewpoints, leading to various improvements. However, there has been a notable lack of attention to the fundamental problem of projection errors introduced by the local affine approximation inherent in the splatting itself, and the consequential impact of these errors on the quality of photo-realistic rendering. This paper addresses the projection error function of 3D Gaussian Splatting, commencing with the residual error from the first-order Taylor expansion of the projection function. The analysis establishes a correlation between the error and the Gaussian mean position. Subsequently, leveraging function optimization theory, this paper analyzes the function's minima to provide an optimal projection strategy for Gaussian Splatting referred to Optimal Gaussian Splatting, which can accommodate a variety of camera models. Experimental validation further confirms that this projection methodology reduces artifacts, resulting in a more convincingly realistic rendering.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/GYRBYS9I/Huang et al. - 2024 - On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection Strategy.pdf}
}

@article{huang_impulsivity_2024,
  title = {Impulsivity Is a Stable, Measurable, and Predictive Psychological Trait},
  author = {Huang, Yuqi and Luan, Shenghua and Wu, Baizhou and Li, Yugang and Wu, Junhui and Chen, Wenfeng and Hertwig, Ralph},
  year = {2024},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {24},
  pages = {e2321758121},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2321758121},
  url = {https://www.pnas.org/doi/10.1073/pnas.2321758121},
  urldate = {2025-02-14},
  abstract = {Impulsivity is a personality construct frequently employed to explain and predict important human behaviors. Major inconsistencies in its definition and measurement, however, have led some researchers to call for an outright rejection of impulsivity as a psychological construct. We address this highly unsatisfactory state with a large-scale, preregistered study (N = 1,676) in which each participant completed 48 measures of impulsivity derived from 10 self-report scales and 10 behavioral tasks and reported frequencies of seven impulsivity-related behaviors (e.g., impulsive buying and social media usage); a subsample (N = 196) then completed a retest session 3 mo later. We found that correlations between self-report measures were substantially higher than those between behavioral tasks and between self-report measures and behavioral tasks. Bifactor analysis of these measures exacted one general factor of impulsivity I, akin to the general intelligence factor g, and six specific factors. Factor I was related mainly to self-report measures, had high test--retest reliability, and could predict impulsivity-related behaviors better than existing measures. We further developed a scale named the adjustable impulsivity scale (AIMS) to measure I. AIMS possesses excellent psychometric properties that are largely retained in shorter versions and could predict impulsivity-related behaviors equally well as I. These findings collectively support impulsivity as a stable, measurable, and predictive trait, indicating that it may be too early to reject it as a valid and useful psychological construct. The bifactorial structure of impulsivity and AIMS, meanwhile, significantly advance the conceptualization and measurement of construct impulsivity.},
  file = {/Users/kshitijgoel/Zotero/storage/TYW5YS9N/Huang et al. - 2024 - Impulsivity is a stable, measurable, and predictive psychological trait.pdf}
}

@article{huang_universal_2024,
  title = {Universal {{Features}} for {{High-Dimensional Learning}} and {{Inference}}},
  author = {Huang, Shao-Lun and Makur, Anuran and Wornell, Gregory W. and Zheng, Lizhong},
  year = {2024},
  month = feb,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {21},
  number = {1-2},
  pages = {1--299},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000107},
  url = {https://www.nowpublishers.com/article/Details/CIT-107},
  urldate = {2024-04-29},
  abstract = {Universal Features for High-Dimensional Learning and Inference},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UKM4WAX9/Huang et al. - 2024 - Universal Features for High-Dimensional Learning a.pdf}
}

@inproceedings{huber_entropy_2008,
  title = {On Entropy Approximation for {{Gaussian}} Mixture Random Vectors},
  booktitle = {2008 {{IEEE International Conference}} on {{Multisensor Fusion}} and {{Integration}} for {{Intelligent Systems}}},
  author = {Huber, Marco F. and Bailey, Tim and {Durrant-Whyte}, Hugh and Hanebeck, Uwe D.},
  year = {2008},
  month = aug,
  pages = {181--188},
  publisher = {IEEE},
  address = {Seoul},
  doi = {10.1109/MFI.2008.4648062},
  url = {http://ieeexplore.ieee.org/document/4648062/},
  urldate = {2023-11-24},
  abstract = {For many practical probability density representations such as for the widely used Gaussian mixture densities, an analytic evaluation of the differential entropy is not possible and thus, approximate calculations are inevitable. For this purpose, the first contribution of this paper deals with a novel entropy approximation method for Gaussian mixture random vectors, which is based on a component-wise Taylor-series expansion of the logarithm of a Gaussian mixture and on a splitting method of Gaussian mixture components. The employed order of the Taylor-series expansion and the number of components used for splitting allows balancing between accuracy and computational demand. The second contribution is the determination of meaningful and efficiently to calculate lower and upper bounds of the entropy, which can be also used for approximation purposes. In addition, a refinement method for the more important upper bound is proposed in order to approach the true entropy value.},
  isbn = {978-1-4244-2143-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VAHWFK8N/Huber et al. - 2008 - On entropy approximation for Gaussian mixture rand.pdf}
}

@article{huber_fast_2023,
  title = {Fast {{Obstacle Avoidance Based}} on {{Real-Time Sensing}}},
  author = {Huber, Lukas and Slotine, Jean-Jacques and Billard, Aude},
  year = {2023},
  month = mar,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {3},
  pages = {1375--1382},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3232271},
  abstract = {Humans excel at navigating and moving through dynamic and complex spaces, such as crowded streets. For robots to do the same, it is crucial that they are endowed with highly reactive obstacle avoidance which is adept at partial and poor sensing. We address the issue of enabling obstacle avoidance based on sparse and asynchronous perception. The proposed control scheme combines a high-level input command provided by either a planner or a human operator with fast reactive obstacle avoidance (FOA). The sampling-based sensor data can be combined with an analytical reconstruction of the obstacles for real-time collision avoidance. Thus, we can ensure that the agent does not become stuck when a feasible path exists between obstacles. Our algorithm was evaluated experimentally on static laser data from cluttered, indoor office environments. Additionally, it was used in shared-control mode in a dynamic and complex outdoor environment in the center of Lausanne. The proposed control scheme successfully avoided collisions in both scenarios. During the experiments, the controller took 1 ms to evaluate over 30000 data points.},
  keywords = {autonomous agents,Collision avoidance,crowd navigation,dynamical systems,Eigenvalues and eigenfunctions,Heuristic algorithms,Matrix decomposition,mobile robots,Modulation,Navigation,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/XT5IUGXU/Huber et al. - 2023 - Fast Obstacle Avoidance Based on Real-Time Sensing.pdf;/Users/kshitijgoel/Zotero/storage/XXVNQ9SU/stamp.html}
}

@article{hudson_heterogeneous_2022,
  title = {Heterogeneous {{Ground}} and {{Air Platforms}}, {{Homogeneous Sensing}}: {{Team CSIRO Data61}}'s {{Approach}} to the {{DARPA Subterranean Challenge}}},
  shorttitle = {Heterogeneous {{Ground}} and {{Air Platforms}}, {{Homogeneous Sensing}}},
  author = {Hudson, Nicolas and Talbot, Fletcher and Cox, Mark and Williams, Jason and Hines, Thomas and Pitt, Alex and Wood, Brett and Frousheger, Dennis and Lo Surdo, Katrina and Molnar, Thomas and Steindl, Ryan and Wildie, Matt and Sa, Inkyu and Kottege, Navinda and Stepanas, Kazys and Hernandez, Emili and Catt, Gavin and Docherty, William and Tidd, Brendan and Tam, Benjamin and Murrell, Simon and Bessell, Mitchell and Hanson, Lauren and {Tychsen-Smith}, Lachlan and Suzuki, Hajime and Overs, Leslie and Kendoul, Farid and Wagner, Glenn and Palmer, Duncan and Milani, Peter and O'Brien, Matthew and Jiang, Shu and Chen, Shengkang and Arkin, Ronald},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {595--636},
  issn = {27713989},
  doi = {10.55417/fr.2022021},
  url = {https://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_21.pdf},
  urldate = {2023-01-26},
  abstract = {Heterogeneous teams of robots, leveraging a balance between autonomy and human interaction, bring powerful capabilities to the problem of exploring dangerous, unstructured subterranean environments. Here we describe the solution developed by Team CSIRO Data61, consisting of CSIRO, Emesent, and Georgia Tech, during the DARPA Subterranean Challenge. These presented systems were fielded in the Tunnel Circuit in August 2019, the Urban Circuit in February 2020, and in our own Cave event, conducted in September 2020. A unique capability of the fielded team is the homogeneous sensing of the platforms utilized, which is used to obtain a decentralized multi-agent SLAM solution on each platform (both ground agents and UAVs) using peer-to-peer communications. This approach enabled a shift in focus from constructing a pervasive communications network to relying on multi-agent autonomy, motivated by experiences in early circuit events. These experiences also showed the surprising capability of rugged tracked platforms for challenging terrain, which in turn led to the heterogeneous team structure based on a BIA5 OzBot Titan ground robot and an Emesent Hovermap UAV, supplemented by smaller tracked or legged ground robots. The ground agents use a common CatPack perception module, which allowed reuse of the perception and autonomy stack across all ground agents with minimal adaptation.},
  file = {/Users/kshitijgoel/Zotero/storage/GSLV4F49/Hudson et al. - 2022 - Heterogeneous Ground and Air Platforms, Homogeneou.pdf}
}

@article{hughes_foundations_2024,
  title = {Foundations of Spatial Perception for Robotics: {{Hierarchical}} Representations and Real-Time Systems},
  shorttitle = {Foundations of Spatial Perception for Robotics},
  author = {Hughes, Nathan and Chang, Yun and Hu, Siyi and Talak, Rajat and Abdulhai, Rumaia and Strader, Jared and Carlone, Luca},
  year = {2024},
  month = sep,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {10},
  pages = {1457--1505},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241229725},
  url = {https://doi.org/10.1177/02783649241229725},
  urldate = {2024-11-01},
  abstract = {3D spatial perception is the problem of building and maintaining an actionable and persistent representation of the environment in real-time using sensor data and prior knowledge. Despite the fast-paced progress in robot perception, most existing methods either build purely geometric maps (as in traditional SLAM) or ``flat'' metric-semantic maps that do not scale to large environments or large dictionaries of semantic labels. The first part of this paper is concerned with representations: we show that scalable representations for spatial perception need to be hierarchical in nature. Hierarchical representations are efficient to store, and lead to layered graphs with small treewidth, which enable provably efficient inference. We then introduce an example of hierarchical representation for indoor environments, namely a 3D scene graph, and discuss its structure and properties. The second part of the paper focuses on algorithms to incrementally construct a 3D scene graph as the robot explores the environment. Our algorithms combine 3D geometry (e.g., to cluster the free space into a graph of places), topology (to cluster the places into rooms), and geometric deep learning (e.g., to classify the type of rooms the robot is moving across). The third part of the paper focuses on algorithms to maintain and correct 3D scene graphs during long-term operation. We propose hierarchical descriptors for loop closure detection and describe how to correct a scene graph in response to loop closures, by solving a 3D scene graph optimization problem. We conclude the paper by combining the proposed perception algorithms into Hydra, a real-time spatial perception system that builds a 3D scene graph from visual-inertial data in real-time. We showcase Hydra's performance in photo-realistic simulations and real data collected by a Clearpath Jackal robots and a Unitree A1 robot. We release an open-source implementation of Hydra at https://github.com/MIT-SPARK/Hydra.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6DIFQVZ8/Hughes et al. - 2024 - Foundations of spatial perception for robotics Hierarchical representations and real-time systems.pdf}
}

@inproceedings{hughes_hydra_2022,
  title = {Hydra: {{A Real-time Spatial Perception System}} for {{3D Scene Graph Construction}} and {{Optimization}}},
  shorttitle = {Hydra},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Hughes, Nathan and Chang, Yun and Carlone, Luca},
  year = {2022},
  month = jun,
  volume = {18},
  url = {http://www.roboticsproceedings.org/rss18/p050.html},
  urldate = {2023-03-16},
  isbn = {978-0-9923747-8-5},
  file = {/Users/kshitijgoel/Zotero/storage/I3BYYKMN/Hughes et al. - 2022 - Hydra A Real-time Spatial Perception System for 3.pdf}
}

@misc{hughes_multirobot_2024,
  title = {Multi-{{Robot Planning}} for {{Filming Groups}} of {{Moving Actors Leveraging Submodularity}} and {{Pixel Density}}},
  author = {Hughes, Skyler and Martin, Rebecca and Corah, Micah and Scherer, Sebastian},
  year = {2024},
  month = sep,
  number = {arXiv:2404.03103},
  eprint = {2404.03103},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.03103},
  url = {http://arxiv.org/abs/2404.03103},
  urldate = {2024-12-11},
  abstract = {Observing and filming a group of moving actors with a team of aerial robots is a challenging problem that combines elements of multi-robot coordination, coverage, and view planning. A single camera may observe multiple actors at once, and a robot team may observe individual actors from multiple views. As actors move about, groups may split, merge, and reform, and robots filming these actors should be able to adapt smoothly to such changes in actor formations. Rather than adopt an approach based on explicit formations or assignments, we propose an approach based on optimizing views directly. We model actors as moving polyhedra and compute approximate pixel densities for each face and camera view. Then, we propose an objective that exhibits diminishing returns as pixel densities increase from repeated observation. This gives rise to a multi-robot perception planning problem that we solve via a combination of value iteration and greedy submodular maximization. We evaluate our approach on challenging scenarios modeled after various social behaviors and featuring different numbers of robots and actors and observe that robot assignments and formations arise implicitly given the movements of groups of actors. Simulation results demonstrate that our approach consistently outperforms baselines, and in addition to performing well with the planner's approximation of pixel densities our approach also performs comparably for evaluation based on rendered views. Overall, the multi-round variant of the sequential planner we propose meets (within 1\%) or exceeds formation and assignment baselines in all scenarios.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/kshitijgoel/Zotero/storage/NM23C4RJ/Hughes et al. - 2024 - Multi-Robot Planning for Filming Groups of Moving Actors Leveraging Submodularity and Pixel Density.pdf;/Users/kshitijgoel/Zotero/storage/IED3N2PJ/2404.html}
}

@article{hui_pcexplorer_2025,
  title = {{{PC-Explorer}}: {{Decentralized Multi-UAV Exploration}} in {{Bandwidth-Limited Environments}}},
  shorttitle = {{{PC-Explorer}}},
  author = {Hui, Yulin and Chang, Guangju and Lu, Junjie and Zhang, Xuewei and Li, Zhiyu and Tian, Bailing},
  year = {2025},
  month = sep,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {9},
  pages = {9200--9207},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3592139},
  url = {https://ieeexplore.ieee.org/document/11091481/},
  urldate = {2025-08-06},
  abstract = {Achieving efficient cooperative exploration with multiple Uncrewed Aerial Vehicles (UAV) is challenging due to the conflict between the requirement for map sharing among UAVs and the limited onboard communication resources. In this letter, we propose PC-Explorer, a decentralized cooperative exploration planner designed for bandwidth-limited environments. To enable efficient data transmission, the map information is abstracted into two novel structures: the spatial information of globally known areas is abstracted into pseudo-convex polytope (PC-polytope), while the information of unknown areas is represented by frontier-cluster cuboid (FC-cuboid). These data structures are further encoded into a lightweight exploration message package (EMP) for transmission among UAVs, which helps to construct an exploration information map on each UAV independently. Supported by the information map, an efficient cooperative exploration planner is developed to generate exploration trajectory for each UAV. The performance of PC-Explorer is compared with state-of-the-art methods in simulation, and its effectiveness is further validated in a real-world experiment conducted in a forest of 5909.89 m2.},
  keywords = {aerial systems: applications,aerial systems: perception and autonomy,Autonomous aerial vehicles,Bandwidth,Cooperating robots,Forestry,Planning,Point cloud compression,Resource management,Robots,Space exploration,Training,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/NMMFVWP4/Hui et al. - 2025 - PC-Explorer Decentralized Multi-UAV Exploration in Bandwidth-Limited Environments.pdf}
}

@inproceedings{ichnowski_concurrent_2020,
  title = {Concurrent {{Nearest-Neighbor Searching}} for {{Parallel Sampling-Based Motion Planning}} in {{SO}}(3), {{SE}}(3), and {{Euclidean Spaces}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIII}}},
  author = {Ichnowski, Jeffrey and Alterovitz, Ron},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {69--85},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-44051-0_5},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-44051-0_5},
  abstract = {This paper presents a fast exact nearest neighbor searching data structure and method that is designed to operate under highly-concurrent parallel operation on modern multi-core processors. Based on a kd-tree, the proposed method is fast, supports metric spaces common to robot motion planning, and supports nearest, k-nearest, and radius-based queries. But unlike traditional approaches using kd-trees, our approach supports simultaneous queries and insertions under concurrency, supports wait-free queries, and provides asymptotically diminishing expected wait-times for random concurrent inserts. We provide proofs of correctness under concurrency, and we demonstrate the proposed method's performance in a parallelized asymptotically-optimal sampling-based motion planner.},
  isbn = {978-3-030-44051-0},
  langid = {english},
  keywords = {Concurrent data structure,Nearest neighbors,Sampling-based motion planning},
  file = {/Users/kshitijgoel/Zotero/storage/IJI25NI6/Ichnowski and Alterovitz - 2020 - Concurrent Nearest-Neighbor Searching for Parallel.pdf}
}

@incollection{ichnowski_fast_2015,
  title = {Fast {{Nearest Neighbor Search}} in {{SE}}(3) for {{Sampling-Based Motion Planning}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XI}}: {{Selected Contributions}} of the {{Eleventh International Workshop}} on the {{Algorithmic Foundations}} of {{Robotics}}},
  author = {Ichnowski, Jeffrey and Alterovitz, Ron},
  editor = {Akin, H. Levent and Amato, Nancy M. and Isler, Volkan and {van der Stappen}, A. Frank},
  year = {2015},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {197--214},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-16595-0_12},
  url = {https://doi.org/10.1007/978-3-319-16595-0_12},
  urldate = {2023-05-10},
  abstract = {Nearest neighborIchnowski, JeffreysearchingNearest neighbor searchingis aAlterovitz, Ronfundamental building block of most sampling-based motion planners. We present a novel method for fast exact nearest neighbor searching in \$\$SE(3)\$\$SE(3)---the 6 dimensional space that represents rotations and translations in 3 dimensions. \$\$SE(3)\$\$SE(3)is commonly used when planning the motions of rigid body robots. Our approach starts by projecting a 4-dimensional cube onto the 3-sphere that is created by the unit quaternion representation of rotations in the rotational group \$\$\{ SO\}(3)\$\$SO(3). We then use 4 kd-trees to efficiently partition the projected faces (and their negatives). We propose efficient methods to handle the recursion pruning checks that arise with this kd-tree splitting approach, discuss splitting strategies that support dynamic data sets, and extend this approach to \$\$SE(3)\$\$SE(3)by incorporating translations. We integrate our approach into RRT and RRT* and demonstrate the fast performance and efficient scaling of our nearest neighbor search as the tree size increases.},
  isbn = {978-3-319-16595-0},
  langid = {english},
  keywords = {Motion Planner,Motion Planning,Neighbor Search,Priority Queue,Rapidly Explore Random Tree},
  file = {/Users/kshitijgoel/Zotero/storage/LRL27BGJ/Ichnowski and Alterovitz - 2015 - Fast Nearest Neighbor Search in SE(3) for Sampling.pdf}
}

@phdthesis{ichnowski_scaling_2019,
  title = {Scaling {{Robot Motion Planning}} to {{Multi-Core Processors}} and the {{Cloud}}},
  author = {Ichnowski, Jeffrey},
  year = {2019},
  address = {United States -- North Carolina},
  url = {https://www.proquest.com/docview/2241621195/abstract/42B70CE6E5EE4E4EPQ/1},
  urldate = {2023-05-11},
  abstract = {Imagine a world in which robots safely interoperate with humans, gracefully and efficiently accomplishing everyday tasks. The robot's motions for these tasks, constrained by the design of the robot and task at hand, must avoid collisions with obstacles. Unfortunately, planning a constrained obstacle-free motion for a robot is computationally complex---often resulting in slow computation of inefficient motions. The methods in this dissertation speed up this motion plan computation with new algorithms and data structures that leverage readily available parallel processing, whether that processing power is on the robot or in the cloud, enabling robots to operate safer, more gracefully, and with improved efficiency. The contributions of this dissertation that enable faster motion planning are novel parallel lock-free algorithms, fast and concurrent nearest neighbor searching data structures, cache-aware operation, and split robot-cloud computation. Parallel lock-free algorithms avoid contention over shared data structures, resulting in empirical speedup proportional to the number of CPU cores working on the problem. Fast nearest neighbor data structures speed up searching in SO(3) and SE(3) metric spaces, which are needed for rigid body motion planning. Concurrent nearest neighbor data structures improve searching performance on metric spaces common to robot motion planning problems, while providing asymptotic wait-free concurrent operation. Cache-aware operation avoids long memory access times, allowing the algorithm to exhibit superlinear speedup. Split robot-cloud computation enables robots with low-power CPUs to react to changing environments by having the robot compute reactive paths in real-time from a set of motion plan options generated in a computationally intensive cloud-based algorithm. We demonstrate the scalability and effectiveness of our contributions in solving motion planning problems both in simulation and on physical robots of varying design and complexity. Problems include finding a solution to a complex motion planning problem, pre-computing motion plans that converge towards the optimal, and reactive interaction with dynamic environments. Robots include 2D holonomic robots, 3D rigid-body robots, a self-driving 1/10 scale car, articulated robot arms with and without mobile bases, and a small humanoid robot.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9781392202838},
  langid = {english},
  school = {The University of North Carolina at Chapel Hill},
  keywords = {Applied sciences,Cache-aware,Cloud-based computing,Concurrent data structure,Nearest neighbor searching,Robot motion planning,Software architecture},
  file = {/Users/kshitijgoel/Zotero/storage/QEDEILZ7/Ichnowski - Scaling Robot Motion Planning to Multi-Core Proces.pdf}
}

@article{indelman_planning_2015,
  title = {Planning in the Continuous Domain: {{A}} Generalized Belief Space Approach for Autonomous Navigation in Unknown Environments},
  shorttitle = {Planning in the Continuous Domain},
  author = {Indelman, Vadim and Carlone, Luca and Dellaert, Frank},
  year = {2015},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {34},
  number = {7},
  pages = {849--882},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364914561102},
  url = {https://doi.org/10.1177/0278364914561102},
  urldate = {2023-10-23},
  abstract = {We investigate the problem of planning under uncertainty, with application to mobile robotics. We propose a probabilistic framework in which the robot bases its decisions on the generalized belief, which is a probabilistic description of its own state and of external variables of interest. The approach naturally leads to a dual-layer architecture: an inner estimation layer, which performs inference to predict the outcome of possible decisions; and an outer decisional layer which is in charge of deciding the best action to undertake. Decision making is entrusted to a model predictive control (MPC) scheme. The formulation is valid for general cost functions and does not discretize the state or control space, enabling planning in continuous domain. Moreover, it allows to relax the assumption of maximum likelihood observations: predicted measurements are treated as random variables, and binary random variables are used to model the event that a measurement is actually taken by the robot. We successfully apply our approach to the problem of uncertainty-constrained exploration, in which the robot has to perform tasks in an unknown environment, while maintaining localization uncertainty within given bounds. We present an extensive numerical analysis of the proposed approach and compare it against related work. In practice, our planning approach produces smooth and natural trajectories and is able to impose soft upper bounds on the uncertainty. Finally, we exploit the results of this analysis to identify current limitations and show that the proposed framework can accommodate several desirable extensions.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/X8IDB5MQ/Indelman et al. - 2015 - Planning in the continuous domain A generalized b.pdf}
}

@inproceedings{indyk_approximate_1998,
  title = {Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality},
  shorttitle = {Approximate Nearest Neighbors},
  booktitle = {Proceedings of the Thirtieth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Indyk, Piotr and Motwani, Rajeev},
  year = {1998},
  month = may,
  series = {{{STOC}} '98},
  pages = {604--613},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/276698.276876},
  url = {https://doi.org/10.1145/276698.276876},
  urldate = {2024-07-18},
  isbn = {978-0-89791-962-3},
  file = {/Users/kshitijgoel/Zotero/storage/D3PQCLAB/Indyk and Motwani - 1998 - Approximate nearest neighbors towards removing the curse of dimensionality.pdf}
}

@misc{intelligence_$p_05$_2025,
  title = {\${$\pi\_$}\{0.5\}\$: A {{Vision-Language-Action Model}} with {{Open-World Generalization}}},
  shorttitle = {\${$\pi\_$}\{0.5\}\$},
  author = {Intelligence, Physical and Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Galliker, Manuel Y. and Ghosh, Dibya and Groom, Lachy and Hausman, Karol and Ichter, Brian and Jakubczak, Szymon and Jones, Tim and Ke, Liyiming and LeBlanc, Devin and Levine, Sergey and {Li-Bell}, Adrian and Mothukuri, Mohith and Nair, Suraj and Pertsch, Karl and Ren, Allen Z. and Shi, Lucy Xiaoyang and Smith, Laura and Springenberg, Jost Tobias and Stachowicz, Kyle and Tanner, James and Vuong, Quan and Walke, Homer and Walling, Anna and Wang, Haohuan and Yu, Lili and Zhilinsky, Ury},
  year = {2025},
  month = apr,
  number = {arXiv:2504.16054},
  eprint = {2504.16054},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.16054},
  url = {http://arxiv.org/abs/2504.16054},
  urldate = {2025-05-24},
  abstract = {In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe \${\textbackslash}pi\_\{0.5\}\$, a new model based on \${\textbackslash}pi\_\{0\}\$ that uses co-training on heterogeneous tasks to enable broad generalization. \${\textbackslash}pi\_\{0.5\}\${\textbackslash} uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/E7NBE3VN/Intelligence et al. - 2025 - $π_ 0.5 $ a Vision-Language-Action Model with Open-World Generalization.pdf}
}

@inproceedings{irani_factorization_2000,
  title = {Factorization with {{Uncertainty}}},
  booktitle = {Computer {{Vision}} - {{ECCV}} 2000},
  author = {Irani, Michal and Anandan, P.},
  year = {2000},
  pages = {539--553},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45054-8_35},
  abstract = {Factorization using Singular Value Decomposition (SVD) is often used for recovering 3D shape and motion from feature correspondences across multiple views. SVD is powerful at finding the global solution to the associated least-square-error minimization problem. However, this is the correct error to minimize only when the x and y positional errors in the features are uncorrelated and identically distributed. But this is rarely the case in real data. Uncertainty in feature position depends on the underlying spatial intensity structure in the image, which has strong directionality to it. Hence, the proper measure to minimize is covariance-weighted squared-error (or the Mahalanobis distance). In this paper, we describe a new approach to covariance-weighted factorization, which can factor noisy feature correspondences with high degree of directional uncertainty into structure and motion. Our approach is based on transforming the raw-data into a covariance-weighted data space, where the components of noise in the different directions are uncorrelated and identically distributed. Applying SVD to the transformed data now minimizes a meaningful objective function. We empirically show that our new algorithm gives good results for varying degrees of directional uncertainty. In particular, we show that unlike other SVD-based factorization algorithms, our method does not degrade with increase in directionality of uncertainty, even in the extreme when only normal-flow data is available. It thus provides a unified approach for treating corner-like points together with points along linear structures in the image.},
  isbn = {978-3-540-45054-2},
  langid = {english},
  keywords = {Factorization Algorithm,Feature Position,Mahalanobis Distance,Singular Value Decomposition,Singular Value Decomposition Algorithm},
  file = {/Users/kshitijgoel/Zotero/storage/SX4GWFIV/Irani and Anandan - 2000 - Factorization with Uncertainty.pdf}
}

@article{isaacs_teleoperation_2022,
  title = {Teleoperation for {{Urban Search}} and {{Rescue Applications}}},
  author = {Isaacs, Jason and Knoedler, Kevin and Herdering, Andrew and Beylik, Mishell and Quintero, Hugo},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {1177--1190},
  issn = {27713989},
  doi = {10.55417/fr.2022039},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_39.pdf},
  urldate = {2023-01-26},
  abstract = {An important application of field robotics research is robotic assistance for search and rescue operations. The problem of robotic search and rescue requires techniques to map, navigate, and search unknown complex environments. In subterranean domains such as tunnels, caves, and underground urban environments these activities are made more difficult due to communication constraints and unavailability of global positioning systems. We present here Coordinated Robotics participation in the Urban Circuit of the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge which addresses these problems in the underground urban environment. Our Teleoperation strategy serves as a baseline approach by which to compare autonomous solutions. Our aim is to provide insight into our system design and our lessons learned from the competition.},
  file = {/Users/kshitijgoel/Zotero/storage/LAE888CE/Isaacs et al. - 2022 - Teleoperation for Urban Search and Rescue Applicat.pdf}
}

@inproceedings{isik_adaptive_2024,
  title = {Adaptive {{Compression}} in {{Federated Learning}} via {{Side Information}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Isik, Berivan and Pase, Francesco and Gunduz, Deniz and Koyejo, Sanmi and Weissman, Tsachy and Zorzi, Michele},
  year = {2024},
  month = apr,
  pages = {487--495},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/isik24a.html},
  urldate = {2024-04-29},
  abstract = {The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client n sends a sample from a client-only probability distribution {$q\phi$}({$n$})q{$\phi$}(n)q\_\{{\textbackslash}phi{\textasciicircum}\{(n)\}\}, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a global distribution {$p\theta$}p{\texttheta}p\_\{{\textbackslash}theta\} that is close to the client-only distribution {$q\phi$}({$n$})q{$\phi$}(n)q\_\{{\textbackslash}phi{\textasciicircum}\{(n)\}\} in Kullback-Leibler (KL) divergence. In this work, we exploit this {\textbackslash}emph\{closeness\} between the clients' distributions {$q\phi$}({$n$})q{$\phi$}(n)q\_\{{\textbackslash}phi{\textasciicircum}\{(n)\}\}'s and the side information {$p\theta$}p{\texttheta}p\_\{{\textbackslash}theta\} at the server, and propose a framework that requires approximately {$DKL$}({$q\phi$}({$n$}){\textbar}{\textbar}{$p\theta$})DKL(q{$\phi$}(n){\textbar}{\textbar}p{\texttheta})D\_\{KL\}(q\_\{{\textbackslash}phi{\textasciicircum}\{(n)\}\}{\textbar}{\textbar} p\_\{{\textbackslash}theta\}) bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks to attain the same (and often higher) test accuracy with up to 82 times smaller bitrate than the prior work -- corresponding to 2,650 times overall compression.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LUXKGBJG/Isik et al. - 2024 - Adaptive Compression in Federated Learning via Sid.pdf}
}

@article{ivan_online_2022,
  title = {Online {{Distance Field Priors}} for {{Gaussian Process Implicit Surfaces}}},
  author = {Ivan, Jean-Paul A. and Stoyanov, Todor and Stork, Johannes A.},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {8996--9003},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3189434},
  url = {https://ieeexplore.ieee.org/document/9822213},
  urldate = {2024-06-03},
  abstract = {Gaussian process (GP) implicit surface models provide environment and object representations which elegantly address noise and uncertainty while remaining sufficiently flexible to capture complex geometry. However, GP models quickly become intractable as the size of the observation set grows---a trait which is difficult to reconcile with the rate at which modern range sensors produce data. Furthermore, na{\"i}ve applications of GPs to implicit surface models allocate model resources uniformly, thus using precious resources to capture simple geometry. In contrast to prior work addressing these challenges though model sparsification, spatial partitioning, or ad-hoc filtering, we propose introducing model bias online through the GP's mean function. We achieve more accurate distance fields using smaller models by creating a distance field prior from features which are easy to extract and have analytic distance fields. In particular, we demonstrate this approach using linear features. We show the proposed distance field halves model size in a 2D mapping task using data from a SICK S300 sensor. When applied to a single 3D scene from the TUM RGB-D SLAM dataset, we achieve a fivefold reduction in model size. Our proposed prior results in more accurate GP implicit surfaces, while allowing existing models to function in larger environments or with larger spatial partitions due to reduced model size.},
  keywords = {Computational modeling,Data models,Feature extraction,Gaussian processes,Geometry,Interpolation,machine learning,robot sensing systems,Robots,supervised learning,Surface treatment},
  file = {/Users/kshitijgoel/Zotero/storage/C8BEI9I2/Ivan et al. - 2022 - Online Distance Field Priors for Gaussian Process Implicit Surfaces.pdf;/Users/kshitijgoel/Zotero/storage/4PQCAAQS/9822213.html}
}

@article{jadhav_wireless_2022,
  title = {A Wireless Signal-Based Sensing Framework for Robotics},
  author = {Jadhav, Ninad and Wang, Weiying and Zhang, Diana and Khatib, Oussama and Kumar, Swarun and Gil, Stephanie},
  year = {2022},
  month = sep,
  journal = {The International Journal of Robotics Research},
  volume = {41},
  number = {11-12},
  pages = {955--992},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649221097989},
  url = {https://doi.org/10.1177/02783649221097989},
  urldate = {2023-06-12},
  abstract = {In this paper, we develop the analytical framework for a novel Wireless signal-based Sensing capability for Robotics (WSR) by leveraging a robots' mobility in 3D space. It allows robots to primarily measure relative direction, or Angle-of-Arrival (AOA), to other robots, while operating in non-line-of-sight unmapped environments and without requiring external infrastructure. We do so by capturing all of the paths that a wireless signal traverses as it travels from a transmitting to a receiving robot in the team, which we term as an AOA profile. The key intuition behind our approach is to enable a robot to emulate antenna arrays as it moves freely in 2D and 3D space. The small differences in the phase of the wireless signals are thus processed with knowledge of robots' local displacement to obtain the profile, via a method akin to Synthetic Aperture Radar (SAR). The main contribution of this work is the development of (i) a framework to accommodate arbitrary 2D and 3D motion, as well as continuous mobility of both signal transmitting and receiving robots, while computing AOA profiles between them and (ii) a Cramer--Rao Bound analysis, based on antenna array theory, that provides a lower bound on the variance in AOA estimation as a function of the geometry of robot motion. This is a critical distinction with previous work on SAR-based methods that restrict robot mobility to prescribed motion patterns, do not generalize to the full 3D space, and require transmitting robots to be stationary during data acquisition periods. We show that allowing robots to use their full mobility in 3D space while performing SAR results in more accurate AOA profiles and thus better AOA estimation. We formally characterize this observation as the informativeness of the robots' motion, a computable quantity for which we derive a closed form. All analytical developments are substantiated by extensive simulation and hardware experiments on air/ground robot platforms using 5~GHz WiFi. Our experimental results bolster our analytical findings, demonstrating that 3D motion provides enhanced and consistent accuracy, with a total AOA error of less than 10{\textopenbullet} for 95\% of trials. We also analytically characterize the impact of displacement estimation errors on the measured AOA and validate this theory empirically using robot displacements obtained using an off-the-shelf Intel Tracking Camera T265. Finally, we demonstrate the performance of our system on a multi-robot task where a heterogeneous air/ground pair of robots continuously measure AOA profiles over a WiFi link to achieve dynamic rendezvous in an unmapped, 300~m2 environment with occlusions.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/T8VY26MB/Jadhav et al. - 2022 - A wireless signal-based sensing framework for robo.pdf}
}

@misc{jadhav_wiserx_2024,
  title = {{{WiSER-X}}: {{Wireless Signals-based Efficient Decentralized Multi-Robot Exploration}} without {{Explicit Information Exchange}}},
  shorttitle = {{{WiSER-X}}},
  author = {Jadhav, Ninad and Behari, Meghna and Wood, Robert J. and Gil, Stephanie},
  year = {2024},
  month = dec,
  number = {arXiv:2412.19876},
  eprint = {2412.19876},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.19876},
  url = {http://arxiv.org/abs/2412.19876},
  urldate = {2024-12-31},
  abstract = {We introduce a Wireless Signal based Efficient multi-Robot eXploration (WiSER-X) algorithm applicable to a decentralized team of robots exploring an unknown environment with communication bandwidth constraints. WiSER-X relies only on local inter-robot relative position estimates, that can be obtained by exchanging signal pings from onboard sensors such as WiFi, Ultra-Wide Band, amongst others, to inform the exploration decisions of individual robots to minimize redundant coverage overlaps. Furthermore, WiSER-X also enables asynchronous termination without requiring a shared map between the robots. It also adapts to heterogeneous robot behaviors and even complete failures in unknown environment while ensuring complete coverage. Simulations show that WiSER-X leads to 58\% lower overlap than a zero-information-sharing baseline algorithm-1 and only 23\% more overlap than a full-information-sharing algorithm baseline algorithm-2.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/MIKGP4PE/Jadhav et al. - 2024 - WiSER-X Wireless Signals-based Efficient Decentralized Multi-Robot Exploration without Explicit Inf.pdf;/Users/kshitijgoel/Zotero/storage/B6HQBVNE/2412.html}
}

@inproceedings{jadidi_exploration_2014,
  title = {Exploration on Continuous {{Gaussian}} Process Frontier Maps},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Jadidi, Maani Ghaffari and Mir{\'o}, Jaime Valls and Valencia, Rafael and {Andrade-Cetto}, Juan},
  year = {2014},
  month = may,
  pages = {6077--6082},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2014.6907754},
  url = {https://ieeexplore.ieee.org/document/6907754},
  urldate = {2024-02-10},
  abstract = {An information-driven autonomous robotic exploration method on a continuous representation of unknown environments is proposed in this paper. The approach conveniently handles sparse sensor measurements to build a continuous model of the environment that exploits structural dependencies without the need to resort to a fixed resolution grid map. A gradient field of occupancy probability distribution is regressed from sensor data as a Gaussian process providing frontier boundaries for further exploration. The resulting continuous global frontier surface completely describes unexplored regions and, inherently, provides an automatic stop criterion for a desired sensitivity. The performance of the proposed approach is evaluated through simulation results in the well-known Freiburg and Cave maps.},
  keywords = {Entropy,Gaussian processes,Measurement by laser beam,Simultaneous localization and mapping,Training},
  file = {/Users/kshitijgoel/Zotero/storage/3ZBCUUAA/Jadidi et al. - 2014 - Exploration on continuous Gaussian process frontie.pdf;/Users/kshitijgoel/Zotero/storage/2TD98ZGS/6907754.html}
}

@article{jaeger_invitation_2024,
  title = {An {{Invitation}} to {{Deep Reinforcement Learning}}},
  author = {Jaeger, Bernhard and Geiger, Andreas},
  year = {2024},
  journal = {Foundations and Trends{\textregistered} in Optimization},
  volume = {7},
  number = {1},
  eprint = {2312.08365},
  primaryclass = {cs},
  pages = {1--80},
  issn = {2167-3888, 2167-3918},
  doi = {10.1561/2400000049},
  url = {http://arxiv.org/abs/2312.08365},
  urldate = {2025-06-04},
  abstract = {Training a deep neural network to maximize a target objective has become the standard recipe for successful machine learning over the last decade. These networks can be optimized with supervised learning, if the target objective is differentiable. For many interesting problems, this is however not the case. Common objectives like intersection over union (IoU), bilingual evaluation understudy (BLEU) score or rewards cannot be optimized with supervised learning. A common workaround is to define differentiable surrogate losses, leading to suboptimal solutions with respect to the actual objective. Reinforcement learning (RL) has emerged as a promising alternative for optimizing deep neural networks to maximize non-differentiable objectives in recent years. Examples include aligning large language models via human feedback, code generation, object detection or control problems. This makes RL techniques relevant to the larger machine learning audience. The subject is, however, time intensive to approach due to the large range of methods, as well as the often very theoretical presentation. In this introduction, we take an alternative approach, different from classic reinforcement learning textbooks. Rather than focusing on tabular problems, we introduce reinforcement learning as a generalization of supervised learning, which we first apply to non-differentiable objectives and later to temporal problems. Assuming only basic knowledge of supervised learning, the reader will be able to understand state-of-the-art deep RL algorithms like proximal policy optimization (PPO) after reading this tutorial.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/PY2SND3H/Jaeger and Geiger - 2024 - An Invitation to Deep Reinforcement Learning.pdf;/Users/kshitijgoel/Zotero/storage/QS8BJG7T/2312.html}
}

@misc{jafari_survey_2021,
  title = {A {{Survey}} on {{Locality Sensitive Hashing Algorithms}} and Their {{Applications}}},
  author = {Jafari, Omid and Maurya, Preeti and Nagarkar, Parth and Islam, Khandker Mushfiqul and Crushev, Chidambaram},
  year = {2021},
  month = feb,
  number = {arXiv:2102.08942},
  eprint = {2102.08942},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2102.08942},
  urldate = {2024-07-18},
  abstract = {Finding nearest neighbors in high-dimensional spaces is a fundamental operation in many diverse application domains. Locality Sensitive Hashing (LSH) is one of the most popular techniques for finding approximate nearest neighbor searches in high-dimensional spaces. The main benefits of LSH are its sub-linear query performance and theoretical guarantees on the query accuracy. In this survey paper, we provide a review of state-of-the-art LSH and Distributed LSH techniques. Most importantly, unlike any other prior survey, we present how Locality Sensitive Hashing is utilized in different application domains.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,H.2.4},
  file = {/Users/kshitijgoel/Zotero/storage/FV6HX2FN/Jafari et al. - 2021 - A Survey on Locality Sensitive Hashing Algorithms and their Applications.pdf}
}

@techreport{jakob_numerically_2015,
  title = {Numerically Stable Sampling of the von {{Mises Fisher}} Distribution on {{S2}} (and Other Tricks)},
  author = {Jakob, Wenzel},
  year = {2015},
  month = jun,
  institution = {Mitsuba Renderer},
  url = {https://www.mitsuba-renderer.org/~wenzel/files/vmf.pdf},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/RFK4ETLW/Jakob - Numerically stable sampling of the von Mises Fisher distribution on S2 (and other tricks).pdf}
}

@article{jakob_progressive_2011,
  title = {Progressive {{Expectation-Maximization}} for {{Hierarchical Volumetric Photon Mapping}}},
  author = {Jakob, Wenzel and Regg, Christian and Jarosz, Wojciech},
  year = {2011},
  journal = {Computer Graphics Forum},
  volume = {30},
  number = {4},
  pages = {1287--1297},
  issn = {1467-8659},
  doi = {10.1111/j.1467-8659.2011.01988.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.01988.x},
  urldate = {2023-03-17},
  abstract = {State-of-the-art density estimation methods for rendering participating media rely on a dense photon representation of the radiance distribution within a scene. A critical bottleneck of such kernel-based approaches is the excessive number of photons that are required in practice to resolve fine illumination details, while controlling the amount of noise. In this paper, we propose a parametric density estimation technique that represents radiance using a hierarchical Gaussian mixture. We efficiently obtain the coefficients of this mixture using a progressive and accelerated form of the Expectation-Maximization algorithm. After this step, we are able to create noise-free renderings of high-frequency illumination using only a few thousand Gaussian terms, where millions of photons are traditionally required. Temporal coherence is trivially supported within this framework, and the compact footprint is also useful in the context of real-time visualization. We demonstrate a hierarchical ray tracing-based implementation, as well as a fast splatting approach that can interactively render animated volume caustics.},
  langid = {english},
  keywords = {I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-Ray Tracing,I.6.8 Simulation and Modeling: Simulation-Monte Carlo},
  file = {/Users/kshitijgoel/Zotero/storage/YD54HZRT/Jakob et al. - 2011 - Progressive Expectation-Maximization for Hierarchi.pdf;/Users/kshitijgoel/Zotero/storage/5YRE4QSS/j.1467-8659.2011.01988.html}
}

@misc{jang_3dgsw_2024,
  title = {{{3D-GSW}}: {{3D Gaussian Splatting Watermark}} for {{Protecting Copyrights}} in {{Radiance Fields}}},
  shorttitle = {{{3D-GSW}}},
  author = {Jang, Youngdong and Park, Hyunje and Yang, Feng and Ko, Heeju and Choo, Euijin and Kim, Sangpil},
  year = {2024},
  month = sep,
  number = {arXiv:2409.13222},
  eprint = {2409.13222},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.13222},
  urldate = {2024-09-26},
  abstract = {Recently, 3D Gaussian splatting has been getting a lot of attention as an innovative method for representing 3D space due to rapid rendering and image quality. However, copyright protection for the 3D Gaussian splatting has not yet been introduced. In this paper, we present a novel watermarking method for 3D Gaussian splatting. The proposed method embeds a binary message into 3D Gaussians by fine-tuning the pre-trained 3D Gaussian splatting model. To achieve this, we present Frequency-Guided Densification (FGD) that utilizes Discrete Fourier Transform to find patches with high-frequencies and split 3D Gaussians based on 3D Gaussian Contribution Vector. It is each 3D Gaussian contribution to rendered pixel colors, improving both rendering quality and bit accuracy. Furthermore, we modify an adaptive gradient mask to enhance rendering quality. Our experiments show that our method can embed a watermark in 3D Gaussians imperceptibly with increased capacity and robustness against attacks. Our method reduces optimization cost and achieves state-of-the-art performance compared to other methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/UH8ZF5QE/Jang et al. - 2024 - 3D-GSW 3D Gaussian Splatting Watermark for Protecting Copyrights in Radiance Fields.pdf}
}

@inproceedings{jang_dbscan_2019,
  title = {{{DBSCAN}}++: {{Towards}} Fast and Scalable Density Clustering},
  shorttitle = {{{DBSCAN}}++},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Jang, Jennifer and Jiang, Heinrich},
  year = {2019},
  month = may,
  pages = {3019--3029},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/jang19a.html},
  urldate = {2023-04-16},
  abstract = {DBSCAN is a classical density-based clustering procedure with tremendous practical relevance. However, DBSCAN implicitly needs to compute the empirical density for each sample point, leading to a quadratic worst-case time complexity, which is too slow on large datasets. We propose DBSCAN++, a simple modification of DBSCAN which only requires computing the densities for a chosen subset of points. We show empirically that, compared to traditional DBSCAN, DBSCAN++ can provide not only competitive performance but also added robustness in the bandwidth hyperparameter while taking a fraction of the runtime. We also present statistical consistency guarantees showing the trade-off between computational cost and estimation rates. Surprisingly, up to a certain point, we can enjoy the same estimation rates while lowering computational cost, showing that DBSCAN++ is a sub-quadratic algorithm that attains minimax optimal rates for level-set estimation, a quality that may be of independent interest.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ARUDGHV3/Jang and Jiang - 2019 - DBSCAN++ Towards fast and scalable density cluste.pdf;/Users/kshitijgoel/Zotero/storage/H7M7XU7N/Jang and Jiang - 2019 - DBSCAN++ Towards fast and scalable density cluste.pdf}
}

@inproceedings{jang_meanshift_2021,
  title = {{{MeanShift}}++: {{Extremely Fast Mode-Seeking With Applications}} to {{Segmentation}} and {{Object Tracking}}},
  shorttitle = {{{MeanShift}}++},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Jang, Jennifer and Jiang, Heinrich},
  year = {2021},
  month = jun,
  pages = {4100--4111},
  publisher = {IEEE},
  address = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.00409},
  url = {https://ieeexplore.ieee.org/document/9578266/},
  urldate = {2022-03-23},
  abstract = {MeanShift is a popular mode-seeking clustering algorithm used in a wide range of applications in machine learning. However, it is known to be prohibitively slow, with quadratic runtime per iteration. We propose MeanShift++, an extremely fast mode-seeking algorithm based on MeanShift that uses a grid-based approach to speed up the mean shift step, replacing the computationally expensive neighbors search with a density-weighted mean of adjacent grid cells. In addition, we show that this grid-based technique for density estimation comes with theoretical guarantees. The runtime is linear in the number of points and exponential in dimension, which makes MeanShift++ ideal on lowdimensional applications such as image segmentation and object tracking. We provide extensive experimental analysis showing that MeanShift++ can be more than 10,000x faster than MeanShift with competitive clustering results on benchmark datasets and nearly identical image segmentations as MeanShift. Finally, we show promising results for object tracking.},
  isbn = {978-1-6654-4509-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZKTLLW8T/Jang and Jiang - 2021 - MeanShift++ Extremely Fast Mode-Seeking With Appl.pdf}
}

@article{jang_multirobot_2020,
  title = {Multi-{{Robot Active Sensing}} and {{Environmental Model Learning With Distributed Gaussian Process}}},
  author = {Jang, Dohyun and Yoo, Jaehyun and Son, Clark Youngdong and Kim, Dabin and Kim, H. Jin},
  year = {2020},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {4},
  pages = {5905--5912},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.3010456},
  url = {https://ieeexplore.ieee.org/document/9144385/?arnumber=9144385},
  urldate = {2024-11-29},
  abstract = {This letter deals with the problem of multiple robots working together to explore and gather at the global maximum of the unknown field. Given noisy sensor measurements obtained at the location of robots with no prior knowledge about the environmental map, Gaussian process regression can be an efficient solution to construct a map that represents spatial information with confidence intervals. However, because the conventional Gaussian process algorithm operates in a centralized manner, it is difficult to process information coming from multiple distributed sensors in real-time. In this work, we propose a multi-robot exploration algorithm that deals with the following challenges: i) distributed environmental map construction using networked sensing platforms; ii) online learning using successive measurements suitable for a multi-robot team; iii) multi-agent coordination to discover the highest peak of an unknown environmental field with collision avoidance. We demonstrate the effectiveness of our algorithm via simulation and a topographic survey experiment with multiple UAVs.},
  keywords = {Data models,distributed robot systems,Gaussian processes,Kernel,Multi-robot systems,networked robots,Protocols,Robot kinematics,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/PJPBV7XN/Jang et al. - 2020 - Multi-Robot Active Sensing and Environmental Model Learning With Distributed Gaussian Process.pdf;/Users/kshitijgoel/Zotero/storage/LJ9QP8AB/9144385.html}
}

@inproceedings{janson_safe_2018,
  title = {Safe {{Motion Planning}} in {{Unknown Environments}}: {{Optimality Benchmarks}} and {{Tractable Policies}}},
  shorttitle = {Safe {{Motion Planning}} in {{Unknown Environments}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIV}}},
  author = {Janson, Lucas and Hu, Tommy and Pavone, Marco},
  year = {2018},
  month = jun,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2018.XIV.061},
  url = {http://www.roboticsproceedings.org/rss14/p61.pdf},
  urldate = {2022-02-28},
  isbn = {978-0-9923747-4-7},
  file = {/Users/kshitijgoel/Zotero/storage/ISZJXVFM/Janson et al. - 2018 - Safe Motion Planning in Unknown Environments Opti.pdf}
}

@inproceedings{jaquier_gaussian_2017,
  title = {Gaussian Mixture Regression on Symmetric Positive Definite Matrices Manifolds: {{Application}} to Wrist Motion Estimation with {{sEMG}}},
  shorttitle = {Gaussian Mixture Regression on Symmetric Positive Definite Matrices Manifolds},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Jaquier, Noemie and Calinon, Sylvain},
  year = {2017},
  month = sep,
  pages = {59--64},
  publisher = {IEEE},
  address = {Vancouver, BC},
  doi = {10.1109/IROS.2017.8202138},
  url = {http://ieeexplore.ieee.org/document/8202138/},
  urldate = {2023-10-14},
  abstract = {In many sensing and control applications, data are represented in the form of symmetric positive definite (SPD) matrices. Considering the underlying geometry of this data space can be beneficial in many robotics applications. In this paper, we present an extension of Gaussian mixture regression (GMR) with input and/or output data on SPD manifolds. As the covariance of SPD datapoints is a 4th-order tensor, we develop a method for parallel transport of high order covariances on SPD manifolds. The proposed approach is experimented in the context of prosthetic hands, with the estimation of wrist movements based on spatial covariance features computed from surface electromyography (sEMG) signals.},
  isbn = {978-1-5386-2682-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7EEX5ST7/Jaquier and Calinon - 2017 - Gaussian mixture regression on symmetric positive .pdf}
}

@article{jaquier_transfer_2025,
  title = {Transfer Learning in Robotics: {{An}} Upcoming Breakthrough? {{A}} Review of Promises and Challenges},
  shorttitle = {Transfer Learning in Robotics},
  author = {Jaquier, No{\'e}mie and Welle, Michael C and Gams, Andrej and Yao, Kunpeng and Fichera, Bernardo and Billard, Aude and Ude, Ale{\v s} and Asfour, Tamim and Kragic, Danica},
  year = {2025},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {3},
  pages = {465--485},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241273565},
  url = {https://doi.org/10.1177/02783649241273565},
  urldate = {2025-04-16},
  abstract = {Transfer learning is a conceptually-enticing paradigm in pursuit of truly intelligent embodied agents. The core concept---reusing prior knowledge to learn in and from novel situations---is successfully leveraged by humans to handle novel situations. In recent years, transfer learning has received renewed interest from the community from different perspectives, including imitation learning, domain adaptation, and transfer of experience from simulation to the real world, among others. In this paper, we unify the concept of transfer learning in robotics and provide the first taxonomy of its kind considering the key concepts of robot, task, and environment. Through a review of the promises and challenges in the field, we identify the need of transferring at different abstraction levels, the need of quantifying the transfer gap and the quality of transfer, as well as the dangers of negative transfer. Via this position paper, we hope to channel the effort of the community towards the most significant roadblocks to realize the full potential of transfer learning in robotics.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MJ8B8A4F/Jaquier et al. - 2025 - Transfer learning in robotics An upcoming breakthrough A review of promises and challenges.pdf}
}

@inproceedings{jarin-lipschitz_experiments_2022,
  title = {Experiments in {{Adaptive Replanning}} for {{Fast Autonomous Flight}} in {{Forests}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {{Jarin-Lipschitz}, Laura and Liu, Xu and Tao, Yuezhan and Kumar, Vijay},
  year = {2022},
  month = may,
  pages = {8185--8191},
  doi = {10.1109/ICRA46639.2022.9812235},
  url = {https://ieeexplore.ieee.org/document/9812235/},
  urldate = {2025-06-01},
  abstract = {Fast, autonomous flight in unstructured, cluttered environments such as forests is challenging because it requires the robot to compute new plans in realtime on a computationally-constrained platform. In this paper, we enable this capability with a search-based planning framework that adapts sampling density in realtime to find dynamically-feasible plans while remaining computationally tractable. A paramount challenge in search-based planning is that dense obstacles both necessitate large graphs (to guarantee completeness) and reduce the efficiency of graph search (as heuristics become less accurate). To address this, we develop a planning framework with two parts: one that maximizes planner completeness for a given graph size, and a second that dynamically maximizes graph size subject to computational constraints. This framework is enabled by motion planning graphs that are defined by a single parameter-dispersion-which quantifies the maximum trajectory cost to reach an arbitrary state from the graph. We show through real and simulated experiments how the dispersion can be adapted to different environments in realtime, allowing operation in environments with varying density. The simulated experiment demonstrates improved performance over a baseline search-based planning algorithm. We also demonstrate flight speeds of up to 2.5m/s in real-world cluttered pine forests.},
  keywords = {Costs,Forestry,Location awareness,Planning,Semantics,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/TXLSAFTR/Jarin-Lipschitz et al. - 2022 - Experiments in Adaptive Replanning for Fast Autonomous Flight in Forests.pdf}
}

@inproceedings{jatavallabhula_conceptfusion_2023,
  title = {{{ConceptFusion}}: {{Open-set}} Multimodal {{3D}} Mapping},
  shorttitle = {{{ConceptFusion}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Jatavallabhula, Krishna Murthy and Kuwajerwala, Alihusein and Gu, Qiao and Omama, Mohd and Iyer, Ganesh and Saryazdi, Soroush and Chen, Tao and Maalouf, Alaa and Li, Shuang and Keetha, Nikhil Varma and Tewari, Ayush and Tenenbaum, Joshua and de Melo, Celso and Krishna, Madhava and Paull, Liam and Shkurti, Florian and Torralba, Antonio},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p066.html},
  urldate = {2023-07-04},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/965QIIZT/Jatavallabhula et al. - 2023 - ConceptFusion Open-set multimodal 3D mapping.pdf}
}

@inproceedings{jatavallabhula_slam_2020,
  title = {∇{{SLAM}}: {{Dense SLAM}} Meets {{Automatic Differentiation}}},
  shorttitle = {∇{{SLAM}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Jatavallabhula, Krishna Murthy and Iyer, Ganesh and Paull, Liam},
  year = {2020},
  month = may,
  pages = {2130--2137},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9197519},
  abstract = {The question of "representation" is central in the context of dense simultaneous localization and mapping (SLAM). Learning-based approaches have the potential to leverage data or task performance to directly inform the representation. However, blending representation learning approaches with "classical" SLAM systems has remained an open question, because of their highly modular and complex nature. A SLAM system transforms raw sensor inputs into a distribution over the state(s) of the robot and the environment. If this transformation (SLAM) were expressible as a differentiable function, we could leverage task-based error signals over the outputs of this function to learn representations that optimize task performance. However, this is infeasible as several components of a typical dense SLAM system are non-differentiable. In this work, we propose ∇SLAM (gradSLAM), a methodology for posing SLAM systems as differentiable computational graphs, which unifies gradient-based learning and SLAM. We propose differentiable trust-region optimizers, surface measurement and fusion schemes, and raycasting, without sacrificing accuracy. This amalgamation of dense SLAM with computational graphs enables us to backprop all the way from 3D maps to 2D pixels, opening up new possibilities in gradient-based learning for SLAM1.},
  keywords = {Damping,Neural networks,Optimization,Simultaneous localization and mapping,Task analysis,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/B5KWMMJ4/Jatavallabhula et al. - 2020 - ∇SLAM Dense SLAM meets Automatic Differentiation.pdf;/Users/kshitijgoel/Zotero/storage/WI4FVBAQ/stamp.html}
}

@article{jenssen_cauchy_2006,
  title = {The {{Cauchy}}--{{Schwarz}} Divergence and {{Parzen}} Windowing: {{Connections}} to Graph Theory and {{Mercer}} Kernels},
  shorttitle = {The {{Cauchy}}--{{Schwarz}} Divergence and {{Parzen}} Windowing},
  author = {Jenssen, Robert and Principe, Jose C. and Erdogmus, Deniz and Eltoft, Torbj{\o}rn},
  year = {2006},
  month = sep,
  journal = {Journal of the Franklin Institute},
  series = {Winners of the Student Paper Competition at the 2005 {{IEEE International Conference}} on {{Acoustics Speech}} and {{Signal Processing}} ({{ICASSP}}) Held in {{Philadelphia PA}}, Provide the State-of-Art in Their Fields of Research},
  volume = {343},
  number = {6},
  pages = {614--629},
  issn = {0016-0032},
  doi = {10.1016/j.jfranklin.2006.03.018},
  url = {https://www.sciencedirect.com/science/article/pii/S0016003206000767},
  urldate = {2022-08-28},
  abstract = {This paper contributes a tutorial level discussion of some interesting properties of the recent Cauchy--Schwarz (CS) divergence measure between probability density functions. This measure brings together elements from several different machine learning fields, namely information theory, graph theory and Mercer kernel and spectral theory. These connections are revealed when estimating the CS divergence non-parametrically using the Parzen window technique for density estimation. An important consequence of these connections is that they enhance our understanding of the different machine learning schemes relative to each other.},
  langid = {english},
  keywords = {Cauchy-Schwarz divergence,Graph cut,Information theory,Mercer kernel theory,Parzen windowing,Spectral methods},
  file = {/Users/kshitijgoel/Zotero/storage/T5I2XDTG/Jenssen et al. - 2006 - The Cauchy–Schwarz divergence and Parzen windowing.pdf;/Users/kshitijgoel/Zotero/storage/IXWG5F3N/S0016003206000767.html}
}

@misc{jeon_informationtheoretic_2024,
  title = {Information-{{Theoretic Foundations}} for {{Machine Learning}}},
  author = {Jeon, Hong Jun and Van Roy, Benjamin},
  year = {2024},
  month = jul,
  number = {arXiv:2407.12288},
  eprint = {2407.12288},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.12288},
  urldate = {2024-07-18},
  abstract = {The staggering progress of machine learning in the past decade has been a sight to behold. In retrospect, it is both remarkable and unsettling that these milestones were achievable with little to no rigorous theory to guide experimentation. Despite this fact, practitioners have been able to guide their future experimentation via observations from previous large-scale empirical investigations. However, alluding to Plato's Allegory of the cave, it is likely that the observations which form the field's notion of reality are but shadows representing fragments of that reality. In this work, we propose a theoretical framework which attempts to answer what exists outside of the cave. To the theorist, we provide a framework which is mathematically rigorous and leaves open many interesting ideas for future exploration. To the practitioner, we provide a framework whose results are very intuitive, general, and which will help form principles to guide future investigations. Concretely, we provide a theoretical framework rooted in Bayesian statistics and Shannon's information theory which is general enough to unify the analysis of many phenomena in machine learning. Our framework characterizes the performance of an optimal Bayesian learner, which considers the fundamental limits of information. Unlike existing analyses that weaken with increasing data complexity, our theoretical tools provide accurate insights across diverse machine learning settings. Throughout this work, we derive very general theoretical results and apply them to derive insights specific to settings ranging from data which is independently and identically distributed under an unknown distribution, to data which is sequential, to data which exhibits hierarchical structure amenable to meta-learning. We conclude with a section dedicated to characterizing the performance of misspecified algorithms. These results are exciting and particularly relevant as we strive to overcome increasingly difficult machine learning challenges in this endlessly complex world.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/CCE2JLBZ/Jeon and Van Roy - 2024 - Information-Theoretic Foundations for Machine Learning.pdf}
}

@article{jepson_robust_2003,
  title = {Robust Online Appearance Models for Visual Tracking},
  author = {Jepson, A.D. and Fleet, D.J. and {El-Maraghi}, T.F.},
  year = {2003},
  month = oct,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {25},
  number = {10},
  pages = {1296--1311},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.2003.1233903},
  url = {http://ieeexplore.ieee.org/document/1233903/},
  urldate = {2024-03-28},
  abstract = {We propose a framework for learning robust, adaptive, appearance models to be used for motion-based tracking of natural objects. The model adapts to slowly changing appearance, and it maintains a natural measure of the stability of the observed image structure during tracking. By identifying stable properties of appearance, we can weight them more heavily for motion estimation, while less stable properties can be proportionately downweighted. The appearance model involves a mixture of stable image structure, learned over long time courses, along with two-frame motion information and an outlier process. An online EM-algorithm is used to adapt the appearance model parameters over time. An implementation of this approach is developed for an appearance model based on the filter responses from a steerable pyramid. This model is used in a motion-based tracking algorithm to provide robustness in the face of image outliers, such as those caused by occlusions, while adapting to natural changes in appearance such as those due to facial expressions or variations in 3D pose.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/P9WHEUPS/Jepson et al. - 2003 - Robust online appearance models for visual trackin.pdf}
}

@inproceedings{ji_elastic_2022,
  title = {Elastic {{Tracker}}: {{A Spatio-temporal Trajectory Planner}} for {{Flexible Aerial Tracking}}},
  shorttitle = {Elastic {{Tracker}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ji, Jialin and Pan, Neng and Xu, Chao and Gao, Fei},
  year = {2022},
  month = may,
  pages = {47--53},
  doi = {10.1109/ICRA46639.2022.9811688},
  url = {https://ieeexplore.ieee.org/document/9811688/},
  urldate = {2025-05-13},
  abstract = {This paper proposes Elastic Tracker, a flexible trajectory planning framework that can deal with challenging tracking tasks with guaranteed safety and visibility. Firstly, an object detection and intension-free motion prediction method is designed. Then an occlusion-aware path finding method is proposed to provide a proper topology. A smart safe flight corridor generation strategy is designed with the guiding path. An analytical occlusion cost is evaluated. Finally, an effective trajectory optimization approach enables to generate a spatio-temporal optimal trajectory within the resultant flight corridor. Particular formulations are designed to guarantee both safety and visibility, with all the above requirements optimized jointly. The experimental results show that our method works more robustly but with less computation than the existing methods, even in some challenging tracking tasks.},
  keywords = {Automation,Costs,Object detection,Prediction methods,Safety,Tracking,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/E9A3UIFQ/Ji et al. - 2022 - Elastic Tracker A Spatio-temporal Trajectory Planner for Flexible Aerial Tracking.pdf}
}

@article{ji_errt_2023,
  title = {E-{{RRT}}*: {{Path Planning}} for {{Hyper-Redundant Manipulators}}},
  shorttitle = {E-{{RRT}}*},
  author = {Ji, Hongcheng and Xie, Haibo and Wang, Cheng and Yang, Huayong},
  year = {2023},
  month = dec,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {12},
  pages = {8128--8135},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3325716},
  url = {https://ieeexplore.ieee.org/document/10287397/},
  urldate = {2024-01-24},
  abstract = {A hyper-redundant manipulator(HRM) can flexibly accomplish tasks in narrow spaces. However, its excessive degrees of freedom pose challenges for path planning. In this letter, an ellipsoid-shape rapidly-exporing random tree (E-RRT*) method is proposed for path planning of HRMs in workspace, particularly those with angle limits. This method replaces line segments with ellipsoids to connect adjacent nodes. Firstly, an analysis of angle constraints of the HRM is conducted, providing restrictions on node selection during path planning. Secondly, a slow-speed informed guiding approach is introduced to optimize the sampling process. Finally, the obtained path is enhanced by adding control points and applying cubic polynomial interpolation to achieve path smoothing. Simulations demonstrate that the proposed E-RRT* method effectively solves the path planning problem for HRMs. Especially in narrow environments, appropriate informed guiding speeds enable E-RRT* to outperform other methods.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2AT6Q6YG/Ji et al. - 2023 - E-RRT Path Planning for Hyper-Redundant Manipula.pdf}
}

@misc{jia_pbnbv_2025,
  title = {{{PB-NBV}}: {{Efficient Projection-Based Next-Best-View Planning Framework}} for {{Reconstruction}} of {{Unknown Objects}}},
  shorttitle = {{{PB-NBV}}},
  author = {Jia, Zhizhou and Li, Yuetao and Hao, Qun and Zhang, Shaohui},
  year = {2025},
  month = jan,
  number = {arXiv:2501.10663},
  eprint = {2501.10663},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.10663},
  url = {http://arxiv.org/abs/2501.10663},
  urldate = {2025-01-26},
  abstract = {Completely capturing the three-dimensional (3D) data of an object is essential in industrial and robotic applications. The task of next-best-view (NBV) planning is to calculate the next optimal viewpoint based on the current data, gradually achieving a complete 3D reconstruction of the object. However, many existing NBV planning algorithms incur heavy computational costs due to the extensive use of ray-casting. Specifically, this framework refits different types of voxel clusters into ellipsoids based on the voxel structure. Then, the next optimal viewpoint is selected from the candidate views using a projection-based viewpoint quality evaluation function in conjunction with a global partitioning strategy. This process replaces extensive ray-casting, significantly improving the computational efficiency. Comparison experiments in the simulation environment show that our framework achieves the highest point cloud coverage with low computational time compared to other frameworks. The real-world experiments also confirm the efficiency and feasibility of the framework. Our method will be made open source to benefit the community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/HDDZ3ETC/Jia et al. - 2025 - PB-NBV Efficient Projection-Based Next-Best-View Planning Framework for Reconstruction of Unknown O.pdf;/Users/kshitijgoel/Zotero/storage/JNLLBE6S/2501.html}
}

@article{jian_robust_2011,
  title = {Robust {{Point Set Registration Using Gaussian Mixture Models}}},
  author = {Jian, Bing and Vemuri, Baba C.},
  year = {2011},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {33},
  number = {8},
  pages = {1633--1645},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2010.223},
  abstract = {In this paper, we present a unified framework for the rigid and nonrigid point set registration problem in the presence of significant amounts of noise and outliers. The key idea of this registration framework is to represent the input point sets using Gaussian mixture models. Then, the problem of point set registration is reformulated as the problem of aligning two Gaussian mixtures such that a statistical discrepancy measure between the two corresponding mixtures is minimized. We show that the popular iterative closest point (ICP) method and several existing point set registration methods in the field are closely related and can be reinterpreted meaningfully in our general framework. Our instantiation of this general framework is based on the the L2 distance between two Gaussian mixtures, which has the closed-form expression and in turn leads to a computationally efficient registration algorithm. The resulting registration algorithm exhibits inherent statistical robustness, has an intuitive interpretation, and is simple to implement. We also provide theoretical and experimental comparisons with other robust methods for point set registration.},
  keywords = {Closed-form solution,Correlation,Gaussian mixtures,Iterative closest point algorithm,Kernel,Maximum likelihood estimation,nonrigid registration,Pattern matching,Point set registration,robust matching.,Robustness},
  file = {/Users/kshitijgoel/Zotero/storage/YB5FLHGJ/Jian and Vemuri - 2011 - Robust Point Set Registration Using Gaussian Mixtu.pdf}
}

@misc{jiang_agslam_2024,
  title = {{{AG-SLAM}}: {{Active Gaussian Splatting SLAM}}},
  shorttitle = {{{AG-SLAM}}},
  author = {Jiang, Wen and Lei, Boshu and Ashton, Katrina and Daniilidis, Kostas},
  year = {2024},
  month = oct,
  number = {arXiv:2410.17422},
  eprint = {2410.17422},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.17422},
  urldate = {2024-10-24},
  abstract = {We present AG-SLAM, the first active SLAM system utilizing 3D Gaussian Splatting (3DGS) for online scene reconstruction. In recent years, radiance field scene representations, including 3DGS have been widely used in SLAM and exploration, but actively planning trajectories for robotic exploration is still unvisited. In particular, many exploration methods assume precise localization and thus do not mitigate the significant risk of constructing a trajectory, which is difficult for a SLAM system to operate on. This can cause camera tracking failure and lead to failures in real-world robotic applications. Our method leverages Fisher Information to balance the dual objectives of maximizing the information gain for the environment while minimizing the cost of localization errors. Experiments conducted on the Gibson and Habitat-Matterport 3D datasets demonstrate state-of-the-art results of the proposed method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/UGZBALTB/Jiang et al. - 2024 - AG-SLAM Active Gaussian Splatting SLAM.pdf;/Users/kshitijgoel/Zotero/storage/HZ5BUJNA/2410.html}
}

@article{jiang_h2mapping_2023,
  title = {H2-{{Mapping}}: {{Real-time Dense Mapping Using Hierarchical Hybrid Representation}}},
  shorttitle = {H2-{{Mapping}}},
  author = {Jiang, Chenxing and Zhang, Hanwen and Liu, Peize and Yu, Zehuan and Cheng, Hui and Zhou, Boyu and Shen, Shaojie},
  year = {2023},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {10},
  eprint = {2306.03207},
  primaryclass = {cs},
  pages = {6787--6794},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3313051},
  url = {http://arxiv.org/abs/2306.03207},
  urldate = {2023-10-06},
  abstract = {Constructing a high-quality dense map in real-time is essential for robotics, AR/VR, and digital twins applications. As Neural Radiance Field (NeRF) greatly improves the mapping performance, in this paper, we propose a NeRF-based mapping method that enables higher-quality reconstruction and real-time capability even on edge computers. Specifically, we propose a novel hierarchical hybrid representation that leverages implicit multiresolution hash encoding aided by explicit octree SDF priors, describing the scene at different levels of detail. This representation allows for fast scene geometry initialization and makes scene geometry easier to learn. Besides, we present a coverage-maximizing keyframe selection strategy to address the forgetting issue and enhance mapping quality, particularly in marginal areas. To the best of our knowledge, our method is the first to achieve high-quality NeRF-based mapping on edge computers of handheld devices and quadrotors in real-time. Experiments demonstrate that our method outperforms existing NeRF-based mapping methods in geometry accuracy, texture realism, and time consumption. The code will be released at: https://github.com/SYSU-STAR/H2-Mapping},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/LJJJVVI2/Jiang et al. - 2023 - H2-Mapping Real-time Dense Mapping Using Hierarch.pdf;/Users/kshitijgoel/Zotero/storage/9VP95IMJ/2306.html}
}

@article{jiang_ligs_2024,
  title = {{{LI-GS}}: {{Gaussian Splatting}} with {{LiDAR Incorporated}} for {{Accurate Large-Scale Reconstruction}}},
  shorttitle = {{{LI-GS}}},
  author = {Jiang, Changjian and Gao, Ruilan and Shao, Kele and Wang, Yue and Xiong, Rong and Zhang, Yu},
  year = {2024},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3522846},
  url = {https://ieeexplore.ieee.org/document/10816486/?arnumber=10816486},
  urldate = {2025-01-03},
  abstract = {Large-scale 3D reconstruction is critical in the field of robotics, and the potential of 3D Gaussian Splatting (3DGS) for achieving accurate object-level reconstruction has been demonstrated. However, ensuring geometric accuracy in outdoor and unbounded scenes remains a significant challenge. This study introduces LI-GS, a reconstruction system that incorporates LiDAR and Gaussian Splatting to enhance geometric accuracy in large-scale scenes. 2D Gaussain surfels are employed as the map representation to enhance surface alignment. Additionally, a novel modeling method is proposed to convert LiDAR point clouds to plane-constrained multimodal Gaussian Mixture Models (GMMs). The GMMs are utilized during both initialization and optimization stages to ensure sufficient and continuous supervision over the entire scene while mitigating the risk of over-fitting. Furthermore, GMMs are employed in mesh extraction to eliminate artifacts and improve the overall geometric quality. Experiments demonstrate that our method outperforms state-of-the-art methods in large-scale 3D reconstruction, achieving higher accuracy compared to both LiDAR-based methods and Gaussian-based methods with improvements of 52.6\% and 68.7\%, respectively.},
  keywords = {Accuracy,Geometry,Image reconstruction,Laser radar,Mapping,Neural radiance field,Optimization,Point cloud compression,Rendering (computer graphics),Sensor Fusion,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/6WXGWCDY/Jiang et al. - 2024 - LI-GS Gaussian Splatting with LiDAR Incorporated for Accurate Large-Scale Reconstruction.pdf;/Users/kshitijgoel/Zotero/storage/FCSE2FQQ/10816486.html}
}

@article{jiang_thermalinertial_2022,
  title = {Thermal-{{Inertial SLAM}} for the {{Environments With Challenging Illumination}}},
  author = {Jiang, Jiajun and Chen, Xingxin and Dai, Weichen and Gao, Zelin and Zhang, Yu},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {8767--8774},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3185385},
  abstract = {In recent years, longwave infrared (LWIR) cameras have become potential in visual simultaneous localization and mapping (SLAM) research since the delivered thermal images can provide information beyond the visible spectrum and are robust to environment illumination. However, due to modality differences, SLAM methods designed for visible cameras cannot be directly applied to thermal data. In this paper, we propose a thermal-inertial SLAM method for all-day autonomous systems. To overcome the challenge of the thermal data association, the proposed method represents several improvements, including singular-value-decomposition-based (SVD-based) image processing and ThermalRAFT tracking methods. Based on the characteristics of the thermal images, the SVD-based image processing method can exploit the fixed noise pattern of thermal images and enhance the image quality to improve the performance of subsequent steps, including thermal feature extraction and loop detection. To achieve real-time and robust feature tracking, we develop ThermalRAFT, an efficient optical flow network with iterative optimization. Moreover, the system introduces a bag-of-words-based loop detection method to maintain global consistency in long-term operation. The experimental results demonstrate that the proposed method can provide competitive performance in indoor and outdoor environments and is robust under challenging illumination conditions.},
  keywords = {Cameras,Feature extraction,Image processing,Lighting,localization,Simultaneous localization and mapping,SLAM,Thermal noise,Thermal sensors,visual-inertial SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/TYVYJ9JE/Jiang et al. - 2022 - Thermal-Inertial SLAM for the Environments With Ch.pdf}
}

@article{jin_activegs_2025,
  title = {{{ActiveGS}}: {{Active Scene Reconstruction Using Gaussian Splatting}}},
  shorttitle = {{{ActiveGS}}},
  author = {Jin, Liren and Zhong, Xingguang and Pan, Yue and Behley, Jens and Stachniss, Cyrill and Popovi{\'c}, Marija},
  year = {2025},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {5},
  pages = {4866--4873},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3555149},
  url = {https://ieeexplore.ieee.org/abstract/document/10938898},
  urldate = {2025-07-16},
  abstract = {Robotics applications often rely on scene reconstructions to enable downstream tasks. In this work, we tackle the challenge of actively building an accurate map of an unknown scene using an RGB-D camera on a mobile platform. We propose a hybrid map representation that combines a Gaussian splatting map with a coarse voxel map, leveraging the strengths of both representations: the high-fidelity scene reconstruction capabilities of Gaussian splatting and the spatial modelling strengths of the voxel map. At the core of our framework is an effective confidence modelling technique for the Gaussian splatting map to identify under-reconstructed areas, while utilising spatial information from the voxel map to target unexplored areas and assist in collision-free path planning. By actively collecting scene information in under-reconstructed and unexplored areas for map updates, our approach achieves superior Gaussian splatting reconstruction results compared to state-of-the-art approaches. Additionally, we demonstrate the real-world applicability of our framework using an unmanned aerial vehicle.},
  keywords = {Accuracy,Cameras,Mapping,Neural radiance field,Path planning,Pipelines,Planning,Point cloud compression,Rendering (computer graphics),RGB-D perception,Robots,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/8CS4PU9U/Jin et al. - 2025 - ActiveGS Active Scene Reconstruction Using Gaussian Splatting.pdf}
}

@misc{jin_gsplanner_2024,
  title = {{{GS-Planner}}: {{A Gaussian-Splatting-based Planning Framework}} for {{Active High-Fidelity Reconstruction}}},
  shorttitle = {{{GS-Planner}}},
  author = {Jin, Rui and Gao, Yuman and Lu, Haojian and Gao, Fei},
  year = {2024},
  month = may,
  number = {arXiv:2405.10142},
  eprint = {2405.10142},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.10142},
  urldate = {2024-05-19},
  abstract = {Active reconstruction technique enables robots to autonomously collect scene data for full coverage, relieving users from tedious and time-consuming data capturing process. However, designed based on unsuitable scene representations, existing methods show unrealistic reconstruction results or the inability of online quality evaluation. Due to the recent advancements in explicit radiance field technology, online active high-fidelity reconstruction has become achievable. In this paper, we propose GS-Planner, a planning framework for active high-fidelity reconstruction using 3D Gaussian Splatting. With improvement on 3DGS to recognize unobserved regions, we evaluate the reconstruction quality and completeness of 3DGS map online to guide the robot. Then we design a sampling-based active reconstruction strategy to explore the unobserved areas and improve the reconstruction geometric and textural quality. To establish a complete robot active reconstruction system, we choose quadrotor as the robotic platform for its high agility. Then we devise a safety constraint with 3DGS to generate executable trajectories for quadrotor navigation in the 3DGS map. To validate the effectiveness of our method, we conduct extensive experiments and ablation studies in highly realistic simulation scenes.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/NHAEQEBD/Jin et al. - 2024 - GS-Planner A Gaussian-Splatting-based Planning Framework for Active High-Fidelity Reconstruction.pdf}
}

@misc{jin_neunbv_2023,
  title = {{{NeU-NBV}}: {{Next Best View Planning Using Uncertainty Estimation}} in {{Image-Based Neural Rendering}}},
  shorttitle = {{{NeU-NBV}}},
  author = {Jin, Liren and Chen, Xieyuanli and R{\"u}ckin, Julius and Popovi{\'c}, Marija},
  year = {2023},
  month = mar,
  number = {arXiv:2303.01284},
  eprint = {2303.01284},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2303.01284},
  urldate = {2023-04-02},
  abstract = {Autonomous robotic tasks require actively perceiving the environment to achieve application-specific goals. In this paper, we address the problem of positioning an RGB camera to collect the most informative images to represent an unknown scene, given a limited measurement budget. We propose a novel mapless planning framework to iteratively plan the next best camera view based on collected image measurements. A key aspect of our approach is a new technique for uncertainty estimation in image-based neural rendering, which guides measurement acquisition at the most uncertain view among view candidates, thus maximising the information value during data collection. By incrementally adding new measurements into our image collection, our approach efficiently explores an unknown scene in a mapless manner. We show that our uncertainty estimation is generalisable and valuable for view planning in unknown scenes. Our planning experiments using synthetic and real-world data verify that our uncertainty-guided approach finds informative images leading to more accurate scene representations when compared against baselines.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/UPXTTF5T/Jin et al. - 2023 - NeU-NBV Next Best View Planning Using Uncertainty.pdf;/Users/kshitijgoel/Zotero/storage/2UETJH44/2303.html}
}

@article{johnson-roberson_generation_2010,
  title = {Generation and Visualization of Large-Scale Three-Dimensional Reconstructions from Underwater Robotic Surveys},
  author = {{Johnson-Roberson}, Matthew and Pizarro, Oscar and Williams, Stefan B. and Mahon, Ian},
  year = {2010},
  journal = {Journal of Field Robotics},
  volume = {27},
  number = {1},
  pages = {21--51},
  issn = {1556-4967},
  doi = {10.1002/rob.20324},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.20324},
  urldate = {2023-03-14},
  abstract = {Robust, scalable simultaneous localization and mapping (SLAM) algorithms support the successful deployment of robots in real-world applications. In many cases these platforms deliver vast amounts of sensor data from large-scale, unstructured environments. These data may be difficult to interpret by end users without further processing and suitable visualization tools. We present a robust, automated system for large-scale three-dimensional (3D) reconstruction and visualization that takes stereo imagery from an autonomous underwater vehicle (AUV) and SLAM-based vehicle poses to deliver detailed 3D models of the seafloor in the form of textured polygonal meshes. Our system must cope with thousands of images, lighting conditions that create visual seams when texturing, and possible inconsistencies between stereo meshes arising from errors in calibration, triangulation, and navigation. Our approach breaks down the problem into manageable stages by first estimating local structure and then combining these estimates to recover a composite georeferenced structure using SLAM-based vehicle pose estimates. A texture-mapped surface at multiple scales is then generated that is interactively presented to the user through a visualization engine. We adapt established solutions when possible, with an emphasis on quickly delivering approximate yet visually consistent reconstructions on standard computing hardware. This allows scientists on a research cruise to use our system to design follow-up deployments of the AUV and complementary instruments. To date, this system has been tested on several research cruises in Australian waters and has been used to reliably generate and visualize reconstructions for more than 60 dives covering diverse habitats and representing hundreds of linear kilometers of survey. {\copyright} 2009 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZZS8GHLV/Johnson-Roberson et al. - 2010 - Generation and visualization of large-scale three-.pdf}
}

@inproceedings{joshi_high_2022,
  title = {High {{Definition}}, {{Inexpensive}}, {{Underwater Mapping}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Joshi, Bharat and Xanthidis, Marios and Rahman, Sharmin and Rekleitis, Ioannis},
  year = {2022},
  month = may,
  pages = {1113--1121},
  doi = {10.1109/ICRA46639.2022.9811695},
  abstract = {In this paper we present a complete framework for Underwater SLAM utilizing a single inexpensive sensor. Over the recent years, imaging technology of action cameras is producing stunning results even under the challenging conditions of the underwater domain. The GoPro 9 camera provides high definition video in synchronization with an Inertial Measurement Unit (IMU) data stream encoded in a single mp4 file. The visual inertial SLAM framework is augmented to adjust the map after each loop closure. Data collected at an artificial wreck of the coast of South Carolina and in caverns and caves in Florida demonstrate the robustness of the proposed approach in a variety of conditions.},
  keywords = {Cameras,Pipelines,Real-time systems,Robustness,Simultaneous localization and mapping,Streaming media,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/2F5ST8AN/Joshi et al. - 2022 - High Definition, Inexpensive, Underwater Mapping.pdf;/Users/kshitijgoel/Zotero/storage/CEDYL6QF/9811695.html}
}

@phdthesis{julian_mutual_2013,
  title = {Mutual {{Information-based Gradient-ascent Control}} for {{Distributed Robotics}}},
  author = {Julian, Brian J.},
  year = {2013},
  month = sep,
  address = {Cambridge, MA},
  school = {Massachusetts Institute of Technology},
  file = {/Users/kshitijgoel/Zotero/storage/G66GPWZD/_.pdf}
}

@inproceedings{julian_mutual_2013a,
  title = {On Mutual Information-Based Control of Range Sensing Robots for Mapping Applications},
  booktitle = {2013 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Julian, Brian J. and Karaman, Sertac and Rus, Daniela},
  year = {2013},
  month = nov,
  pages = {5156--5163},
  issn = {2153-0866},
  doi = {10.1109/IROS.2013.6697102},
  abstract = {In this paper we examine the correlation between the information content and the spatial realization of range measurements taken by a mapping robot. To do so, we consider the task of constructing an occupancy grid map with a binary Bayesian filter. Using a narrow beam-based sensor model (versus an additive white Gaussian noise model), we prove that any controller tasked to maximize a mutual information reward function is eventually attracted to unexplored space. This intuitive behavior is derived solely from the geometric dependencies of the occupancy grid mapping algorithm and the monotonie properties of mutual information. Since it is a function of both the robot's position and the uncertainty of the surrounding cells, mutual information encodes geometric relationships that are fundamental to robot control, thus yielding geometrically relevant reward surfaces on which the robot can navigate. Lastly, we present the results of two experiments employing an omnidirectional ground robot equipped with a laser rangefinder.},
  keywords = {Bayes methods,Entropy,Measurement by laser beam,Mutual information,Random variables,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/YZQ5UK2J/Julian et al. - 2013 - On mutual information-based control of range sensi.pdf;/Users/kshitijgoel/Zotero/storage/EKIEUW2Z/6697102.html}
}

@article{julian_mutual_2014,
  title = {On Mutual Information-Based Control of Range Sensing Robots for Mapping Applications},
  author = {Julian, Brian J. and Karaman, Sertac and Rus, Daniela},
  year = {2014},
  month = sep,
  journal = {The International Journal of Robotics Research},
  volume = {33},
  number = {10},
  pages = {1375--1392},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364914526288},
  url = {https://doi.org/10.1177/0278364914526288},
  urldate = {2022-04-22},
  abstract = {In this paper we examine the correlation between the information content and the spatial realization of range measurements taken by a mapping robot. To do so, we consider the task of constructing an occupancy grid map with a binary Bayesian filter. Using a beam-based sensor model (versus an additive white Gaussian noise model), we prove that any controller tasked to maximize a mutual information reward function is eventually attracted to unexplored space. This intuitive behavior is derived solely from the geometric dependencies of the occupancy grid mapping algorithm and the monotonic properties of mutual information. Since it is dependent on both the robot's position and the uncertainty of the surrounding cells, mutual information encodes geometric relationships that are fundamental to robot control, thus yielding geometrically relevant reward surfaces on which the robot can navigate. We also provide an algorithmic implementation for computing mutual information and show that its worst-case time and space complexities are quadratic and linear, respectively, with respect to the map's spatial resolution. Lastly, we present the results of experiments employing an omnidirectional ground robot equipped with a laser range finder. Our experimental results support our theoretical and computational findings.},
  langid = {english},
  keywords = {Bayes methods,Mapping robot,mutual information,range sensing robot,robot control},
  file = {/Users/kshitijgoel/Zotero/storage/LE6QG9QH/Julian et al. - 2014 - On mutual information-based control of range sensi.pdf}
}

@inproceedings{julier_new_1997,
  title = {New Extension of the {{Kalman}} Filter to Nonlinear Systems},
  booktitle = {Signal {{Processing}}, {{Sensor Fusion}}, and {{Target Recognition VI}}},
  author = {Julier, Simon J. and Uhlmann, Jeffrey K.},
  year = {1997},
  month = jul,
  volume = {3068},
  pages = {182--193},
  publisher = {SPIE},
  doi = {10.1117/12.280797},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/3068/0000/New-extension-of-the-Kalman-filter-to-nonlinear-systems/10.1117/12.280797.full},
  urldate = {2024-01-27},
  abstract = {The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.},
  file = {/Users/kshitijgoel/Zotero/storage/GN28F7KS/Julier and Uhlmann - 1997 - New extension of the Kalman filter to nonlinear sy.pdf}
}

@article{jung_gaussian_2022,
  title = {Gaussian {{Mixture Midway-Merge}} for {{Object SLAM}} with {{Pose Ambiguity}}},
  author = {Jung, Jae Hyung and Park, Chan Gook},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3224665},
  abstract = {In this letter, we propose a novel method to merge a Gaussian mixture on matrix Lie groups and present its application for a simultaneous localization and mapping problem with symmetric objects. The key idea is to predetermine the weighted mean called a midway point and merge Gaussian mixture components at the associated tangent space. Through this rule, the covariance matrix captures the original density more accurately, and the need for the back-projection is spared when compared to the conventional merge. We highlight the midway-merge by numerically evaluating dissimilarity metrics of density functions before and after the merge on the rotational group. Furthermore, we experimentally discover that the rotational error of symmetric objects follows heavy-tailed behavior and formulate the Gaussian sum filter to model it by a Gaussian mixture noise. The effectiveness of our approach is validated through virtual and real-world datasets.},
  keywords = {Gaussian mixture,matrix Lie group,object detection,SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/QAX72TUP/Jung and Park - 2022 - Gaussian Mixture Midway-Merge for Object SLAM with.pdf;/Users/kshitijgoel/Zotero/storage/D33ABSFU/9963653.html}
}

@phdthesis{junior_hunter_2021,
  title = {Hunter Drones : Drones Cooperation for Tracking an Intruder Drone},
  shorttitle = {Hunter Drones},
  author = {Junior, Cristino de Souza},
  year = {2021},
  month = apr,
  url = {https://theses.hal.science/tel-03418557},
  urldate = {2025-03-10},
  abstract = {In the last decade, we have witnessed significant advances in multi-robot systems. Much attention has been paid to the modeling of coordinated movement, called flocking;however, some current applications require more than the ability to navigate cohesively and without collision, for example, the use of drones to intercept a faster intruder. This application, to which this thesis is dedicated, although it is a subset of collective motion,has characteristics contrary to flocking, such as dispersion, in place of aggregation, and capture, instead of keeping desired distance. To reproduce more efficient and performing group-pursuit behavior in robotic applications,we propose in this work several behavior-based multi-agent strategies. Along most of this work, the interaction rules between the pursuers and the target are designed based on the geometric rules and relative kinematic models, commonly used in missiles'guidance laws. Furthermore, we investigate the application of the proposed strategies in real-timerobots. For that, a multilayer motion controller architecture is proposed, allowing theapplication of high-level navigation laws in a quadcopter. Our strategy shares concepts with classical multi-agents methods [49, 77, 58], such aslocal sense, limited interaction, and decentralization decision-make. Nevertheless, wediffer from most of them for considering the environment's perception of polar andrelative coordinates, which is a consistent assumption considering embedded sensors(LIDAR and camera). Besides, our work extends known techniques of navigation guidance laws to the multiagent problem. In other words, pursuer behavior is given by modified guidance laws,where the parameters are adapted according to the pursuit's engagement. As a result,we have emergent group ambush with non-crossing trajectories between pursuers.},
  langid = {english},
  school = {Universit{\'e} de Technologie de Compi{\`e}gne},
  file = {/Users/kshitijgoel/Zotero/storage/KHC6H5HH/Junior - 2021 - Hunter drones  drones cooperation for tracking an intruder drone.pdf}
}

@article{kaelbling_planning_1998,
  title = {Planning and Acting in Partially Observable Stochastic Domains},
  author = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
  year = {1998},
  month = may,
  journal = {Artificial Intelligence},
  volume = {101},
  number = {1},
  pages = {99--134},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(98)00023-X},
  url = {https://www.sciencedirect.com/science/article/pii/S000437029800023X},
  urldate = {2023-10-23},
  abstract = {In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.},
  keywords = {Partially observable Markov decision processes,Planning,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/UL3J2WRJ/Kaelbling et al. - 1998 - Planning and acting in partially observable stocha.pdf;/Users/kshitijgoel/Zotero/storage/ZQ46HR3E/S000437029800023X.html}
}

@inproceedings{kafai_directional_2010,
  title = {Directional Mean Shift and Its Application for Topology Classification of Local {{3D}} Structures},
  booktitle = {2010 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} - {{Workshops}}},
  author = {Kafai, Mehran and Miao, Yiyi and Okada, Kazunori},
  year = {2010},
  month = jun,
  pages = {170--177},
  issn = {2160-7516},
  doi = {10.1109/CVPRW.2010.5543591},
  url = {https://ieeexplore.ieee.org/document/5543591},
  urldate = {2024-06-27},
  abstract = {In this study, we introduce a new directional nonparametric clustering algorithm for 3D medical structure topology classification. This paper proposes directional mean shift (DMS) which extends the well known mean shift-based clustering, for handling directional statistics, toward analyzing directional/circular-domain data with phase-wraparound boundary conditions. Our overall approach transforms the 3D topology classification problem into a clustering analysis of a 2D image, following the work by Bahlmann et al. in the context of computer-aided diagnosis (CAD). The proposed DMS replaces the expectation-maximization (EM) algorithm for Gaussian mixture model (GMM) fitting used in the previous method addressing the shortcomings of the Bahlmann's method. Results from our experiments demonstrate the effectiveness of DMS in contrast to the original EM-based approach in solving the clustering problem with a 2D image unwrapped from a 3D spherical data, leading to better accuracy in the topology classification task.},
  keywords = {Biomedical imaging,Clustering algorithms,Computer science,Data analysis,Image analysis,Image color analysis,Medical diagnostic imaging,Statistical analysis,Statistics,Topology},
  file = {/Users/kshitijgoel/Zotero/storage/K3CQ3BNN/Kafai et al. - 2010 - Directional mean shift and its application for topology classification of local 3D structures.pdf;/Users/kshitijgoel/Zotero/storage/WN9SR8EV/5543591.html}
}

@article{kairouz_advances_2021,
  title = {Advances and {{Open Problems}} in {{Federated Learning}}},
  author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gasc{\'o}n, Adri{\`a} and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konecn{\'y}, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancr{\`e}de and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and {\"O}zg{\"u}r, Ayfer and Pagh, Rasmus and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Raykova, Mariana and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tram{\`e}r, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
  year = {2021},
  month = jun,
  journal = {Foundations and Trends{\textregistered} in Machine Learning},
  volume = {14},
  number = {1--2},
  pages = {1--210},
  publisher = {Now Publishers, Inc.},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000083},
  url = {https://www.nowpublishers.com/article/Details/MAL-083},
  urldate = {2024-02-23},
  abstract = {Advances and Open Problems in Federated Learning},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3SWIB9LT/Kairouz et al. - 2021 - Advances and Open Problems in Federated Learning.pdf}
}

@article{kaiser_simultaneous_2017,
  title = {Simultaneous {{State Initialization}} and {{Gyroscope Bias Calibration}} in {{Visual Inertial Aided Navigation}}},
  author = {Kaiser, Jacques and Martinelli, Agostino and Fontana, Flavio and Scaramuzza, Davide},
  year = {2017},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {1},
  pages = {18--25},
  issn = {2377-3766},
  doi = {10.1109/LRA.2016.2521413},
  url = {https://ieeexplore.ieee.org/document/7390213},
  urldate = {2024-12-17},
  abstract = {State of the art approaches for visual-inertial sensor fusion use filter-based or optimization-based algorithms. Due to the nonlinearity of the system, a poor initialization can have a dramatic impact on the performance of these estimation methods. Recently, a closed-form solution providing such an initialization was derived in [1]. That solution determines the velocity (angular and linear) of a monocular camera in metric units by only using inertial measurements and image features acquired in a short time interval. In this letter, we study the impact of noisy sensors on the performance of this closed-form solution. We show that the gyroscope bias, not accounted for in [1], significantly affects the performance of the method. Therefore, we introduce a new method to automatically estimate this bias. Compared to the original method, the new approach now models the gyroscope bias and is robust to it. The performance of the proposed approach is successfully demonstrated on real data from a quadrotor MAV.},
  keywords = {Calibration,Cameras,Closed-form solutions,Gyroscopes,Linear systems,localization,Localization,Robot sensing systems,Sensor fusion,Sensor Fusion,visual-based navigation,Visual-Based Navigation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/JRX2LEHU/Kaiser et al. - 2017 - Simultaneous State Initialization and Gyroscope Bias Calibration in Visual Inertial Aided Navigation.pdf}
}

@article{kalai_disentangling_2012,
  title = {Disentangling {{Gaussians}}},
  author = {Kalai, Adam Tauman and Moitra, Ankur and Valiant, Gregory},
  year = {2012},
  month = feb,
  journal = {Communications of the ACM},
  volume = {55},
  number = {2},
  pages = {113--120},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/2076450.2076474},
  url = {https://dl.acm.org/doi/10.1145/2076450.2076474},
  urldate = {2023-09-20},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/N9IMTU6Y/Kalai et al. - 2012 - Disentangling Gaussians.pdf}
}

@inproceedings{kalai_efficiently_2010,
  title = {Efficiently Learning Mixtures of Two {{Gaussians}}},
  booktitle = {Proceedings of the Forty-Second {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Kalai, Adam Tauman and Moitra, Ankur and Valiant, Gregory},
  year = {2010},
  month = jun,
  series = {{{STOC}} '10},
  pages = {553--562},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1806689.1806765},
  url = {https://dl.acm.org/doi/10.1145/1806689.1806765},
  urldate = {2024-05-26},
  abstract = {Given data drawn from a mixture of multivariate Gaussians, a basic problem is to accurately estimate the mixture parameters. We provide a polynomial-time algorithm for this problem for the case of two Gaussians in \$n\$ dimensions (even if they overlap), with provably minimal assumptions on the Gaussians, and polynomial data requirements. In statistical terms, our estimator converges at an inverse polynomial rate, and no such estimator (even exponential time) was known for this problem (even in one dimension). Our algorithm reduces the n-dimensional problem to the one-dimensional problem, where the method of moments is applied. One technical challenge is proving that noisy estimates of the first six moments of a univariate mixture suffice to recover accurate estimates of the mixture parameters, as conjectured by Pearson (1894), and in fact these estimates converge at an inverse polynomial rate. As a corollary, we can efficiently perform near-optimal clustering: in the case where the overlap between the Gaussians is small, one can accurately cluster the data, and when the Gaussians have partial overlap, one can still accurately cluster those data points which are not in the overlap region. A second consequence is a polynomial-time density estimation algorithm for arbitrary mixtures of two Gaussians, generalizing previous work on axis-aligned Gaussians (Feldman \{{\textbackslash}em et al\}, 2006).},
  isbn = {978-1-4503-0050-6},
  keywords = {finite mixture models,Gaussians,method of moments},
  file = {/Users/kshitijgoel/Zotero/storage/HYET36B7/Kalai et al. - 2010 - Efficiently learning mixtures of two Gaussians.pdf}
}

@inproceedings{kalaiah_statistical_2003,
  title = {Statistical Point Geometry},
  booktitle = {Proceedings of the 2003 {{Eurographics}}/{{ACM SIGGRAPH}} Symposium on {{Geometry}} Processing},
  author = {Kalaiah, Aravind and Varshney, Amitabh},
  year = {2003},
  month = jun,
  series = {{{SGP}} '03},
  pages = {107--115},
  publisher = {Eurographics Association},
  address = {Goslar, DEU},
  urldate = {2024-04-18},
  abstract = {We propose a scheme for modeling point sample geometry with statistical analysis. In our scheme we depart from the current schemes that deterministically represent the attributes of each point sample. We show how the statistical analysis of a densely sampled point model can be used to improve the geometry bandwidth bottleneck and to do randomized rendering without sacrificing visual realism. We first carry out a hierarchical principal component analysis (PCA) of the model. This stage partitions the model into compact local geometries by exploiting local coherence. Our scheme handles vertex coordinates, normals, and color. The input model is reconstructed and rendered using a probability distribution derived from the PCA analysis. We demonstrate the benefits of this approach in all stages of the graphics pipeline: (1) orders of magnitude improvement in the storage and transmission complexity of point geometry, (2) direct rendering from compressed data, and (3) view-dependent randomized rendering.},
  isbn = {978-1-58113-687-6},
  file = {/Users/kshitijgoel/Zotero/storage/SPBKUWH8/Kalaiah and Varshney - Statistical Point Geometry.pdf}
}

@article{kalaiah_statistical_2005,
  title = {Statistical Geometry Representation for Efficient Transmission and Rendering},
  author = {Kalaiah, Aravind and Varshney, Amitabh},
  year = {2005},
  month = apr,
  journal = {ACM Transactions on Graphics},
  volume = {24},
  number = {2},
  pages = {348--373},
  issn = {0730-0301},
  doi = {10.1145/1061347.1061356},
  url = {https://dl.acm.org/doi/10.1145/1061347.1061356},
  urldate = {2024-04-18},
  abstract = {Traditional geometry representations have focused on representing the details of the geometry in a deterministic fashion. In this article we propose a statistical representation of the geometry that leverages local coherence for very large datasets. We show how the statistical analysis of a densely sampled point model can be used to improve the geometry bandwidth bottleneck, both on the system bus and over the network as well as for randomized rendering, without sacrificing visual realism. Our statistical representation is built using a clustering-based hierarchical principal component analysis (PCA) of the point geometry. It gives us a hierarchical partitioning of the geometry into compact local nodes representing attributes such as spatial coordinates, normal, and color. We pack this information into a few bytes using classification and quantization. This allows our representation to directly render from compressed format for efficient remote as well as local rendering. Our representation supports both view-dependent and on-demand rendering. Our approach renders each node using quasi-random sampling utilizing the probability distribution derived from the PCA analysis. We show many benefits of our approach: (1) several-fold improvement in the storage and transmission complexity of point geometry; (2) direct rendering from compressed data; and (3) support for local and remote rendering on a variety of rendering platforms such as CPUs, GPUs, and PDAs.},
  keywords = {network graphics,Point-based rendering,principal component analysis,programmable GPU,progressive transmission,quasi-random numbers,view-dependent rendering},
  file = {/Users/kshitijgoel/Zotero/storage/N7CI4EBG/Kalaiah and Varshney - 2005 - Statistical geometry representation for efficient .pdf}
}

@article{kalman_new_1960,
  title = {A {{New Approach}} to {{Linear Filtering}} and {{Prediction Problems}}},
  author = {Kalman, R. E.},
  year = {1960},
  month = mar,
  journal = {Journal of Basic Engineering},
  volume = {82},
  number = {1},
  pages = {35--45},
  issn = {0021-9223},
  doi = {10.1115/1.3662552},
  url = {https://doi.org/10.1115/1.3662552},
  urldate = {2023-08-12},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  file = {/Users/kshitijgoel/Zotero/storage/FV58NR7F/Kalman - 1960 - A New Approach to Linear Filtering and Prediction .pdf;/Users/kshitijgoel/Zotero/storage/M268AJTQ/A-New-Approach-to-Linear-Filtering-and-Prediction.html}
}

@article{kambesis_importance_2007,
  title = {{{THE IMPORTANCE OF CAVE EXPLORATION TO SCIENTIFIC RESEARCH}}},
  author = {Kambesis, Patricia},
  year = {2007},
  month = apr,
  journal = {Journal of Cave and Karst Studies},
  volume = {69},
  number = {1},
  pages = {46--58},
  abstract = {Of the many objects of scientific interest, caves present a unique challenge because, except for entrance areas, caves are largely hidden from view. As a consequence, caves have not generally attracted the attention of mainstream scientists. With the exception of cave entrances noted on some topographic maps, most caves are not apparent from topographic maps, satellite and LANDSAT imagery, or aerial photographs. Caves and their features exist in an environment with no natural light and contain a myriad of physical and psychological obstacles. It is the cave explorer who ventures past these obstacles, motivated by curiosity and the desire to find and document places previously unknown. Systematic cave exploration is a two-fold process that involves the physical pursuit and discovery of caves and cave systems, and field documentation that provides baseline data in the form of cave survey data and notes, cave entrance and cave/karst feature locations and inventories, written observations, and photo-documentation. These data are synthesized into cave maps, topographic overlays, narrative descriptions, and reports that serve as exploration tools for finding more passages and caves. Systematic documentation and its derivative products also bring the hidden nature of caves and their features to the attention of scientists and provide a basis not only for cave-related research but for a wide range of related scientific endeavors.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZFLPJ9CE/Kambesis - THE IMPORTANCE OF CAVE EXPLORATION TO SCIENTIFIC R.pdf}
}

@inproceedings{kamgar-parsi_quantization_1989,
  title = {Quantization Error in Spatial Sampling: Comparison between Square and Hexagonal Pixels},
  shorttitle = {Quantization Error in Spatial Sampling},
  booktitle = {Proceedings {{CVPR}} '89: {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {{Kamgar-Parsi}, B. and {Kamgar-Parsi}, B. and Sander, W.A.},
  year = {1989},
  pages = {604--611},
  publisher = {IEEE Comput. Soc. Press},
  address = {San Diego, CA, USA},
  doi = {10.1109/CVPR.1989.37908},
  url = {http://ieeexplore.ieee.org/document/37908/},
  urldate = {2024-02-14},
  isbn = {978-0-8186-1918-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6A9ZSWFP/Kamgar-Parsi et al. - 1989 - Quantization error in spatial sampling comparison.pdf}
}

@inproceedings{kampa_closedform_2011,
  title = {Closed-Form Cauchy-Schwarz {{PDF}} Divergence for Mixture of {{Gaussians}}},
  booktitle = {The 2011 {{International Joint Conference}} on {{Neural Networks}}},
  author = {Kampa, Kittipat and Hasanbelliu, Erion and Principe, Jose C.},
  year = {2011},
  month = jul,
  pages = {2578--2585},
  issn = {2161-4407},
  doi = {10.1109/IJCNN.2011.6033555},
  abstract = {This paper presents an efficient approach to calculate the difference between two probability density functions (pdfs), each of which is a mixture of Gaussians (MoG). Unlike Kullback-Leibler divergence (DKL), the authors propose that the Cauchy-Schwarz (CS) pdf divergence measure (DCS) can give an analytic, closed-form expression for MoG. This property of the DCS makes fast and efficient calculations possible, which is tremendously desired in real-world applications where the dimensionality of the data/features is very high. We show that DCS follows similar trends to DKL, but can be computed much faster, especially when the dimensionality is high. Moreover, the proposed method is shown to significantly outperform DKL in classifying real-world 2D and 3D objects, and static hand posture recognition based on distances alone.},
  keywords = {Accuracy,Closed-form solutions,Feature extraction,Nickel,Probability density function,Silicon,Three dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/DRPYMXLF/Kampa et al. - 2011 - Closed-form cauchy-schwarz PDF divergence for mixt.pdf;/Users/kshitijgoel/Zotero/storage/7CYN9JQN/6033555.html}
}

@phdthesis{kampa_structured_2011,
  title = {Structured Graphical Models for Unsupervised Image Segmentation},
  author = {Kampa, Kittipat},
  year = {2011},
  address = {United States -- Florida},
  url = {https://www.proquest.com/docview/1112878477/abstract/3CC77E0312BA4513PQ/1},
  urldate = {2024-11-05},
  abstract = {In the dissertation, we seek the following goals: (1) to come up with a probabilistic graphical model framework for unsupervised segmentation on structured data, and (2) to find a computationally efficient and reliable solution to image segmentation with superpixels as opposed to pixels. We develop a Data-Driven Tree-structured Bayesian network (DDT), a novel probabilistic graphical model for hierarchical unsupervised image segmentation. Like tree-structure belief networks (TSBNs), DDT captures both long and short-ranged correlations between neighboring regions in each image using a tree-structured prior. Unlike other approaches, DDT first segments an input image into superpixels and learns a tree-structured prior based on the topology of superpixels in different scales. Such a tree structure is referred to as a data-driven tree structure. Each superpixel is represented by a variable node taking a discrete value of segmentation class/label. The probabilistic relationships among the nodes are represented by edges in the network. Hence, unsupervised image segmentation can be viewed as an inference problem on the DDT structure nodes, which can be carried out efficiently. The end image segmentation result can be obtained by applying the maximum posterior marginal to each variable node in the network. We provide the parameter estimation regime using the Expectation-Maximization (EM) algorithm combined with the sum-product algorithm. With respect to the objectives, we hypothesize that 1) Hierarchical segmentation gives more meaningful results than the results from only one scale; 2) The tree-structure prior would smooth the segmentation results, yielding better segmentation; 3) Exploiting the superpixel would be a way to smooth the segmentation, so the segmentation differences between the model with and without the tree-structured prior would be less at the superpixel-level segmentation than the pixel-level; 4) The model with evidence in all scales gives better results than the one without. We evaluate quantitatively our results with respect to the ground-truth segmentation in the Berkeley Segmentation Dataset and Benchmark 500 (BSDS500), a well-known image database benchmark, demonstrating that our proposed framework performs competitively with the state of the art in unsupervised image segmentation and contour detection. (Full text of this dissertation may be available via the University of Florida Libraries web site. Please check http://www.uflib.ufl.edu/etd.html)},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9781267734433},
  langid = {english},
  school = {University of Florida},
  keywords = {Applied sciences,Artificial intelligence,Bayesian networks,Communication and the arts,Computer vision,Graphical models,Image,Information science,Machine learning,Unsupervised segmentation},
  file = {/Users/kshitijgoel/Zotero/storage/EX5NM2RW/Kampa - 2011 - Structured graphical models for unsupervised image segmentation.pdf}
}

@inproceedings{karaman_highspeed_2012,
  title = {High-Speed Flight in an Ergodic Forest},
  booktitle = {2012 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Karaman, Sertac and Frazzoli, Emilio},
  year = {2012},
  month = may,
  pages = {2899--2906},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2012.6225235},
  abstract = {Inspired by birds flying through cluttered environments such as dense forests, this paper studies the theoretical foundations of high-speed motion through a randomly-generated obstacle field. Assuming that the locations and the sizes of the trees are determined by an ergodic point process, and under mild technical conditions on the dynamics of the bird, it is shown that the existence of an infinite collision-free trajectory through the forest exhibits a phase transition. In other words, if the bird flies faster than a certain critical speed, there is no infinite collision-free trajectory, with probability one, i.e., the bird will eventually collide with some tree, almost surely, regardless of the planning algorithm governing its motion. On the other hand, if the bird flies slower than this critical speed, then there exists at least one infinite collision-free trajectory, almost surely. Lower and upper bounds on the critical speed are derived for the special case of a Poisson forest considering a simple model for the bird's dynamics. Moreover, results from an extensive Monte-Carlo simulation study are presented. This paper also establishes novel connections between robot motion planning and statistical physics through ergodic theory and the theory of percolation, which may be of independent interest.},
  keywords = {Birds,Equations,Lattices,Mathematical model,Q measurement,Trajectory,Vegetation},
  file = {/Users/kshitijgoel/Zotero/storage/9IZHTRXE/Karaman and Frazzoli - 2012 - High-speed flight in an ergodic forest.pdf;/Users/kshitijgoel/Zotero/storage/U2P4X48Y/6225235.html}
}

@article{karaman_samplingbased_2011,
  title = {Sampling-Based Algorithms for Optimal Motion Planning},
  author = {Karaman, Sertac and Frazzoli, Emilio},
  year = {2011},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {30},
  number = {7},
  pages = {846--894},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364911406761},
  url = {https://doi.org/10.1177/0278364911406761},
  urldate = {2023-05-04},
  abstract = {During the last decade, sampling-based path planning algorithms, such as probabilistic roadmaps (PRM) and rapidly exploring random trees (RRT), have been shown to work well in practice and possess theoretical guarantees such as probabilistic completeness. However, little effort has been devoted to the formal analysis of the quality of the solution returned by such algorithms, e.g. as a function of the number of samples. The purpose of this paper is to fill this gap, by rigorously analyzing the asymptotic behavior of the cost of the solution returned by stochastic sampling-based algorithms as the number of samples increases. A number of negative results are provided, characterizing existing algorithms, e.g. showing that, under mild technical conditions, the cost of the solution returned by broadly used sampling-based algorithms converges almost surely to a non-optimal value. The main contribution of the paper is the introduction of new algorithms, namely, PRM* and RRT*, which are provably asymptotically optimal, i.e. such that the cost of the returned solution converges almost surely to the optimum. Moreover, it is shown that the computational complexity of the new algorithms is within a constant factor of that of their probabilistically complete (but not asymptotically optimal) counterparts. The analysis in this paper hinges on novel connections between stochastic sampling-based path planning algorithms and the theory of random geometric graphs.},
  file = {/Users/kshitijgoel/Zotero/storage/PAM6RPJN/Karaman and Frazzoli - 2011 - Sampling-based algorithms for optimal motion plann.pdf}
}

@inproceedings{karimi_global_2019,
  title = {On the {{Global Convergence}} of ({{Fast}}) {{Incremental Expectation Maximization Methods}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Karimi, Belhal and Wai, Hoi-To and Moulines, Eric and Lavielle, Marc},
  year = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2019/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html},
  urldate = {2023-02-18},
  abstract = {The EM algorithm is one of the most popular algorithm for inference in latent data models. The original formulation of the EM algorithm does not scale to large data set, because the whole data set is required at each iteration of the algorithm. To alleviate this problem, Neal and Hinton [1998] have proposed an incremental version of the EM (iEM) in which at each iteration the conditional expectation of the latent data (E-step) is updated only for a mini-batch of observations. Another approach has been proposed by Cappe and Moulines [2009] in which the E-step is replaced by a stochastic approximation step, closely related to stochastic gradient. In this paper, we analyze incremental and stochastic version of the EM algorithm as well as the variance reduced-version of [Chen et al., 2018] in a common unifying framework. We also introduce a new version incremental version, inspired by the SAGA algorithm by Defazio et al. [2014]. We establish non-asymptotic convergence bounds for global convergence. Numerical applications are presented in this article to illustrate our findings.},
  file = {/Users/kshitijgoel/Zotero/storage/SAF2HH86/Karimi et al. - 2019 - On the Global Convergence of (Fast) Incremental Ex.pdf}
}

@article{karydis_energetics_2017,
  title = {Energetics in Robotic Flight at Small Scales},
  author = {Karydis, Konstantinos and Kumar, Vijay},
  year = {2017},
  month = feb,
  journal = {Interface Focus},
  volume = {7},
  number = {1},
  pages = {20160088},
  publisher = {Royal Society},
  doi = {10.1098/rsfs.2016.0088},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsfs.2016.0088},
  urldate = {2023-11-14},
  abstract = {Recent advances in design, sensing and control have led to aerial robots that offer great promise in a range of real-world applications. However, one critical open question centres on how to improve the energetic efficiency of aerial robots so that they can be useful in practical situations. This review paper provides a survey on small-scale aerial robots (i.e. less than 1 m2 area foot print, and less than 3 kg weight) from the point of view of energetics. The paper discusses methods to improve the efficiency of aerial vehicles, and reports on recent findings by the authors and other groups on modelling the impact of aerodynamics for the purpose of building energy-aware motion planners and controllers.},
  keywords = {aerial robots,aerodynamic and ground effects,energetics,energy-aware motion planning,high-speed robotic flight,unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/2RMF7NRL/Karydis and Kumar - 2017 - Energetics in robotic flight at small scales.pdf}
}

@article{kasarapu_minimum_2015,
  title = {Minimum Message Length Estimation of Mixtures of Multivariate {{Gaussian}} and von {{Mises-Fisher}} Distributions},
  author = {Kasarapu, Parthan and Allison, Lloyd},
  year = {2015},
  month = sep,
  journal = {Machine Learning},
  volume = {100},
  number = {2},
  pages = {333--378},
  issn = {1573-0565},
  doi = {10.1007/s10994-015-5493-0},
  url = {https://doi.org/10.1007/s10994-015-5493-0},
  urldate = {2024-07-15},
  abstract = {Mixture modelling involves explaining some observed evidence using a combination of probability distributions. The crux of the problem is the inference of an optimal number of mixture components and their corresponding parameters. This paper discusses unsupervised learning of mixture models using the Bayesian Minimum Message Length (MML) criterion. To demonstrate the effectiveness of search and inference of mixture parameters using the proposed approach, we select two key probability distributions, each handling fundamentally different types of data: the multivariate Gaussian distribution to address mixture modelling of data distributed in Euclidean space, and the multivariate von Mises-Fisher (vMF) distribution to address mixture modelling of directional data distributed on a unit hypersphere. The key contributions of this paper, in addition to the general search and inference methodology, include the derivation of MML expressions for encoding the data using multivariate Gaussian and von Mises-Fisher distributions, and the analytical derivation of the MML estimates of the parameters of the two distributions. Our approach is tested on simulated and real world data sets. For instance, we infer vMF mixtures that concisely explain experimentally determined three-dimensional protein conformations, providing an effective null model description of protein structures that is central to many inference problems in structural bioinformatics. The experimental results demonstrate that the performance of our proposed search and inference method along with the encoding schemes improve on the state of the art mixture modelling techniques.},
  langid = {english},
  keywords = {Minimum message length,Mixture modelling,Multivariate Gaussian,Protein structure,von Mises-Fisher},
  file = {/Users/kshitijgoel/Zotero/storage/AUPQVVK8/Kasarapu and Allison - 2015 - Minimum message length estimation of mixtures of multivariate Gaussian and von Mises-Fisher distribu.pdf}
}

@inproceedings{katz_visibility_2015,
  title = {On the {{Visibility}} of {{Point Clouds}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Katz, Sagi and Tal, Ayellet},
  year = {2015},
  month = dec,
  pages = {1350--1358},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2015.159},
  url = {https://ieeexplore.ieee.org/document/7410516},
  urldate = {2024-11-05},
  abstract = {Is it possible to determine the visible subset of points directly from a given point cloud? Interestingly, it was shown that this is indeed the case - despite the fact that points cannot occlude each other, this task can be performed without surface reconstruction or normal estimation. The operator is very simple - it first transforms the points to a new domain and then constructs the convex hull in that domain. Points that lie on the convex hull of the transformed set of points are the images of the visible points. This operator found numerous applications in computer vision, including face reconstruction, keypoint detection, finding the best viewpoints, reduction of points, and many more. The current paper addresses a fundamental question: What properties should a transformation function satisfy, in order to be utilized in this operator? We show that three such properties are sufficient: the sign of the function, monotonicity, and a condition regarding the function's parameter. The correctness of an algorithm that satisfies these three properties is proved. Finally, we show an interesting application of the operator - assignment of visibility-confidence score. This feature is missing from previous approaches, where a binary yes/no visibility is determined. This score can be utilized in various applications, we illustrate its use in view-dependent curvature estimation.},
  keywords = {Computer vision,Estimation,Face,Image reconstruction,Kernel,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/JVMCTVTL/Katz and Tal - 2015 - On the Visibility of Point Clouds.pdf;/Users/kshitijgoel/Zotero/storage/A87M7C7D/7410516.html}
}

@inproceedings{kaufmann_copilot_2021,
  title = {Copilot {{MIKE}}: {{An Autonomous Assistant}} for {{Multi-Robot Operations}} in {{Cave Exploration}}},
  shorttitle = {Copilot {{MIKE}}},
  booktitle = {2021 {{IEEE Aerospace Conference}} (50100)},
  author = {Kaufmann, Marcel and Vaquero, Tiago Stegun and Correa, Gustavo J. and Otstr, Kyohei and Ginting, Muhammad F. and Beltrame, Giovanni and {Agha-Mohammadi}, Ali-Akbar},
  year = {2021},
  month = mar,
  pages = {1--9},
  issn = {1095-323X},
  doi = {10.1109/AERO50100.2021.9438530},
  abstract = {Operating a team of robots under time and risk constraints can be challenging for a human operator. Environmental conditions, extrinsic risks, and accessibility might restrict humans from directly partaking in exploration tasks altogether. Hence, robotic systems with autonomous exploration and disaster response capabilities have evolved over the past years and help keep human explorers and emergency response teams from harm. In this work, we introduce Copilot MIKE, an autonomous assistant for human-in-the-loop multi-robot operations. Copilot MIKE assists a single operator in monitoring robot teams, strategic planning, and communicating high level commands to the robots. During complex and potentially stressful exploration missions, Copilot MIKE helps to maintain a bearable workload and high situational awareness. In this work, we mainly focus on cave exploration tasks in the context of the DARPA Subterranean Challenge (SubT), but we designed a generic assistant that can be used in other domains, such as search and rescue, science, and (space) exploration missions as well. Experimental mission runs were conducted in preparation for the SubT cave challenge and Copilot MIKE has been tested in realistic cave exploration simulations. We show that Copilot MIKE has the potential to reduce workload, while our operators place trust in the system. They report that they focused on important parts of a mission, rather than planning, adopting and memorizing a complete mission strategy themselves.},
  keywords = {Emergency services,Physiology,Schedules,Scheduling algorithms,Space missions,Strategic planning,Time factors},
  file = {/Users/kshitijgoel/Zotero/storage/8Y6GLWFG/Kaufmann et al. - 2021 - Copilot MIKE An Autonomous Assistant for Multi-Ro.pdf;/Users/kshitijgoel/Zotero/storage/YZ8PC6TB/9438530.html}
}

@inproceedings{kaymaz_obstacle_2023,
  title = {Obstacle {{Identification}} and {{Ellipsoidal Decomposition}} for {{Fast Motion Planning}} in {{Unknown Dynamic Environments}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Kaymaz, Mehmetcan and Ure, Naz{\i}m Kemal},
  year = {2023},
  month = may,
  pages = {1694--1700},
  doi = {10.1109/ICRA48891.2023.10160444},
  abstract = {Collision avoidance in the presence of dynamic obstacles in unknown environments is one of the most critical challenges for unmanned systems. In this paper, we present a method that identifies obstacles in terms of ellipsoids to estimate linear and angular obstacle velocities. Our proposed method is based on the idea of any object can be approximately expressed by ellipsoids. To achieve this, we propose a method based on variational Bayesian estimation of Gaussian mixture model, the Kyachiyan algorithm, and a refinement algorithm. Our proposed method does not require knowledge of the number of clusters and can operate in real-time, unlike existing optimization-based methods. In addition, we define an ellipsoid-based feature vector to match obstacles given two timely close point frames. Our method can be applied to any environment with static and dynamic obstacles, including ones with rotating obstacles. We compare our algorithm with other clustering methods and show that when coupled with a trajectory planner, the overall system can efficiently traverse unknown environments in the presence of dynamic obstacles.},
  keywords = {Approximation algorithms,Clustering algorithms,Clustering methods,Dynamics,Heuristic algorithms,Real-time systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/F9XP2U65/Kaymaz and Ure - 2023 - Obstacle Identification and Ellipsoidal Decomposit.pdf;/Users/kshitijgoel/Zotero/storage/M4H5MTWV/10160444.html}
}

@article{kazhdan_screened_2013,
  title = {Screened Poisson Surface Reconstruction},
  author = {Kazhdan, Michael and Hoppe, Hugues},
  year = {2013},
  month = jun,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {3},
  pages = {1--13},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2487228.2487237},
  url = {https://dl.acm.org/doi/10.1145/2487228.2487237},
  urldate = {2023-10-08},
  abstract = {Poisson surface reconstruction creates watertight surfaces from oriented point sets. In this work we extend the technique to explicitly incorporate the points as interpolation constraints. The extension can be interpreted as a generalization of the underlying mathematical framework to a screened Poisson equation. In contrast to other image and geometry processing techniques, the screening term is defined over a sparse set of points rather than over the full domain. We show that these sparse constraints can nonetheless be integrated efficiently. Because the modified linear system retains the same finite-element discretization, the sparsity structure is unchanged, and the system can still be solved using a multigrid approach. Moreover we present several algorithmic improvements that together reduce the time complexity of the solver to linear in the number of points, thereby enabling faster, higher-quality surface reconstructions.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/96FM9488/Kazhdan and Hoppe - 2013 - Screened poisson surface reconstruction.pdf}
}

@inproceedings{keetha_splatam_2024,
  title = {{{SplaTAM}}: {{Splat Track}} \& {{Map 3D Gaussians}} for {{Dense RGB-D SLAM}}},
  shorttitle = {{{SplaTAM}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Keetha, Nikhil and Karhade, Jay and Jatavallabhula, Krishna Murthy and Yang, Gengshan and Scherer, Sebastian and Ramanan, Deva and Luiten, Jonathon},
  year = {2024},
  pages = {21357--21366},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Keetha_SplaTAM_Splat_Track__Map_3D_Gaussians_for_Dense_RGB-D_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SVUUY8US/Keetha et al. - 2024 - SplaTAM Splat Track & Map 3D Gaussians for Dense RGB-D SLAM.pdf}
}

@article{keidar_efficient_2014,
  title = {Efficient Frontier Detection for Robot Exploration},
  author = {Keidar, Matan and Kaminka, Gal A.},
  year = {2014},
  month = feb,
  journal = {The International Journal of Robotics Research},
  volume = {33},
  number = {2},
  pages = {215--236},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364913494911},
  url = {https://doi.org/10.1177/0278364913494911},
  urldate = {2023-11-03},
  abstract = {Frontier-based exploration is the most common approach to exploration, a fundamental problem in robotics. In frontier-based exploration, robots explore by repeatedly detecting (and moving towards) frontiers, the segments which separate the known regions from those unknown. A frontier detection sub-process examines map and/or sensor readings to identify frontiers for exploration. However, most frontier detection algorithms process the entire map data. This can be a time-consuming process, which affects the exploration decisions. In this work, we present several novel frontier detection algorithms that do not process the entire map data, and explore them in depth. We begin by investigating algorithms that represent two approaches: Wavefront Frontier Detector (WFD), a graph-search-based algorithm which examines only known areas, and Fast Frontier Detector (FFD), which examines only new laser readings data. We analytically examine the complexity of both algorithms, and discuss their correctness. We then improve by combining elements of both, to create two additional algorithms, called WFD-INC and WFD-IP . We empirically evaluate all algorithms, and show that they are all faster than a state-of-the-art frontier detector implementation (by several orders of magnitude). We additionally contrast them with each other and demonstrate the FFD and WFD-IP are faster than the others by one additional order of magnitude.},
  file = {/Users/kshitijgoel/Zotero/storage/HBUP5BRC/Keidar and Kaminka - 2014 - Efficient frontier detection for robot exploration.pdf}
}

@inproceedings{keller_realtime_2013,
  title = {Real-{{Time 3D Reconstruction}} in {{Dynamic Scenes Using Point-Based Fusion}}},
  booktitle = {2013 {{International Conference}} on {{3D Vision}} - {{3DV}} 2013},
  author = {Keller, Maik and Lefloch, Damien and Lambers, Martin and Izadi, Shahram and Weyrich, Tim and Kolb, Andreas},
  year = {2013},
  month = jun,
  pages = {1--8},
  issn = {1550-6185},
  doi = {10.1109/3DV.2013.9},
  abstract = {Real-time or online 3D reconstruction has wide applicability and receives further interest due to availability of consumer depth cameras. Typical approaches use a moving sensor to accumulate depth measurements into a single model which is continuously refined. Designing such systems is an intricate balance between reconstruction quality, speed, spatial scale, and scene assumptions. Existing online methods either trade scale to achieve higher quality reconstructions of small objects/scenes. Or handle larger scenes by trading real-time performance and/or quality, or by limiting the bounds of the active reconstruction. Additionally, many systems assume a static scene, and cannot robustly handle scene motion or reconstructions that evolve to reflect scene changes. We address these limitations with a new system for real-time dense reconstruction with equivalent quality to existing online methods, but with support for additional spatial scale and robustness in dynamic scenes. Our system is designed around a simple and flat point-Based representation, which directly works with the input acquired from range/depth sensors, without the overhead of converting between representations. The use of points enables speed and memory efficiency, directly leveraging the standard graphics pipeline for all central operations, i.e., camera pose estimation, data association, outlier removal, fusion of depth maps into a single denoised model, and detection and update of dynamic objects. We conclude with qualitative and quantitative results that highlight robust tracking and high quality reconstructions of a diverse set of scenes at varying scales.},
  keywords = {3D cameras and sensors,3D shape reconstruction,Cameras,Data models,Estimation,GPU,Iterative closest point algorithm,Kinect Fusion,Real-time,Robustness,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/7BCESG84/Keller et al. - 2013 - Real-Time 3D Reconstruction in Dynamic Scenes Usin.pdf}
}

@article{kerbl_3d_2023,
  title = {{{3D Gaussian Splatting}} for {{Real-Time Radiance Field Rendering}}},
  author = {Kerbl, Bernhard and Kopanas, Georgios and Leimkuehler, Thomas and Drettakis, George},
  year = {2023},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {42},
  number = {4},
  pages = {139:1--139:14},
  issn = {0730-0301},
  doi = {10.1145/3592433},
  url = {https://dl.acm.org/doi/10.1145/3592433},
  urldate = {2023-09-14},
  abstract = {Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time ({$\geq$} 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.},
  keywords = {3D gaussians,novel view synthesis,radiance fields,real-time rendering},
  file = {/Users/kshitijgoel/Zotero/storage/E7MIUT8Q/Kerbl et al. - 2023 - 3D Gaussian Splatting for Real-Time Radiance Field.pdf}
}

@book{kernighan_programming_1991,
  title = {The {{C}} Programming Language},
  author = {Kernighan, Brian W. and Ritchie, Dennis M.},
  year = {1991},
  series = {Prentice-{{Hall}} Software Series},
  edition = {28. print},
  publisher = {Prentice-Hall},
  address = {Englewood Cliffs, NJ},
  isbn = {978-0-13-110163-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/REDXKN32/k&r.pdf}
}

@inproceedings{keselman_approximate_2022,
  title = {Approximate {{Differentiable Rendering}} with~{{Algebraic Surfaces}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2022: 17th {{European Conference}}, {{Tel Aviv}}, {{Israel}}, {{October}} 23--27, 2022, {{Proceedings}}, {{Part XXXII}}},
  author = {Keselman, Leonid and Hebert, Martial},
  year = {2022},
  month = oct,
  pages = {596--614},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-031-19824-3_35},
  url = {https://doi.org/10.1007/978-3-031-19824-3_35},
  urldate = {2023-10-06},
  abstract = {Differentiable renderers provide a direct mathematical link between an object's 3D representation and images of that object. In this work, we develop an approximate differentiable renderer for a compact, interpretable representation, which we call Fuzzy Metaballs. Our approximate renderer focuses on rendering shapes via depth maps and silhouettes. It sacrifices fidelity for utility, producing fast runtimes and high-quality gradient information that can be used to solve vision tasks. Compared to mesh-based differentiable renderers, our method has forward passes that are 5x faster and backwards passes that are 30x faster. The depth maps and silhouette images generated by our method are smooth and defined everywhere. In our evaluation of differentiable renderers for pose estimation, we show that our method is the only one comparable to classic techniques. In shape from silhouette, our method performs well using only gradient descent and a per-pixel loss, without any surrogate losses or regularization. These reconstructions work well even on natural video sequences with segmentation artifacts. Project page: https://leonidk.github.io/fuzzy-metaballs},
  isbn = {978-3-031-19823-6},
  keywords = {Differentiable rendering,Gaussian mixture models,Implicit surfaces,Metaballs,Pose estimation,Shape from silhouette},
  file = {/Users/kshitijgoel/Zotero/storage/UVPPTTRT/Keselman and Hebert - 2022 - Approximate Differentiable Rendering with Algebrai.pdf}
}

@inproceedings{keselman_direct_2019,
  title = {Direct {{Fitting}} of {{Gaussian Mixture Models}}},
  booktitle = {2019 16th {{Conference}} on {{Computer}} and {{Robot Vision}} ({{CRV}})},
  author = {Keselman, Leonid and Hebert, Martial},
  year = {2019},
  month = may,
  pages = {25--32},
  doi = {10.1109/CRV.2019.00012},
  url = {https://ieeexplore.ieee.org/document/8781611/?arnumber=8781611},
  urldate = {2025-01-06},
  abstract = {When fitting Gaussian Mixture Models to 3D geometry, the model is typically fit to point clouds, even when the shapes were obtained as 3D meshes. Here we present a formulation for fitting Gaussian Mixture Models (GMMs) directly to geometric objects, using the triangles of triangular mesh instead of using points sampled from its surface. We demonstrate that this modification enables fitting higher-quality GMMs under a wider range of initialization conditions. Additionally, models obtained from this fitting method are shown to produce an improvement in 3D registration for both meshes and RGB-D frames.},
  keywords = {Gaussian mixture model,gmm shape mesh registration approximation representation 3d point cloud vision mixture model slam,Mathematical model,Robots,Solid modeling,Three-dimensional displays,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/FNZRGHMS/Keselman and Hebert - 2019 - Direct Fitting of Gaussian Mixture Models.pdf;/Users/kshitijgoel/Zotero/storage/6T6NV75S/8781611.html}
}

@misc{keselman_flexible_2023,
  title = {Flexible {{Techniques}} for {{Differentiable Rendering}} with {{3D Gaussians}}},
  author = {Keselman, Leonid and Hebert, Martial},
  year = {2023},
  month = aug,
  number = {arXiv:2308.14737},
  eprint = {2308.14737},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2308.14737},
  urldate = {2023-10-06},
  abstract = {Fast, reliable shape reconstruction is an essential ingredient in many computer vision applications. Neural Radiance Fields demonstrated that photorealistic novel view synthesis is within reach, but was gated by performance requirements for fast reconstruction of real scenes and objects. Several recent approaches have built on alternative shape representations, in particular, 3D Gaussians. We develop extensions to these renderers, such as integrating differentiable optical flow, exporting watertight meshes and rendering per-ray normals. Additionally, we show how two of the recent methods are interoperable with each other. These reconstructions are quick, robust, and easily performed on GPU or CPU. For code and visual examples, see https://leonidk.github.io/fmb-plus},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,I.2.10,I.3.7,I.4.0},
  file = {/Users/kshitijgoel/Zotero/storage/TWH4KQSW/Keselman and Hebert - 2023 - Flexible Techniques for Differentiable Rendering w.pdf;/Users/kshitijgoel/Zotero/storage/TLI79WKF/2308.html}
}

@article{keshav_how_2007,
  title = {How to Read a Paper},
  author = {Keshav, S.},
  year = {2007},
  month = jul,
  journal = {ACM SIGCOMM Computer Communication Review},
  volume = {37},
  number = {3},
  pages = {83--84},
  issn = {0146-4833},
  doi = {10.1145/1273445.1273458},
  url = {https://dl.acm.org/doi/10.1145/1273445.1273458},
  urldate = {2023-08-09},
  abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient               three-pass method               for reading research papers. I also describe how to use this method to do a literature survey.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JH6799XE/Keshav - 2007 - How to read a paper.pdf}
}

@inproceedings{khan_adaptive_2015,
  title = {Adaptive Rectangular Cuboids for {{3D}} Mapping},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Khan, Sheraz and Wollherr, Dirk and Buss, Martin},
  year = {2015},
  month = may,
  pages = {2132--2139},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7139480},
  abstract = {This paper presents an extension of the standard occupancy grid for 3D environment mapping. The presented approach adds a fusion process after the occupancy update which modifies the resolution of the grid cells in an incremental manner. Consequently, the proposed approach requires fewer grid cells for 3D representation in comparison to a standard occupancy grid. The resolution adaptation process is based on the occupancy probabilities of the grid cells and leads to the relaxation of the cubic grid cell assumption common to most 3D occupancy grids. The aim of this paper is to show the advantage of the proposed incremental fusion process which leads to the approximation of the 3D environment using rectangular cuboids. Evaluation on a large scale dataset and comparison to the state of the art shows that the proposed approach has faster access time for all occupied grid cells and requires a smaller number of cells for 3D environment representation.},
  keywords = {Data structures,Fuses,Laser beams,Robot sensing systems,Standards,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/5Q3X4VHC/Khan et al. - 2015 - Adaptive rectangular cuboids for 3D mapping.pdf;/Users/kshitijgoel/Zotero/storage/JQJP2UEE/7139480.html}
}

@article{khorunzhina_finite_2019,
  title = {Finite {{Gaussian Mixture Approximations}} to {{Analytically Intractable Density Kernels}}},
  author = {Khorunzhina, Natalia and Richard, Jean-Fran{\c c}ois},
  year = {2019},
  month = mar,
  journal = {Computational Economics},
  volume = {53},
  number = {3},
  pages = {991--1017},
  issn = {1572-9974},
  doi = {10.1007/s10614-017-9777-2},
  url = {https://doi.org/10.1007/s10614-017-9777-2},
  urldate = {2024-07-02},
  abstract = {The objective of the paper is that of constructing finite Gaussian mixture approximations to analytically intractable density kernels. The proposed method is adaptive in that terms are added one at the time and the mixture is fully re-optimized at each step using a distance measure that approximates the corresponding importance sampling variance. All functions of interest are evaluated under Gaussian product rules. Since product rules suffer from an obvious curse of dimensionality, the proposed algorithm as presented is only applicable to models whose non-linear and/or non-Gaussian subspace is of dimension up to three. Extensions to higher-dimensional applications would require the use of sparse grids, as discussed in the paper. Examples include a sequential (filtering) evaluation of the likelihood function of a stochastic volatility model where all relevant densities (filtering, predictive and likelihood) are closely approximated by mixtures.},
  langid = {english},
  keywords = {Adaptive algorithm,Density kernel,Distance measure,Finite mixture,Gaussian quadrature,Importance sampling,Stochastic volatility},
  file = {/Users/kshitijgoel/Zotero/storage/FKCK4SH3/Khorunzhina and Richard - 2019 - Finite Gaussian Mixture Approximations to Analytically Intractable Density Kernels.pdf}
}

@misc{khosoussi_joint_2025,
  title = {Joint {{State}} and {{Noise Covariance Estimation}}},
  author = {Khosoussi, Kasra and Shames, Iman},
  year = {2025},
  month = feb,
  number = {arXiv:2502.04584},
  eprint = {2502.04584},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.04584},
  url = {http://arxiv.org/abs/2502.04584},
  urldate = {2025-02-10},
  abstract = {This paper tackles the problem of jointly estimating the noise covariance matrix alongside primary parameters (such as poses and points) from measurements corrupted by Gaussian noise. In such settings, the noise covariance matrix determines the weights assigned to individual measurements in the least squares problem. We show that the joint problem exhibits a convex structure and provide a full characterization of the optimal noise covariance estimate (with analytical solutions) within joint maximum a posteriori and likelihood frameworks and several variants. Leveraging this theoretical result, we propose two novel algorithms that jointly estimate the primary parameters and the noise covariance matrix. To validate our approach, we conduct extensive experiments across diverse scenarios and offer practical insights into their application in robotics and computer vision estimation problems with a particular focus on SLAM.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics,Mathematics - Optimization and Control},
  file = {/Users/kshitijgoel/Zotero/storage/6MEPPXEQ/Khosoussi and Shames - 2025 - Joint State and Noise Covariance Estimation.pdf;/Users/kshitijgoel/Zotero/storage/WNVGUA6I/2502.html}
}

@article{kicki_fast_2024,
  title = {Fast {{Kinodynamic Planning}} on the {{Constraint Manifold With Deep Neural Networks}}},
  author = {Kicki, Piotr and Liu, Puze and Tateo, Davide and {Bou-Ammar}, Haitham and Walas, Krzysztof and Skrzypczy{\'n}ski, Piotr and Peters, Jan},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {277--297},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3326922},
  url = {https://ieeexplore.ieee.org/document/10292912},
  urldate = {2024-04-04},
  abstract = {Motion planning is a mature area of research in robotics with many well-established methods based on optimization or sampling the state space, suitable for solving kinematic motion planning. However, when dynamic motions under constraints are needed and computation time is limited, fast kinodynamic planning on the constraint manifold is indispensable. In recent years, learning-based solutions have become alternatives to classical approaches, but they still lack comprehensive handling of complex constraints, such as planning on a lower dimensional manifold of the task space while considering the robot's dynamics. This article introduces a novel learning-to-plan framework that exploits the concept of constraint manifold, including dynamics, and neural planning methods. Our approach generates plans satisfying an arbitrary set of constraints and computes them in a short constant time, namely the inference time of a neural network. This allows the robot to plan and replan reactively, making our approach suitable for dynamic environments. We validate our approach on two simulated tasks and in a demanding real-world scenario, where we use a Kuka LBR Iiwa 14 robotic arm to perform the hitting movement in robotic air hockey.},
  keywords = {Dynamics,Kinodynamic planning,learning to plan,Manifolds,motion planning,neural networks,Planning,Robot kinematics,Robots,Task analysis,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/8YWQXZBN/Kicki et al. - 2024 - Fast Kinodynamic Planning on the Constraint Manifo.pdf}
}

@inproceedings{kim_bridging_2023,
  title = {Bridging {{Active Exploration}} and {{Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Kim, Taekyung and Mun, Jungwi and Seo, Junwon and Kim, Beomsu and Hong, Seongil},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p086.html},
  urldate = {2023-07-04},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/CVTEBRAC/Kim et al. - 2023 - Bridging Active Exploration and Uncertainty-Aware .pdf}
}

@inproceedings{kim_continuous_2013,
  title = {Continuous Occupancy Maps Using Overlapping Local {{Gaussian}} Processes},
  booktitle = {2013 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Kim, Soohwan and Kim, Jonghyuk},
  year = {2013},
  month = nov,
  pages = {4709--4714},
  issn = {2153-0866},
  doi = {10.1109/IROS.2013.6697034},
  abstract = {This paper presents an efficient method of building continuous occupancy maps using Gaussian processes for large-scale environments. Although Gaussian processes have been successfully applied to map building, the applications are limited to small-scale environments due to the high computational complexity. To improve the scalability, we adopt a divide and conquer strategy where data are partitioned into manageable size of clusters and local Gaussian processes are applied to each cluster. Particularly, we propose overlapping clusters to mitigate the discontinuity problem that predictions of local estimators do not match along the boundaries. The results are consistent and continuous occupancy voxel maps in a fully Bayesian framework. We evaluate our method with simulated data and compare map accuracy and computational time with previous work. We also demonstrate our method with real data acquired from a laser range finder.},
  keywords = {Buildings,Computational complexity,Gaussian processes,Laser beams,Robots,Three-dimensional displays,Training data},
  file = {/Users/kshitijgoel/Zotero/storage/6DPWTCYU/Kim and Kim - 2013 - Continuous occupancy maps using overlapping local .pdf}
}

@incollection{kim_gpmap_2015,
  title = {{{GPmap}}: {{A Unified Framework}} for {{Robotic Mapping Based}} on {{Sparse Gaussian Processes}}},
  shorttitle = {{{GPmap}}},
  booktitle = {Field and {{Service Robotics}}: {{Results}} of the 9th {{International Conference}}},
  author = {Kim, Soohwan and Kim, Jonghyuk},
  editor = {Mejias, Luis and Corke, Peter and Roberts, Jonathan},
  year = {2015},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {319--332},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-07488-7_22},
  url = {https://doi.org/10.1007/978-3-319-07488-7_22},
  urldate = {2022-02-06},
  abstract = {This paper proposes a unified framework called GPmap for reconstructing surface meshes and building continuous occupancy maps using sparse Gaussian processes. Previously, Gaussian processes have been separately applied for surface reconstruction and occupancy mapping with different function definitions. However, by adopting the signed distance function as the latent function and applying the probabilistic least square classification, we solve two different problems in a single framework. Thus, two different map representations can be obtained at a single cast, for instance, an object shape for grasping and an occupancy map for obstacle avoidance. Another contribution of this paper is reduction of computational complexity for scalability. The cubic computational complexity of Gaussian processes is a well-known issue limiting its applications for large-scale data. We address this by applying the sparse covariance function which makes distant data independent and thus divides both training and test data into grid blocks of manageable sizes. In contrast to previous work, the size of grid blocks is determined in a principled way by learning the characteristic length-scale of the sparse covariance function from the training data. We compare theoretical complexity with previous work and demonstrate our method with structured indoor and unstructured outdoor datasets.},
  isbn = {978-3-319-07488-7},
  langid = {english},
  keywords = {Covariance Function,Gaussian Process,Grid Block,Point Cloud,Test Position},
  file = {/Users/kshitijgoel/Zotero/storage/PW29CQTT/Kim and Kim - 2015 - GPmap A Unified Framework for Robotic Mapping Bas.pdf}
}

@inproceedings{kim_interpolation_2015,
  title = {Interpolation on the {{Manifold}} of {{K Component GMMs}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Kim, Hyunwoo J. and Adluru, Nagesh and Banerjee, Monami and Vemuri, Baba C. and Singh, Vikas},
  year = {2015},
  pages = {2884--2892},
  url = {https://openaccess.thecvf.com/content_iccv_2015/html/Kim_Interpolation_on_the_ICCV_2015_paper.html},
  urldate = {2024-03-19},
  file = {/Users/kshitijgoel/Zotero/storage/4ECVGDYP/Kim et al. - 2015 - Interpolation on the Manifold of K Component GMMs.pdf;/Users/kshitijgoel/Zotero/storage/5SMJZC9Q/Kim et al. - 2015 - Interpolation on the Manifold of K Component GMMs.pdf}
}

@phdthesis{kim_methods_2022,
  type = {Doctoral {{Thesis}}},
  title = {Methods for {{Merging}}, {{Parsimony}} and {{Interpretability}} of {{Finite Mixture Models}}},
  author = {Kim, Nam-Hwui},
  year = {2022},
  month = aug,
  url = {https://uwspace.uwaterloo.ca/handle/10012/18486},
  urldate = {2024-04-30},
  abstract = {To combat the increasing data dimensionality, parsimonious modelling for finite mixture models has risen to be an active research area. These modelling frameworks offer various constraints that can reduce the number of free parameters in a finite mixture model. However, the constraint selection process is not always clear to the user. Moreover, the relationship between the chosen constraint and the data set is often left unexplained. Such issues affect adversely the interpretability of the fitted model. That is, one may end up with a model with reduced number of free parameters, but how it was selected, and what the parameter-reducing constraints mean, remain mysterious.   Over-estimation of the mixture component count is another way in which the model interpretability may suffer. When the individual components of a mixture model fail to capture adequately the underlying clusters of a data set, the model may compensate by introducing extra components, thereby representing a single cluster with multiple components. This reality challenges the common assumption that a single component represents a cluster.  Addressing the interpretability-related issues can improve the informativeness of model-based clustering, thereby better assisting the user during the exploratory analysis and/or data segmentation step.},
  langid = {english},
  school = {University of Waterloo},
  annotation = {Accepted: 2022-08-04T13:01:32Z},
  file = {/Users/kshitijgoel/Zotero/storage/HRHSRRIN/Kim - 2022 - Methods for Merging, Parsimony and Interpretabilit.pdf}
}

@inproceedings{kim_superpixelguided_2024,
  title = {Superpixel-Guided {{Sampling}} for {{Compact 3D Gaussian Splatting}}},
  booktitle = {Proceedings of the 30th {{ACM Symposium}} on {{Virtual Reality Software}} and {{Technology}}},
  author = {Kim, Myoung Gon and Jeong, SeungWon and Park, Seohyeon and Han, JungHyun},
  year = {2024},
  month = oct,
  series = {{{VRST}} '24},
  pages = {1--15},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3641825.3687719},
  url = {https://dl.acm.org/doi/10.1145/3641825.3687719},
  urldate = {2025-01-09},
  abstract = {In this paper, we propose to integrate superpixel-guided sampling into the framework of 3D Gaussian Splatting for novel view synthesis. Given a sequence of frames, where each frame is a pair of RGB-D image and the camera pose that captures the image, we first select the keyframes. Then, we decompose each keyframe image into superpixels, back-project each superpixel's center into 3D space, and initialize a 3D Gaussian at the back-projected position. This superpixel-guided sampling produces a set of sparse but well-distributed Gaussians, which enables the optimization procedure to converge quickly. The experimental results show that with a significantly reduced computing cost, we can synthesize a novel view the quality of which is comparable to that generated by the state-of-the-art methods.},
  isbn = {979-8-4007-0535-9},
  file = {/Users/kshitijgoel/Zotero/storage/YR9SQ9HM/Kim et al. - 2024 - Superpixel-guided Sampling for Compact 3D Gaussian Splatting.pdf}
}

@misc{kim_uncertaintyaware_2024,
  title = {Uncertainty-Aware {{Semantic Mapping}} in {{Off-road Environments}} with {{Dempster-Shafer Theory}} of {{Evidence}}},
  author = {Kim, Junyoung and Seo, Junwon},
  year = {2024},
  month = may,
  number = {arXiv:2405.06265},
  eprint = {2405.06265},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.06265},
  urldate = {2024-06-01},
  abstract = {Semantic mapping with Bayesian Kernel Inference (BKI) has shown promise in providing a richer understanding of environments by effectively leveraging local spatial information. However, existing methods face challenges in constructing accurate semantic maps or reliable uncertainty maps in perceptually challenging environments due to unreliable semantic predictions. To address this issue, we propose an evidential semantic mapping framework, which integrates the evidential reasoning of Dempster-Shafer Theory of Evidence (DST) into the entire mapping pipeline by adopting Evidential Deep Learning (EDL) and Dempster's rule of combination. Additionally, the extended belief is devised to incorporate local spatial information based on their uncertainty during the mapping process. Comprehensive experiments across various off-road datasets demonstrate that our framework enhances the reliability of uncertainty maps, consistently outperforming existing methods in scenes with high perceptual uncertainties while showing semantic accuracy comparable to the best-performing semantic mapping techniques.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/59NB3LVY/Kim and Seo - 2024 - Uncertainty-aware Semantic Mapping in Off-road Environments with Dempster-Shafer Theory of Evidence.pdf}
}

@misc{kingma_adam_2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2024-05-28},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/WB7RPPU5/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf}
}

@misc{kingma_autoencoding_2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2022},
  month = dec,
  number = {arXiv:1312.6114},
  eprint = {1312.6114},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2024-06-08},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/ZTKN6EFG/Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf}
}

@article{kingston_scaling_2023,
  title = {Scaling {{Multimodal Planning}}: {{Using Experience}} and {{Informing Discrete Search}}},
  shorttitle = {Scaling {{Multimodal Planning}}},
  author = {Kingston, Zachary and Kavraki, Lydia E.},
  year = {2023},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {1},
  pages = {128--146},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3197080},
  abstract = {Robotic manipulation is inherently continuous, but typically has an underlying discrete structure, such as if an object is grasped. Many problems like these are multimodal, such as pick-and-place tasks where every object grasp and placement is a mode. Multimodal problems require finding a sequence of transitions between modes---for example, a particular sequence of object picks and placements. However, many multimodal planners fail to scale when motion planning is difficult (e.g., in clutter) or the task has a long horizon (e.g., rearrangement). This work presents solutions for multimodal scalability in both these areas. For motion planning, we present an experience-based planning framework alef which reuses experience from similar modes both online and from training data. For task satisfaction, we present a layered planning approach that uses a discrete lead to bias search toward useful mode transitions, informed by weights over mode transitions. Together, these contributions enable multimodal planners to tackle complex manipulation tasks that were previously infeasible or inefficient, and provide significant improvements in scenes with high-dimensional robots.},
  keywords = {Lead,Manifolds,Manipulation planning,motion and path planning,path planning,Planning,Probabilistic logic,Robot kinematics,robotics,Search problems,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/49NATUEG/Kingston and Kavraki - 2023 - Scaling Multimodal Planning Using Experience and .pdf;/Users/kshitijgoel/Zotero/storage/IAL4V9LD/stamp.html}
}

@misc{kirillov_segment_2023,
  title = {Segment {{Anything}}},
  author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  year = {2023},
  month = apr,
  number = {arXiv:2304.02643},
  eprint = {2304.02643},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.02643},
  url = {http://arxiv.org/abs/2304.02643},
  urldate = {2024-11-18},
  abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/VCBKB4JK/Kirillov et al. - 2023 - Segment Anything.pdf;/Users/kshitijgoel/Zotero/storage/J2E2P23T/2304.html}
}

@article{kitanov_topological_2024,
  title = {Topological Belief Space Planning for Active {{SLAM}} with Pairwise {{Gaussian}} Potentials and Performance Guarantees},
  author = {Kitanov, Andrej and Indelman, Vadim},
  year = {2024},
  month = jan,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {1},
  pages = {69--97},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231204898},
  url = {https://doi.org/10.1177/02783649231204898},
  urldate = {2024-04-19},
  abstract = {Determining a globally optimal solution of belief space planning (BSP) in high-dimensional state spaces directly is computationally expensive, as it involves belief propagation and objective function evaluation for each candidate action. However, many problems of interest, such as active SLAM, exhibit structure that can be harnessed to expedite planning. Also, in order to choose an optimal action, an exact value of the objective function is not required as long as the actions can be sorted in the same way. In this paper we leverage these two key aspects and present the topological belief space planning (t-bsp) concept that uses topological signatures to perform this ranking for information-theoretic cost functions, considering only topologies of factor graphs that correspond to future posterior beliefs. In particular, we propose a highly efficient topological signature based on the von Neumann graph entropy that is a function of graph node degrees and supports an incremental update. We analyze it in the context of active pose SLAM and derive error bounds between the proposed topological signature and the original information-theoretic cost function. These bounds are then used to provide performance guarantees for t-bsp with respect to a given solver of the original information-theoretic BSP problem. Realistic and synthetic simulations demonstrate drastic speed-up of the proposed method with respect to the state-of-the-art methods while retaining the ability to select a near-optimal solution. A proof of concept of t-bsp is given in a small-scale real-world active SLAM experiment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UDDXBI53/Kitanov and Indelman - 2024 - Topological belief space planning for active SLAM .pdf}
}

@inproceedings{klingensmith_chisel_2015,
  title = {Chisel: {{Real Time Large Scale 3D Reconstruction Onboard}} a {{Mobile Device}} Using {{Spatially Hashed Signed Distance Fields}}},
  shorttitle = {Chisel},
  booktitle = {Robotics: {{Science}} and {{Systems XI}}},
  author = {Klingensmith, Matthew and Dryanovski, Ivan and Srinivasa, Siddhartha and Xiao, Jizhong},
  year = {2015},
  month = jul,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2015.XI.040},
  url = {http://www.roboticsproceedings.org/rss11/p40.pdf},
  urldate = {2022-02-28},
  isbn = {978-0-9923747-1-6},
  file = {/Users/kshitijgoel/Zotero/storage/JAB4NEJA/Klingensmith et al. - 2015 - Chisel Real Time Large Scale 3D Reconstruction On.pdf}
}

@article{ko_robust_1992,
  title = {Robust {{Estimation}} of the {{Concentration Parameter}} of the {{Von Mises-Fisher Distribution}}},
  author = {Ko, Daijin},
  year = {1992},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {20},
  number = {2},
  pages = {917--928},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176348663},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-20/issue-2/Robust-Estimation-of-the-Concentration-Parameter-of-the-Von-Mises/10.1214/aos/1176348663.full},
  urldate = {2024-07-09},
  abstract = {We introduce a simple procedure for obtaining robust estimates of the concentration parameter of the von Mises-Fisher distribution on the \$q\$-dimensional unit sphere. The procedure is based on the median deviation from a location parameter. Its influence function is derived and standardized bias robustness is proved. The asymptotic efficiency is calculated and an example is given.},
  keywords = {62F10,62F35,62H12,Concentration parameter,directional data,robustness,SB robustness,von Mises-Fisher distribution},
  file = {/Users/kshitijgoel/Zotero/storage/GZLEEBHK/Ko - 1992 - Robust Estimation of the Concentration Parameter of the Von Mises-Fisher Distribution.pdf}
}

@inproceedings{kobayashi_misesfisher_2010,
  title = {Von {{Mises-Fisher Mean Shift}} for {{Clustering}} on a {{Hypersphere}}},
  booktitle = {2010 20th {{International Conference}} on {{Pattern Recognition}}},
  author = {Kobayashi, Takumi and Otsu, Nobuyuki},
  year = {2010},
  month = aug,
  pages = {2130--2133},
  issn = {1051-4651},
  doi = {10.1109/ICPR.2010.522},
  url = {https://ieeexplore.ieee.org/document/5595925},
  urldate = {2024-06-27},
  abstract = {We propose a method of clustering sample vectors on a hypersphere. Sample vectors are normalized in many cases, especially when applying kernel functions, and thus lie on a (unit) hypersphere. Considering the constraint of the hypersphere, the proposed method utilizes the von Mises-Fisher distribution in the framework of mean shift. It is also extended to the kernel-based clustering method via kernel tricks to cope with complex distributions. The algorithms of the proposed methods are based on simple matrix calculations. In the experiments, including a practical motion clustering task, the proposed methods produce favorable clustering results.},
  keywords = {clustering,Clustering algorithms,Clustering methods,Feature extraction,hypersphere,Kernel,mean shift,Probability distribution,Transient analysis,Vectors,von Mises-Fisher distribution},
  file = {/Users/kshitijgoel/Zotero/storage/9SV8N5XS/Kobayashi and Otsu - 2010 - Von Mises-Fisher Mean Shift for Clustering on a Hypersphere.pdf}
}

@article{kohonen_selforganizing_1990,
  title = {The Self-Organizing Map},
  author = {Kohonen, T.},
  year = {1990},
  month = sep,
  journal = {Proceedings of the IEEE},
  volume = {78},
  number = {9},
  pages = {1464--1480},
  issn = {1558-2256},
  doi = {10.1109/5.58325},
  url = {https://ieeexplore.ieee.org/document/58325},
  urldate = {2024-11-15},
  abstract = {The self-organized map, an architecture suggested for artificial neural networks, is explained by presenting simulation experiments and practical applications. The self-organizing map has the property of effectively creating spatially organized internal representations of various features of input signals and their abstractions. One result of this is that the self-organization process can discover semantic relationships in sentences. Brain maps, semantic maps, and early work on competitive learning are reviewed. The self-organizing map algorithm (an algorithm which order responses spatially) is reviewed, focusing on best matching cell selection and adaptation of the weight vectors. Suggestions for applying the self-organizing map algorithm, demonstrations of the ordering process, and an example of hierarchical clustering of data are presented. Fine tuning the map by learning vector quantization is addressed. The use of self-organized maps in practical speech recognition and a simulation experiment on semantic mapping are discussed.{$<>$}},
  keywords = {Animals,Artificial neural networks,Biological neural networks,Computer networks,Organizing,Pattern recognition,Process control,Signal processing,Signal processing algorithms,Speech recognition},
  file = {/Users/kshitijgoel/Zotero/storage/56LTZU7X/Kohonen - 1990 - The self-organizing map.pdf}
}

@book{kohonen_selforganizing_2001,
  title = {Self-{{Organizing Maps}}},
  author = {Kohonen, Teuvo},
  editor = {Huang, Thomas S. and Kohonen, Teuvo and Schroeder, Manfred R.},
  year = {2001},
  series = {Springer {{Series}} in {{Information Sciences}}},
  volume = {30},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-56927-2},
  url = {http://link.springer.com/10.1007/978-3-642-56927-2},
  urldate = {2023-03-17},
  isbn = {978-3-540-67921-9 978-3-642-56927-2},
  keywords = {Adaptive and Learning Networks,Adaptive und Lernende Netze,Cluster Analysis,CON_D044,Klassifikator,Klusteranalyse,Lernen ohne Lehrer,Neural Networks,Neuronale Netze,pattern recognition,Selbstlernen,Selbstorganisierende Karten,self-organizing m},
  file = {/Users/kshitijgoel/Zotero/storage/5W5NIUCU/Kohonen - 2001 - Self-Organizing Maps.pdf}
}

@article{kolchinsky_estimating_2017,
  title = {Estimating {{Mixture Entropy}} with {{Pairwise Distances}}},
  author = {Kolchinsky, Artemy and Tracey, Brendan D.},
  year = {2017},
  month = jul,
  journal = {Entropy},
  volume = {19},
  number = {7},
  pages = {361},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1099-4300},
  doi = {10.3390/e19070361},
  url = {https://www.mdpi.com/1099-4300/19/7/361},
  urldate = {2023-10-23},
  abstract = {Mixture distributions arise in many parametric and non-parametric settings---for example, in Gaussian mixture models and in non-parametric estimation. It is often necessary to compute the entropy of a mixture, but, in most cases, this quantity has no closed-form expression, making some form of approximation necessary. We propose a family of estimators based on a pairwise distance function between mixture components, and show that this estimator class has many attractive properties. For many distributions of interest, the proposed estimators are efficient to compute, differentiable in the mixture parameters, and become exact when the mixture components are clustered. We prove this family includes lower and upper bounds on the mixture entropy. The Chernoff    {$\alpha$}   -divergence gives a lower bound when chosen as the distance function, with the Bhattacharyaa distance providing the tightest lower bound for components that are symmetric and members of a location family. The Kullback--Leibler divergence gives an upper bound when used as the distance function. We provide closed-form expressions of these bounds for mixtures of Gaussians, and discuss their applications to the estimation of mutual information. We then demonstrate that our bounds are significantly tighter than well-known existing bounds using numeric simulations. This estimator class is very useful in optimization problems involving maximization/minimization of entropy and mutual information, such as MaxEnt and rate distortion problems.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {entropy estimation,MaxEnt,mixture distribution,mixture of Gaussians,rate distortion},
  file = {/Users/kshitijgoel/Zotero/storage/8DEGW6ND/Kolchinsky and Tracey - 2017 - Estimating Mixture Entropy with Pairwise Distances.pdf}
}

@article{koliander_fusion_2022,
  title = {Fusion of {{Probability Density Functions}}},
  author = {Koliander, Gunther and {El-Laham}, Yousef and Djuric, Petar M. and Hlawatsch, Franz},
  year = {2022},
  month = apr,
  journal = {Proceedings of the IEEE},
  volume = {110},
  number = {4},
  pages = {404--453},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2022.3154399},
  url = {https://ieeexplore.ieee.org/document/9747966/},
  urldate = {2024-03-13},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KWZIJSEI/Koliander et al. - 2022 - Fusion of Probability Density Functions.pdf}
}

@article{kolouri_optimal_2017,
  title = {Optimal {{Mass Transport}}: {{Signal}} Processing and Machine-Learning Applications},
  shorttitle = {Optimal {{Mass Transport}}},
  author = {Kolouri, Soheil and Park, Se Rim and Thorpe, Matthew and Slepcev, Dejan and Rohde, Gustavo K.},
  year = {2017},
  month = jul,
  journal = {IEEE Signal Processing Magazine},
  volume = {34},
  number = {4},
  pages = {43--59},
  issn = {1558-0792},
  doi = {10.1109/MSP.2017.2695801},
  abstract = {Transport-based techniques for signal and data analysis have recently received increased interest. Given their ability to provide accurate generative models for signal intensities and other data distributions, they have been used in a variety of applications, including content-based retrieval, cancer detection, image superresolution, and statistical machine learning, to name a few, and they have been shown to produce state-of-the-art results. Moreover, the geometric characteristics of transport-related metrics have inspired new kinds of algorithms for interpreting the meaning of data distributions. Here, we provide a practical overview of the mathematical underpinnings of mass transport-related methods, including numerical implementation, as well as a review, with demonstrations, of several applications. Software accompanying this article is available from [43].},
  keywords = {Analytical models,Data models,Estimation,Linear programming,Morphology,Probability density function,Transportation},
  file = {/Users/kshitijgoel/Zotero/storage/CZWMGUKH/Kolouri et al. - 2017 - Optimal Mass Transport Signal processing and mach.pdf;/Users/kshitijgoel/Zotero/storage/7I97B58E/7974883.html}
}

@inproceedings{kolouri_sliced_2018,
  title = {Sliced {{Wasserstein Distance}} for {{Learning Gaussian Mixture Models}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Kolouri, Soheil and Rohde, Gustavo K. and Hoffmann, Heiko},
  year = {2018},
  month = jun,
  pages = {3427--3436},
  publisher = {IEEE},
  address = {Salt Lake City, UT},
  doi = {10.1109/CVPR.2018.00361},
  url = {https://ieeexplore.ieee.org/document/8578459/},
  urldate = {2023-09-20},
  abstract = {Gaussian mixture models (GMM) are powerful parametric tools with many applications in machine learning and computer vision. Expectation maximization (EM) is the most popular algorithm for estimating the GMM parameters. However, EM guarantees only convergence to a stationary point of the log-likelihood function, which could be arbitrarily worse than the optimal solution. Inspired by the relationship between the negative log-likelihood function and the Kullback-Leibler (KL) divergence, we propose an alternative formulation for estimating the GMM parameters using the sliced Wasserstein distance, which gives rise to a new algorithm. Specifically, we propose minimizing the sliced-Wasserstein distance between the mixture model and the data distribution with respect to the GMM parameters. In contrast to the KL-divergence, the energy landscape for the sliced-Wasserstein distance is more well-behaved and therefore more suitable for a stochastic gradient descent scheme to obtain the optimal GMM parameters. We show that our formulation results in parameter estimates that are more robust to random initializations and demonstrate that it can estimate high-dimensional data distributions more faithfully than the EM algorithm.},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UA4YCMUQ/Kolouri et al. - 2018 - Sliced Wasserstein Distance for Learning Gaussian .pdf}
}

@article{kompis_informed_2021,
  title = {Informed {{Sampling Exploration Path Planner}} for {{3D Reconstruction}} of {{Large Scenes}}},
  author = {Kompis, Yves and Bartolomei, Luca and Mascaro, Ruben and Teixeira, Lucas and Chli, Margarita},
  year = {2021},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {4},
  pages = {7893--7900},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3101856},
  url = {https://ieeexplore.ieee.org/abstract/document/9507252},
  urldate = {2024-06-10},
  abstract = {As vision-based navigation of small aircraft has been demonstrated to reach relative maturity, research into effective path-planning algorithms to complete the loop of autonomous navigation has been booming. Although the literature has seen some impressive works in this area, efficient path-planning that can be used in tasks such as inspection and coverage is still an open problem. In this spirit, this letter presents an online path-planning algorithm for fast exploration and 3D reconstruction of a previously unknown area of interest. Micro Aerial Vehicles (MAVs) are an ideal candidate for this task due to their maneuverability, but their limited computational power and endurance require efficient planning strategies. Popular sampling-based methods randomly sample the MAV's configuration space and evaluate viewpoints according to their expected information gain. Most often, however, valuable resources are spent on information gain calculations of unpromising viewpoints. This letter proposes a novel informed sampling approach that leverages surface frontiers to sample viewpoints only where high information gain is expected, leading to faster exploration. We study the impact of informed sampling in a wide range of photo-realistic scenes, and we show that our approach outperforms state-of-the-art exploration path planners in terms of both speed and reconstruction quality.},
  keywords = {Aerial systems: perception and autonomy,motion and path planning,Planning,Robot sensing systems,Robots,Surface reconstruction,Task analysis,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/VRQQ3QMD/Kompis et al. - 2021 - Informed Sampling Exploration Path Planner for 3D Reconstruction of Large Scenes.pdf;/Users/kshitijgoel/Zotero/storage/WZRZ3BS7/9507252.html}
}

@article{kong_marsim_2023,
  title = {{{MARSIM}}: {{A Light-Weight Point-Realistic Simulator}} for {{LiDAR-Based UAVs}}},
  shorttitle = {{{MARSIM}}},
  author = {Kong, Fanze and Liu, Xiyuan and Tang, Benxu and Lin, Jiarong and Ren, Yunfan and Cai, Yixi and Zhu, Fangcheng and Chen, Nan and Zhang, Fu},
  year = {2023},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {5},
  pages = {2954--2961},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3264163},
  url = {https://ieeexplore.ieee.org/document/10091117/?arnumber=10091117},
  urldate = {2025-01-10},
  abstract = {The emergence of LiDAR sensors have brought new opportunities for autonomous unmanned aerial vehicles (UAVs) by advancing navigation safety and computation efficiency. Yet the successful developments of LiDAR-based UAVs must rely on extensive simulations. Existing simulators can hardly perform simulations of real-world environments due to the requirements of dense mesh maps that are difficult to obtain. Therefore, we develop a point-realistic simulator of real-world scenes for LiDAR-based UAVs. The key idea is the underlying point rendering method, where we construct a depth image directly from the point cloud map and interpolate it to obtain realistic LiDAR point measurements. Our developed simulator is able to run on a light-weight computing platform and supports the simulation of LiDARs with different resolution and scanning patterns, dynamic obstacles, and multi-UAV systems. Developed in the ROS framework, the simulator can easily communicate with other key modules of an autonomous robot, such as perception, state estimation, planning, and control. Finally, the simulator provides 10 high-resolution point cloud maps of various real-world environments, including forests of different densities, historic building, office, parking garage, and various complex indoor environments. Evaluation results show that the developed simulator achieves superior performance in terms of time and memory consumption against Gazebo and that the simulated UAV flights highly match the actual one in real-world environments. We believe such a point-realistic and light-weight simulator is crucial to bridge the gap between UAV simulation and experiments and will significantly facilitate the research of LiDAR-based autonomous UAVs in the future.},
  keywords = {Aerial systems: simulator,Atmospheric modeling,Autonomous aerial vehicles,Computational modeling,Laser radar,lidar,perception and autonomy,Point cloud compression,Simultaneous localization and mapping,Solid modeling},
  file = {/Users/kshitijgoel/Zotero/storage/RWJSNMC4/Kong et al. - 2023 - MARSIM A Light-Weight Point-Realistic Simulator for LiDAR-Based UAVs.pdf;/Users/kshitijgoel/Zotero/storage/BNDIYWQ9/10091117.html}
}

@inproceedings{kontoudis_decentralized_2023,
  title = {Decentralized {{Federated Learning}} Using {{Gaussian Processes}}},
  booktitle = {2023 {{International Symposium}} on {{Multi-Robot}} and {{Multi-Agent Systems}} ({{MRS}})},
  author = {Kontoudis, George P. and Stilwell, Daniel J.},
  year = {2023},
  month = dec,
  pages = {1--7},
  doi = {10.1109/MRS60187.2023.10416790},
  url = {https://ieeexplore.ieee.org/document/10416790/?arnumber=10416790},
  urldate = {2024-11-29},
  abstract = {Gaussian process (GP) training of kernel hyperparameters still remains a major challenge due to high computational complexity. The typical GP training method employs maximum likelihood estimation to solve an optimization problem that requires cubic computations for each iteration. In addition, GP training in multi-agent systems requires significant amount of inter-agent communication that typically involves sharing of local data. In this paper, we propose a scalable optimization algorithm for decentralized learning of GP hyperparameters in multi-agent systems. To distribute the implementation of GP training, we employ the alternating direction method of multipliers (ADMM). We provide a closed-form solution of the nested optimization of decentralized proximal ADMM for the case of GP modeling with the separable squared exponential kernel. Decentralized federated learning is promoted by prohibiting local data exchange between agents. The efficiency of the proposed method is illustrated with numerical experiments.},
  keywords = {Convex functions,Federated learning,Gaussian processes,Kernel,Multi-agent systems,Optimization,Training},
  file = {/Users/kshitijgoel/Zotero/storage/YCUKBTXP/Kontoudis and Stilwell - 2023 - Decentralized Federated Learning using Gaussian Processes.pdf;/Users/kshitijgoel/Zotero/storage/NLG69LNJ/10416790.html}
}

@inproceedings{koolen_julia_2019,
  title = {Julia for Robotics: Simulation and Real-Time Control in a High-Level Programming Language},
  shorttitle = {Julia for Robotics},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Koolen, Twan and Deits, Robin},
  year = {2019},
  month = may,
  pages = {604--611},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8793875},
  abstract = {Robotics applications often suffer from the `two-language problem', requiring a low-level language for performance-sensitive components and a high-level language for interactivity and experimentation, which tends to increase software complexity. We demonstrate the use of the Julia programming language to solve this problem by being fast enough for online control of a humanoid robot and flexible enough for prototyping. We present several Julia packages developed by the authors, which together enable roughly 2{\texttimes} realtime simulation of the Boston Dynamics Atlas humanoid robot balancing on flat ground using a quadratic-programming-based controller. Benchmarks show a sufficiently low variation in control frequency to make deployment on the physical robot feasible. We also show that Julia's naturally generic programming style results in versatile packages that are easy to compose and adapt to a wide variety of computational tasks in robotics.},
  keywords = {C++ languages,Libraries,Productivity,Resource management,Robots,Software packages},
  file = {/Users/kshitijgoel/Zotero/storage/3MESJHPS/Koolen and Deits - 2019 - Julia for robotics simulation and real-time contr.pdf;/Users/kshitijgoel/Zotero/storage/HD4EHIK7/stamp.html}
}

@inproceedings{korkinof_online_2013,
  title = {Online Quantum Mixture Regression for Trajectory Learning by Demonstration},
  booktitle = {2013 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Korkinof, Dimitrios and Demiris, Yiannis},
  year = {2013},
  month = nov,
  pages = {3222--3229},
  issn = {2153-0866},
  doi = {10.1109/IROS.2013.6696814},
  url = {https://ieeexplore.ieee.org/abstract/document/6696814},
  urldate = {2024-03-28},
  abstract = {In this work, we present the online Quantum Mixture Model (oQMM), which combines the merits of quantum mechanics and stochastic optimization. More specifically it allows for quantum effects on the mixture states, which in turn become a superposition of conventional mixture states. We propose an efficient stochastic online learning algorithm based on the online Expectation Maximization (EM), as well as a generation and decay scheme for model components. Our method is suitable for complex robotic applications, where data is abundant or where we wish to iteratively refine our model and conduct predictions during the course of learning. With a synthetic example, we show that the algorithm can achieve higher numerical stability. We also empirically demonstrate the efficacy of our method in well-known regression benchmark datasets. Under a trajectory Learning by Demonstration setting we employ a multi-shot learning application in joint angle space, where we observe higher quality of learning and reproduction. We compare against popular and well-established methods, widely adopted across the robotics community.},
  keywords = {Mathematical model,Prediction algorithms,Probability,Robots,Stochastic processes,Trajectory,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/9IN4SSM8/Korkinof and Demiris - 2013 - Online quantum mixture regression for trajectory l.pdf;/Users/kshitijgoel/Zotero/storage/K9VSVA4V/6696814.html}
}

@article{korn_color_,
  title = {Color Supported Generalized-{{ICP}}},
  author = {Korn, Michael and Holzkothen, Martin and Pauli, Josef},
  abstract = {This paper presents a method to support point cloud registration with color information. For this purpose we integrate L?a?b? color space information into the Generalized Iterative Closest Point (GICP) algorithm, a state-of-the-art Plane-To-Plane ICP variant. A six-dimensional k-d tree based nearest neighbor search is used to match corresponding points between the clouds. We demonstrate that the additional effort in general does not have an immoderate impact on the runtime, since the number of iterations can be reduced. The influence on the estimated 6 DoF transformations is quantitatively evaluated on six different datasets. It will be shown that the modified algorithm can improve the results without needing any special parameter adjustment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JY3E7P27/Korn et al. - Color supported generalized-ICP.pdf}
}

@article{korotkine_hessian_2024,
  title = {A {{Hessian}} for {{Gaussian Mixture Likelihoods}} in {{Nonlinear Least Squares}}},
  author = {Korotkine, Vassili and Cohen, Mitchell and Forbes, James Richard},
  year = {2024},
  month = sep,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {9},
  pages = {7891--7898},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3432350},
  url = {https://ieeexplore.ieee.org/document/10607873},
  urldate = {2024-08-13},
  abstract = {This letter proposes a novel Hessian approximation for Maximum a Posteriori estimation problems in robotics involving Gaussian mixture likelihoods. Previous approaches manipulate the Gaussian mixture likelihood into a form that allows the problem to be represented as a nonlinear least squares (NLS) problem. The resulting Hessian approximation used within NLS solvers from these approaches neglects certain nonlinearities. The proposed Hessian approximation is derived by setting the Hessians of the Gaussian mixture component errors to zero, which is the same starting point as for the Gauss-Newton Hessian approximation for NLS, and using the chain rule to account for additional nonlinearities. The proposed Hessian approximation results in improved convergence speed and uncertainty characterization for simulated experiments, and similar performance to the state of the art on real-world experiments. A method to maintain compatibility with existing solvers, such as ceres, is also presented.},
  keywords = {Jacobian matrices,Localization,Newton method,Optimization,optimization and optimal control,Optimization methods,probabilistic inference,sensor fusion,Simultaneous localization and mapping,SLAM,Standards,State estimation},
  file = {/Users/kshitijgoel/Zotero/storage/BVAJX22Y/Korotkine et al. - 2024 - A Hessian for Gaussian Mixture Likelihoods in Nonlinear Least Squares.pdf;/Users/kshitijgoel/Zotero/storage/HR8DFYCH/10607873.html}
}

@misc{kottege_heterogeneous_2023,
  title = {Heterogeneous Robot Teams with Unified Perception and Autonomy: {{How Team CSIRO Data61}} Tied for the Top Score at the {{DARPA Subterranean Challenge}}},
  shorttitle = {Heterogeneous Robot Teams with Unified Perception and Autonomy},
  author = {Kottege, Navinda and Williams, Jason and Tidd, Brendan and Talbot, Fletcher and Steindl, Ryan and Cox, Mark and Frousheger, Dennis and Hines, Thomas and Pitt, Alex and Tam, Benjamin and Wood, Brett and Hanson, Lauren and Surdo, Katrina Lo and Molnar, Thomas and Wildie, Matt and Stepanas, Kazys and Catt, Gavin and {Tychsen-Smith}, Lachlan and Penfold, Dean and Overs, Leslie and Ramezani, Milad and Khosoussi, Kasra and Kendoul, Farid and Wagner, Glenn and Palmer, Duncan and Manderson, Jack and Medek, Corey and O'Brien, Matthew and Chen, Shengkang and Arkin, Ronald C.},
  year = {2023},
  month = feb,
  number = {arXiv:2302.13230},
  eprint = {2302.13230},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2302.13230},
  urldate = {2023-03-05},
  abstract = {The DARPA Subterranean Challenge was designed for competitors to develop and deploy teams of autonomous robots to explore difficult unknown underground environments. Categorised in to human-made tunnels, underground urban infrastructure and natural caves, each of these subdomains had many challenging elements for robot perception, locomotion, navigation and autonomy. These included degraded wireless communication, poor visibility due to smoke, narrow passages and doorways, clutter, uneven ground, slippery and loose terrain, stairs, ledges, overhangs, dripping water, and dynamic obstacles that move to block paths among others. In the Final Event of this challenge held in September 2021, the course consisted of all three subdomains. The task was for the robot team to perform a scavenger hunt for a number of pre-defined artefacts within a limited time frame. Only one human supervisor was allowed to communicate with the robots once they were in the course. Points were scored when accurate detections and their locations were communicated back to the scoring server. A total of 8 teams competed in the finals held at the Mega Cavern in Louisville, KY, USA. This article describes the systems deployed by Team CSIRO Data61 that tied for the top score and won second place at the event.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/JEXQ22QT/Kottege et al. - 2023 - Heterogeneous robot teams with unified perception .pdf;/Users/kshitijgoel/Zotero/storage/5EPXXBAQ/2302.html}
}

@inproceedings{krainin_autonomous_2011,
  title = {Autonomous Generation of Complete {{3D}} Object Models Using next Best View Manipulation Planning},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Krainin, Michael and Curless, Brian and Fox, Dieter},
  year = {2011},
  month = may,
  pages = {5031--5037},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980429},
  url = {https://ieeexplore.ieee.org/document/5980429},
  urldate = {2024-06-06},
  abstract = {Recognizing and manipulating objects is an important task for mobile robots performing useful services in everyday environments. In this paper, we develop a system that enables a robot to grasp an object and to move it in front of its depth camera so as to build a 3D surface model of the object. We derive an information gain based variant of the next best view algorithm in order to determine how the manipulator should move the object in front of the camera. By considering occlusions caused by the robot manipulator, our technique also determines when and how the robot should re-grasp the object in order to build a complete model.},
  keywords = {Cameras,Manipulators,Robot vision systems,Surface reconstruction,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/F2TN6V3H/Krainin et al. - 2011 - Autonomous generation of complete 3D object models using next best view manipulation planning.pdf;/Users/kshitijgoel/Zotero/storage/R7GDPVKF/5980429.html}
}

@article{krause_nearoptimal_2008,
  title = {Near-{{Optimal Sensor Placements}} in {{Gaussian Processes}}: {{Theory}}, {{Efficient Algorithms}} and {{Empirical Studies}}},
  shorttitle = {Near-{{Optimal Sensor Placements}} in {{Gaussian Processes}}},
  author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
  year = {2008},
  journal = {Journal of Machine Learning Research},
  volume = {9},
  number = {8},
  pages = {235--284},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v9/krause08a.html},
  urldate = {2024-02-10},
  abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
  file = {/Users/kshitijgoel/Zotero/storage/2SGGZBSA/Krause et al. - 2008 - Near-Optimal Sensor Placements in Gaussian Process.pdf}
}

@misc{krause_probabilistic_2025,
  title = {Probabilistic {{Artificial Intelligence}}},
  author = {Krause, Andreas and H{\"u}botter, Jonas},
  year = {2025},
  month = feb,
  number = {arXiv:2502.05244},
  eprint = {2502.05244},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.05244},
  url = {http://arxiv.org/abs/2502.05244},
  urldate = {2025-03-05},
  abstract = {Artificial intelligence commonly refers to the science and engineering of artificial systems that can carry out tasks generally associated with requiring aspects of human intelligence, such as playing games, translating languages, and driving cars. In recent years, there have been exciting advances in learning-based, data-driven approaches towards AI, and machine learning and deep learning have enabled computer systems to perceive the world in unprecedented ways. Reinforcement learning has enabled breakthroughs in complex games such as Go and challenging robotics tasks such as quadrupedal locomotion. A key aspect of intelligence is to not only make predictions, but reason about the uncertainty in these predictions, and to consider this uncertainty when making decisions. This is what this manuscript on "Probabilistic Artificial Intelligence" is about. The first part covers probabilistic approaches to machine learning. We discuss the differentiation between "epistemic" uncertainty due to lack of data and "aleatoric" uncertainty, which is irreducible and stems, e.g., from noisy observations and outcomes. We discuss concrete approaches towards probabilistic inference and modern approaches to efficient approximate inference. The second part of the manuscript is about taking uncertainty into account in sequential decision tasks. We consider active learning and Bayesian optimization -- approaches that collect data by proposing experiments that are informative for reducing the epistemic uncertainty. We then consider reinforcement learning and modern deep RL approaches that use neural network function approximation. We close by discussing modern approaches in model-based RL, which harness epistemic and aleatoric uncertainty to guide exploration, while also reasoning about safety.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/PEZATRFS/Krause and Hübotter - 2025 - Probabilistic Artificial Intelligence.pdf;/Users/kshitijgoel/Zotero/storage/HPZJ4BA4/2502.html}
}

@article{kristan_fast_2016,
  title = {Fast {{Image-Based Obstacle Detection From Unmanned Surface Vehicles}}},
  author = {Kristan, Matej and Suli{\'c} Kenk, Vildana and Kova{\v c}i{\v c}, Stanislav and Per{\v s}, Janez},
  year = {2016},
  month = mar,
  journal = {IEEE Transactions on Cybernetics},
  volume = {46},
  number = {3},
  pages = {641--654},
  issn = {2168-2267, 2168-2275},
  doi = {10.1109/TCYB.2015.2412251},
  url = {https://ieeexplore.ieee.org/document/7073635/},
  urldate = {2024-03-14},
  abstract = {Obstacle detection plays an important role in unmanned surface vehicles (USVs). The USVs operate in a highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken on board. This paper addresses the problem of online detection by constrained, unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured on board a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real time. The algorithm is tested on a new, challenging, dataset for segmentation, and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CRGUULZQ/Kristan et al. - 2016 - Fast Image-Based Obstacle Detection From Unmanned .pdf}
}

@inproceedings{kristan_incremental_2008,
  title = {Incremental Learning with {{Gaussian}} Mixture Models},
  booktitle = {Computer Vision Winter Workshop},
  author = {Kristan, Matej and Skocaj, Danijel and Leonardis, Ale{\v s}},
  year = {2008},
  pages = {25--32},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=44434a3e2df871debe73cf103d7a2b52733b3e46},
  urldate = {2024-06-06},
  file = {/Users/kshitijgoel/Zotero/storage/4M6TY8HY/Kristan et al. - 2008 - Incremental learning with Gaussian mixture models.pdf}
}

@article{kristan_multivariate_2010,
  title = {Multivariate Online Kernel Density Estimation},
  author = {Kristan, Matej and Leonardis, Ales},
  year = {2010},
  month = jan,
  abstract = {We propose an approach for online kernel den-sity estimation (KDE) which enables building probability density functions from data by observing only a single data-point at a time. The method maintains a non-parametric model of the data itself and uses this model to calculate the corresponding KDE. We propose an new automatic band-width selection rule, which can be computed directly from the non-parametric model of the data. Low complexity of the model is maintained through a novel compression and refine-ment scheme. We compare the online KDE to some state-of-the-art batch KDEs on examples of estimating distributions and on an example of classification. The results show that the online KDE generally achieves comparable performance to the batch approaches, while producing models with lower complexity and allowing online updating using only a single observation at a time.},
  file = {/Users/kshitijgoel/Zotero/storage/27KTA57C/Kristan and Leonardis - 2010 - Multivariate online kernel density estimation.pdf}
}

@article{kristan_multivariate_2011,
  title = {Multivariate Online Kernel Density Estimation with {{Gaussian}} Kernels},
  author = {Kristan, Matej and Leonardis, Ale{\v s} and Sko{\v c}aj, Danijel},
  year = {2011},
  month = oct,
  journal = {Pattern Recognition},
  series = {Semi-{{Supervised Learning}} for {{Visual Content Analysis}} and {{Understanding}}},
  volume = {44},
  number = {10},
  pages = {2630--2642},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2011.03.019},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320311001233},
  urldate = {2024-03-14},
  abstract = {We propose a novel approach to online estimation of probability density functions, which is based on kernel density estimation (KDE). The method maintains and updates a non-parametric model of the observed data, from which the KDE can be calculated. We propose an online bandwidth estimation approach and a compression/revitalization scheme which maintains the KDE's complexity low. We compare the proposed online KDE to the state-of-the-art approaches on examples of estimating stationary and non-stationary distributions, and on examples of classification. The results show that the online KDE outperforms or achieves a comparable performance to the state-of-the-art and produces models with a significantly lower complexity while allowing online adaptation.},
  keywords = {Gaussian mixture models,Kernel density estimation,Online models,Probability density estimation},
  file = {/Users/kshitijgoel/Zotero/storage/YVLDT2D7/Kristan et al. - 2011 - Multivariate online kernel density estimation with.pdf;/Users/kshitijgoel/Zotero/storage/B7552KYS/S0031320311001233.html}
}

@misc{kuang_active_2024,
  title = {Active {{Neural Mapping}} at {{Scale}}},
  author = {Kuang, Zijia and Yan, Zike and Zhao, Hao and Zhou, Guyue and Zha, Hongbin},
  year = {2024},
  month = sep,
  number = {arXiv:2409.20276},
  eprint = {2409.20276},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.20276},
  urldate = {2024-10-07},
  abstract = {We introduce a NeRF-based active mapping system that enables efficient and robust exploration of large-scale indoor environments. The key to our approach is the extraction of a generalized Voronoi graph (GVG) from the continually updated neural map, leading to the synergistic integration of scene geometry, appearance, topology, and uncertainty. Anchoring uncertain areas induced by the neural map to the vertices of GVG allows the exploration to undergo adaptive granularity along a safe path that traverses unknown areas efficiently. Harnessing a modern hybrid NeRF representation, the proposed system achieves competitive results in terms of reconstruction accuracy, coverage completeness, and exploration efficiency even when scaling up to large indoor environments. Extensive results at different scales validate the efficacy of the proposed system.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/CHWMPCXL/Kuang et al. - 2024 - Active Neural Mapping at Scale.pdf}
}

@book{kucner_probabilistic_2020,
  title = {Probabilistic {{Mapping}} of {{Spatial Motion Patterns}} for {{Mobile Robots}}},
  author = {Kucner, Tomasz Piotr and Lilienthal, Achim J. and Magnusson, Martin and Palmieri, Luigi and Srinivas Swaminathan, Chittaranjan},
  year = {2020},
  series = {Cognitive {{Systems Monographs}}},
  volume = {40},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-41808-3},
  url = {http://link.springer.com/10.1007/978-3-030-41808-3},
  urldate = {2024-07-11},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-030-41807-6 978-3-030-41808-3},
  langid = {english},
  keywords = {Autonomous Robots,Cognitive Systems,Mobile Robots,Probabilistic Mapping,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/38VY8EK3/Kucner et al. - 2020 - Probabilistic Mapping of Spatial Motion Patterns for Mobile Robots.pdf}
}

@article{kucner_survey_2023,
  title = {Survey of Maps of Dynamics for Mobile Robots},
  author = {Kucner, Tomasz Piotr and Magnusson, Martin and Mghames, Sariah and Palmieri, Luigi and Verdoja, Francesco and Swaminathan, Chittaranjan Srinivas and Krajn{\'i}k, Tom{\'a}{\v s} and Schaffernicht, Erik and Bellotto, Nicola and Hanheide, Marc and Lilienthal, Achim J},
  year = {2023},
  month = sep,
  journal = {The International Journal of Robotics Research},
  volume = {42},
  number = {11},
  pages = {977--1006},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231190428},
  url = {https://doi.org/10.1177/02783649231190428},
  urldate = {2024-05-30},
  abstract = {Robotic mapping provides spatial information for autonomous agents. Depending on the tasks they seek to enable, the maps created range from simple 2D representations of the environment geometry to complex, multilayered semantic maps. This survey article is about maps of dynamics (MoDs), which store semantic information about typical motion patterns in a given environment. Some MoDs use trajectories as input, and some can be built from short, disconnected observations of motion. Robots can use MoDs, for example, for global motion planning, improved localization, or human motion prediction. Accounting for the increasing importance of maps of dynamics, we present a comprehensive survey that organizes the knowledge accumulated in the field and identifies promising directions for future work. Specifically, we introduce field-specific vocabulary, summarize existing work according to a novel taxonomy, and describe possible applications and open research problems. We conclude that the field is mature enough, and we expect that maps of dynamics will be increasingly used to improve robot performance in real-world use cases. At the same time, the field is still in a phase of rapid development where novel contributions could significantly impact this research area.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9EWIBINW/Kucner et al. - 2023 - Survey of maps of dynamics for mobile robots.pdf}
}

@inproceedings{kulich_distance_2011,
  title = {On Distance Utility in the Exploration Task},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Kulich, Miroslav and Faigl, Jan and P{\v r}eu{\v c}il, Libor},
  year = {2011},
  month = may,
  pages = {4455--4460},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980221},
  url = {https://ieeexplore.ieee.org/abstract/document/5980221},
  urldate = {2024-11-15},
  abstract = {Performance of exploration strategies strongly depends on the process of determination of a next robot goal. Current approaches define different utility functions how to evaluate and select possible next goal candidates. One of the mostly used evaluation criteria is the distance cost that prefers candidates close to the current robot position. If this is the only criterion, simply the nearest candidate is chosen as the next goal. Although this criterion is simple to implement and gives feasible results there are situations where the criterion leads to wrong decisions. This paper presents the distance cost that reflects traveling through all goal candidates. The cost is determined as a solution of the Traveling Salesman Problem using the Chained Lin-Kernighan heuristic. The cost can be used as a stand-alone criterion as well as it can be integrated into complex decision systems. Experimental results for open-space and office-like experiments show that the proposed approach outperforms the standard one in the length of the traversed trajectory during the exploration while the computational burden is not significantly increased.},
  keywords = {Automation,Conferences,Joining processes,Navigation,Robot sensing systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/D7A3X4KZ/Kulich et al. - 2011 - On distance utility in the exploration task.pdf;/Users/kshitijgoel/Zotero/storage/H8X4FNR4/5980221.html}
}

@article{kulkarni_aerial_2025,
  title = {Aerial {{Gym Simulator}}: {{A Framework}} for {{Highly Parallelized Simulation}} of {{Aerial Robots}}},
  shorttitle = {Aerial {{Gym Simulator}}},
  author = {Kulkarni, Mihir and Rehberg, Welf and Alexis, Kostas},
  year = {2025},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {4},
  pages = {4093--4100},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3548507},
  url = {https://ieeexplore.ieee.org/document/10910148/},
  urldate = {2025-06-10},
  abstract = {This paper contributes the Aerial Gym Simulator, a highly parallelized, modular framework for simulation and rendering of arbitrary multirotor platforms based on NVIDIA Isaac Gym. Aerial Gym supports the simulation of under-, fully- and over-actuated multirotors offering parallelized geometric controllers, alongside a custom GPU-accelerated rendering framework for ray-casting capable of capturing depth, segmentation and vertex-level annotations from the environment. Multiple examples for key tasks, such as depth-based navigation through reinforcement learning are provided. The comprehensive set of tools developed within the framework makes it a powerful resource for research on learning for control, planning, and navigation using state information as well as exteroceptive sensor observations. Extensive simulation studies are conducted and successful sim2real transfer of trained policies is demonstrated.},
  keywords = {Aerial Systems: perception and autonomy,Autonomous aerial vehicles,Engines,machine learning for robot control,Motors,Navigation,Physics,Planning,reinforcement learning,Rendering (computer graphics),Robot sensing systems,Robots,Training},
  file = {/Users/kshitijgoel/Zotero/storage/8D6DDB3T/Kulkarni et al. - 2025 - Aerial Gym Simulator A Framework for Highly Parallelized Simulation of Aerial Robots.pdf}
}

@inproceedings{kulkarni_autonomous_2022,
  title = {Autonomous {{Teamed Exploration}} of {{Subterranean Environments}} Using {{Legged}} and {{Aerial Robots}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Kulkarni, Mihir and Dharmadhikari, Mihir and Tranzatto, Marco and Zimmermann, Samuel and Reijgwart, Victor and De Petris, Paolo and Nguyen, Huan and Khedekar, Nikhil and Papachristos, Christos and Ott, Lionel and Siegwart, Roland and Hutter, Marco and Alexis, Kostas},
  year = {2022},
  month = may,
  pages = {3306--3313},
  doi = {10.1109/ICRA46639.2022.9812401},
  abstract = {This paper presents a novel strategy for autonomous teamed exploration of subterranean environments using legged and aerial robots. Tailored to the fact that subterranean settings, such as cave networks and underground mines, often involve complex, large-scale and multi-branched topologies, while wireless communication within them can be particularly challenging, this work is structured around the synergy of an onboard exploration path planner that allows for resilient long-term autonomy, and a multi-robot coordination framework. The onboard path planner is unified across legged and flying robots and enables navigation in environments with steep slopes, and diverse geometries. When a communication link is available, each robot of the team shares submaps to a centralized location where a multi-robot coordination framework identifies global frontiers of the exploration space to inform each system about where it should re-position to best continue its mission. The strategy is verified through a field deployment inside an underground mine in Switzerland using a legged and a flying robot collectively exploring for 45 min, as well as a longer simulation study with three systems.},
  keywords = {Legged locomotion,Navigation,Network topology,Robot kinematics,Space missions,Three-dimensional displays,Wireless communication},
  file = {/Users/kshitijgoel/Zotero/storage/K9XT7IVX/Kulkarni et al. - 2022 - Autonomous Teamed Exploration of Subterranean Envi.pdf;/Users/kshitijgoel/Zotero/storage/Z25TBGNH/9812401.html}
}

@article{kumar_bandlimited_2015,
  title = {On {{Bandlimited Signal Reconstruction From}} the {{Distribution}} of {{Unknown Sampling Locations}}},
  author = {Kumar, Animesh},
  year = {2015},
  month = mar,
  journal = {IEEE Transactions on Signal Processing},
  volume = {63},
  number = {5},
  pages = {1259--1267},
  issn = {1941-0476},
  doi = {10.1109/TSP.2015.2394248},
  url = {https://ieeexplore.ieee.org/document/7015611/?arnumber=7015611},
  urldate = {2024-12-03},
  abstract = {In remote sensing with a large array of spatially distributed sensors, localization of individual sensor nodes could be difficult. Motivated by the smart-dust paradigm, this work addresses the reconstruction of spatially bandlimited fields from samples taken at unknown but statistically distributed sampling locations. Periodic one-dimensional bandlimited fields are considered for sampling. Samples of the field at uniform independent and identically distributed locations are obtained. The statistical realization of the sampling locations is not known. First, it is shown that a bandlimited field cannot be uniquely determined with samples taken at uniformly distributed but unknown locations, even if the number of samples is infinite. Next, it is assumed that the order of sample locations is known. With order information on sample locations, consistent bandlimited field estimates are designed and analyzed for mean-squared error. The proposed estimates are analyzed for mean-squared error for two cases-when the field measurements are noiseless and when the field measurements are affected by additive independent noise process with finite variance. Finally, a central-limit is established for the field estimate in the case where field measurements are noiseless.},
  keywords = {Additive white noise,Additives,Convergence,Estimation,Noise,Noise measurement,nonuniform sampling,Sensors,signal reconstruction,signal sampling,Vectors,wireless sensor networks},
  file = {/Users/kshitijgoel/Zotero/storage/KMAH8YRP/Kumar - 2015 - On Bandlimited Signal Reconstruction From the Distribution of Unknown Sampling Locations.pdf;/Users/kshitijgoel/Zotero/storage/WZRKLZCD/7015611.html}
}

@inproceedings{kumar_gridshift_2022,
  title = {{{GridShift}}: {{A Faster Mode-Seeking Algorithm}} for {{Image Segmentation}} and {{Object Tracking}}},
  shorttitle = {{{GridShift}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Kumar, Abhishek and Ajani, Oladayo S. and Das, Swagatam and Mallipeddi, Rammohan},
  year = {2022},
  pages = {8131--8139},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.html},
  urldate = {2024-03-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4E2K8U4K/Kumar et al. - 2022 - GridShift A Faster Mode-Seeking Algorithm for Ima.pdf}
}

@article{kummerle_large_2011,
  title = {Large Scale Graph-Based {{SLAM}} Using Aerial Images as Prior Information},
  author = {K{\"u}mmerle, Rainer and Steder, Bastian and Dornhege, Christian and Kleiner, Alexander and Grisetti, Giorgio and Burgard, Wolfram},
  year = {2011},
  month = jan,
  journal = {Autonomous Robots},
  volume = {30},
  number = {1},
  pages = {25--39},
  issn = {1573-7527},
  doi = {10.1007/s10514-010-9204-1},
  url = {https://doi.org/10.1007/s10514-010-9204-1},
  urldate = {2023-03-14},
  abstract = {The problem of learning a map with a mobile robot has been intensively studied in the past and is usually referred to as the simultaneous localization and mapping (SLAM) problem. However, most existing solutions to the SLAM problem learn the maps from scratch and have no means for incorporating prior information. In this paper, we present a novel SLAM approach that achieves global consistency by utilizing publicly accessible aerial photographs as prior information. It inserts correspondences found between stereo and three-dimensional range data and the aerial images as constraints into a graph-based formulation of the SLAM problem. We evaluate our algorithm based on large real-world datasets acquired even in mixed in- and outdoor environments by comparing the global accuracy with state-of-the-art SLAM approaches and GPS. The experimental results demonstrate that the maps acquired with our method show increased global consistency.},
  langid = {english},
  keywords = {Aerial images,Localization,Mapping},
  file = {/Users/kshitijgoel/Zotero/storage/6JPCA78V/Kümmerle et al. - 2011 - Large scale graph-based SLAM using aerial images a.pdf}
}

@inproceedings{kurz_kullbackleibler_2016,
  title = {Kullback-{{Leibler Divergence}} and Moment Matching for Hyperspherical Probability Distributions},
  booktitle = {2016 19th {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Kurz, Gerhard and Pfaff, Florian and Hanebeck, Uwe D.},
  year = {2016},
  month = jul,
  pages = {2087--2094},
  url = {https://ieeexplore.ieee.org/abstract/document/7528140},
  urldate = {2024-07-14},
  abstract = {When approximating one probability density with another density, it is desirable to minimize the information loss of the approximation as quantified by, e.g., the Kullback-Leibler divergence (KLD). It has been known for some time that in the case of the Gaussian distribution, matching the first two moments of the original density yields the optimal approximation in terms of minimizing the KLD. In this paper, we will show that a similar property can be proven for certain hyperspherical probability distributions, namely the von Mises-Fisher and the Watson distribution. This result has profound implications for moment-based filtering on the unit hypersphere as it shows that moment-based approaches are optimal in the information-theoretic sense.},
  keywords = {Covariance matrices,Entropy,Maximum likelihood estimation,parameter estimation,Parameter estimation,Probability distribution,Target tracking,von Mises-Fisher distribution,Watson distribution},
  file = {/Users/kshitijgoel/Zotero/storage/BC45BGWS/Kurz et al. - 2016 - Kullback-Leibler Divergence and moment matching for hyperspherical probability distributions.pdf;/Users/kshitijgoel/Zotero/storage/V843FKSC/7528140.html}
}

@inproceedings{laconte_dynamic_2021,
  title = {Dynamic {{Lambda-Field}}: {{A Counterpart}} of the {{Bayesian Occupancy Grid}} for {{Risk Assessment}} in {{Dynamic Environments}}},
  shorttitle = {Dynamic {{Lambda-Field}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Laconte, Johann and Randriamiarintsoa, Elie and Kasmi, Abderrahim and Pomerleau, Francois and Chapuis, Roland and Debain, Christophe and Aufrere, Romuald},
  year = {2021},
  month = sep,
  pages = {4846--4853},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/IROS51168.2021.9636804},
  url = {https://ieeexplore.ieee.org/document/9636804/},
  urldate = {2024-01-24},
  abstract = {In the context of autonomous vehicles, one of the most crucial tasks is to estimate the risk of the undertaken action. While navigating in complex urban environments, the Bayesian occupancy grid is one of the most popular types of maps, where the information of occupancy is stored as the probability of collision. Although widely used, this kind of representation is not well suited for risk assessment: because of its discrete nature, the probability of collision becomes dependent on the tessellation size. Therefore, risk assessments on Bayesian occupancy grids cannot yield risks with meaningful physical units. In this article, we propose an alternative framework called Dynamic Lambda-Field that is able to assess generic physical risks in dynamic environments without being dependent on the tessellation size. Using our framework, we are able to plan safe trajectories where the risk function can be adjusted depending on the scenario. We validate our approach with quantitative experiments, showing the convergence speed of the grid and that the framework is suitable for real-world scenarios.},
  isbn = {978-1-6654-1714-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GSED2ZI4/Laconte et al. - 2021 - Dynamic Lambda-Field A Counterpart of the Bayesia.pdf}
}

@inproceedings{laconte_lambdafield_2019,
  title = {Lambda-{{Field}}: {{A Continuous Counterpart}} of the {{Bayesian Occupancy Grid}} for {{Risk Assessment}}},
  shorttitle = {Lambda-{{Field}}},
  booktitle = {2019 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Laconte, Johann and Debain, Christophe and Chapuis, Roland and Pomerleau, Fran{\c c}ois and Aufr{\`e}re, Romuald},
  year = {2019},
  month = nov,
  pages = {167--172},
  issn = {2153-0866},
  doi = {10.1109/IROS40897.2019.8968100},
  url = {https://ieeexplore.ieee.org/document/8968100},
  urldate = {2024-01-24},
  abstract = {In a context of autonomous robots, one of the most important tasks is to ensure the safety of the robot and its surrounding. The risk of navigation is usually said to be the probability of collision. This notion of risk is not well defined in the literature, especially when dealing with occupancy grids. The Bayesian occupancy grid is the most used method to deal with complex environments. However, this is not fitted to compute the risk along a path by its discrete nature. In this article, we present a new way to store the occupancy of the environment that allows the computation of risk along a given path. We then define the risk as the force of collision that would occur for a given obstacle. Using this framework, we are able to generate navigation paths ensuring the safety of the robot.},
  file = {/Users/kshitijgoel/Zotero/storage/AIS94VZG/Laconte et al. - 2019 - Lambda-Field A Continuous Counterpart of the Baye.pdf;/Users/kshitijgoel/Zotero/storage/EJGTW5E5/8968100.html}
}

@misc{laina_scalable_2024,
  title = {Scalable {{Autonomous Drone Flight}} in the {{Forest}} with {{Visual-Inertial SLAM}} and {{Dense Submaps Built}} without {{LiDAR}}},
  author = {Laina, Sebasti{\'a}n Barbas and Boche, Simon and Papatheodorou, Sotiris and Tzoumanikas, Dimos and Schaefer, Simon and Chen, Hanzhi and Leutenegger, Stefan},
  year = {2024},
  month = mar,
  number = {arXiv:2403.09596},
  eprint = {2403.09596},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.09596},
  urldate = {2024-06-09},
  abstract = {Forestry constitutes a key element for a sustainable future, while it is supremely challenging to introduce digital processes to improve efficiency. The main limitation is the difficulty of obtaining accurate maps at high temporal and spatial resolution as a basis for informed forestry decisionmaking, due to the vast area forests extend over and the sheer number of trees. To address this challenge, we present an autonomous Micro Aerial Vehicle (MAV) system which purely relies on cost-effective and light-weight passive visual and inertial sensors to perform under-canopy autonomous navigation. We leverage visual-inertial simultaneous localization and mapping (VI-SLAM) for accurate MAV state estimates and couple it with a volumetric occupancy submapping system to achieve a scalable mapping framework which can be directly used for path planning. As opposed to a monolithic map, submaps inherently deal with inevitable drift and corrections from VI-SLAM, since they move with pose estimates as they are updated. To ensure the safety of the MAV during navigation, we also propose a novel reference trajectory anchoring scheme that moves and deforms the reference trajectory the MAV is tracking upon state updates from the VI-SLAM system in a consistent way, even upon large changes in state estimates due to loop-closures. We thoroughly validate our system in both real and simulated forest environments with high tree densities in excess of 400 trees per hectare and at speeds up to 3 m/s -- while not encountering a single collision or system failure. To the best of our knowledge this is the first system which achieves this level of performance in such unstructured environment using low-cost passive visual sensors and fully on-board computation including VI-SLAM.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/H328743P/Laina et al. - 2024 - Scalable Autonomous Drone Flight in the Forest with Visual-Inertial SLAM and Dense Submaps Built wit.pdf}
}

@article{lajoie_swarmslam_2024,
  title = {Swarm-{{SLAM}}: {{Sparse Decentralized Collaborative Simultaneous Localization}} and {{Mapping Framework}} for {{Multi-Robot Systems}}},
  shorttitle = {Swarm-{{SLAM}}},
  author = {Lajoie, Pierre-Yves and Beltrame, Giovanni},
  year = {2024},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {1},
  pages = {475--482},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3333742},
  url = {https://ieeexplore.ieee.org/document/10321649/},
  urldate = {2023-12-03},
  abstract = {Collaborative Simultaneous Localization And Mapping (C-SLAM) is a vital component for successful multi-robot operations in environments without an external positioning system, such as indoors, underground or underwater. In this paper, we introduce Swarm-SLAM, an open-source C-SLAM system that is designed to be scalable, flexible, decentralized, and sparse, which are all key properties in swarm robotics. Our system supports lidar, stereo, and RGB-D sensing, and it includes a novel inter-robot loop closure prioritization technique that reduces communication and accelerates convergence. We evaluated our ROS 2 implementation on five different datasets, and in a real-world experiment with three robots communicating through an ad-hoc network.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M5RNV6GH/Lajoie and Beltrame - 2024 - Swarm-SLAM Sparse Decentralized Collaborative Sim.pdf}
}

@misc{landgraf_critical_2025,
  title = {A {{Critical Synthesis}} of {{Uncertainty Quantification}} and {{Foundation Models}} in {{Monocular Depth Estimation}}},
  author = {Landgraf, Steven and Qin, Rongjun and Ulrich, Markus},
  year = {2025},
  month = jan,
  number = {arXiv:2501.08188},
  eprint = {2501.08188},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.08188},
  url = {http://arxiv.org/abs/2501.08188},
  urldate = {2025-01-30},
  abstract = {While recent foundation models have enabled significant breakthroughs in monocular depth estimation, a clear path towards safe and reliable deployment in the real-world remains elusive. Metric depth estimation, which involves predicting absolute distances, poses particular challenges, as even the most advanced foundation models remain prone to critical errors. Since quantifying the uncertainty has emerged as a promising endeavor to address these limitations and enable trustworthy deployment, we fuse five different uncertainty quantification methods with the current state-of-the-art DepthAnythingV2 foundation model. To cover a wide range of metric depth domains, we evaluate their performance on four diverse datasets. Our findings identify fine-tuning with the Gaussian Negative Log-Likelihood Loss (GNLL) as a particularly promising approach, offering reliable uncertainty estimates while maintaining predictive performance and computational efficiency on par with the baseline, encompassing both training and inference time. By fusing uncertainty quantification and foundation models within the context of monocular depth estimation, this paper lays a critical foundation for future research aimed at improving not only model performance but also its explainability. Extending this critical synthesis of uncertainty quantification and foundation models into other crucial tasks, such as semantic segmentation and pose estimation, presents exciting opportunities for safer and more reliable machine vision systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/6SJ82GBA/Landgraf et al. - 2025 - A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimati.pdf;/Users/kshitijgoel/Zotero/storage/S7CPIR4G/2501.html}
}

@inproceedings{lange_incremental_2013,
  title = {Incremental Smoothing vs. Filtering for Sensor Fusion on an Indoor {{UAV}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Lange, Sven and S{\"u}nderhauf, Niko and Protzel, Peter},
  year = {2013},
  month = may,
  pages = {1773--1778},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6630810},
  url = {https://ieeexplore.ieee.org/document/6630810/?arnumber=6630810&tag=1},
  urldate = {2025-03-24},
  abstract = {Our paper explores the performance of a recently proposed incremental smoother in the context of nonlinear sensor fusion for a real-world UAV. This efficient factor graph based smoothing approach has a number of advantages compared to conventional filtering techniques like the EKF or its variants. It can more easily incorporate asynchronous and delayed measurements from sensors operating at different rates and is supposed to be less error-prone in highly nonlinear settings. We compare the novel incremental smoothing approach based on iSAM2 against our conventional EKF based sensor fusion framework. Unlike previously presented work, the experiments are not only performed in simulation, but also on a real-world quadrotor UAV system using IMU, optical flow and altitude measurements.},
  keywords = {Mathematical model,Noise,Optical sensors,Optical variables measurement,Sensor fusion,Smoothing methods,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/57DHJJU7/Lange et al. - 2013 - Incremental smoothing vs. filtering for sensor fusion on an indoor UAV.pdf;/Users/kshitijgoel/Zotero/storage/AZXJUQK9/6630810.html}
}

@article{langevin_magnetisme_1905,
  title = {{Magn{\'e}tisme et th{\'e}orie des {\'e}lectrons}},
  author = {Langevin, Paul},
  year = {1905},
  journal = {Ann. de Chimie et Physique},
  volume = {5},
  number = {70},
  publisher = {CNRS},
  url = {https://www.rcin.org.pl/dlibra/publication/226769/edition/194960},
  urldate = {2024-07-23},
  abstract = {[6], 687 s. : il. ; 24 cm},
  copyright = {Public Domain},
  langid = {fre},
  file = {/Users/kshitijgoel/Zotero/storage/ZI8KSUAR/Langevin and Langevin - 1950 - Magnétisme et théorie des électrons, Ann. de Chimie et Physique, 1905, 5, 70.pdf;/Users/kshitijgoel/Zotero/storage/UJ65ZNY4/content.html}
}

@inproceedings{larsson_evaluation_2010,
  title = {An Evaluation of Local Autonomy Applied to Teleoperated Vehicles in Underground Mines},
  booktitle = {2010 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Larsson, Johan and Broxvall, Mathias and Saffiotti, Alessandro},
  year = {2010},
  month = may,
  pages = {1745--1752},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2010.5509276},
  abstract = {Autonomous vehicles are being increasingly introduced in the mining industry. While these may offer high safety and high productivity, fully autonomous solutions are not always applicable or economically viable. Teleoperation is an attractive option, since it increases safety and comfort of the drivers. Unfortunately, the difficulty to operate the vehicle remotely often results in reduced productivity. In this paper, we show that techniques from the field of mobile robotics can be used to mitigate this problem. We extend a commercial teleoperation system for use in underground mines with a local autonomy functionality, with the main purpose to evaluate if the achieved productivity improvement motivates development of general algorithms and a fully commercial implementation. We then describe a user study performed in an underground mine with a 38 tonne articulated wheel loader, which proves that local autonomy gives a significant improvement in productivity of the teleoperation system, while retaining or even reducing the maintenance costs.},
  keywords = {Costs,Mining industry,Mobile robots,Product safety,Productivity,Remotely operated vehicles,Robotics and automation,USA Councils,Vehicle driving,Wheels},
  file = {/Users/kshitijgoel/Zotero/storage/E76V48XT/Larsson et al. - 2010 - An evaluation of local autonomy applied to teleope.pdf;/Users/kshitijgoel/Zotero/storage/5AE42ZZ6/5509276.html}
}

@article{latif_communicationefficient_2024,
  title = {Communication-{{Efficient Multi-Robot Exploration Using Coverage-biased Distributed Q-Learning}}},
  author = {Latif, Ehsan and Parasuraman, Ramviyas},
  year = {2024},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2024.3358095},
  url = {https://ieeexplore.ieee.org/document/10413563/},
  urldate = {2024-01-29},
  abstract = {Frontier exploration and reinforcement learning have historically been used to solve the problem of enabling many mobile robots to autonomously and cooperatively explore complex surroundings. These methods need to keep an internal global map for navigation, but they do not consider the high costs of communication and information sharing between robots. This study offers CQLite, a novel distributed Q-learning technique that minimizes data communication between robots while achieving rapid convergence and thorough coverage in multirobot exploration. The proposed CQLite method uses ad hoc map merging, and selectively shares updated Q-values at recently identified frontiers to reduce communication costs significantly. The theoretical analysis of CQLite's convergence and efficiency and extensive numerical verification on simulated indoor maps utilizing several robots demonstrate the method's novelty. With over 2x reductions in computation and communication alongside improved mapping performance, CQLite outperformed cuttingedge multi-robot exploration techniques like Rapidly-exploring Random Trees and Deep Reinforcement Learning.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PJLP3KJ2/Latif and Parasuraman - 2024 - Communication-Efficient Multi-Robot Exploration Us.pdf}
}

@book{latombe_robot_1991,
  title = {Robot {{Motion Planning}}},
  author = {Latombe, Jean-Claude},
  year = {1991},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-1-4615-4022-9},
  url = {http://link.springer.com/10.1007/978-1-4615-4022-9},
  urldate = {2023-04-20},
  isbn = {978-0-7923-9206-4 978-1-4615-4022-9},
  keywords = {actuator,autonomous robot,computer,control,manufacturing,motion planning,perception,robot,robotics,sensor,sensors,space exploration},
  file = {/Users/kshitijgoel/Zotero/storage/9V4B9J5V/Latombe - 1991 - Robot Motion Planning.pdf}
}

@article{lauri_planning_2016,
  title = {Planning for Robotic Exploration Based on Forward Simulation},
  author = {Lauri, Mikko and Ritala, Risto},
  year = {2016},
  month = sep,
  journal = {Robotics and Autonomous Systems},
  volume = {83},
  pages = {15--31},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2016.06.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0921889015301779},
  urldate = {2023-01-20},
  abstract = {We address the problem of controlling a mobile robot to explore a partially known environment. The robot's objective is the maximization of the amount of information collected about the environment. We formulate the problem as a partially observable Markov decision process (POMDP) with an information-theoretic objective function, and solve it applying forward simulation algorithms with an open-loop approximation. We present a new sample-based approximation for mutual information useful in mobile robotics. The approximation can be seamlessly integrated with forward simulation planning algorithms. We investigate the usefulness of POMDP based planning for exploration, and to alleviate some of its weaknesses propose a combination with frontier based exploration. Experimental results in simulated and real environments show that, depending on the environment, applying POMDP based planning for exploration can improve performance over frontier exploration.},
  langid = {english},
  keywords = {Active sensing,Mutual information,Partially observable Markov decision process,Robotic exploration,Sensor management},
  file = {/Users/kshitijgoel/Zotero/storage/RRUWV5FH/Lauri and Ritala - 2016 - Planning for robotic exploration based on forward .pdf;/Users/kshitijgoel/Zotero/storage/M2GI9QB5/S0921889015301779.html}
}

@article{lavalle_sensing_2012,
  title = {Sensing and {{Filtering}}: {{A Fresh Perspective Based}} on {{Preimages}} and {{Information Spaces}}},
  shorttitle = {Sensing and {{Filtering}}},
  author = {LaValle, Steven M.},
  year = {2012},
  month = feb,
  journal = {Foundations and Trends{\textregistered} in Robotics},
  volume = {1},
  number = {4},
  pages = {253--372},
  publisher = {Now Publishers, Inc.},
  issn = {1935-8253, 1935-8261},
  doi = {10.1561/2300000004},
  url = {https://www.nowpublishers.com/article/Details/ROB-004},
  urldate = {2023-03-14},
  abstract = {Sensing and Filtering: A Fresh Perspective Based on Preimages and Information Spaces},
  langid = {english},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/books/lavalle-sensing-filtering.pdf}
}

@article{lawonn_gray_2023,
  title = {{{GRay}}: {{Ray Casting}} for {{Visualization}} and {{Interactive Data Exploration}} of {{Gaussian Mixture Models}}},
  shorttitle = {{{GRay}}},
  author = {Lawonn, Kai and Meuschke, Monique and Eulzer, Pepe and Mitterreiter, Matthias and Giesen, Joachim and G{\"u}nther, Tobias},
  year = {2023},
  month = jan,
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {29},
  number = {1},
  pages = {526--536},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2022.3209374},
  abstract = {The Gaussian mixture model (GMM) describes the distribution of random variables from several different populations. GMMs have widespread applications in probability theory, statistics, machine learning for unsupervised cluster analysis and topic modeling, as well as in deep learning pipelines. So far, few efforts have been made to explore the underlying point distribution in combination with the GMMs, in particular when the data becomes high-dimensional and when the GMMs are composed of many Gaussians. We present an analysis tool comprising various GPU-based visualization techniques to explore such complex GMMs. To facilitate the exploration of high-dimensional data, we provide a novel navigation system to analyze the underlying data. Instead of projecting the data to 2D, we utilize interactive 3D views to better support users in understanding the spatial arrangements of the Gaussian distributions. The interactive system is composed of two parts: (1) raycasting-based views that visualize cluster memberships, spatial arrangements, and support the discovery of new modes. (2) overview visualizations that enable the comparison of Gaussians with each other, as well as small multiples of different choices of basis vectors. Users are supported in their exploration with customization tools and smooth camera navigations. Our tool was developed and assessed by five domain experts, and its usefulness was evaluated with 23 participants. To demonstrate the effectiveness, we identify interesting features in several data sets.},
  keywords = {Data visualization,Gaussian mixture model,Gaussian mixture models,ray casting,Scientific visualization,Shape,Statistics,Task analysis,Three-dimensional displays,Visualization,volume visualization},
  file = {/Users/kshitijgoel/Zotero/storage/XDAKM62W/Lawonn et al. - 2023 - GRay Ray Casting for Visualization and Interactiv.pdf;/Users/kshitijgoel/Zotero/storage/GBEVSMZS/stamp.html}
}

@phdthesis{lebanon_riemannian_2005,
  title = {Riemannian Geometry and Statistical Machine Learning},
  author = {Lebanon, Guy},
  year = {2005},
  address = {United States -- Pennsylvania},
  url = {https://www.proquest.com/docview/305006693/abstract/72133DF8B10C46C1PQ/1},
  urldate = {2024-07-15},
  abstract = {Statistical machine learning algorithms deal with the problem of selecting an appropriate statistical model from a model space {$\Theta$} based on a training set [special characters omitted] {$\subset$} X or [special characters omitted] {$\subset$} X {\texttimes} Y. In doing so they either implicitly or explicitly make assumptions on the geometries of the model space {$\Theta$} and the data space X. Such assumptions are crucial to the success of the algorithms as different geometries are appropriate for different models and data spaces. By studying these assumptions we are able to develop new theoretical results that enhance our understanding of several popular learning algorithms. Furthermore, using geometrical reasoning we are able to adapt existing algorithms such as radial basis kernels and linear margin classifiers to non-Euclidean geometries. Such adaptation is shown to be useful when the data space does not exhibit Euclidean geometry. In particular, we focus in our experiments on the space of text documents that is naturally associated with the Fisher information metric on corresponding multinomial models.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780496934720},
  langid = {english},
  school = {Carnegie Mellon University},
  keywords = {Applied sciences,Information geometry,Machine learning,Riemannian geometry,Statistical machine learning},
  file = {/Users/kshitijgoel/Zotero/storage/Y3NRZGTG/Lebanon - Riemannian geometry and statistical machine learning.pdf}
}

@inproceedings{lee_autonomous_2012,
  title = {Autonomous Landing of a {{VTOL UAV}} on a Moving Platform Using Image-Based Visual Servoing},
  booktitle = {2012 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Lee, Daewon and Ryan, Tyler and Kim, H. {\relax Jin}.},
  year = {2012},
  month = may,
  pages = {971--976},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2012.6224828},
  url = {https://ieeexplore.ieee.org/document/6224828/},
  urldate = {2025-05-13},
  abstract = {In this paper we describe a vision-based algorithm to control a vertical-takeoff-and-landing unmanned aerial vehicle while tracking and landing on a moving platform. Specifically, we use image-based visual servoing (IBVS) to track the platform in two-dimensional image space and generate a velocity reference command used as the input to an adaptive sliding mode controller. Compared with other vision-based control algorithms that reconstruct a full three-dimensional representation of the target, which requires precise depth estimation, IBVS is computationally cheaper since it is less sensitive to the depth estimation allowing for a faster method to obtain this estimate. To enhance velocity tracking of the sliding mode controller, an adaptive rule is described to account for the ground effect experienced during the maneuver. Finally, the IBVS algorithm integrated with the adaptive sliding mode controller for tracking and landing is validated in an experimental setup using a quadrotor.},
  keywords = {Aerodynamics,Aerospace electronics,Cameras,Image reconstruction,Target tracking,Vectors,Visual servoing},
  file = {/Users/kshitijgoel/Zotero/storage/YWSNXDSY/Lee et al. - 2012 - Autonomous landing of a VTOL UAV on a moving platform using image-based visual servoing.pdf}
}

@article{lee_bpmptracker_2024,
  title = {{{BPMP-Tracker}}: {{A Versatile Aerial Target Tracker Using Bernstein Polynomial Motion Primitives}}},
  shorttitle = {{{BPMP-Tracker}}},
  author = {Lee, Yunwoo and Park, Jungwon and Jeon, Boseong and Jung, Seungwoo and Kim, H. Jin},
  year = {2024},
  month = dec,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {12},
  pages = {10938--10945},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3475879},
  url = {https://ieeexplore.ieee.org/document/10714432/},
  urldate = {2025-05-13},
  abstract = {This letter presents a versatile trajectory planning pipeline for aerial tracking. The proposed tracker is capable of handling various chasing settings such as complex unstructured environments, crowded dynamic obstacles and multiple-target following. Among the entire pipeline, we focus on developing a predictor for future target motion and a chasing trajectory planner. For rapid computation, we employ the sample-check-select strategy: modules sample a set of candidate movements, check multiple constraints, and then select the best trajectory. Also, we leverage the properties of Bernstein polynomials for quick calculations. The prediction module predicts the trajectories of the targets, which do not overlap with static and dynamic obstacles. Then the trajectory planner outputs a trajectory, ensuring various conditions such as occlusion and collision avoidance, the visibility of all targets within a camera image and dynamical limits. We fully test the proposed tracker in simulations and hardware experiments under challenging scenarios, including dual-target following, environments with dozens of dynamic obstacles and complex indoor and outdoor spaces.},
  keywords = {Aerodynamics,Cameras,Drones,Ellipsoids,motion and path planning,Pipelines,Planning,Polynomials,Reactive and sensor-based planning,Target tracking,Trajectory,Trajectory planning,visual servoing},
  file = {/Users/kshitijgoel/Zotero/storage/IXYJWZRK/Lee et al. - 2024 - BPMP-Tracker A Versatile Aerial Target Tracker Using Bernstein Polynomial Motion Primitives.pdf}
}

@inproceedings{lee_compact_2024,
  title = {Compact {{3D Gaussian Representation}} for {{Radiance Field}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Lee, Joo Chan and Rho, Daniel and Sun, Xiangyu and Ko, Jong Hwan and Park, Eunbyung},
  year = {2024},
  pages = {21719--21728},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Compact_3D_Gaussian_Representation_for_Radiance_Field_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/698536ZU/Lee et al. - 2024 - Compact 3D Gaussian Representation for Radiance Field.pdf}
}

@article{lee_dmvctracker_2025,
  title = {{{DMVC-Tracker}}: {{Distributed Multi-Agent Trajectory Planning}} for {{Target Tracking Using Dynamic Buffered Voronoi}} and {{Inter-Visibility Cells}}},
  shorttitle = {{{DMVC-Tracker}}},
  author = {Lee, Yunwoo and Park, Jungwon and Kim, H. Jin},
  year = {2025},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {5},
  pages = {4842--4849},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3551255},
  url = {https://ieeexplore.ieee.org/document/10925881/},
  urldate = {2025-05-13},
  abstract = {This letter presents a distributed trajectory planning method for multi-agent aerial tracking. The proposed method uses a Dynamic Buffered Voronoi Cell (DBVC) and a Dynamic Inter-Visibility Cell (DIVC) to formulate the distributed trajectory generation. Specifically, the DBVC and the DIVC are time-variant spaces that prevent mutual collisions and occlusions among agents, while enabling them to maintain suitable distances from the moving target. We combine the DBVC and the DIVC with an efficient Bernstein polynomial motion primitive-based tracking trajectory generation method, which has been refined into a less conservative approach than in our previous work. The proposed algorithm can compute each agent's trajectory within several milliseconds on an Intel i7 desktop. We validate the tracking performance in challenging scenarios, including environments with dozens of obstacles.},
  keywords = {aerial tracking,Cameras,distributed robot systems,Drones,Indexes,Path planning for multiple mobile robots,Planning,Polynomials,Real-time systems,Target tracking,Trajectory,Trajectory planning,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/TGBPE8Q8/Lee et al. - 2025 - DMVC-Tracker Distributed Multi-Agent Trajectory Planning for Target Tracking Using Dynamic Buffered.pdf}
}

@article{lee_mmp_2024,
  title = {{{MMP}}++: {{Motion Manifold Primitives With Parametric Curve Models}}},
  shorttitle = {{{MMP}}++},
  author = {Lee, Yonghyeon},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {3950--3963},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3444068},
  url = {https://ieeexplore.ieee.org/document/10637485/?arnumber=10637485},
  urldate = {2024-08-31},
  abstract = {Motion manifold primitives (MMP), a manifold-based approach for encoding basic motion skills, can produce diverse trajectories, enabling the system to adapt to unseen constraints. Nonetheless, we argue that current MMP models lack crucial functionalities of movement primitives, such as temporal and via-points modulation, found in traditional approaches. This shortfall primarily stems from MMP's reliance on discrete-time trajectories. To overcome these limitations, we introduce motion manifold primitives++ (MMP++), a new model that integrates the strengths of both MMP and traditional methods by incorporating parametric curve representations into the MMP framework. Furthermore, we identify a significant challenge with MMP++: performance degradation due to geometric distortions in the latent space, meaning that similar motions are not closely positioned. To address this, isometric motion manifold primitives++ (IMMP++) is proposed to ensure the latent space accurately preserves the manifold's geometry. Our experimental results across various applications, including two-DoF planar motions, seven-DoF robot arm motions, and SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing methods in trajectory generation tasks, achieving substantial improvements in some cases. Moreover, they enable the modulation of latent coordinates and via-points, thereby allowing efficient online adaptation to dynamic environments.},
  keywords = {Adaptation models,Autoencoders,isometric representation learning,manifold,Manifolds,Measurement,Modulation,movement primitives,Riemannian geometry,Robot kinematics,Task analysis,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/7NLHAGU6/Lee - 2024 - MMP++ Motion Manifold Primitives With Parametric Curve Models.pdf;/Users/kshitijgoel/Zotero/storage/8SSXLJ6W/10637485.html}
}

@inproceedings{lee_multiplemodel_2017,
  title = {Multiple-{{Model Adaptive Estimation}} for {{Measurements}} with {{Unknown Time Delay}}},
  booktitle = {{{AIAA Guidance}}, {{Navigation}}, and {{Control Conference}}},
  author = {Lee, Kyuman and Johnson, Eric N.},
  year = {2017},
  month = jan,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  address = {Grapevine, Texas},
  doi = {10.2514/6.2017-1260},
  url = {https://arc.aiaa.org/doi/10.2514/6.2017-1260},
  urldate = {2025-03-26},
  isbn = {978-1-62410-450-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QYGG4FW3/Lee and Johnson - 2017 - Multiple-Model Adaptive Estimation for Measurements with Unknown Time Delay.pdf}
}

@inproceedings{lee_online_2019,
  title = {Online {{Continuous Mapping}} Using {{Gaussian Process Implicit Surfaces}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lee, Bhoram and Zhang, Clark and Huang, Zonghao and Lee, Daniel D.},
  year = {2019},
  month = may,
  pages = {6884--6890},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8794324},
  url = {https://ieeexplore.ieee.org/document/8794324},
  urldate = {2024-01-27},
  abstract = {The representation of the environment strongly affects how robots can move and interact with it. This paper presents an online approach for continuous mapping using Gaussian Process Implicit Surfaces (GPISs). Compared with grid-based methods, GPIS better utilizes sparse measurements to represent the world seamlessly. It provides direct access to the signed-distance function (SDF) and its derivatives which are invaluable for other robotic tasks and it incorporates uncertainty in the sensor measurements. Our approach incrementally and efficiently updates GPIS by employing a regressor on observations and a spatial tree structure. The effectiveness of the suggested approach is demonstrated using simulations and real world 2D/3D data.},
  keywords = {Noise measurement,Planning,Robot kinematics,Robot sensing systems,Surface treatment,Training},
  file = {/Users/kshitijgoel/Zotero/storage/D69RMEC6/Lee et al. - 2019 - Online Continuous Mapping using Gaussian Process I.pdf;/Users/kshitijgoel/Zotero/storage/XSXZUJ77/8794324.html}
}

@inproceedings{lee_rapid_2024,
  title = {Rapid {{Quadrotor Navigation}} in {{Diverse Environments Using}} an {{Onboard Depth Camera}}},
  booktitle = {2024 {{IEEE International Symposium}} on {{Safety Security Rescue Robotics}} ({{SSRR}})},
  author = {Lee, Jonnthan and Rathod, Abhishek and Goel, Kshitij and Stecklein, John and Tabib, Wennie},
  year = {2024},
  month = nov,
  pages = {18--25},
  issn = {2475-8426},
  doi = {10.1109/SSRR62954.2024.10770033},
  url = {https://ieeexplore.ieee.org/document/10770033/?arnumber=10770033},
  urldate = {2025-01-16},
  abstract = {Search and rescue environments exhibit challenging 3D geometry (e.g., confined spaces, rubble, and breakdown), which necessitates agile and maneuverable aerial robotic systems. Because these systems are size, weight, and power (SWaP) constrained, rapid navigation is essential for maximizing environment coverage. Onboard autonomy must be robust to prevent collisions, which may endanger rescuers and victims. Prior works have developed high-speed navigation solutions for autonomous aerial systems, but few have considered safety for search and rescue applications. These works have also not demonstrated their approaches in diverse environments. We bridge this gap in the state of the art by developing a reactive planner using forward-arc motion primitives, which leverages a history of RGB-D observations to safely maneuver in close proximity to obstacles. At every planning round, a safe stopping action is scheduled, which is executed if no feasible motion plan is found at the next planning round. The approach is evaluated in thousands of simulations and deployed in diverse environments, including caves and forests. The results demonstrate a 24 \% increase in success rate compared to state-of-the-art approaches.},
  keywords = {Cameras,Collision avoidance,Forests,History,Navigation,Planning,Robots,Safety,Trajectory,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/VU2SDG4E/Lee et al. - 2024 - Rapid Quadrotor Navigation in Diverse Environments Using an Onboard Depth Camera.pdf;/Users/kshitijgoel/Zotero/storage/5IZX4ZVM/10770033.html}
}

@article{lee_spatiotemporal_2025,
  title = {Spatiotemporal {{Multi-Camera Calibration Using Freely Moving People}}},
  author = {Lee, Sang-Eun and Nishino, Ko and Nobuhara, Shohei},
  year = {2025},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {5},
  pages = {4818--4825},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3554102},
  url = {https://ieeexplore.ieee.org/document/10937736/},
  urldate = {2025-04-15},
  abstract = {We propose a novel method for spatiotemporal multi-camera calibration using freely moving people in multi-view videos. Since calibrating multiple cameras and finding matches across their views are inherently interdependent, performing both in a unified framework poses a significant challenge. We address these issues as a single registration problem of matching two sets of 3D points, leveraging human motion in dynamic multi-person scenes. To this end, we utilize 3D human poses obtained from an off-the-shelf monocular 3D human pose estimator and transform them into 3D points on a unit sphere, to solve the rotation, time offset, and the association alternatingly. We employ a probabilistic approach that can jointly solve both problems of aligning spatiotemporal data and establishing correspondences through soft assignment between two views. The translation is determined by applying coplanarity constraints. The pairwise registration results are integrated into a multiview setup, and then a nonlinear optimization method is used to improve the accuracy of the camera poses, temporal offsets, and multi-person associations. Extensive experiments on synthetic and real data demonstrate the effectiveness and flexibility of the proposed method as a practical marker-free calibration tool.},
  keywords = {Calibration,Calibration and identification,camera calibration and synchronization,Cameras,computer vision for automation,people association,Probabilistic logic,Robot vision systems,Spatiotemporal phenomena,Synchronization,Three-dimensional displays,Trajectory,Translation,Videos},
  file = {/Users/kshitijgoel/Zotero/storage/3SUDA4HG/Lee et al. - 2025 - Spatiotemporal Multi-Camera Calibration Using Freely Moving People.pdf}
}

@article{lee_uncertainty_2022,
  title = {Uncertainty {{Guided Policy}} for {{Active Robotic 3D Reconstruction Using Neural Radiance Fields}}},
  author = {Lee, Soomin and Chen, Le and Wang, Jiahao and Liniger, Alexander and Kumar, Suryansh and Yu, Fisher},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {12070--12077},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3212668},
  abstract = {In this letter, we tackle the problem of active robotic 3D reconstruction of an object. In particular, we study how a mobile robot with an arm-held camera can select a favorable number of views to recover an object's 3D shape efficiently. Contrary to the existing solution to this problem, we leverage the popular neural radiance fields-based object representation, which has recently shown impressive results for various computer vision tasks. However, it is not straightforward to directly reason about an object's explicit 3D geometric details using such a representation, making the next-best-view selection problem for dense 3D reconstruction challenging. This paper introduces a ray-based volumetric uncertainty estimator, which computes the entropy of the weight distribution of the color samples along each ray of the object's implicit neural representation. We show that it is possible to infer the uncertainty of the underlying 3D geometry given a novel view with the proposed estimator. We then present a next-best-view selection policy guided by the ray-based volumetric uncertainty in neural radiance fields-based representations. Encouraging experimental results on synthetic and real-world data suggest that the approach presented in this paper can enable a new research direction of using an implicit 3D object representation for the next-best-view problem in robot vision applications, distinguishing our approach from the existing approaches that rely on explicit 3D geometric modeling.},
  keywords = {Active 3D reconstruction,neural radiance fields,next-best-view selection,Rendering (computer graphics),Robot sensing systems,robot vision,Robots,Shape,Task analysis,Three-dimensional displays,Uncertainty,uncertainty estimation},
  file = {/Users/kshitijgoel/Zotero/storage/KEKLLAIA/Lee et al. - 2022 - Uncertainty Guided Policy for Active Robotic 3D Re.pdf;/Users/kshitijgoel/Zotero/storage/QAR724ZV/9913658.html}
}

@article{legentil_accurate_2024,
  title = {Accurate {{Gaussian-Process-Based Distance Fields With Applications}} to {{Echolocation}} and {{Mapping}}},
  author = {Le Gentil, Cedric and Ouabi, Othmane-Latif and Wu, Lan and Pradalier, Cedric and {Vidal-Calleja}, Teresa},
  year = {2024},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {2},
  pages = {1365--1372},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3346759},
  url = {https://ieeexplore.ieee.org/abstract/document/10373132},
  urldate = {2024-01-07},
  abstract = {This letter introduces a novel method to estimate distance fields from noisy point clouds using Gaussian Process (GP) regression. Distance fields, or distance functions, gained popularity for applications like point cloud registration, odometry, SLAM, path planning, shape reconstruction, etc. A distance field provides a continuous representation of the scene defined as the shortest distance from any query point and the closest surface. The key concept of the proposed method is the transformation of a GP-inferred latent scalar field into an accurate distance field by using a reverting function related to the kernel inverse. The latent field can be interpreted as a smooth occupancy map. This letter provides the theoretical derivation of the proposed method as well as a novel uncertainty proxy for the distance estimates. The improved performance compared with existing distance fields is demonstrated with simulated experiments. The level of accuracy of the proposed approach enables novel applications that rely on precise distance estimation: this work presents echolocation and mapping frameworks for ultrasonic-guided wave sensing in metallic structures. These methods leverage the proposed distance field with a physics-based measurement model accounting for the propagation of the ultrasonic waves in the material. Real-world experiments are conducted to demonstrate the soundness of these frameworks.},
  file = {/Users/kshitijgoel/Zotero/storage/W59EQDAM/Le Gentil et al. - 2024 - Accurate Gaussian-Process-Based Distance Fields Wi.pdf}
}

@article{leingartner_evaluation_2016,
  title = {Evaluation of {{Sensors}} and {{Mapping Approaches}} for {{Disasters}} in {{Tunnels}}},
  author = {Leingartner, Max and Maurer, Johannes and Ferrein, Alexander and Steinbauer, Gerald},
  year = {2016},
  journal = {Journal of Field Robotics},
  volume = {33},
  number = {8},
  pages = {1037--1057},
  issn = {1556-4967},
  doi = {10.1002/rob.21611},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21611},
  urldate = {2022-07-25},
  abstract = {Ground or aerial robots equipped with advanced sensing technologies, such as three-dimensional laser scanners and advanced mapping algorithms, are deemed useful as a supporting technology for first responders. A great deal of excellent research in the field exists, but practical applications at real disaster sites are scarce. Many projects concentrate on equipping robots with advanced capabilities, such as autonomous exploration or object manipulation. In spite of this, realistic application areas for such robots are limited to teleoperated reconnaissance or search. In this paper, we investigate how well state-of-the-art and off-the-shelf components and algorithms are suited for reconnaissance in current disaster-relief scenarios. The basic idea is to make use of some of the most common sensors and deploy some widely used algorithms in a disaster situation, and to evaluate how well the components work for these scenarios. We acquired the sensor data from two field experiments, one from a disaster-relief operation in a motorway tunnel, and one from a mapping experiment in a partly closed down motorway tunnel. Based on these data, which we make publicly available, we evaluate state-of-the-art and off-the-shelf mapping approaches. In our analysis, we integrate opinions and replies from first responders as well as from some algorithm developers on the usefulness of the data and the limitations of the deployed approaches, respectively. We discuss the lessons we learned during the two missions. These lessons are interesting for the community working in similar areas of urban search and rescue, particularly reconnaissance and search.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/T4H2YGDK/Leingartner et al. - 2016 - Evaluation of Sensors and Mapping Approaches for D.pdf;/Users/kshitijgoel/Zotero/storage/WP9WP8MN/rob.html}
}

@inproceedings{levin_motion_2018,
  title = {Motion {{Planning}} for a {{Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Levin, Joshua and Paranjape, Aditya and Nahon, Meyer},
  year = {2018},
  month = oct,
  pages = {8464--8470},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8593670},
  url = {https://ieeexplore.ieee.org/document/8593670},
  urldate = {2024-11-15},
  abstract = {A motion planner is developed for guiding a small aerobatic fixed-wing unmanned aerial vehicle to a desired goal region in a highly constrained, three-dimensional, known environment with static obstacles. The planner is based on the Rapidly-Exploring Random Trees (RRT) algorithm, and pieces together feasible trajectories from a library of motion primitives. Among other more conventional motion primitives, the library includes three extreme maneuvers: a cruise-to-hover transition, a hover-to-cruise transition, and an aggressive turn-around. The algorithm is efficient; it can be run in real-time to rapidly generate a plan starting from the aircraft's configuration at run-time. The motion planner is closely coupled to a feedback controller. Simulations using an aircraft dynamics model demonstrate the effectiveness of the system to guide and control the aircraft to a desired goal region. Preliminary flight test results are also presented.},
  keywords = {Aerodynamics,Aircraft,Atmospheric modeling,Heuristic algorithms,Libraries,Planning,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/CR85E7PY/Levin et al. - 2018 - Motion Planning for a Small Aerobatic Fixed-Wing Unmanned Aerial Vehicle.pdf;/Users/kshitijgoel/Zotero/storage/7M7YN8RG/8593670.html}
}

@misc{li_3dhgs_2024,
  title = {{{3D-HGS}}: {{3D Half-Gaussian Splatting}}},
  shorttitle = {{{3D-HGS}}},
  author = {Li, Haolin and Liu, Jinyang and Sznaier, Mario and Camps, Octavia},
  year = {2024},
  month = jun,
  number = {arXiv:2406.02720},
  eprint = {2406.02720},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.02720},
  urldate = {2024-07-23},
  abstract = {Photo-realistic 3D Reconstruction is a fundamental problem in 3D computer vision. This domain has seen considerable advancements owing to the advent of recent neural rendering techniques. These techniques predominantly aim to focus on learning volumetric representations of 3D scenes and refining these representations via loss functions derived from rendering. Among these, 3D Gaussian Splatting (3D-GS) has emerged as a significant method, surpassing Neural Radiance Fields (NeRFs). 3D-GS uses parameterized 3D Gaussians for modeling both spatial locations and color information, combined with a tile-based fast rendering technique. Despite its superior rendering performance and speed, the use of 3D Gaussian kernels has inherent limitations in accurately representing discontinuous functions, notably at edges and corners for shape discontinuities, and across varying textures for color discontinuities. To address this problem, we propose to employ 3D Half-Gaussian (3D-HGS) kernels, which can be used as a plug-and-play kernel. Our experiments demonstrate their capability to improve the performance of current 3D-GS related methods and achieve state-of-the-art rendering performance on various datasets without compromising rendering speed. The code and trained models are available at here.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/HVFWHLDX/Li et al. - 2024 - 3D-HGS 3D Half-Gaussian Splatting.pdf}
}

@article{li_activesplat_2025,
  title = {{{ActiveSplat}}: {{High-Fidelity Scene Reconstruction Through Active Gaussian Splatting}}},
  shorttitle = {{{ActiveSplat}}},
  author = {Li, Yuetao and Kuang, Zijia and Li, Ting and Hao, Qun and Yan, Zike and Zhou, Guyue and Zhang, Shaohui},
  year = {2025},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3580331},
  url = {https://ieeexplore.ieee.org/document/11037548/},
  urldate = {2025-06-20},
  abstract = {We propose ActiveSplat, an autonomous high-fidelity reconstruction system leveraging Gaussian splatting. Taking advantage of efficient and realistic rendering, the system establishes a unified framework for online mapping, viewpoint selection, and path planning. The key to ActiveSplat is a hybrid map representation that integrates both dense information about the environment and a sparse abstraction of the workspace. Therefore, the system leverages sparse topology for efficient viewpoint sampling and path planning, while exploiting view-dependent dense prediction for viewpoint selection, facilitating efficient decision-making with promising accuracy and completeness. A hierarchical planning strategy based on the topological map is adopted to mitigate repetitive trajectories and improve local granularity given limited time budgets, ensuring high-fidelity reconstruction with photorealistic view synthesis. Extensive experiments and ablation studies validate the efficacy of the proposed method in terms of reconstruction accuracy, data coverage, and exploration efficiency. The released code will be available on our project page},
  keywords = {Accuracy,Artificial intelligence,Autonomous Agents,Data mining,Image color analysis,Image reconstruction,Mapping,Optimization,Planning,Rendering (computer graphics),Robots,Three-dimensional displays,View Planning for SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/9E4LP4E7/Li et al. - 2025 - ActiveSplat High-Fidelity Scene Reconstruction Through Active Gaussian Splatting.pdf}
}

@article{li_continuous_2022,
  title = {Continuous and {{Precise Positioning}} in {{Urban Environments}} by {{Tightly Coupled Integration}} of {{GNSS}}, {{INS}} and {{Vision}}},
  author = {Li, Xingxing and Li, Shengyu and Zhou, Yuxuan and Shen, Zhiheng and Wang, Xuanbin and Li, Xin and Wen, Weisong},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {11458--11465},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3201694},
  abstract = {Accurate, continuous and seamless state estimation is the fundamental module for intelligent navigation applications, such as self-driving cars and autonomous robots. However, it is often difficult for a standalone sensor to fulfill the demanding requirements of precise navigation in complex scenarios. To fill this gap, this letter proposes to exploit the complementariness of the global navigation satellite system (GNSS), inertial measurement unit (IMU) and vision via a tightly coupled integration method, aiming to achieve continuous and accurate navigation in urban environments. Specifically, the raw GNSS carrier phase and pseudorange measurements, IMU data, and visual features are directly fused at the observation level through a centralized Extended Kalman Filter (EKF) to make full use of the multi-sensor information and reject potential outlier measurements. Furthermore, the widely used high-precision GNSS models including precise point positioning (PPP) and real-time kinematic (RTK) are unified in the proposed integrated system to increase usability and flexibility. We validate the performance of the proposed method on several challenging datasets collected in urban canyons and compare against the loosely coupled and state-of-the-art methods.},
  keywords = {Cameras,Global navigation satellite system,GNSS,INS,localization,Navigation,Phase measurement,Robot sensing systems,Satellites,sensor fusion,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/VJ6BFPQ5/Li et al. - 2022 - Continuous and Precise Positioning in Urban Enviro.pdf;/Users/kshitijgoel/Zotero/storage/ENZ8FA7S/9866851.html}
}

@inproceedings{li_estimation_2019,
  title = {Estimation and {{Tracking}} of a {{Moving Target}} by {{Unmanned Aerial Vehicles}}},
  booktitle = {2019 {{American Control Conference}} ({{ACC}})},
  author = {Li, Jun-Ming and Chen, Ching Wen and Cheng, Teng-Hu},
  year = {2019},
  month = jul,
  pages = {3944--3949},
  issn = {2378-5861},
  doi = {10.23919/ACC.2019.8815101},
  url = {https://ieeexplore.ieee.org/document/8815101/},
  urldate = {2025-06-01},
  abstract = {An image-based control strategy along with estimation of target motion is developed to track dynamic targets without motion constraints. To the best of our knowledge, this is the first work that utilizes a bounding box as image features for tracking control and estimation of dynamic target without motion constraint. The features generated from a You-Only-Look-Once (YOLO) deep neural network can relax the assumption of continuous availability of the feature points in most literature and minimize the gap for applications. The challenges are that the motion pattern of the target is unknown and modeling its dynamics is infeasible. To resolve these issues, the dynamics of the target is modeled by a constant-velocity model and is employed as a process model in the Unscented Kalman Filter (UKF), but process noise is uncertain and sensitive to system instability. To ensure convergence of the estimate error, the noise covariance matrix is estimated according to history data within a moving window. The estimated motion from the UKF is implemented as a feedforward term in the developed controller, so that tracking performance is enhanced. Simulations are demonstrated to verify the efficacy of the developed estimator and controller.},
  keywords = {Cameras,Covariance matrices,Dynamics,Estimation,Target tracking,Tracking of moving targets,UAV,Unscented Kalman Filter,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/YPTME3MQ/Li et al. - 2019 - Estimation and Tracking of a Moving Target by Unmanned Aerial Vehicles.pdf}
}

@article{li_gmmap_2024,
  title = {{{GMMap}}: {{Memory-Efficient Continuous Occupancy Map Using Gaussian Mixture Model}}},
  shorttitle = {{{GMMap}}},
  author = {Li, Peter Zhi Xuan and Karaman, Sertac and Sze, Vivienne},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {1339--1355},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3348305},
  url = {https://ieeexplore.ieee.org/document/10379145/},
  urldate = {2024-03-09},
  abstract = {Energy consumption of memory accesses dominates the compute energy in energy-constrained robots, which require a compact 3-D map of the environment to achieve autonomy. Recent mapping frameworks only focused on reducing the map size while incurring significant memory usage during map construction due to the multipass processing of each depth image. In this work, we present a memory-efficient continuous occupancy map, named GMMap, that accurately models the 3-D environment using a Gaussian mixture model (GMM). Memory-efficient GMMap construction is enabled by the single-pass compression of depth images into local GMMs, which are directly fused together into a globallyconsistent map. By extending Gaussian Mixture Regression (GMR) to model unexplored regions, occupancy probability is directly computed from Gaussians. Using a low-power ARM Cortex A57 CPU, GMMap can be constructed in real time at up to 60 images/s. Compared with prior works, GMMap maintains high accuracy while reducing the map size by at least 56\%, memory overhead by at least 88\%, dynamic random-access memory (DRAM) access by at least 78\%, and energy consumption by at least 69\%. Thus, GMMap enables real-time 3-D mapping on energy-constrained robots.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GHFVG3XV/getPDF.pdf}
}

@misc{li_ikap_2024,
  title = {{{iKap}}: {{Kinematics-aware Planning}} with {{Imperative Learning}}},
  shorttitle = {{{iKap}}},
  author = {Li, Qihang and Chen, Zhuoqun and Zheng, Haoze and He, Haonan and Su, Shaoshu and Geng, Junyi and Wang, Chen},
  year = {2024},
  month = dec,
  number = {arXiv:2412.09496},
  eprint = {2412.09496},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.09496},
  url = {http://arxiv.org/abs/2412.09496},
  urldate = {2024-12-13},
  abstract = {Trajectory planning in robotics aims to generate collision-free pose sequences that can be reliably executed. Recently, vision-to-planning systems have garnered increasing attention for their efficiency and ability to interpret and adapt to surrounding environments. However, traditional modular systems suffer from increased latency and error propagation, while purely data-driven approaches often overlook the robot's kinematic constraints. This oversight leads to discrepancies between planned trajectories and those that are executable. To address these challenges, we propose iKap, a novel vision-to-planning system that integrates the robot's kinematic model directly into the learning pipeline. iKap employs a self-supervised learning approach and incorporates the state transition model within a differentiable bi-level optimization framework. This integration ensures the network learns collision-free waypoints while satisfying kinematic constraints, enabling gradient back-propagation for end-to-end training. Our experimental results demonstrate that iKap achieves higher success rates and reduced latency compared to the state-of-the-art methods. Besides the complete system, iKap offers a visual-to-planning network that seamlessly integrates kinematics into various controllers, providing a robust solution for robots navigating complex and dynamic environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/3TJTCR2S/Li et al. - 2024 - iKap Kinematics-aware Planning with Imperative Learning.pdf;/Users/kshitijgoel/Zotero/storage/JJX2YMVT/2412.html}
}

@article{li_improved_2017,
  title = {An {{Improved RANSAC}} for {{3D Point Cloud Plane Segmentation Based}} on {{Normal Distribution Transformation Cells}}},
  author = {Li, Lin and Yang, Fan and Zhu, Haihong and Li, Dalin and Li, You and Tang, Lei},
  year = {2017},
  month = may,
  journal = {Remote Sensing},
  volume = {9},
  number = {5},
  pages = {433},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs9050433},
  url = {https://www.mdpi.com/2072-4292/9/5/433},
  urldate = {2024-11-01},
  abstract = {Plane segmentation is a basic task in the automatic reconstruction of indoor and urban environments from unorganized point clouds acquired by laser scanners. As one of the most common plane-segmentation methods, standard Random Sample Consensus (RANSAC) is often used to continually detect planes one after another. However, it suffers from the spurious-plane problem when noise and outliers exist due to the uncertainty of randomly sampling the minimum subset with 3 points. An improved RANSAC method based on Normal Distribution Transformation (NDT) cells is proposed in this study to avoid spurious planes for 3D point-cloud plane segmentation. A planar NDT cell is selected as a minimal sample in each iteration to ensure the correctness of sampling on the same plane surface. The 3D NDT represents the point cloud with a set of NDT cells and models the observed points with a normal distribution within each cell. The geometric appearances of NDT cells are used to classify the NDT cells into planar and non-planar cells. The proposed method is verified on three indoor scenes. The experimental results show that the correctness exceeds 88.5\% and the completeness exceeds 85.0\%, which indicates that the proposed method identifies more reliable and accurate planes than standard RANSAC. It also executes faster. These results validate the suitability of the method.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {NDT features,normal distribution transformation,plane segmentation,point cloud,RANSAC},
  file = {/Users/kshitijgoel/Zotero/storage/Q8K3L3IN/Li et al. - 2017 - An Improved RANSAC for 3D Point Cloud Plane Segmentation Based on Normal Distribution Transformation.pdf}
}

@article{li_integration_2008,
  title = {Integration of Prior Knowledge of Measurement Noise in Kernel Density Classification},
  author = {Li, Yunlei and {de Ridder}, Dick and Duin, Robert P. W. and Reinders, Marcel J. T.},
  year = {2008},
  month = jan,
  journal = {Pattern Recognition},
  volume = {41},
  number = {1},
  pages = {320--330},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2007.05.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320307002154},
  urldate = {2024-03-14},
  abstract = {Samples can be measured with different precisions and reliabilities in different experiments, or even within the same experiment. These varying levels of measurement noise may deteriorate the performance of a pattern recognition system, if not treated with care. Here we seek to investigate the benefit of incorporating prior knowledge about measurement noise into system construction. We propose a kernel density classifier which integrates such prior knowledge. Instead of using an identical kernel for each sample, we transform the prior knowledge into a distinct kernel for each sample. The integration procedure is straightforward and easy to interpret. In addition, we show how to estimate the diverse measurement noise levels in a real world dataset. Compared to the basic methods, the new kernel density classifier can give a significantly better classification performance. As expected, this improvement is more obvious for small sample size datasets and large number of features.},
  keywords = {Kernel method,Measurement noise,mRNA co-expression coefficient,Parzen,Prior knowledge,Protein complex},
  file = {/Users/kshitijgoel/Zotero/storage/ZG88SLLL/Li et al. - 2008 - Integration of prior knowledge of measurement nois.pdf;/Users/kshitijgoel/Zotero/storage/QVCUDREP/S0031320307002154.html}
}

@inproceedings{li_memoryefficient_2022,
  title = {Memory-{{Efficient Gaussian Fitting}} for {{Depth Images}} in {{Real Time}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Li, Peter Zhi Xuan and Karaman, Sertac and Sze, Vivienne},
  year = {2022},
  month = may,
  pages = {8003--8009},
  doi = {10.1109/ICRA46639.2022.9811682},
  url = {https://ieeexplore.ieee.org/document/9811682},
  urldate = {2024-01-27},
  abstract = {Computing consumes a significant portion of energy in many robotics applications, especially the ones involving energy-constrained robots. In addition, memory access accounts for a significant portion of the computing energy. For mapping a 3D environment, prior approaches reduce the map size while incurring a large memory overhead used for storing sensor measurements and temporary variables during computation. In this work, we present a memory-efficient algorithm, named Single-Pass Gaussian Fitting (SPGF), that accurately constructs a compact Gaussian Mixture Model (GMM) which approximates measurements from a depthmap generated from a depth camera. By incrementally constructing the GMM one pixel at a time in a single pass through the depthmap, SPGF achieves higher throughput and orders-of-magnitude lower memory overhead than prior multipass approaches. By processing the depthmap row-by-row, SPGF exploits intrinsic properties of the camera to efficiently and accurately infer surface geometries, which leads to higher precision than prior approaches while maintaining the same compactness of the GMM. Using a low-power ARM Cortex-A57 CPU on the NVIDIA Jetson TX2 platform, SPGF operates at 32fps, requires 43KB of memory overhead, and consumes only 0.11J per frame (depthmap). Thus, SPGF enables real-time mapping of large 3D environments on energy-constrained robots.},
  keywords = {Cameras,Fitting,Memory management,Program processors,Robot sensing systems,Three-dimensional displays,Throughput},
  file = {/Users/kshitijgoel/Zotero/storage/FWML2FLJ/Li et al. - 2022 - Memory-Efficient Gaussian Fitting for Depth Images.pdf;/Users/kshitijgoel/Zotero/storage/D95DIP5L/9811682.html}
}

@inproceedings{li_novel_2013,
  title = {A {{Novel Earth Mover}}'s {{Distance Methodology}} for {{Image Matching}} with {{Gaussian Mixture Models}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Li, Peihua and Wang, Qilong and Zhang, Lei},
  year = {2013},
  month = dec,
  pages = {1689--1696},
  publisher = {IEEE},
  address = {Sydney, Australia},
  doi = {10.1109/ICCV.2013.212},
  url = {http://ieeexplore.ieee.org/document/6751320/},
  urldate = {2023-09-20},
  abstract = {The similarity or distance measure between Gaussian mixture models (GMMs) plays a crucial role in contentbased image matching. Though the Earth Mover's Distance (EMD) has shown its advantages in matching histogram features, its potentials in matching GMMs remain unclear and are not fully explored. To address this problem, we propose a novel EMD methodology for GMM matching. We srst present a sparse representation based EMD called SR-EMD by exploiting the sparse property of the underlying problem. SR-EMD is more efscient and robust than the conventional EMD. Second, we present two novel ground distances between component Gaussians based on the information geometry. The perspective from the Riemannian geometry distinguishes the proposed ground distances from the classical entropy- or divergence-based ones. Furthermore, motivated by the success of distance metric learning of vector data, we make the srst attempt to learn the EMD distance metrics between GMMs by using a simple yet effective supervised pair-wise based method. It can adapt the distance metrics between GMMs to specisc classiscation tasks. The proposed method is evaluated on both simulated data and benchmark real databases and achieves very promising performance.},
  isbn = {978-1-4799-2840-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/NILQGZ63/Li et al. - 2013 - A Novel Earth Mover's Distance Methodology for Ima.pdf}
}

@article{li_subspace_2019,
  title = {Subspace {{Clustering Under Complex Noise}}},
  author = {Li, Baohua and Lu, Huchuan and Zhang, Ying and Lin, Zhouchen and Wu, Wei},
  year = {2019},
  month = apr,
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {29},
  number = {4},
  pages = {930--940},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2018.2793359},
  url = {https://ieeexplore.ieee.org/document/8258994/?arnumber=8258994},
  urldate = {2024-07-17},
  abstract = {In this paper, we study the subspace clustering problem under complex noise. A wide class of reconstruction-based methods model the subspace clustering problem by combining a quadratic data-fidelity term and a regularization term. In a statistical framework, the data-fidelity term assumes to be contaminated by a unimodal Gaussian noise, which is a popular setting in most current subspace clustering models. However, the realistic noise is much more complex than our assumptions. Besides, the coarse representation of the data-fidelity term may depress the clustering accuracy, which is often used to evaluate the models. To address this issue, we propose the mixture of Gaussian regression (MoG Regression) for subspace clustering. The MoG Regression seeks a valid way to model the unknown noise distribution, which approaches the real one as far as possible, so that the desired affinity matrix is better at characterizing the structure of data in the real world, and furthermore, improving the performance. Theoretically, the proposed model enjoys the grouping effect, which encourages the coefficients of highly correlated points are nearly equal. Drawing upon the ideal of the minimum message length, a model selection strategy is proposed to estimate the numbers of the Gaussian components that shows a way how to seek the number of Gaussian components besides determining it by empirical value. In addition, the asymptotic property of our model is investigated. The proposed model is evaluated on the challenging datasets. The experimental results show that the proposed MoG Regression model significantly outperforms several state-of-the-art subspace clustering methods.},
  keywords = {Clustering algorithms,Clustering methods,Computer vision,expectation maximization,Gaussian processes,mixture of Gaussian regression,Pattern clustering,Regression analysis,Subspace clustering},
  file = {/Users/kshitijgoel/Zotero/storage/VAJ4D2YQ/Li et al. - 2019 - Subspace Clustering Under Complex Noise.pdf;/Users/kshitijgoel/Zotero/storage/A34FZ259/8258994.html}
}

@inproceedings{li_unified_2021,
  title = {Toward a {{Unified Framework}} for {{Point Set Registration}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Li, Feiran and Fujiwara, Kent and Matsushita, Yasuyuki},
  year = {2021},
  month = may,
  pages = {12981--12987},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561594},
  abstract = {Point set registration plays a critical role in robotics and computer vision. Early methods considered registration as a purely geometric problem, presenting excellent extensibility for various tasks due to their explicit handling of correspondences; statistical methods were later introduced to handle noise. However, the two categories of algorithms have evolved independently without sharing much in common. In this paper, we leverage the concept of information geometry to theoretically unify the two classes together by interpreting them as the same operation but in different spaces associated with respective metrics. Moreover, based on the proposed unification, we also develop a novel bandwidth estimation strategy to solve the long-standing problem of statistical registration algorithms, and demonstrate its theoretical and practical advantages over deterministic annealing, the most commonly used technique. We also present a case study to show how geometric and statistical approaches can benefit from each other.},
  keywords = {Annealing,Automation,Computer vision,Conferences,Estimation,Information geometry,Statistical analysis},
  file = {/Users/kshitijgoel/Zotero/storage/B85GBASH/Li et al. - 2021 - Toward a Unified Framework for Point Set Registrat.pdf;/Users/kshitijgoel/Zotero/storage/N542VLC7/stamp.html}
}

@misc{li_visfly_2024,
  title = {{{VisFly}}: {{An Efficient}} and {{Versatile Simulator}} for {{Training Vision-based Flight}}},
  shorttitle = {{{VisFly}}},
  author = {Li, Fanxing and Sun, Fangyu and Zhang, Tianbao and Zou, Danping},
  year = {2024},
  month = sep,
  number = {arXiv:2407.14783},
  eprint = {2407.14783},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.14783},
  url = {http://arxiv.org/abs/2407.14783},
  urldate = {2024-12-10},
  abstract = {We present VisFly, a quadrotor simulator designed to efficiently train vision-based flight policies using reinforcement learning algorithms. VisFly offers a user-friendly framework and interfaces, leveraging Habitat-Sim's rendering engines to achieve frame rates exceeding 10,000 frames per second for rendering motion and sensor data. The simulator incorporates differentiable physics and is seamlessly wrapped with the Gym environment, facilitating the straightforward implementation of various learning algorithms. It supports the directly importing open-source scene datasets compatible with Habitat-Sim, enabling training on diverse real-world environments simultaneously. To validate our simulator, we also make three reinforcement learning examples for typical flight tasks relying on visual observations. The simulator is now available at [https://github.com/SJTU-ViSYS-team/VisFly].},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/AYKWJI7U/Li et al. - 2024 - VisFly An Efficient and Versatile Simulator for Training Vision-based Flight.pdf;/Users/kshitijgoel/Zotero/storage/TWPFL5GR/2407.html}
}

@misc{liang_foundations_2024,
  title = {Foundations of {{Multisensory Artificial Intelligence}}},
  author = {Liang, Paul Pu},
  year = {2024},
  month = apr,
  number = {arXiv:2404.18976},
  eprint = {2404.18976},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2404.18976},
  urldate = {2024-05-28},
  abstract = {Building multisensory AI systems that learn from multiple sensory inputs such as text, speech, video, real-world sensors, wearable devices, and medical data holds great promise for impact in many scientific areas with practical benefits, such as in supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. By synthesizing a range of theoretical frameworks and application domains, this thesis aims to advance the machine learning foundations of multisensory AI. In the first part, we present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems, and their quantification enables users to understand their multimodal datasets, design principled approaches to learn these interactions, and analyze whether their model has succeeded in learning. In the second part, we study the design of practical multimodal foundation models that generalize over many modalities and tasks, which presents a step toward grounding large language models to real-world sensory modalities. We introduce MultiBench, a unified large-scale benchmark across a wide range of modalities, tasks, and research areas, followed by the cross-modal attention and multimodal transformer architectures that now underpin many of today's multimodal foundation models. Scaling these architectures on MultiBench enables the creation of general-purpose multisensory AI systems, and we discuss our collaborative efforts in applying these models for real-world impact in affective computing, mental health, cancer prognosis, and robotics. Finally, we conclude this thesis by discussing how future work can leverage these ideas toward more general, interactive, and safe multisensory AI.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Multimedia},
  file = {/Users/kshitijgoel/Zotero/storage/REV9TW25/Liang - 2024 - Foundations of Multisensory Artificial Intelligence.pdf}
}

@inproceedings{lim_fisher_2023,
  title = {Fisher {{Information Based Active Planning}} for {{Aerial Photogrammetry}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lim, Jaeyoung and Lawrance, Nicholas and Achermann, Florian and Stastny, Thomas and B{\"a}hnemann, Rik and Siegwart, Roland},
  year = {2023},
  month = may,
  pages = {1249--1255},
  doi = {10.1109/ICRA48891.2023.10161136},
  abstract = {Small uncrewed aerial systems (sUASs) are useful tools for 3D reconstruction due to their speed, ease of use, and ability to access high-utility viewpoints. Today, most aerial survey approaches generate a preplanned coverage pattern assuming a planar target region. However, this is inefficient since it results in superfluous overlap and suboptimal viewing angles and does not utilize the entire flight envelope. In this work, we propose active path planning for photogrammetric reconstruction. Our main contribution is a view utility function based on Fisher information approximating the offline reconstruction uncertainty. The metric enables online path planning to make in-flight decisions to collect geometrically informative image data in complex terrain. We evaluate our approach in a photorealistic simulation. A viewpoint selection study shows that our metric leads to faster and more precise reconstruction than state-of-the-art active planning metrics and adapts to different camera resolutions. Comparing our online planning approach to an ordinary fixed-wing aerial survey yields 3.2 {\texttimes} faster coverage of 16 ha undulated terrain without sacrificing precision.},
  keywords = {Cameras,Image resolution,Measurement,Robot vision systems,Surveys,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/IPEAPGHU/Lim et al. - 2023 - Fisher Information Based Active Planning for Aeria.pdf}
}

@inproceedings{lin_active_2022,
  title = {Active {{View Planning}} for {{Radiance Fields}}},
  booktitle = {Implicit {{Representations}} for {{Robotic Manipulation}}},
  author = {Lin, Kevin and Yi, Brent},
  year = {2022},
  month = jul,
  abstract = {We motivate, discuss, and present a study on the problem of view planning for radiance fields. While implicit representations like radiance fields have demonstrated significant promise as a 3D representation for downstream tasks in manipulation, mapping, and navigation, success relies heavily on the coverage of captured views, which are typically manually specified. Our contributions focus on intelligently selecting these views: building on a rich history of classical work in active vision, we (1) discuss the design of active-3d-gym, our high-level interface for benchmarking view planning for radiance fields, and (2) propose and experimentally evaluate a simple solution for the view planning problem based on radiance field ensembles.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YANQWJXA/Zeng et al. - 2020 - View planning in robot active vision A survey of .pdf}
}

@article{lin_distance_2002,
  title = {On the {{Distance}} between {{Two Ellipsoids}}},
  author = {Lin, Anhua and Han, Shih-Ping},
  year = {2002},
  month = jan,
  journal = {SIAM Journal on Optimization},
  volume = {13},
  number = {1},
  pages = {298--308},
  issn = {1052-6234, 1095-7189},
  doi = {10.1137/S1052623401396510},
  url = {http://epubs.siam.org/doi/10.1137/S1052623401396510},
  urldate = {2023-10-23},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XYGE9GRB/Lin and Han - 2002 - On the Distance between Two Ellipsoids.pdf}
}

@inproceedings{lin_evaluating_2021,
  title = {Evaluating {{Initialization Methods}} for {{Discriminative}} and {{Fast-Converging HGMM Point Clouds}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lin, Haohan and Chen, Xuzhan and Tucsok, Matthew and Ji, Li and Najjaran, Homayoun},
  year = {2021},
  month = may,
  pages = {13871--13876},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9560882},
  url = {https://ieeexplore.ieee.org/document/9560882},
  urldate = {2024-11-15},
  abstract = {Discriminative data representations for point cloud data are critical for computer vision applications. Recently, the Hierarchical Gaussian Mixture Model (HGMM) has become a popular representation due to its compactness and real-time execution. However, HGMM still lacks a well-designed and robust initialization criterion. Ad-hoc initializations for HGMM can lead to a low discriminative clustering capability, slow convergence, and loss of scale-invariance. To adopt the optimal initialization scheme, we evaluate four potential candidates: K-Means++, Fuzzy C-Means (FCM), uniform, and random initialization across a few synthetic and measured datasets. Our experiments involve comparing the quality of HGMM point cloud reconstruction based on different initialization methods. The reconstruction quality is evaluated by the peak signal-to-noise ratio (PSNR). Our experiments show that clustering-based initialization methods can result in higher-quality HGMMs because of i) faster convergence of the Expectation-Maximization (EM) optimization, ii) better scaleinvariance across differently sized datasets, and iii) greater stability for different initial scales of covariance matrices of the HGMM.},
  keywords = {Conferences,Covariance matrices,Fluctuations,PSNR,Real-time systems,Robustness,Stability criteria},
  file = {/Users/kshitijgoel/Zotero/storage/EWVSPM2Y/Lin et al. - 2021 - Evaluating Initialization Methods for Discriminative and Fast-Converging HGMM Point Clouds.pdf}
}

@phdthesis{lin_formalizing_2024,
  type = {Thesis},
  title = {Formalizing {{Object Equivalence}} in {{Machine Knitting}}},
  author = {Lin, Jenny},
  year = {2024},
  month = dec,
  doi = {10.1184/R1/28063193.v1},
  url = {https://kilthub.cmu.edu/articles/thesis/Formalizing_Object_Equivalence_in_Machine_Knitting/28063193/1},
  urldate = {2025-01-03},
  abstract = {Correctness is a desirable property for any program, whether that program computes an equation, controls a machine, or interprets data. Defining what it means for a program to be correct can be surprisingly nuanced, however, especially when that program is used to create a physical object. We can reframe this problem by treating correctness as a question of equivalence. Given some target object, is the result of a fabrication process equivalent to the target object? However, this now requires that we answer the still complicated question of what it means for two objects to be equivalent. In order to do so, we not only need a precise definition of object meaning, but also a strong understanding of how we create and interact with the objects around us. In this thesis, I tackle this problem of meaning and equivalence for machine knitting pro grams. Knitting is the act of taking a few strands of yarn and deforming them into interlocking loops that result in a stable structure. While knitting machines are capable of quickly fabricat ing a vast array of structures with controllable material properties, the complexity of both the machine control process and the resulting physical object makes translating between the two incredibly difficult. This gap prevents existing programing and design tools from accessing the full breadth of its fabrication possibilities. To address this, I formally characterize the complete space of machine knitting programmings. I begin by introducing fenced tangles, a novel mathematical object designed to match intuition about knit object meaning. From there, I use fenced tangles to define a semantics for knitout, which is a low-level language for controlling v-bed knitting machines. The underlying program meaning is then used to reason about the correctness of a set of practical program transformations. I then use this semantic function as guidance for developing Instruction Graphs, which are an intermediate representation of knit objects. Unlike existing knit object representations, Instruction Graphs can capture the full range of machine knittable objects and can be verified as machine knit table using three easy to check graph embedding properties. Finally, I discuss how fabrication constraints may enable an algebraic approach to computing machine knitting program equivalence.},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/IM3T39LC/Lin - 2024 - Formalizing Object Equivalence in Machine Knitting.pdf}
}

@article{lin_immesh_2023,
  title = {{{ImMesh}}: {{An Immediate LiDAR Localization}} and {{Meshing Framework}}},
  shorttitle = {{{ImMesh}}},
  author = {Lin, Jiarong and Yuan, Chongjian and Cai, Yixi and Li, Haotian and Ren, Yunfan and Zou, Yuying and Hong, Xiaoping and Zhang, Fu},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3321227},
  url = {https://ieeexplore.ieee.org/document/10304337},
  urldate = {2023-11-29},
  abstract = {In this article, we propose a novel light detection and ranging (LiDAR)(-inertial) odometry and mapping framework to achieve the goal of simultaneous localization and meshing in real time. This proposed framework termed immediately meshing (ImMesh) comprises four tightly-coupled modules: receiver, localization, meshing, and broadcaster. The localization module first utilizes the preprocessed sensor data from the receiver, estimates the sensor pose online by registering LiDAR scans to maps, and dynamically grows the map. Then, our meshing module takes the registered LiDAR scan for incrementally reconstructing the triangle mesh on the fly. Finally, the real-time odometry, map, and mesh are published via our broadcaster. The primary contribution of this work is the meshing module, which represents a scene by an efficient voxel structure, performs fast finding of voxels observed by new scans, and incrementally reconstructs triangle facets in each voxel. This voxel-wise meshing operation is delicately designed for the purpose of efficiency; it first performs a dimension reduction by projecting 3-D points to a 2-D local plane contained in the voxel, and then executes the meshing operation with pull, commit, and push steps for incremental reconstruction of triangle facets. To the best of authors' knowledge, this is the first work in the literature that can reconstruct online the triangle mesh of large-scale scenes, just relying on a standard CPU without GPU acceleration.},
  file = {/Users/kshitijgoel/Zotero/storage/CAGZT6ZV/Lin et al. - 2023 - ImMesh An Immediate LiDAR Localization and Meshin.pdf;/Users/kshitijgoel/Zotero/storage/X336Y487/10304337.html}
}

@misc{lin_lie_2024,
  title = {Lie {{Neurons}}: {{Adjoint-Equivariant Neural Networks}} for {{Semisimple Lie Algebras}}},
  shorttitle = {Lie {{Neurons}}},
  author = {Lin, Tzu-Yuan and Zhu, Minghan and Ghaffari, Maani},
  year = {2024},
  month = feb,
  number = {arXiv:2310.04521},
  eprint = {2310.04521},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2310.04521},
  urldate = {2024-06-01},
  abstract = {This paper proposes an equivariant neural network that takes data in any semi-simple Lie algebra as input. The corresponding group acts on the Lie algebra as adjoint operations, making our proposed network adjoint-equivariant. Our framework generalizes the Vector Neurons, a simple SO(3)-equivariant network, from 3-D Euclidean space to Lie algebra spaces, building upon the invariance property of the Killing form. Furthermore, we propose novel Lie bracket layers and geometric channel mixing layers that extend the modeling capacity. Experiments are conducted for the so(3) and sl(3) Lie algebras on various tasks, including fitting equivariant and invariant functions, learning system dynamics, point cloud registration, and homography-based shape classification. Our proposed equivariant network shows wide applicability and competitive performance in various domains.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/9KHQGNTG/Lin et al. - 2024 - Lie Neurons Adjoint-Equivariant Neural Networks for Semisimple Lie Algebras.pdf}
}

@inproceedings{lin_robust_2020,
  title = {Robust {{Vision-based Obstacle Avoidance}} for {{Micro Aerial Vehicles}} in {{Dynamic Environments}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lin, Jiahao and Zhu, Hai and {Alonso-Mora}, Javier},
  year = {2020},
  month = may,
  pages = {2682--2688},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9197481},
  url = {https://ieeexplore.ieee.org/document/9197481/},
  urldate = {2023-11-28},
  abstract = {In this paper, we present an on-board visionbased approach for avoidance of moving obstacles in dynamic environments. Our approach relies on an efficient obstacle detection and tracking algorithm based on depth image pairs, which provides the estimated position, velocity and size of the obstacles. Robust collision avoidance is achieved by formulating a chance-constrained model predictive controller (CC-MPC) to ensure that the collision probability between the micro aerial vehicle (MAV) and each moving obstacle is below a specified threshold. The method takes into account MAV dynamics, state estimation and obstacle sensing uncertainties. The proposed approach is implemented on a quadrotor equipped with a stereo camera and is tested in a variety of environments, showing effective on-line collision avoidance of moving obstacles.},
  isbn = {978-1-7281-7395-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZS4B2F4L/Lin et al. - 2020 - Robust Vision-based Obstacle Avoidance for Micro A.pdf}
}

@article{lin_surface_2022,
  title = {Surface {{Reconstruction}} from {{Point Clouds}} without {{Normals}} by {{Parametrizing}} the {{Gauss Formula}}},
  author = {Lin, Siyou and Xiao, Dong and Shi, Zuoqiang and Wang, Bin},
  year = {2022},
  month = oct,
  journal = {ACM Transactions on Graphics},
  volume = {42},
  number = {2},
  pages = {14:1--14:19},
  issn = {0730-0301},
  doi = {10.1145/3554730},
  url = {https://dl.acm.org/doi/10.1145/3554730},
  urldate = {2024-01-07},
  abstract = {We propose Parametric Gauss Reconstruction (PGR) for surface reconstruction from point clouds without normals. Our insight builds on the Gauss formula in potential theory, which represents the indicator function of a region as an integral over its boundary. By viewing surface normals and surface element areas as unknown parameters, the Gauss formula interprets the indicator as a member of some parametric function space. We can solve for the unknown parameters using the Gauss formula and simultaneously obtain the indicator function. Our method bypasses the need for accurate input normals as required by most existing non-data-driven methods, while also exhibiting superiority over data-driven methods, since no training is needed. Moreover, by modifying the Gauss formula and employing regularization, PGR also adapts to difficult cases such as noisy inputs, thin structures, sparse or nonuniform points, for which accurate normal estimation becomes quite difficult. Our code is publicly available at https://github.com/jsnln/ParametricGaussRecon.},
  keywords = {3D shape modeling,Gauss formula,mesh models,point-based models,Surface reconstruction},
  file = {/Users/kshitijgoel/Zotero/storage/EWPLL8RR/Lin et al. - 2022 - Surface Reconstruction from Point Clouds without N.pdf}
}

@article{lindley_measure_1956,
  title = {On a {{Measure}} of the {{Information Provided}} by an {{Experiment}}},
  author = {Lindley, D. V.},
  year = {1956},
  month = dec,
  journal = {The Annals of Mathematical Statistics},
  volume = {27},
  number = {4},
  pages = {986--1005},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177728069},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-4/On-a-Measure-of-the-Information-Provided-by-an-Experiment/10.1214/aoms/1177728069.full},
  urldate = {2024-04-26},
  abstract = {A measure is introduced of the information provided by an experiment. The measure is derived from the work of Shannon [10] and involves the knowledge prior to performing the experiment, expressed through a prior probability distribution over the parameter space. The measure is used to compare some pairs of experiments without reference to prior distributions; this method of comparison is contrasted with the methods discussed by Blackwell. Finally, the measure is applied to provide a solution to some problems of experimental design, where the object of experimentation is not to reach decisions but rather to gain knowledge about the world.},
  file = {/Users/kshitijgoel/Zotero/storage/J76SFSBJ/Lindley - 1956 - On a Measure of the Information Provided by an Exp.pdf}
}

@inproceedings{lionar_neuralblox_2021,
  title = {{{NeuralBlox}}: {{Real-Time Neural Representation Fusion}} for {{Robust Volumetric Mapping}}},
  shorttitle = {{{NeuralBlox}}},
  booktitle = {2021 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Lionar, Stefan and Schmid, Lukas and Cadena, Cesar and Siegwart, Roland and Cramariuc, Andrei},
  year = {2021},
  month = dec,
  pages = {1279--1289},
  issn = {2475-7888},
  doi = {10.1109/3DV53792.2021.00135},
  abstract = {We present a novel 3D mapping method leveraging the recent progress in neural implicit representation for 3D reconstruction. Most existing state-of-the-art neural implicit representation methods are limited to object-level reconstructions and can not incrementally perform updates given new data. In this work, we propose a fusion strategy and training pipeline to incrementally build and update neural implicit representations that enable the reconstruction of large scenes from sequential partial observations. By representing an arbitrarily sized scene as a grid of latent codes and performing updates directly in latent space, we show that incrementally built occupancy maps can be obtained in real-time even on a CPU. Compared to traditional approaches such as Truncated Signed Distance Fields (TSDFs), our map representation is significantly more robust in yielding a better scene completeness given noisy inputs. We demonstrate the performance of our approach in thorough experimental validation on real-world datasets with varying degrees of added pose noise.},
  keywords = {Codes,dense reconstruction,neural implicit representation,Pipelines,Real-time systems,robotic mapping,Sensor systems,Shape,Three-dimensional displays,Training},
  file = {/Users/kshitijgoel/Zotero/storage/MFBU4SUL/Lionar et al. - 2021 - NeuralBlox Real-Time Neural Representation Fusion.pdf}
}

@misc{lipman_flow_2023,
  title = {Flow {{Matching}} for {{Generative Modeling}}},
  author = {Lipman, Yaron and Chen, Ricky T. Q. and {Ben-Hamu}, Heli and Nickel, Maximilian and Le, Matt},
  year = {2023},
  month = feb,
  number = {arXiv:2210.02747},
  eprint = {2210.02747},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.02747},
  url = {http://arxiv.org/abs/2210.02747},
  urldate = {2025-05-24},
  abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/N6IDFR3T/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf}
}

@misc{lipman_flow_2024,
  title = {Flow {{Matching Guide}} and {{Code}}},
  author = {Lipman, Yaron and Havasi, Marton and Holderrieth, Peter and Shaul, Neta and Le, Matt and Karrer, Brian and Chen, Ricky T. Q. and {Lopez-Paz}, David and {Ben-Hamu}, Heli and Gat, Itai},
  year = {2024},
  month = dec,
  number = {arXiv:2412.06264},
  eprint = {2412.06264},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.06264},
  url = {http://arxiv.org/abs/2412.06264},
  urldate = {2024-12-11},
  abstract = {Flow Matching (FM) is a recent framework for generative modeling that has achieved state-of-the-art performance across various domains, including image, video, audio, speech, and biological structures. This guide offers a comprehensive and self-contained review of FM, covering its mathematical foundations, design choices, and extensions. By also providing a PyTorch package featuring relevant examples (e.g., image and text generation), this work aims to serve as a resource for both novice and experienced researchers interested in understanding, applying and further developing FM.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/SVIAFQVI/Lipman et al. - 2024 - Flow Matching Guide and Code.pdf;/Users/kshitijgoel/Zotero/storage/V5BTEA3V/2412.html}
}

@article{liu_active_2021,
  title = {Active and {{Interactive Mapping With Dynamic Gaussian Process Implicit Surfaces}} for {{Mobile Manipulators}}},
  author = {Liu, Liyang and Fryc, Simon and Wu, Lan and Vu, Thanh Long and Paul, Gavin and {Vidal-Calleja}, Teresa},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {3679--3686},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3061324},
  abstract = {In this letter, we present an interactive probabilistic mapping framework for a mobile manipulator picking objects from a pile. The aim is to map the scene, actively decide where to go next and which object to pick, make changes to the scene by picking the chosen object, and then map these changes alongside. The proposed framework uses a novel dynamic Gaussian Process (GP) Implicit Surface method to incrementally build and update the scene map that reflects environment changes. Actively the framework computes the next-best-view, balancing the terms of object reachability for picking and map information gain (IG) for fidelity and coverage. To enforce a priority of visiting boundary segments over unknown regions, the IG formulation includes an uncertainty gradient-based frontier score by exploiting the GP kernel derivative. This leads to an efficient strategy that addresses the often conflicting requirement of unknown environment exploration and object picking exploitation given a limited execution horizon. We demonstrate the effectiveness of our framework with software simulation and real-life experiments.},
  keywords = {Automatic building construction,exploration,gaussian process implicit surfaces,Manipulator dynamics,mapping,mobile manipulator,Probabilistic logic,Robots,Surface treatment,Three-dimensional displays,Training,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/6UICKRXN/Liu et al. - 2021 - Active and Interactive Mapping With Dynamic Gaussi.pdf;/Users/kshitijgoel/Zotero/storage/Q5E89LF7/9361306.html}
}

@inproceedings{liu_active_2023,
  title = {Active {{Metric-Semantic Mapping}} by {{Multiple Aerial Robots}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liu, Xu and Prabhu, Ankit and Cladera, Fernando and Miller, Ian D. and Zhou, Lifeng and Taylor, Camillo J. and Kumar, Vijay},
  year = {2023},
  month = may,
  pages = {3282--3288},
  doi = {10.1109/ICRA48891.2023.10161564},
  abstract = {Traditional approaches for active mapping focus on building geometric maps. For most real-world applications, however, actionable information is related to semantically meaningful objects in the environment. We propose an approach to the active metric-semantic mapping problem that enables multiple heterogeneous robots to collaboratively build a map of the environment. The robots actively explore to minimize the uncertainties in both semantic (object classification) and geometric (object modeling) information. We represent the environment using informative but sparse object models, each consisting of a basic shape and a semantic class label, and characterize uncertainties empirically using a large amount of real-world data. Given a prior map, we use this model to select actions for each robot to minimize uncertainties. The performance of our algorithm is demonstrated through multi-robot experiments in diverse real-world environments. The proposed framework is applicable to a wide range of real-world problems, such as precision agriculture, infrastructure inspection, and asset mapping in factories.},
  keywords = {Automation,Autonomous aerial vehicles,Buildings,Inspection,Semantics,Shape,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/5SLEDI7Z/Liu et al. - 2023 - Active Metric-Semantic Mapping by Multiple Aerial .pdf}
}

@inproceedings{liu_approximation_2023,
  title = {On the {{Approximation}} of the {{Quotient}} of {{Two Gaussian Densities}} for {{Multiple-Model Smoothing}}},
  booktitle = {2023 26th {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Liu, Yi and Li, Xi and Yang, Le and Mihaylova, Lyudmila and Xue, Yanbo},
  year = {2023},
  month = jun,
  pages = {1--8},
  doi = {10.23919/FUSION52260.2023.10224163},
  url = {https://ieeexplore.ieee.org/abstract/document/10224163},
  urldate = {2024-07-24},
  abstract = {The quotient of two multivariate Gaussian densities can be written as an unnormalized Gaussian density, which has been applied in some recently developed multiple-model fixed-interval smoothing algorithms. However, this expression is invalid if instead of being positive definite, the covariance of the unnormalized Gaussian density is indefinite (i.e., it has both positive and negative eigenvalues) or undefined (i.e., computing it requires inverting a singular matrix). This paper considers approximating the quotient of two Gaussian densities in this case using two different approaches to mitigate the caused numerical problems. The first approach directly replaces the indefinite covariance of the unnormalized Gaussian density with a positive definite matrix nearest to it. The second approach computes the approximation through solving, using the natural gradient, an optimization problem with a Kullback-Leibler divergence-based cost function. This paper illustrates the application of the theoretical results by incorporating them into an existing smoothing method for jump Markov systems and utilizing the obtained smoothers to track a maneuvering target.},
  keywords = {Approximation algorithms,Cost function,Eigenvalues and eigenfunctions,Markov processes,Minimization,Smoothing methods,Target tracking},
  file = {/Users/kshitijgoel/Zotero/storage/YKJ6RC2F/Liu et al. - 2023 - On the Approximation of the Quotient of Two Gaussian Densities for Multiple-Model Smoothing.pdf;/Users/kshitijgoel/Zotero/storage/8YE9XDR3/10224163.html}
}

@article{liu_contextaware_2019,
  title = {Context-{{Aware Three-Dimensional Mean-Shift With Occlusion Handling}} for {{Robust Object Tracking}} in {{RGB-D Videos}}},
  author = {Liu, Ye and Jing, Xiao-Yuan and Nie, Jianhui and Gao, Hao and Liu, Jun and Jiang, Guo-Ping},
  year = {2019},
  month = mar,
  journal = {IEEE Transactions on Multimedia},
  volume = {21},
  number = {3},
  pages = {664--677},
  issn = {1941-0077},
  doi = {10.1109/TMM.2018.2863604},
  abstract = {Depth cameras have recently become popular and many vision problems can be better solved with depth information. But, how to integrate depth information into a visual tracker to overcome the challenges such as occlusion and background distraction is still underinvestigated in current literature on visual tracking. In this paper, we investigate a 3-D extension of a classical mean-shift tracker whose greedy gradient ascend strategy is generally considered as unreliable in conventional 2-D tracking. However, through careful study of the physical property of 3-D point clouds, we reveal that objects which may appear to be adjacent on a 2-D image will form distinctive modes in the 3-D probability distribution approximated by kernel density estimation, and finding the nearest mode using 3-D mean-shift can always work in tracking. Based on the understanding of 3-D mean-shift, we propose two important mechanisms to further boost the tracker's robustness: one is to enable the tracker to be aware of potential distractions and make corresponding adjustments to the appearance model; and the other is to enable the tracker to detect and recover from tracking failures caused by total occlusion. The proposed method is both effective and computationally efficient. On a conventional personal computer, it runs at more than 60 FPS without graphical processing unit acceleration.},
  keywords = {Cameras,Histograms,Image color analysis,mean-shift,point cloud,RGB-D camera,Target tracking,Three-dimensional displays,Two dimensional displays,Visual tracking},
  file = {/Users/kshitijgoel/Zotero/storage/K7XCVVR3/Liu et al. - 2019 - Context-Aware Three-Dimensional Mean-Shift With Oc.pdf}
}

@article{liu_efficient_2022,
  title = {Efficient and Multifidelity Terrain Modeling for {{3D}} Large-Scale and Unstructured Environments},
  author = {Liu, Xu and Li, Decai and He, Yuqing and Gu, Feng},
  year = {2022},
  journal = {Journal of Field Robotics},
  volume = {39},
  number = {8},
  pages = {1286--1322},
  issn = {1556-4967},
  doi = {10.1002/rob.22108},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22108},
  urldate = {2024-02-10},
  abstract = {The vast amount of data captured by robots in large-scale unstructured environments brings computation and storage problems to terrain modeling methods. Considering the practical terrain geometry structures, we design a large-scale terrain modeling framework for efficiently generating the compact and accurate terrain models from incomplete and uncertain measurements. The multiresolution elevation filtering is developed to generate terrain surfaces that preserve terrain details in the bumpy areas while achieving a sparse representation over the flat areas, which simultaneously reduces the computation time, storage space, and inference error. To further reduce the high computational complexity, we propose a computation decomposition strategy by adopting the Gaussian mixture model to partition the whole terrain surface into several subsurfaces, enabling the method to scale to much larger environments. For each subsurface, we train a Gaussian process model using the local data to adapt to the local terrain structure, concurrently resolving the data incompleteness and uncertainty. Furthermore, to provide a more informative terrain model, we efficiently derive terrain gradient through a closed-form solution by treating the generated terrain models as continuous functions, enabling more robotics applications, such as the path planning. We perform extensive experiments to evaluate our framework, including the use of two medium-sized terrain data sets to evaluate the overall and local performance, and two large-scale glacier terrain and mountain terrain in the area of up to 9 km2 to validate the practical applications.},
  copyright = {{\copyright} 2022 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {mobile robots,terrain inference,terrain modeling,unstructured environment},
  file = {/Users/kshitijgoel/Zotero/storage/FZYVNKN8/Liu et al. - 2022 - Efficient and multifidelity terrain modeling for 3.pdf}
}

@article{liu_expressive_2024,
  title = {{{AN EXPRESSIVE REPRESENTATION OF GENERAL 3D SHAPES}}},
  author = {Liu, Zhen and Feng, Yao and Xiu, Yuliang and Liu, Weiyang and Paull, Liam and Black, Michael J and Sch{\"o}lkopf, Bernhard},
  year = {2024},
  abstract = {The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects. For this, meshes are appealing since they 1) enable fast physics-based rendering with realistic material and lighting, 2) support physical simulation, and 3) are memory-efficient for modern graphics pipelines. Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible. To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces. Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling. Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parameterize open surfaces by defining a manifold signed distance field on watertight templates. With this parameterization, we further develop a grid-based and differentiable representation that parameterizes both watertight and non-watertight meshes of arbitrary topology. Our new representation, called Ghost-on-the-Shell (G-SHELL), enables two important applications: differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes. We empirically demonstrate that G-SHELL achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9VPZQWKT/Liu et al. - 2024 - AN EXPRESSIVE REPRESENTATION OF GENERAL 3D SHAPES.pdf}
}

@article{liu_gaussian_2010,
  title = {Gaussian {{Mixture Model}} with {{Local Consistency}}},
  author = {Liu, Jialu and Cai, Deng and He, Xiaofei},
  year = {2010},
  month = jul,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {24},
  number = {1},
  pages = {512--517},
  issn = {2374-3468},
  doi = {10.1609/aaai.v24i1.7659},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/7659},
  urldate = {2023-03-17},
  abstract = {Gaussian Mixture Model (GMM) is one of the most popular data clustering methods which can be viewed as a linear combination of different Gaussian components. In GMM, each cluster obeys Gaussian distribution and the task of clustering is to group observations into different components through estimating each cluster's own parameters. The Expectation-Maximization algorithm is always involved in such estimation problem. However, many previous studies have shown naturally occurring data may reside on or close to an underlying submanifold. In this paper, we consider the case where the probability distribution is supported on a submanifold of the ambient space. We take into account the smoothness of the conditional probability distribution along the geodesics of data manifold. That is, if two observations are close in intrinsic geometry, their distributions over different Gaussian components are similar. Simply speaking, we introduce a novel method based on manifold structure for data clustering, called Locally Consistent Gaussian Mixture Model (LCGMM). Specifically, we construct a nearest neighbor graph and adopt Kullback-Leibler Divergence as the distance measurement to regularize the objective function of GMM. Experiments on several data sets demonstrate the effectiveness of such regularization.},
  copyright = {Copyright (c) 2021 Proceedings of the AAAI Conference on Artificial Intelligence},
  langid = {english},
  keywords = {Manifold},
  file = {/Users/kshitijgoel/Zotero/storage/3CV39BQ8/Liu et al. - 2010 - Gaussian Mixture Model with Local Consistency.pdf}
}

@inproceedings{liu_high_2016,
  title = {High Speed Navigation for Quadrotors with Limited Onboard Sensing},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Liu, Sikang and Watterson, Michael and Tang, Sarah and Kumar, Vijay},
  year = {2016},
  month = may,
  pages = {1484--1491},
  doi = {10.1109/ICRA.2016.7487284},
  abstract = {We address the problem of high speed autonomous navigation of quadrotor micro aerial vehicles with limited onboard sensing and computation. In particular, we propose a dual range planning horizon method to safely and quickly navigate quadrotors to specified goal locations in previously unknown and unstructured environments. In each planning epoch, a short-range planner uses a local map to generate a new trajectory. At the same time, a safe stopping policy is found. This allows the robot to come to an emergency halt when necessary. Our algorithm guarantees collision avoidance and demonstrates important advances in real-time planning. First, our novel short range planning method allows us to generate and re-plan trajectories that are dynamically feasible, comply with state and input constraints, and avoid obstacles in real-time. Further, previous planning algorithms abstract away the obstacle detection problem by assuming the instantaneous availability of geometric information about the environment. In contrast, our method addresses the challenge of using the raw sensor data to form a map and navigate in real-time. Finally, in addition to simulation examples, we provide physical experiments that demonstrate the entire algorithmic pipeline from obstacle detection to trajectory execution.},
  keywords = {Collision avoidance,Navigation,Planning,Real-time systems,Robot sensing systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/6HTQNI49/Liu et al. - 2016 - High speed navigation for quadrotors with limited .pdf;/Users/kshitijgoel/Zotero/storage/6K5WB74N/7487284.html}
}

@inproceedings{liu_marchingprimitives_2023,
  title = {Marching-{{Primitives}}: {{Shape Abstraction}} from {{Signed Distance Function}}},
  shorttitle = {Marching-{{Primitives}}},
  booktitle = {2023 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Liu, Weixiao and Wu, Yuwei and Ruan, Sipu and Chirikjian, Gregory S.},
  year = {2023},
  month = jun,
  pages = {8771--8780},
  publisher = {IEEE},
  address = {Vancouver, BC, Canada},
  doi = {10.1109/CVPR52729.2023.00847},
  url = {https://ieeexplore.ieee.org/document/10204128/},
  urldate = {2023-10-23},
  abstract = {Representing complex objects with basic geometric primitives has long been a topic in computer vision. Primitive-based representations have the merits of compactness and computational efficiency in higher-level tasks such as physics simulation, collision checking, and robotic manipulation. Unlike previous works which extract polygonal meshes from a signed distance function (SDF), in this paper, we present a novel method, named MarchingPrimitives, to obtain a primitive-based abstraction directly from an SDF. Our method grows geometric primitives (such as superquadrics) iteratively by analyzing the connectivity of voxels while marching at different levels of signed distance. For each valid connected volume of interest, we march on the scope of voxels from which a primitive is able to be extracted in a probabilistic sense and simultaneously solve for the parameters of the primitive to capture the underlying local geometry. We evaluate the performance of our method on both synthetic and real-world datasets. The results show that the proposed method outperforms the state-of-the-art in terms of accuracy, and is directly generalizable among different categories and scales. The code is open-sourced at https://github.com/ ChirikjianLab/Marching-Primitives.git.},
  isbn = {979-8-3503-0129-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G2A9KQGD/Liu et al. - 2023 - Marching-Primitives Shape Abstraction from Signed.pdf}
}

@article{liu_perceptual_2022,
  title = {Perceptual {{Quality Assessment}} of {{Colored 3D Point Clouds}}},
  author = {Liu, Qi and Su, Honglei and Duanmu, Zhengfang and Liu, Wentao and Wang, Zhou},
  year = {2022},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  pages = {1--1},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2022.3167151},
  abstract = {3D point clouds have found a wide variety of applications in multimedia processing, remote sensing, and scientific computing. Although most point cloud processing systems are developed to improve viewer experiences, little work has been dedicated to perceptual quality assessment of 3D point clouds. In this work, we build a new 3D point cloud database, namely the Waterloo Point Cloud (WPC) database. In contrast to existing datasets consisting of small-scale and low-quality source content of constrained viewing angles, the WPC database contains 20 high quality, realistic, and omni-directional source point clouds and 740 diversely distorted point clouds. We carry out a subjective quality assessment experiment over the database in a controlled lab environment. Our statistical analysis suggests that existing objective point cloud quality assessment (PCQA) models only achieve limited success in predicting subjective quality ratings. We propose a novel objective PCQA model based on an attention mechanism and a variant of information content-weighted structural similarity, which significantly outperforms existing PCQA models. The database has been made publicly available at https://github.com/qdushl/Waterloo-Point-Cloud-Database.},
  keywords = {attention model,Color,Colored noise,Databases,Monitoring,objective quality assessment,Point cloud,Point cloud compression,Quality assessment,subjective quality assessment,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/3DWUYZS3/Liu et al. - 2022 - Perceptual Quality Assessment of Colored 3D Point .pdf;/Users/kshitijgoel/Zotero/storage/Q6Y2SY5V/stamp.html}
}

@inproceedings{liu_robust_2022,
  title = {Robust and {{Accurate Superquadric Recovery}}: A {{Probabilistic Approach}}},
  shorttitle = {Robust and {{Accurate Superquadric Recovery}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Liu, Weixiao and Wu, Yuwei and Ruan, Sipu and Chirikjian, Gregory S.},
  year = {2022},
  month = jun,
  pages = {2666--2675},
  publisher = {IEEE},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.00270},
  url = {https://ieeexplore.ieee.org/document/9878948/},
  urldate = {2023-10-23},
  abstract = {Interpreting objects with basic geometric primitives has long been studied in computer vision. Among geometric primitives, superquadrics are well known for their ability to represent a wide range of shapes with few parameters. However, as the first and foremost step, recovering superquadrics accurately and robustly from 3D data still remains challenging. The existing methods are subject to local optima and sensitive to noise and outliers in real-world scenarios, resulting in frequent failure in capturing geometric shapes. In this paper, we propose the first probabilistic method to recover superquadrics from point clouds. Our method builds a Gaussian-uniform mixture model (GUM) on the parametric surface of a superquadric, which explicitly models the generation of outliers and noise. The superquadric recovery is formulated as a Maximum Likelihood Estimation (MLE) problem. We propose an algorithm, Expectation, Maximization, and Switching (EMS), to solve this problem, where: (1) outliers are predicted from the posterior perspective; (2) the superquadric parameter is optimized by the trust-region reflective algorithm; and (3) local optima are avoided by globally searching and switching among parameters encoding similar superquadrics. We show that our method can be extended to the multisuperquadrics recovery for complex objects. The proposed method outperforms the state-of-the-art in terms of accuracy, efficiency, and robustness on both synthetic and realworld datasets. The code is at http://github.com/ bmlklwx/EMS-superquadric\_fitting.git.},
  isbn = {978-1-6654-6946-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/S93C3SH7/Liu et al. - 2022 - Robust and Accurate Superquadric Recovery a Proba.pdf}
}

@inproceedings{liu_searchbased_2017,
  title = {Search-Based Motion Planning for Quadrotors Using Linear Quadratic Minimum Time Control},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Liu, Sikang and Atanasov, Nikolay and Mohta, Kartik and Kumar, Vijay},
  year = {2017},
  month = sep,
  pages = {2872--2879},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8206119},
  url = {https://ieeexplore.ieee.org/abstract/document/8206119?signout=success},
  urldate = {2023-11-28},
  abstract = {In this work, we propose a search-based planning method to compute dynamically feasible trajectories for a quadrotor flying in an obstacle-cluttered environment. Our approach searches for smooth, minimum-time trajectories by exploring the map using a set of short-duration motion primitives. The primitives are generated by solving an optimal control problem and induce a finite lattice discretization on the state space which can be explored using a graph-search algorithm. The proposed approach is able to generate resolution-complete (i.e., optimal in the discretized space), safe, dynamically feasibility trajectories efficiently by exploiting the explicit solution of a Linear Quadratic Minimum Time problem. It does not assume a hovering initial condition and, hence, is suitable for fast online re-planning while the robot is moving. Quadrotor navigation with online re-planning is demonstrated using the proposed approach in simulation and physical experiments and comparisons with trajectory generation based on state-of-art quadratic programming are presented.},
  file = {/Users/kshitijgoel/Zotero/storage/WF9MEQRE/Liu et al. - 2017 - Search-based motion planning for quadrotors using .pdf;/Users/kshitijgoel/Zotero/storage/3EZ2I4F6/8206119.html}
}

@article{liu_searchbased_2018,
  title = {Search-{{Based Motion Planning}} for {{Aggressive Flight}} in {{SE}}(3)},
  author = {Liu, Sikang and Mohta, Kartik and Atanasov, Nikolay and Kumar, Vijay},
  year = {2018},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {3},
  pages = {2439--2446},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2018.2795654},
  url = {http://ieeexplore.ieee.org/document/8264768/},
  urldate = {2023-10-13},
  abstract = {Quadrotors with large thrust-to-weight ratios are able to track aggressive trajectories with sharp turns and high accelerations. In this letter, we develop a search-based trajectory planning algorithm that exploits the quadrotor maneuverability to generate sequences of motion primitives in cluttered environments. We model the quadrotor body as an ellipsoid and compute its flight attitude along trajectories in order to check for collisions against obstacles. The ellipsoid model allows the quadrotor to pass through gaps that are smaller than its diameter with nonzero pitch or roll angles. Without any prior information about the location of gaps and associated attitude constraints, our algorithm is able to find a safe and optimal trajectory that guides the robot to its goal as fast as possible. To accelerate planning, we first perform a lower dimensional search and use it as a heuristic to guide the generation of a final dynamically feasible trajectory. We analyze critical discretization parameters of motion primitive planning and demonstrate the feasibility of the generated trajectories in various simulations and real-world experiments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/993QZKML/Liu et al. - 2018 - Search-Based Motion Planning for Aggressive Flight.pdf}
}

@misc{liu_slideslam_2024,
  title = {{{SlideSLAM}}: {{Sparse}}, {{Lightweight}}, {{Decentralized Metric-Semantic SLAM}} for {{Multi-Robot Navigation}}},
  shorttitle = {{{SlideSLAM}}},
  author = {Liu, Xu and Lei, Jiuzhou and Prabhu, Ankit and Tao, Yuezhan and Spasojevic, Igor and Chaudhari, Pratik and Atanasov, Nikolay and Kumar, Vijay},
  year = {2024},
  month = jun,
  number = {arXiv:2406.17249},
  eprint = {2406.17249},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.17249},
  urldate = {2024-06-26},
  abstract = {This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) approach that leverages a sparse and lightweight object-based representation to enable a heterogeneous robot team to autonomously explore 3D environments featuring indoor, urban, and forested areas without relying on GPS. We use a hierarchical metric-semantic representation of the environment, including high-level sparse semantic maps of object models and low-level voxel maps. We leverage the informativeness and viewpoint invariance of the high-level semantic map to obtain an effective semantics-driven place-recognition algorithm for interrobot loop closure detection across aerial and ground robots with different sensing modalities. A communication module is designed to track each robot's observations and those of other robots within the communication range. Such observations are then used to construct a merged map. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate and deploy our proposed framework on three types of aerial and ground robots. Extensive experimental results show an average localization error of 0.22 meters in position and -0.16 degrees in orientation, an object mapping F1 score of 0.92, and a communication packet size of merely 2-3 megabytes per kilometer trajectory with 1,000 landmarks. The project website can be found at https://xurobotics.github.io/slideslam/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/N5GNJYIW/Liu et al. - 2024 - SlideSLAM Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation.pdf}
}

@article{liu_surface_2023,
  title = {Surface {{Simplification}} Using {{Intrinsic Error Metrics}}},
  author = {Liu, Hsueh-Ti Derek and Gillespie, Mark and Chislett, Benjamin and Sharp, Nicholas and Jacobson, Alec and Crane, Keenan},
  year = {2023},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {42},
  number = {4},
  pages = {118:1--118:17},
  issn = {0730-0301},
  doi = {10.1145/3592403},
  url = {https://dl.acm.org/doi/10.1145/3592403},
  urldate = {2024-02-15},
  abstract = {This paper describes a method for fast simplification of surface meshes. Whereas past methods focus on visual appearance, our goal is to solve equations on the surface. Hence, rather than approximate the extrinsic geometry, we construct a coarse intrinsic triangulation of the input domain. In the spirit of the quadric error metric (QEM), we perform greedy decimation while agglomerating global information about approximation error. In lieu of extrinsic quadrics, however, we store intrinsic tangent vectors that track how far curvature "drifts" during simplification. This process also yields a bijective map between the fine and coarse mesh, and prolongation operators for both scalar- and vector-valued data. Moreover, we obtain hard guarantees on element quality via intrinsic retriangulation---a feature unique to the intrinsic setting. The overall payoff is a "black box" approach to geometry processing, which decouples mesh resolution from the size of matrices used to solve equations. We show how our method benefits several fundamental tasks, including geometric multigrid, all-pairs geodesic distance, mean curvature flow, geodesic Voronoi diagrams, and the discrete exponential map.},
  keywords = {geometry processing,mesh simplification},
  file = {/Users/kshitijgoel/Zotero/storage/TVVI5QSJ/Liu et al. - 2023 - Surface Simplification using Intrinsic Error Metri.pdf}
}

@article{liu_theory_1996,
  title = {A Theory of {{Gaussian}} Belief Functions},
  author = {Liu, Liping},
  year = {1996},
  month = feb,
  journal = {International Journal of Approximate Reasoning},
  volume = {14},
  number = {2},
  pages = {95--126},
  issn = {0888-613X},
  doi = {10.1016/0888-613X(96)00115-6},
  url = {https://www.sciencedirect.com/science/article/pii/0888613X96001156},
  urldate = {2024-06-04},
  abstract = {A Gaussian belief function can be intuitively described as a Gaussian distribution over a hyperplane, whose parallel subhyperplanes are the focal elements. This paper elaborates on the idea of Dempster and Shafer and formally represents a Gaussian belief function as a wide-sense inner product and a linear functional over a variable space, and as their duals over a hyperplane in a sample space. By adapting Dempster's rule to the continuous case, it derives a rule of combination and proves its equivalence to its geometric description by Dempster. It illustrates by examples how mixed knowledge involving linear equations, multivariate Gaussian distributions, and partial ignorance can be represented and combined as Gaussian belief functions.},
  keywords = {belief networks,Dempster-Shafer theory,expert systems,knowledge representation,multivariate Gaussian distributions},
  file = {/Users/kshitijgoel/Zotero/storage/QBBLTGLC/Liu - 1996 - A theory of Gaussian belief functions.pdf;/Users/kshitijgoel/Zotero/storage/8LETY7DG/0888613X96001156.html}
}

@inproceedings{liu_tight_2023,
  title = {Tight {{Collision Probability}} for {{UAV Motion Planning}} in {{Uncertain Environment}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Liu, Tianyu and Zhang, Fu and Gao, Fei and Pan, Jia},
  year = {2023},
  month = oct,
  pages = {1055--1062},
  publisher = {IEEE},
  address = {Detroit, MI, USA},
  doi = {10.1109/IROS55552.2023.10342141},
  url = {https://ieeexplore.ieee.org/document/10342141/},
  urldate = {2024-01-19},
  abstract = {Operating unmanned aerial vehicles (UAVs) in complex environments that feature dynamic obstacles and external disturbances poses significant challenges, primarily due to the inherent uncertainty in such scenarios. Additionally, inaccurate robot localization and modeling errors further exacerbate these challenges. Recent research on UAV motion planning in static environments has been unable to cope with the rapidly changing surroundings, resulting in trajectories that may not be feasible. Moreover, previous approaches that have addressed dynamic obstacles or external disturbances in isolation are insufficient to handle the complexities of such environments. This paper proposes a reliable motion planning framework for UAVs, integrating various uncertainties into a chance constraint that characterizes the uncertainty in a probabilistic manner. The chance constraint provides a probabilistic safety certificate by calculating the collision probability between the robot's Gaussian-distributed forward reachable set and states of obstacles. To reduce the conservatism of the planned trajectory, we propose a tight upper bound of the collision probability and evaluate it both exactly and approximately. The approximated solution is used to generate motion primitives as a reference trajectory, while the exact solution is leveraged to iteratively optimize the trajectory for better results. Our method is thoroughly tested in simulation and real-world experiments, verifying its reliability and effectiveness in uncertain environments.},
  isbn = {978-1-6654-9190-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PHR6LSSH/Liu et al. - 2023 - Tight Collision Probability for UAV Motion Plannin.pdf}
}

@inproceedings{liu_visionbased_2025,
  title = {Vision-{{Based Collision Avoidance}} and {{Path Planning}} for {{UAVs Using Bearing}} and {{Pixel Area}}},
  booktitle = {2025 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Liu, Jen-Jui and Evans, Curtis P. and Beard, Randal W.},
  year = {2025},
  month = may,
  pages = {1190--1197},
  issn = {2575-7296},
  doi = {10.1109/ICUAS65942.2025.11007929},
  url = {https://ieeexplore.ieee.org/document/11007929/},
  urldate = {2025-06-01},
  abstract = {This paper presents an innovative collision avoid-ance and path planning framework for unmanned aerial vehicles (UAVs) using minimal camera-based inputs. The system leverages visual data to predict the future trajectories of nearby flying objects and compute low collision risk paths while maintaining progress toward designated targets. This solution extracts only two essential parameters from the vi-sual feed-bearing and pixel area-enabling practical obstacle detection and avoidance. Furthermore, our approach avoids the target observability problem without relying on extensive ownship maneuvers, allowing collision avoidance with minimal movement. Designed for UAVs operating in shared airspace with manned aircraft, the proposed framework emphasizes autonomous decision-making to improve operational safety. Simulation results demonstrate the system's capability to effec-tively plan avoidance maneuvers and generate feasible routes in complex and dynamic environments.},
  keywords = {Air traffic control,Aircraft,Autonomous aerial vehicles,Cameras,Collision avoidance,Quantization (signal),Three-dimensional displays,Trajectory,Vehicle dynamics,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/AMA95SRJ/Liu et al. - 2025 - Vision-Based Collision Avoidance and Path Planning for UAVs Using Bearing and Pixel Area.pdf}
}

@article{lluvia_active_2021,
  title = {Active {{Mapping}} and {{Robot Exploration}}: {{A Survey}}},
  shorttitle = {Active {{Mapping}} and {{Robot Exploration}}},
  author = {Lluvia, Iker and Lazkano, Elena and Ansuategi, Ander},
  year = {2021},
  month = jan,
  journal = {Sensors},
  volume = {21},
  number = {7},
  pages = {2445},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s21072445},
  url = {https://www.mdpi.com/1424-8220/21/7/2445},
  urldate = {2023-10-25},
  abstract = {Simultaneous localization and mapping responds to the problem of building a map of the environment without any prior information and based on the data obtained from one or more sensors. In most situations, the robot is driven by a human operator, but some systems are capable of navigating autonomously while mapping, which is called active simultaneous localization and mapping. This strategy focuses on actively calculating the trajectories to explore the environment while building a map with a minimum error. In this paper, a comprehensive review of the research work developed in this field is provided, targeting the most relevant contributions in indoor mobile robotics.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {exploration,frontiers,mapping,mobile robots,next best view,path planning},
  file = {/Users/kshitijgoel/Zotero/storage/T4UVFE49/Lluvia et al. - 2021 - Active Mapping and Robot Exploration A Survey.pdf}
}

@inproceedings{loop_closedform_2016,
  title = {A {{Closed-Form Bayesian Fusion Equation Using Occupancy Probabilities}}},
  booktitle = {2016 {{Fourth International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Loop, Charles and Cai, Qin and {Orts-Escolano}, Sergio and Chou, Philip A.},
  year = {2016},
  month = oct,
  pages = {380--388},
  doi = {10.1109/3DV.2016.47},
  url = {https://ieeexplore.ieee.org/document/7785112},
  urldate = {2024-04-28},
  abstract = {We present a new mathematical framework for multi-view surface reconstruction from a set of calibrated color and depth images. We estimate the occupancy probability of points in space along sight rays, and combine these estimates using a normalized product derived from Bayes' rule. The advantage of this approach is that the free space constraint is a natural consequence of the formulation, and not a separate logical operation. We present a single closed form implicit expression for the reconstructed surface in terms of the image data and camera projections, making analytic properties such as surface normals not only easy to compute, but exact. This expression can be efficiently evaluated on the GPU, making it ideal for high performance real-time applications, such as live human body capture for immersive telepresence.},
  keywords = {Bayes methods,Cameras,Image reconstruction,Mathematical model,Real-time systems,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/E4DAHDXF/Loop et al. - 2016 - A Closed-Form Bayesian Fusion Equation Using Occup.pdf;/Users/kshitijgoel/Zotero/storage/HZ6JDMQU/7785112.html}
}

@inproceedings{lopez_aggressive_2017,
  title = {Aggressive 3-{{D}} Collision Avoidance for High-Speed Navigation},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lopez, Brett T. and How, Jonathan P.},
  year = {2017},
  month = may,
  pages = {5759--5765},
  doi = {10.1109/ICRA.2017.7989677},
  abstract = {Autonomous robot navigation through unknown, cluttered environments at high-speeds is still an open problem. Quadrotor platforms with this capability have only begun to emerge with the advancements in light-weight, small form factor sensing and computing. Many of the existing platforms, however, require excessive computation time to perform collision avoidance, which ultimately limits the vehicle's top speed. This work presents an efficient perception and planning approach that significantly reduces the computation time by using instantaneous perception data for collision avoidance. Minimum-time, state and input constrained motion primitives are generated by sampling terminal states until a collision-free path is found. The worst case performance of the Triple Integrator Planner (TIP) is nearly an order of magnitude faster than the state-of-the-art. Experimental results demonstrate the algorithm's ability to plan and execute aggressive collision avoidance maneuvers in highly cluttered environments.},
  keywords = {Collision avoidance,Computational modeling,Navigation,Planning,Robot sensing systems,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/HS2JWSN5/Lopez and How - 2017 - Aggressive 3-D collision avoidance for high-speed .pdf;/Users/kshitijgoel/Zotero/storage/9YG7LSUE/7989677.html}
}

@article{lopez-rubio_soft_2008,
  title = {Soft Clustering for Nonparametric Probability Density Function Estimation},
  author = {{L{\'o}pez-Rubio}, Ezequiel and {Ortiz-de-Lazcano-Lobato}, Juan Miguel},
  year = {2008},
  month = dec,
  journal = {Pattern Recognition Letters},
  volume = {29},
  number = {16},
  pages = {2085--2091},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2008.07.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865508002328},
  urldate = {2024-03-14},
  abstract = {We present a nonparametric probability density estimation model. The classical Parzen window approach builds a spherical Gaussian density around every input sample. Our method has a first stage where hard neighborhoods are determined for every sample. Then soft clusters are considered to merge the information coming from several hard neighborhoods. Our proposal estimates the local principal directions to yield a specific Gaussian mixture component for each soft cluster. This leads to outperform other proposals where local parameter selection is not allowed and/or there are no smoothing strategies, like the manifold Parzen windows.},
  keywords = {Nonparametric modeling,Parzen window,Probability density estimation,Soft clustering},
  file = {/Users/kshitijgoel/Zotero/storage/R3GVA8AN/López-Rubio and Ortiz-de-Lazcano-Lobato - 2008 - Soft clustering for nonparametric probability dens.pdf;/Users/kshitijgoel/Zotero/storage/UWWKCEKZ/S0167865508002328.html}
}

@article{loquercio_autotune_2022,
  title = {{{AutoTune}}: {{Controller Tuning}} for {{High-Speed Flight}}},
  shorttitle = {{{AutoTune}}},
  author = {Loquercio, Antonio and Saviolo, Alessandro and Scaramuzza, Davide},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {4432--4439},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3146897},
  url = {https://ieeexplore.ieee.org/document/9696365/?arnumber=9696365},
  urldate = {2025-01-15},
  abstract = {Due to noisy actuation and external disturbances, tuning controllers for high-speed flight is very challenging. In this letter, we ask the following questions: How sensitive are controllers to tuning when tracking high-speed maneuvers? What algorithms can we use to automatically tune them? To answer the first question, we study the relationship between parameters and performance and find out that the faster the maneuver, the more sensitive a controller becomes to its parameters. To answer the second question, we review existing methods for controller tuning and discover that prior works often perform poorly on the task of high-speed flight. Therefore, we propose AutoTune, a sampling-based tuning algorithm specifically tailored to high-speed flight. In contrast to previous work, our algorithm does not assume any prior knowledge of the drone or its optimization function and can deal with the multi-modal characteristics of the parameters' optimization space. We thoroughly evaluate AutoTune both in simulation and in the physical world. In our experiments, we outperform existing tuning algorithms by up to 90\% in trajectory completion. The resulting controllers are tested in the AirSim Game of Drones competition, where we outperform the winner by up to 25\% in lap-time. Finally, we validate AutoTune in real-world flights in one of the world's largest motion-capture systems. In these experiments, we outperform human experts on the task of parameter tuning for trajectory tracking, achieving flight speeds over 50 {\textbackslash},{\textbackslash}mathrmk{\textbackslash}mathrmm{\textbackslash}mathrmh{\textasciicircum}-1.},
  keywords = {Heuristic algorithms,Noise measurement,Optimization,Robot learning,Robots,Task analysis,Trajectory,Tuning,unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/LLSGY2HK/Loquercio et al. - 2022 - AutoTune Controller Tuning for High-Speed Flight.pdf;/Users/kshitijgoel/Zotero/storage/STDZVDI6/9696365.html}
}

@article{loquercio_learning_2021,
  title = {Learning High-Speed Flight in the Wild},
  author = {Loquercio, Antonio and Kaufmann, Elia and Ranftl, Ren{\'e} and M{\"u}ller, Matthias and Koltun, Vladlen and Scaramuzza, Davide},
  year = {2021},
  month = oct,
  journal = {Science Robotics},
  volume = {6},
  number = {59},
  pages = {eabg5810},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.abg5810},
  url = {https://www.science.org/doi/10.1126/scirobotics.abg5810},
  urldate = {2022-04-08},
  file = {/Users/kshitijgoel/Zotero/storage/ATHMXRAB/Loquercio et al. - 2021 - Learning high-speed flight in the wild.pdf}
}

@article{lorensen_marching_1987,
  title = {Marching Cubes: {{A}} High Resolution {{3D}} Surface Construction Algorithm},
  shorttitle = {Marching Cubes},
  author = {Lorensen, William E. and Cline, Harvey E.},
  year = {1987},
  month = aug,
  journal = {ACM SIGGRAPH Computer Graphics},
  volume = {21},
  number = {4},
  pages = {163--169},
  issn = {0097-8930},
  doi = {10.1145/37402.37422},
  url = {https://doi.org/10.1145/37402.37422},
  urldate = {2022-02-06},
  abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
  file = {/Users/kshitijgoel/Zotero/storage/GKD5XA6K/Lorensen and Cline - 1987 - Marching cubes A high resolution 3D surface const.pdf}
}

@inproceedings{loshchilov_decoupled_2018,
  title = {Decoupled {{Weight Decay Regularization}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2018},
  month = sep,
  url = {https://openreview.net/forum?id=Bkg6RiCqY7},
  urldate = {2024-06-11},
  abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at {\textbackslash}url\{https://github.com/loshchil/AdamW-and-SGDW\}},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/A3NGZ7JD/Loshchilov and Hutter - 2018 - Decoupled Weight Decay Regularization.pdf}
}

@article{low_geometric_2023,
  title = {Geometric {{Algebra}} for {{Optimal Control With Applications}} in {{Manipulation Tasks}}},
  author = {L{\"o}w, Tobias and Calinon, Sylvain},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {3586--3600},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3277282},
  url = {https://ieeexplore.ieee.org/document/10144070},
  urldate = {2023-10-17},
  abstract = {Many problems in robotics are fundamentally problems of geometry, which have led to an increased research effort in geometric methods for robotics in recent years. The results were algorithms using the various frameworks of screw theory, Lie algebra, and dual quaternions. A unification and generalization of these popular formalisms can be found in geometric algebra. The aim of this article is to showcase the capabilities of geometric algebra when applied to robot manipulation tasks. In particular, the modeling of cost functions for optimal control can be done uniformly across different geometric primitives leading to a low symbolic complexity of the resulting expressions and a geometric intuitiveness. We demonstrate the usefulness, simplicity, and computational efficiency of geometric algebra in several experiments using a Franka Emika robot. The presented algorithms were implemented in c++20 and resulted in the publicly available library gafro. The benchmark shows faster computation of the kinematics than state-of-the-art robotics libraries.},
  file = {/Users/kshitijgoel/Zotero/storage/XES3C5LC/Löw and Calinon - 2023 - Geometric Algebra for Optimal Control With Applica.pdf}
}

@article{lozano-perez_algorithm_1979,
  title = {An Algorithm for Planning Collision-Free Paths among Polyhedral Obstacles},
  author = {{Lozano-P{\'e}rez}, Tom{\'a}s and Wesley, Michael A.},
  year = {1979},
  month = oct,
  journal = {Communications of the ACM},
  volume = {22},
  number = {10},
  pages = {560--570},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/359156.359164},
  url = {https://dl.acm.org/doi/10.1145/359156.359164},
  urldate = {2024-01-31},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5WDPIUHE/Lozano-Pérez and Wesley - 1979 - An algorithm for planning collision-free paths amo.pdf}
}

@article{lu_comprehensive_2023,
  title = {A Comprehensive Survey on Non-Cooperative Collision Avoidance for Micro Aerial Vehicles: {{Sensing}} and Obstacle Detection},
  shorttitle = {A Comprehensive Survey on Non-Cooperative Collision Avoidance for Micro Aerial Vehicles},
  author = {Lu, Liang and Fasano, Giancarmine and Carrio, Adrian and Lei, Maolin and Bavle, Hriday and Campoy, Pascual},
  year = {2023},
  journal = {Journal of Field Robotics},
  volume = {40},
  number = {6},
  pages = {1697--1720},
  issn = {1556-4967},
  doi = {10.1002/rob.22189},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22189},
  urldate = {2024-01-24},
  abstract = {In recent years, unmanned aerial vehicles (UAVs) have been confirmed as a powerful tool for countless applications in nearly every industry, in which collision avoidance plays a vital role for micro aerial vehicles (MAVs) performing autonomous missions. The complexity of collision avoidance systems is directly related to the complexity of the navigation environment, the avoidance of highly uncertain obstacles being a more thoroughly researched critical aspect. The non-cooperative collision avoidance strategy is necessary when communication between the agents is unavailable, under the case with many existing passive obstacles and non-cooperative flying objects. In this article, we review the topic of non-cooperative collision avoidance for MAVs in dynamic environments by covering two main issues: onboard sensing and obstacle description algorithms. A detailed discussion of these two topics is provided to face non-cooperative collision avoidance technology for MAVs. Finally, the paper summarizes the open challenges and foreseen future directions in this field.},
  langid = {english},
  keywords = {autonomous UAV,collision avoidance,dynamic obstacle avoidance,obstacle sensing and detection},
  file = {/Users/kshitijgoel/Zotero/storage/9RJ2NBND/Lu et al. - 2023 - A comprehensive survey on non-cooperative collisio.pdf;/Users/kshitijgoel/Zotero/storage/LYNMP4GJ/rob.html}
}

@article{lu_heterogeneous_2022,
  title = {A {{Heterogeneous Unmanned Ground Vehicle}} and {{Blimp Robot Team}} for {{Search}} and {{Rescue}} Using {{Data-driven Autonomy}} and {{Communication-aware Navigation}}},
  author = {Lu, Chen-Lung and Huang, Jui-Te and Huang, Ching-I and Liu, Zi-Yan and Hsu, Chao-Chun and Huang, Yu-Yen and Huang, Siao-Cing and Chang, Po-Kai and Ewe, Zu Lin and Huang, Po-Jui and Li, Po-Lin and Wang, Bo-Hui and Yim, Lai-Sum and Huang, Sheng-Wei and Bai, MingSian and Wang, Hsueh-Cheng},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {557--594},
  issn = {27713989},
  doi = {10.55417/fr.2022020},
  url = {https://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_20.pdf},
  urldate = {2023-01-26},
  abstract = {This paper describes the architecture and implementation of a heterogeneous team comprising unmanned ground vehicles and blimp robots capable of navigating unknown subter- ranean environments for search and rescue missions. The ground vehicles are equipped with a range of sensors for accurate perception, localization, and mapping. The blimps feature a long flight duration and collision tolerance when traversing uneven terrain. The design of the system was meant to satisfy the requirements of the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge in terms of perception capability and autonomy. To facilitate navigation through smoke-filled spaces, we employed novel millimeter wave radar to enable cross-modal representations for integration via deep reinforcement learning. The autonomy of the proposed scheme was augmented using simulations to train deep neural networks, thereby allowing the system to perform sequential decision-making for collision avoidance and navigation toward a specific goal. The navigation system was evaluated in the DARPA SubT Urban Circuit, and quantitative localization results and recovery strategy from failures was discussed. The proposed communication system comprises mesh WiFi with XBee (ZigBee network with XBee radios) and ultra-wideband (UWB) communication modules as well as spherical nodes that can be shot out like a cannonball and miniature cars deployed as mobile nodes. The propagation and radio signal strength index of various modules were evaluated using data collected during field tests in order to overcome the uncertainties of subterranean environments, including non-line-of-sight propagation, multipath propagation, and fading reception. We also discuss the lessons learned during this project and reflect on future plans.}
}

@inproceedings{lu_selfsupervised_2023,
  title = {Self-{{Supervised Learning}} of {{Object Segmentation}} from {{Unlabeled RGB-D Videos}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lu, Shiyang and Deng, Yunfu and Boularias, Abdeslam and Bekris, Kostas},
  year = {2023},
  month = may,
  pages = {7017--7023},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160786},
  url = {https://ieeexplore.ieee.org/document/10160786/},
  urldate = {2024-06-23},
  abstract = {This work proposes a self-supervised learning system for segmenting rigid objects in RGB images. The proposed pipeline is trained on unlabeled RGB-D videos of static objects, which can be captured with a camera carried by a mobile robot. A key feature of the self-supervised training process is a graphmatching algorithm that operates on the over-segmentation output of the point cloud that is reconstructed from each video. The graph matching, along with point cloud registration, is able to find reoccurring object patterns across videos and combine them into 3D object pseudo labels, even under occlusions or different viewing angles. Projected 2D object masks from 3D pseudo labels are used to train a pixel-wise feature extractor through contrastive learning. During online inference, a clustering method uses the learned features to cluster foreground pixels into object segments. Experiments highlight the method's effectiveness on both real and synthetic video datasets, which include cluttered scenes of tabletop objects. The proposed method outperforms existing unsupervised methods for object segmentation by a large margin.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZU5N6ULT/Lu et al. - 2023 - Self-Supervised Learning of Object Segmentation from Unlabeled RGB-D Videos.pdf}
}

@article{lu_semanticsaware_2024,
  title = {Semantics-{{Aware Receding Horizon Planner}} for {{Object-Centric Active Mapping}}},
  author = {Lu, Liang and Zhang, Yinqiang and Zhou, Peng and Qi, Jiaming and Pan, Yipeng and Fu, Changhong and Pan, Jia},
  year = {2024},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {4},
  pages = {3838--3845},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2024.3371873},
  url = {https://ieeexplore.ieee.org/document/10453941/},
  urldate = {2024-04-22},
  abstract = {The escalating demands for real-time scene comprehension in modern industries underscore the growing significance of semantic information in the daily tasks of robots, particularly in areas like autonomous inspection and target searching. This letter introduces a semantics-aware receding horizon planner (SARHP) for efficiently building the object-centric volumetric map. It includes a multi-layer mapping strategy and a semantics-aware frontier detection and planning method. With the multi-layer map, the semantics-aware frontier detection is conducted in the local layer, and the route assessment is conducted in the Field-of-View layer, which can reduce the time cost of the planning stage. Moreover, kinematic cost, geometric cost, and semantic cost are considered in the planner to ensure high search performance for semantic objects without affecting the overall mapping efficiency. The effectiveness of the proposed mapping and planning algorithm is validated in simulation and real-world experiments.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4PBRE3P7/Lu et al. - 2024 - Semantics-Aware Receding Horizon Planner for Objec.pdf}
}

@misc{lu_yopov2tracker_2025,
  title = {{{YOPOv2-Tracker}}: {{An End-to-End Agile Tracking}} and {{Navigation Framework}} from {{Perception}} to {{Action}}},
  shorttitle = {{{YOPOv2-Tracker}}},
  author = {Lu, Junjie and Hui, Yulin and Zhang, Xuewei and Feng, Wencan and Shen, Hongming and Li, Zhiyu and Tian, Bailing},
  year = {2025},
  month = may,
  number = {arXiv:2505.06923},
  eprint = {2505.06923},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.06923},
  url = {http://arxiv.org/abs/2505.06923},
  urldate = {2025-06-27},
  abstract = {Traditional target tracking pipelines including detection, mapping, navigation, and control are comprehensive but introduce high latency, limitting the agility of quadrotors. On the contrary, we follow the design principle of "less is more", striving to simplify the process while maintaining effectiveness. In this work, we propose an end-to-end agile tracking and navigation framework for quadrotors that directly maps the sensory observations to control commands. Importantly, leveraging the multimodal nature of navigation and detection tasks, our network maintains interpretability by explicitly integrating the independent modules of the traditional pipeline, rather than a crude action regression. In detail, we adopt a set of motion primitives as anchors to cover the searching space regarding the feasible region and potential target. Then we reformulate the trajectory optimization as regression of primitive offsets and associated costs considering the safety, smoothness, and other metrics. For tracking task, the trajectories are expected to approach the target and additional objectness scores are predicted. Subsequently, the predictions, after compensation for the estimated lumped disturbance, are transformed into thrust and attitude as control commands for swift response. During training, we seamlessly integrate traditional motion planning with deep learning by directly back-propagating the gradients of trajectory costs to the network, eliminating the need for expert demonstration in imitation learning and providing more direct guidance than reinforcement learning. Finally, we deploy the algorithm on a compact quadrotor and conduct real-world validations in both forest and building environments to demonstrate the efficiency of the proposed method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/ENSK7I86/Lu et al. - 2025 - YOPOv2-Tracker An End-to-End Agile Tracking and Navigation Framework from Perception to Action.pdf;/Users/kshitijgoel/Zotero/storage/ASJRM95Z/2505.html}
}

@article{lu_you_2024,
  title = {You {{Only Plan Once}}: {{A Learning-Based One-Stage Planner With Guidance Learning}}},
  shorttitle = {You {{Only Plan Once}}},
  author = {Lu, Junjie and Zhang, Xuewei and Shen, Hongming and Xu, Liwen and Tian, Bailing},
  year = {2024},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {7},
  pages = {6083--6090},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3399589},
  url = {https://ieeexplore.ieee.org/document/10528860/},
  urldate = {2025-06-27},
  abstract = {In this work, we propose a learning-based one-stage planner for trajectory generation of quadrotor in obstacle-cluttered environment without relying on explicit map. We integrate perception and mapping, front-end path searching, and back-end optimization into a single network. We frame the motion planning problem as a regression of spatially separated polynomial trajectories and associated scores. Specifically, our approach adopts a set of motion primitives to cover the searching space, and predicts the offsets and scores of primitives for local optimization in a single forward propagation. A novel unsupervised learning strategy, termed guidance learning, is developed to provide numerical gradients as the guidance for training. We train the network policy with privileged information about the surroundings while only the noisy depth observations are available during inference. Finally, a series of experiments are conducted to demonstrate the effectiveness and time-efficiency of the proposed method in both simulation and real-world.},
  keywords = {aerial systems,collision avoidance,Integrated planning and learning,Navigation,perception and autonomy,Planning,Polynomials,Reinforcement learning,Supervised learning,Training,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/YQRM7R4M/Lu et al. - 2024 - You Only Plan Once A Learning-Based One-Stage Planner With Guidance Learning.pdf}
}

@article{luo_fmb_2025,
  title = {{{FMB}}: {{A}} Functional Manipulation Benchmark for Generalizable Robotic Learning},
  shorttitle = {{{FMB}}},
  author = {Luo, Jianlan and Xu, Charles and Liu, Fangchen and Tan, Liam and Lin, Zipeng and Wu, Jeffrey and Abbeel, Pieter and Levine, Sergey},
  year = {2025},
  month = apr,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {4},
  pages = {592--606},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241276017},
  url = {https://doi.org/10.1177/02783649241276017},
  urldate = {2025-04-16},
  abstract = {In this paper, we propose a real-world benchmark for studying robotic learning in the context of functional manipulation: a robot needs to accomplish complex long-horizon behaviors by composing individual manipulation skills in functionally relevant ways. The core design principles of our Functional Manipulation Benchmark (FMB) emphasize a harmonious balance between complexity and accessibility. Tasks are deliberately scoped to be narrow, ensuring that models and datasets of manageable scale can be utilized effectively to track progress. Simultaneously, they are diverse enough to pose a significant generalization challenge. Furthermore, the benchmark is designed to be easily replicable, encompassing all essential hardware and software components. To achieve this goal, FMB consists of a variety of 3D-printed objects designed for easy and accurate replication by other researchers. The objects are procedurally generated, providing a principled framework to study generalization in a controlled fashion. We focus on fundamental manipulation skills, including grasping, repositioning, and a range of assembly behaviors. The FMB can be used to evaluate methods for acquiring individual skills, as well as methods for effectively combining and ordering such skills in order to solve complex, multi-stage manipulation tasks. We also offer an imitation learning framework that includes a suite of policies trained to solve the proposed tasks. This enables researchers to utilize our tasks as a versatile toolkit for examining various parts of the pipeline. For example, researchers could propose a better design for a grasping controller and evaluate it in combination with our baseline reorientation and assembly policies as part of a pipeline for solving multi-stage tasks. Our dataset, object CAD files, code, and evaluation videos can be found on our project website: https://functional-manipulation-benchmark.github.io.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JRHKQIYG/Luo et al. - 2025 - FMB A functional manipulation benchmark for generalizable robotic learning.pdf}
}

@inproceedings{luo_multirobot_2020,
  title = {Multi-{{Robot Collision Avoidance}} under {{Uncertainty}} with {{Probabilistic Safety Barrier Certificates}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Luo, Wenhao and Sun, Wen and Kapoor, Ashish},
  year = {2020},
  volume = {33},
  pages = {372--383},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/03793ef7d06ffd63d34ade9d091f1ced-Abstract.html},
  urldate = {2023-11-20},
  abstract = {Safety in terms of collision avoidance for multi-robot systems is a difficult challenge under uncertainty, non-determinism, and lack of complete information. This paper aims to propose a collision avoidance method that accounts for both measurement uncertainty and motion uncertainty. In particular, we propose Probabilistic Safety Barrier Certificates (PrSBC) using Control Barrier Functions to define the space of admissible control actions that are probabilistically safe with formally provable theoretical guarantee. By formulating the chance constrained safety set into deterministic control constraints with PrSBC, the method entails minimally modifying an existing controller to determine an alternative safe controller via quadratic programming constrained to PrSBC constraints. The key advantage of the approach is that no assumptions about the form of uncertainty are required other than finite support, also enabling worst-case guarantees. We demonstrate effectiveness of the approach through experiments on realistic simulation environments.},
  file = {/Users/kshitijgoel/Zotero/storage/EAKDBYGW/Luo et al. - 2020 - Multi-Robot Collision Avoidance under Uncertainty .pdf}
}

@article{luo_starsearcher_2024,
  title = {Star-{{Searcher}}: {{A Complete}} and {{Efficient Aerial System}} for {{Autonomous Target Search}} in {{Complex Unknown Environments}}},
  shorttitle = {Star-{{Searcher}}},
  author = {Luo, Yiming and Zhuang, Zixuan and Pan, Neng and Feng, Chen and Shen, Shaojie and Gao, Fei and Cheng, Hui and Zhou, Boyu},
  year = {2024},
  month = may,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {5},
  pages = {4329--4336},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3379840},
  url = {https://ieeexplore.ieee.org/document/10476680/?arnumber=10476680},
  urldate = {2024-12-11},
  abstract = {This letter tackles the challenge of autonomous target search using unmanned aerial vehicles (UAVs) in complex unknown environments. To fill the gap in systematic approaches for this task, we introduce Star-Searcher, an aerial system featuring specialized sensor suites, mapping, and planning modules to optimize searching. Path planning challenges due to increased inspection requirements are addressed through a hierarchical planner with a visibility-based viewpoint clustering method. This simplifies planning by breaking it into global and local sub-problems, ensuring efficient global and local path coverage in real-time. Furthermore, our global path planning employs a history-aware mechanism to reduce motion inconsistency from frequent map changes, significantly enhancing search efficiency. We conduct comparisons with state-of-the-art methods in both simulation and the real world, demonstrating shorter flight paths, reduced time, and higher target search completeness. Our approach will be open-sourced for community benefit.1},
  keywords = {aerial systems: applications,Aerial systems: perception and autonomy,Autonomous aerial vehicles,Cameras,Inspection,Path planning,Planning,search and rescue robots,Search problems,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/M8RYEWXV/Luo et al. - 2024 - Star-Searcher A Complete and Efficient Aerial System for Autonomous Target Search in Complex Unknow.pdf;/Users/kshitijgoel/Zotero/storage/NCL6TR46/10476680.html}
}

@misc{luxburg_tutorial_2007,
  title = {A {{Tutorial}} on {{Spectral Clustering}}},
  author = {von Luxburg, Ulrike},
  year = {2007},
  month = nov,
  number = {arXiv:0711.0189},
  eprint = {0711.0189},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.0711.0189},
  url = {http://arxiv.org/abs/0711.0189},
  urldate = {2024-12-19},
  abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/K2MYGERL/Luxburg - 2007 - A Tutorial on Spectral Clustering.pdf;/Users/kshitijgoel/Zotero/storage/3U5EM9T6/0711.html}
}

@article{lyu_optimal_2023,
  title = {Optimal Estimation and Computational Limit of Low-Rank {{Gaussian}} Mixtures},
  author = {Lyu, Zhongyuan and Xia, Dong},
  year = {2023},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {51},
  number = {2},
  pages = {646--667},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/23-AOS2264},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-51/issue-2/Optimal-estimation-and-computational-limit-of-low-rank-Gaussian-mixtures/10.1214/23-AOS2264.full},
  urldate = {2023-08-15},
  abstract = {Structural matrix-variate observations routinely arise in diverse fields such as multilayer network analysis and brain image clustering. While data of this type have been extensively investigated with fruitful outcomes being delivered, the fundamental questions like its statistical optimality and computational limit are largely under-explored. In this paper, we propose a low-rank Gaussian mixture model (LrMM) assuming each matrix-valued observation has a planted low-rank structure. Minimax lower bounds for estimating the underlying low-rank matrix are established allowing a whole range of sample sizes and signal strength. Under a minimal condition on signal strength, referred to as the information-theoretical limit or statistical limit, we prove the minimax optimality of a maximum likelihood estimator which, in general, is computationally infeasible. If the signal is stronger than a certain threshold, called the computational limit, we design a computationally fast estimator based on spectral aggregation and demonstrate its minimax optimality. Moreover, when the signal strength is smaller than the computational limit, we provide evidences based on the low-degree likelihood ratio framework to claim that no polynomial-time algorithm can consistently recover the underlying low-rank matrix. Our results reveal multiple phase transitions in the minimax error rates and the statistical-to-computational gap. Numerical experiments confirm our theoretical findings. We further showcase the merit of our spectral aggregation method on the worldwide food trading dataset.},
  keywords = {62C20,62F30,Gaussian mixtures,low-rank matrix,Minimax optimality},
  file = {/Users/kshitijgoel/Zotero/storage/Z7FVGEAT/Lyu and Xia - 2023 - Optimal estimation and computational limit of low-.pdf}
}

@inproceedings{ma_covert_2024,
  title = {Covert {{Planning}} against {{Imperfect Observers}}},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Autonomous Agents}} and {{Multiagent Systems}}},
  author = {Ma, Haoxiang and Shi, Chongyang and Han, Shuo and Dorothy, Michael R. and Fu, Jie},
  year = {2024},
  month = may,
  series = {{{AAMAS}} '24},
  pages = {1319--1327},
  publisher = {{International Foundation for Autonomous Agents and Multiagent Systems}},
  address = {Richland, SC},
  urldate = {2025-01-03},
  abstract = {Covert planning refers to a class of constrained planning problems where an agent aims to accomplish a task with minimal information leaked to a passive observer to avoid detection. However, existing methods of covert planning often consider deterministic environments or do not exploit the observer's imperfect information. This paper studies how covert planning can leverage the coupling of stochastic dynamics and the observer's imperfect observation to achieve optimal task performance without being detected. Specifically, we employ a Markov decision process to model the interaction between the agent and its stochastic environment, and a partial observation function to capture the leaked information to a passive observer. Assuming the observer employs hypothesis testing to detect if the observation deviates from a nominal policy, the covert planning agent aims to maximize the total discounted reward while keeping the probability of being detected as an adversary below a given threshold. We prove that finite-memory policies are more powerful than Markovian policies in covert planning. Then, we develop a primal-dual proximal policy gradient method with a two-time-scale update to compute a (locally) optimal covert policy. We demonstrate the effectiveness of our methods using a stochastic gridworld example. Our experimental results illustrate that the proposed method computes a policy that maximizes the adversary's expected reward without violating the detection constraint, and empirically demonstrates how the environmental noises can influence the performance of the covert policies.},
  isbn = {979-8-4007-0486-4},
  file = {/Users/kshitijgoel/Zotero/storage/H2II2VY4/Ma et al. - 2024 - Covert Planning against Imperfect Observers.pdf}
}

@inproceedings{ma_image_2022,
  title = {Image as {{Set}} of {{Points}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Ma, Xu and Zhou, Yuqian and Wang, Huan and Qin, Can and Sun, Bin and Liu, Chang and Fu, Yun},
  year = {2022},
  month = sep,
  url = {https://openreview.net/forum?id=awnvqZja69},
  urldate = {2023-07-24},
  abstract = {What is an image, and how to extract latent features? Convolutional Networks (ConvNets) consider an image as organized pixels in a rectangular shape and extract features via convolutional operation in a local region; Vision Transformers (ViTs) treat an image as a sequence of patches and extract features via attention mechanism in a global range. In this work, we introduce a straightforward and promising paradigm for visual representation, which is called Context Clusters. Context clusters (CoCs) view an image as a set of unorganized points and extract features via a simplified clustering algorithm. In detail, each point includes the raw feature (e.g., color) and positional information (e.g., coordinates), and a simplified clustering algorithm is employed to group and extract deep features hierarchically. Our CoCs are convolution- and attention-free, only relying on clustering algorithm for spatial interaction. Owing to the simple design, we show CoCs endow gratifying interpretability via the visualization of the clustering process. Our CoCs aim at providing a new perspective on image and visual representation, which may enjoy broad applications in different domains and exhibit profound insights. Even though we are not targeting SOTA performance, COCs still achieve comparable or even better performance than ConvNets or ViTs on several benchmarks.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DS5DN6HQ/Ma et al. - 2022 - Image as Set of Points.pdf}
}

@misc{ma_privileged_2024,
  title = {Privileged {{Reinforcement}} and {{Communication Learning}} for {{Distributed}}, {{Bandwidth-limited Multi-robot Exploration}}},
  author = {Ma, Yixiao and Liang, Jingsong and Cao, Yuhong and Tan, Derek Ming Siang and Sartoretti, Guillaume},
  year = {2024},
  month = jul,
  number = {arXiv:2407.20203},
  eprint = {2407.20203},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.20203},
  urldate = {2024-08-02},
  abstract = {Communication bandwidth is an important consideration in multi-robot exploration, where information exchange among robots is critical. While existing methods typically aim to reduce communication throughput, they either require significant computation or significantly compromise exploration efficiency. In this work, we propose a deep reinforcement learning framework based on communication and privileged reinforcement learning to achieve a significant reduction in bandwidth consumption, while minimally sacrificing exploration efficiency. Specifically, our approach allows robots to learn to embed the most salient information from their individual belief (partial map) over the environment into fixed-sized messages. Robots then reason about their own belief as well as received messages to distributedly explore the environment while avoiding redundant work. In doing so, we employ privileged learning and learned attention mechanisms to endow the critic (i.e., teacher) network with ground truth map knowledge to effectively guide the policy (i.e., student) network during training. Compared to relevant baselines, our model allows the team to reduce communication by up to two orders of magnitude, while only sacrificing a marginal 2.4\% in total travel distance, paving the way for efficient, distributed multi-robot exploration in bandwidth-limited scenarios. We open-sourced our full code 3..},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/PZYAPZ4C/Ma et al. - 2024 - Privileged Reinforcement and Communication Learning for Distributed, Bandwidth-limited Multi-robot E.pdf}
}

@article{ma_segmentation_2007,
  title = {Segmentation of {{Multivariate Mixed Data}} via {{Lossy Data Coding}} and {{Compression}}},
  author = {Ma, Yi and Derksen, Harm and Hong, Wei and Wright, John},
  year = {2007},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {29},
  number = {9},
  pages = {1546--1562},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2007.1085},
  url = {https://ieeexplore.ieee.org/document/4288157},
  urldate = {2024-03-29},
  abstract = {In this paper, based on ideas from lossy data coding and compression, we present a simple but effective technique for segmenting multivariate mixed data that are drawn from a mixture of Gaussian distributions, which are allowed to be almost degenerate. The goal is to find the optimal segmentation that minimizes the overall coding length of the segmented data, subject to a given distortion. By analyzing the coding length/rate of mixed data, we formally establish some strong connections of data segmentation to many fundamental concepts in lossy data compression and rate-distortion theory. We show that a deterministic segmentation is approximately the (asymptotically) optimal solution for compressing mixed data. We propose a very simple and effective algorithm that depends on a single parameter, the allowable distortion. At any given distortion, the algorithm automatically determines the corresponding number and dimension of the groups and does not involve any parameter estimation. Simulation results reveal intriguing phase-transition-like behaviors of the number of segments when changing the level of distortion or the amount of outliers. Finally, we demonstrate how this technique can be readily applied to segment real imagery and bioinformatic data.},
  keywords = {Bioinformatics,Data Clustering,Data compression,Data Segmentation,Gaussian distribution,Image coding,Image segmentation,Image Segmentation,Lossy Coding,Lossy Compression,Maximum likelihood estimation,Microarray Data Clustering,Multivariate Mixed Data,Parameter estimation,Phase distortion,Rate Distortion,Rate-distortion,Signal processing algorithms},
  file = {/Users/kshitijgoel/Zotero/storage/H3XKA44V/Ma et al. - 2007 - Segmentation of Multivariate Mixed Data via Lossy .pdf}
}

@article{macenski_robot_2022,
  title = {Robot {{Operating System}} 2: {{Design}}, Architecture, and Uses in the Wild},
  shorttitle = {Robot {{Operating System}} 2},
  author = {Macenski, Steven and Foote, Tully and Gerkey, Brian and Lalancette, Chris and Woodall, William},
  year = {2022},
  month = may,
  journal = {Science Robotics},
  volume = {7},
  number = {66},
  pages = {eabm6074},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.abm6074},
  url = {https://www.science.org/doi/10.1126/scirobotics.abm6074},
  urldate = {2022-11-17},
  abstract = {The next chapter of the robotics revolution is well underway with the deployment of robots for a broad range of commercial use cases. Even in a myriad of applications and environments, there exists a common vocabulary of components that robots share---the need for a modular, scalable, and reliable architecture; sensing; planning; mobility; and autonomy. The Robot Operating System (ROS) was an integral part of the last chapter, demonstrably expediting robotics research with freely available components and a modular framework. However, ROS 1 was not designed with many necessary production-grade features and algorithms. ROS 2 and its related projects have been redesigned from the ground up to meet the challenges set forth by modern robotic systems in new and exploratory domains at all scales. In this Review, we highlight the philosophical and architectural changes of ROS 2 powering this new chapter in the robotics revolution. We also show through case studies the influence ROS 2 and its adoption has had on accelerating real robot systems to reliable deployment in an assortment of challenging environments.},
  file = {/Users/kshitijgoel/Zotero/storage/VIY2PTVY/Macenski et al. - 2022 - Robot Operating System 2 Design, architecture, an.pdf}
}

@article{mackay_informationbased_1992,
  title = {Information-{{Based Objective Functions}} for {{Active Data Selection}}},
  author = {MacKay, David J. C.},
  year = {1992},
  month = jul,
  journal = {Neural Computation},
  volume = {4},
  number = {4},
  pages = {590--604},
  issn = {0899-7667},
  doi = {10.1162/neco.1992.4.4.590},
  url = {https://doi.org/10.1162/neco.1992.4.4.590},
  urldate = {2025-02-12},
  abstract = {Learning can be made more efficient if we can actively select particularly salient data points. Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements. Three alternative specifications of what we want to gain information about lead to three different criteria for data selection. All these criteria depend on the assumption that the hypothesis space is correct, which may prove to be their main weakness.},
  file = {/Users/kshitijgoel/Zotero/storage/GWRVU9L4/MacKay - 1992 - Information-Based Objective Functions for Active Data Selection.pdf;/Users/kshitijgoel/Zotero/storage/DRNEXTWM/Information-Based-Objective-Functions-for-Active.html}
}

@misc{maele_variational_2024,
  title = {Variational {{Bayes Gaussian Splatting}}},
  author = {de Maele, Toon Van and Catal, Ozan and Tschantz, Alexander and Buckley, Christopher L. and Verbelen, Tim},
  year = {2024},
  month = oct,
  number = {arXiv:2410.03592},
  eprint = {2410.03592},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.03592},
  urldate = {2024-10-12},
  abstract = {Recently, 3D Gaussian Splatting has emerged as a promising approach for modeling 3D scenes using mixtures of Gaussians. The predominant optimization method for these models relies on backpropagating gradients through a differentiable rendering pipeline, which struggles with catastrophic forgetting when dealing with continuous streams of data. To address this limitation, we propose Variational Bayes Gaussian Splatting (VBGS), a novel approach that frames training a Gaussian splat as variational inference over model parameters. By leveraging the conjugacy properties of multivariate Gaussians, we derive a closed-form variational update rule, allowing efficient updates from partial, sequential observations without the need for replay buffers. Our experiments show that VBGS not only matches state-of-the-art performance on static datasets, but also enables continual learning from sequentially streamed 2D and 3D data, drastically improving performance in this setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/4GKRLJEX/Maele et al. - 2024 - Variational Bayes Gaussian Splatting.pdf;/Users/kshitijgoel/Zotero/storage/XQUQ9DBB/2410.html}
}

@misc{maggio_bayesian_2025,
  title = {Bayesian {{Fields}}: {{Task-driven Open-Set Semantic Gaussian Splatting}}},
  shorttitle = {Bayesian {{Fields}}},
  author = {Maggio, Dominic and Carlone, Luca},
  year = {2025},
  month = mar,
  number = {arXiv:2503.05949},
  eprint = {2503.05949},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.05949},
  url = {http://arxiv.org/abs/2503.05949},
  urldate = {2025-03-14},
  abstract = {Open-set semantic mapping requires (i) determining the correct granularity to represent the scene (e.g., how should objects be defined), and (ii) fusing semantic knowledge across multiple 2D observations into an overall 3D reconstruction -ideally with a high-fidelity yet low-memory footprint. While most related works bypass the first issue by grouping together primitives with similar semantics (according to some manually tuned threshold), we recognize that the object granularity is task-dependent, and develop a task-driven semantic mapping approach. To address the second issue, current practice is to average visual embedding vectors over multiple views. Instead, we show the benefits of using a probabilistic approach based on the properties of the underlying visual-language foundation model, and leveraging Bayesian updating to aggregate multiple observations of the scene. The result is Bayesian Fields, a task-driven and probabilistic approach for open-set semantic mapping. To enable high-fidelity objects and a dense scene representation, Bayesian Fields uses 3D Gaussians which we cluster into task-relevant objects, allowing for both easy 3D object extraction and reduced memory usage. We release Bayesian Fields open-source at https: //github.com/MIT-SPARK/Bayesian-Fields.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/DFGBFKMQ/Maggio and Carlone - 2025 - Bayesian Fields Task-driven Open-Set Semantic Gaussian Splatting.pdf;/Users/kshitijgoel/Zotero/storage/DN3CM7JS/2503.html}
}

@article{maggio_clio_2024,
  title = {{\emph{Clio:}} {{Real-Time Task-Driven Open-Set 3D Scene Graphs}}},
  shorttitle = {{\emph{Clio}}},
  author = {Maggio, Dominic and Chang, Yun and Hughes, Nathan and Trang, Matthew and Griffith, Dan and Dougherty, Carlyn and Cristofalo, Eric and Schmid, Lukas and Carlone, Luca},
  year = {2024},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {10},
  pages = {8921--8928},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2024.3451395},
  url = {https://ieeexplore.ieee.org/document/10659066/},
  urldate = {2024-10-14},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/W86446QQ/Maggio et al. - 2024 - Clio Real-time Task-Driven Open-Set 3D Scene Graphs.pdf;/Users/kshitijgoel/Zotero/storage/CEA3F5R5/2404.html}
}

@article{magnusson_scan_2007,
  title = {Scan Registration for Autonomous Mining Vehicles Using {{3D-NDT}}},
  author = {Magnusson, Martin and Lilienthal, Achim and Duckett, Tom},
  year = {2007},
  journal = {Journal of Field Robotics},
  volume = {24},
  number = {10},
  pages = {803--827},
  issn = {1556-4967},
  doi = {10.1002/rob.20204},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.20204},
  urldate = {2022-09-25},
  abstract = {Scan registration is an essential subtask when building maps based on range finder data from mobile robots. The problem is to deduce how the robot has moved between consecutive scans, based on the shape of overlapping portions of the scans. This paper presents a new algorithm for registration of 3D data. The algorithm is a generalization and improvement of the normal distributions transform (NDT) for 2D data developed by Biber and Strasser, which allows for accurate registration using a memory-efficient representation of the scan surface. A detailed quantitative and qualitative comparison of the new algorithm with the 3D version of the popular ICP (iterative closest point) algorithm is presented. Results with actual mine data, some of which were collected with a new prototype 3D laser scanner, show that the presented algorithm is faster and slightly more reliable than the standard ICP algorithm for 3D registration, while using a more memory-efficient scan surface representation. {\copyright} 2007 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/52JQMGPQ/Magnusson et al. - 2007 - Scan registration for autonomous mining vehicles u.pdf;/Users/kshitijgoel/Zotero/storage/KBMPLBL3/rob.html}
}

@article{mahony_multirotor_2012,
  title = {Multirotor {{Aerial Vehicles}}: {{Modeling}}, {{Estimation}}, and {{Control}} of {{Quadrotor}}},
  shorttitle = {Multirotor {{Aerial Vehicles}}},
  author = {Mahony, Robert and Kumar, Vijay and Corke, Peter},
  year = {2012},
  month = sep,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {19},
  number = {3},
  pages = {20--32},
  issn = {1558-223X},
  doi = {10.1109/MRA.2012.2206474},
  url = {https://ieeexplore.ieee.org/document/6289431},
  urldate = {2024-11-15},
  abstract = {This article provides a tutorial introduction to modeling, estimation, and control formultirotor aerial vehicles that includes the common four-rotor or quadrotor case.},
  keywords = {Aerodynamics,Aircraft manufacture,Atmospheric modeling,Blades,Estimation,Modeling,Rotors,Tutorials},
  file = {/Users/kshitijgoel/Zotero/storage/889MVEEA/Mahony et al. - 2012 - Multirotor Aerial Vehicles Modeling, Estimation, and Control of Quadrotor.pdf;/Users/kshitijgoel/Zotero/storage/ZSD8MVIY/6289431.html}
}

@article{mahony_nonlinear_2008,
  title = {Nonlinear {{Complementary Filters}} on the {{Special Orthogonal Group}}},
  author = {Mahony, Robert and Hamel, Tarek and Pflimlin, Jean-Michel},
  year = {2008},
  month = jun,
  journal = {IEEE Transactions on Automatic Control},
  volume = {53},
  number = {5},
  pages = {1203--1218},
  issn = {1558-2523},
  doi = {10.1109/TAC.2008.923738},
  url = {https://ieeexplore.ieee.org/document/4608934/},
  urldate = {2025-04-06},
  abstract = {This paper considers the problem of obtaining good attitude estimates from measurements obtained from typical low cost inertial measurement units. The outputs of such systems are characterized by high noise levels and time varying additive biases. We formulate the filtering problem as deterministic observer kinematics posed directly on the special orthogonal group SO (3) driven by reconstructed attitude and angular velocity measurements. Lyapunov analysis results for the proposed observers are derived that ensure almost global stability of the observer error. The approach taken leads to an observer that we term the direct complementary filter. By exploiting the geometry of the special orthogonal group a related observer, termed the passive complementary filter, is derived that decouples the gyro measurements from the reconstructed attitude in the observer inputs. Both the direct and passive filters can be extended to estimate gyro bias online. The passive filter is further developed to provide a formulation in terms of the measurement error that avoids any algebraic reconstruction of the attitude. This leads to an observer on SO(3), termed the explicit complementary filter, that requires only accelerometer and gyro outputs; is suitable for implementation on embedded hardware; and provides good attitude estimates as well as estimating the gyro biases online. The performance of the observers are demonstrated with a set of experiments performed on a robotic test-bed and a radio controlled unmanned aerial vehicle.},
  keywords = {Additive noise,Angular velocity,Attitude estimates,complementary filter,Costs,Filtering,Kinematics,Measurement units,Noise level,nonlinear observer,Passive filters,Position measurement,special orthogonal group,Time varying systems},
  file = {/Users/kshitijgoel/Zotero/storage/NFDN2KND/Mahony et al. - 2008 - Nonlinear Complementary Filters on the Special Orthogonal Group.pdf}
}

@misc{mai_ever_2024,
  title = {{{EVER}}: {{Exact Volumetric Ellipsoid Rendering}} for {{Real-time View Synthesis}}},
  shorttitle = {{{EVER}}},
  author = {Mai, Alexander and Hedman, Peter and Kopanas, George and Verbin, Dor and Futschik, David and Xu, Qiangeng and Kuester, Falko and Barron, Jonathan T. and Zhang, Yinda},
  year = {2024},
  month = oct,
  number = {arXiv:2410.01804},
  eprint = {2410.01804},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.01804},
  urldate = {2024-11-01},
  abstract = {We present Exact Volumetric Ellipsoid Rendering (EVER), a method for real-time differentiable emission-only volume rendering. Unlike recent rasterization based approach by 3D Gaussian Splatting (3DGS), our primitive based representation allows for exact volume rendering, rather than alpha compositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does not suffer from popping artifacts and view dependent density, but still achieves frame rates of \${\textbackslash}sim{\textbackslash}!30\$ FPS at 720p on an NVIDIA RTX4090. Since our approach is built upon ray tracing it enables effects such as defocus blur and camera distortion (e.g. such as from fisheye cameras), which are difficult to achieve by rasterization. We show that our method is more accurate with fewer blending issues than 3DGS and follow-up work on view-consistent rendering, especially on the challenging large-scale scenes from the Zip-NeRF dataset where it achieves sharpest results among real-time techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/V467PYTZ/Mai et al. - 2024 - EVER Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis.pdf;/Users/kshitijgoel/Zotero/storage/TJMLEGBW/2410.html}
}

@article{majumdar_fundamental_2022,
  title = {Fundamental {{Performance Limits}} for {{Sensor-Based Robot Control}} and {{Policy Learning}}},
  author = {Majumdar, Anirudha and Pacelli, Vincent},
  year = {2022},
  month = may,
  journal = {arXiv:2202.00129 [cs, math]},
  eprint = {2202.00129},
  primaryclass = {cs, math},
  url = {http://arxiv.org/abs/2202.00129},
  urldate = {2022-05-11},
  abstract = {Our goal is to develop theory and algorithms for establishing fundamental limits on performance for a given task imposed by a robot's sensors. In order to achieve this, we define a quantity that captures the amount of task-relevant information provided by a sensor. Using a novel version of the generalized Fano inequality from information theory, we demonstrate that this quantity provides an upper bound on the highest achievable expected reward for one-step decision making tasks. We then extend this bound to multi-step problems via a dynamic programming approach. We present algorithms for numerically computing the resulting bounds, and demonstrate our approach on three examples: (i) the lava problem from the literature on partially observable Markov decision processes, (ii) an example with continuous state and observation spaces corresponding to a robot catching a freely-falling object, and (iii) obstacle avoidance using a depth sensor with non-Gaussian noise. We demonstrate the ability of our approach to establish strong limits on achievable performance for these problems by comparing our upper bounds with achievable lower bounds (computed by synthesizing or learning concrete control policies).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Theory,Computer Science - Machine Learning,Computer Science - Robotics,Mathematics - Optimization and Control},
  file = {/Users/kshitijgoel/Zotero/storage/C7QXY9QQ/Majumdar and Pacelli - 2022 - Fundamental Performance Limits for Sensor-Based Ro.pdf;/Users/kshitijgoel/Zotero/storage/QIEBKNYF/2202.html}
}

@article{majumdar_fundamental_2023,
  title = {Fundamental Limits for Sensor-Based Robot Control},
  author = {Majumdar, Anirudha and Mei, Zhiting and Pacelli, Vincent},
  year = {2023},
  month = oct,
  journal = {The International Journal of Robotics Research},
  volume = {42},
  number = {12},
  pages = {1051--1069},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231190947},
  url = {https://doi.org/10.1177/02783649231190947},
  urldate = {2024-04-19},
  abstract = {Our goal is to develop theory and algorithms for establishing fundamental limits on performance imposed by a robot's sensors for a given task. In order to achieve this, we define a quantity that captures the amount of task-relevant information provided by a sensor. Using a novel version of the generalized Fano's inequality from information theory, we demonstrate that this quantity provides an upper bound on the highest achievable expected reward for one-step decision-making tasks. We then extend this bound to multi-step problems via a dynamic programming approach. We present algorithms for numerically computing the resulting bounds, and demonstrate our approach on three examples: (i) the lava problem from the literature on partially observable Markov decision processes, (ii) an example with continuous state and observation spaces corresponding to a robot catching a freely-falling object, and (iii) obstacle avoidance using a depth sensor with non-Gaussian noise. We demonstrate the ability of our approach to establish strong limits on achievable performance for these problems by comparing our upper bounds with achievable lower bounds (computed by synthesizing or learning concrete control policies).},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IVZD5VUV/Majumdar et al. - 2023 - Fundamental limits for sensor-based robot control.pdf}
}

@inproceedings{makarenko_experiment_2002,
  title = {An Experiment in Integrated Exploration},
  booktitle = {{{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Makarenko, A.A. and Williams, S.B. and Bourgault, F. and {Durrant-Whyte}, H.F.},
  year = {2002},
  month = sep,
  volume = {1},
  pages = {534-539 vol.1},
  doi = {10.1109/IRDS.2002.1041445},
  url = {https://ieeexplore.ieee.org/document/1041445},
  urldate = {2023-10-23},
  abstract = {Integrated exploration strategy advocated in this paper refers to a tight coupling between the tasks of localization, mapping, and motion control and the effect of this. coupling on the overall effectiveness of an exploration strategy. Our approach to exploration calls for a balanced evaluation of alternative motion actions from the point of view of information gain, localization quality, and navigation cost. To provide a uniform basis of comparison of localization quality between different locations, a "localizability" metric is introduced. It is based on the estimate of the lowest vehicle pose covariance attainable from a given location.},
  file = {/Users/kshitijgoel/Zotero/storage/HA4RP25P/Makarenko et al. - 2002 - An experiment in integrated exploration.pdf}
}

@inproceedings{malago_information_2015,
  title = {Information {{Geometry}} of the {{Gaussian Distribution}} in {{View}} of {{Stochastic Optimization}}},
  booktitle = {Proceedings of the 2015 {{ACM Conference}} on {{Foundations}} of {{Genetic Algorithms XIII}}},
  author = {Malag{\`o}, Luigi and Pistone, Giovanni},
  year = {2015},
  month = jan,
  pages = {150--162},
  publisher = {ACM},
  address = {Aberystwyth United Kingdom},
  doi = {10.1145/2725494.2725510},
  url = {https://dl.acm.org/doi/10.1145/2725494.2725510},
  urldate = {2023-07-05},
  abstract = {We study the optimization of a continuous function by its stochastic relaxation, i.e., the optimization of the expected value of the function itself with respect to a density in a statistical model. We focus on gradient descent techniques applied to models from the exponential family and in particular on the multivariate Gaussian distribution. From the theory of the exponential family, we reparametrize the Gaussian distribution using natural and expectation parameters, and we derive formulas for natural gradients in both parameterizations. We discuss some advantages of the natural parameterization for the identification of sub-models in the Gaussian distribution based on conditional independence assumptions among variables. Gaussian distributions are widely used in stochastic optimization and in particular in model-based Evolutionary Computation, as in Estimation of Distribution Algorithms and Evolutionary Strategies. By studying natural gradient flows over Gaussian distributions our analysis and results directly apply to the study of CMAES and NES algorithms.},
  isbn = {978-1-4503-3434-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/I7Z6923U/Malagò and Pistone - 2015 - Information Geometry of the Gaussian Distribution .pdf}
}

@inproceedings{malhotra_optimizing_2022,
  title = {Optimizing {{Camera Placements}} for {{Overlapped Coverage}} with {{3D Camera Projections}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Malhotra, Akshay and Singh, Dhananjay and Dadlani, Tushar and Morales, Luis Yoichi},
  year = {2022},
  month = may,
  pages = {5002--5009},
  doi = {10.1109/ICRA46639.2022.9812042},
  abstract = {This paper proposes a method to compute camera 6 DoF poses to achieve a user defined coverage. The camera placement problem is modeled as a combinatorial optimization where given the maximum number of cameras, a camera set is selected from a larger pool of possible camera poses. We propose to minimize the squared error between the desired and the achieved coverage, and formulate the non-linear cost function as a mixed integer linear programming problem. A camera lens model is utilized to project the camera's view on a 3D voxel map to compute a coverage score which makes the optimization problem in real environments tractable. Experimental results in two real retail store environments demonstrate the better performance of the proposed formulation in terms of coverage and overlap for triangulation compared to existing methods.},
  keywords = {Automation,Cameras,Computational modeling,Cost function,Robot vision systems,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/DCVPVCCB/Malhotra et al. - 2022 - Optimizing Camera Placements for Overlapped Covera.pdf;/Users/kshitijgoel/Zotero/storage/6URS6SLJ/9812042.html}
}

@inproceedings{mallasto_learning_2017,
  title = {Learning from Uncertain Curves: {{The}} 2-{{Wasserstein}} Metric for {{Gaussian}} Processes},
  shorttitle = {Learning from Uncertain Curves},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mallasto, Anton and Feragen, Aasa},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/7a006957be65e608e863301eb98e1808-Abstract.html},
  urldate = {2023-09-28},
  abstract = {We introduce a novel framework for statistical analysis of populations of non-degenerate Gaussian processes (GPs), which are natural representations of uncertain curves. This allows inherent variation or uncertainty in function-valued data to be properly incorporated in the population analysis. Using the 2-Wasserstein metric we geometrize the space of GPs with L2 mean and covariance functions over compact index spaces. We prove uniqueness of the barycenter of a population of GPs, as well as convergence of the metric and the barycenter of their finite-dimensional counterparts. This justifies practical computations. Finally, we demonstrate our framework through experimental validation on GP datasets representing brain connectivity and climate development. A Matlab library for relevant computations will be published at https://sites.google.com/view/antonmallasto/software.},
  file = {/Users/kshitijgoel/Zotero/storage/FFWPK9XM/Mallasto and Feragen - 2017 - Learning from uncertain curves The 2-Wasserstein .pdf}
}

@article{manzini_harnessing_2023,
  title = {Harnessing {{AI}} and Robotics in Humanitarian Assistance and Disaster Response},
  author = {Manzini, Thomas and Murphy, Robin R. and Heim, Eric and Robinson, Caleb and Zarrella, Guido and Gupta, Ritwik},
  year = {2023},
  month = jul,
  journal = {Science Robotics},
  volume = {8},
  number = {80},
  pages = {eadj2767},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.adj2767},
  url = {https://www.science.org/doi/10.1126/scirobotics.adj2767},
  urldate = {2023-08-02},
  abstract = {AI and robotics can facilitate humanitarian assistance and disaster response, but partnerships with practitioners are crucial.},
  file = {/Users/kshitijgoel/Zotero/storage/9IVV5A5I/Manzini et al. - 2023 - Harnessing AI and robotics in humanitarian assista.pdf}
}

@article{mao_training_2024,
  title = {The Training Process of Many Deep Networks Explores the Same Low-Dimensional Manifold},
  author = {Mao, Jialin and Griniasty, Itay and Teoh, Han Kheng and Ramesh, Rahul and Yang, Rubing and Transtrum, Mark K. and Sethna, James P. and Chaudhari, Pratik},
  year = {2024},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {12},
  pages = {e2310002121},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2310002121},
  url = {https://www.pnas.org/doi/10.1073/pnas.2310002121},
  urldate = {2024-03-21},
  abstract = {We develop information-geometric techniques to analyze the trajectories of the predictions of deep networks during training. By examining the underlying high-dimensional probabilistic models, we reveal that the training process explores an effectively low-dimensional manifold. Networks with a wide range of architectures, sizes, trained using different optimization methods, regularization techniques, data augmentation techniques, and weight initializations lie on the same manifold in the prediction space. We study the details of this manifold to find that networks with different architectures follow distinguishable trajectories, but other factors have a minimal influence; larger networks train along a similar manifold as that of smaller networks, just faster; and networks initialized at very different parts of the prediction space converge to the solution along a similar manifold.},
  file = {/Users/kshitijgoel/Zotero/storage/WAL7E6UJ/Mao et al. - 2024 - The training process of many deep networks explore.pdf}
}

@article{marcucci_fast_2024,
  title = {Fast {{Path Planning Through Large Collections}} of {{Safe Boxes}}},
  author = {Marcucci, Tobia and Nobel, Parth and Tedrake, Russ and Boyd, Stephen},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {3795--3811},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3434168},
  url = {https://ieeexplore.ieee.org/document/10612232/?arnumber=10612232},
  urldate = {2024-11-14},
  abstract = {We present a fast algorithm for the design of smooth paths (or trajectories) that are constrained to lie in a collection of axis-aligned boxes. We consider the case where the number of these safe boxes is large, and basic preprocessing of them (such as finding their intersections) can be done offline. At runtime, we quickly generate a smooth path between given initial and terminal positions. Our algorithm designs trajectories that are guaranteed to be safe at all times, and detects infeasibility whenever such a trajectory does not exist. Our algorithm is based on two subproblems that we can solve very efficiently: finding a shortest path in a weighted graph, and solving (multiple) convex optimal-control problems. We demonstrate the proposed path planner on large-scale numerical examples, and we provide an efficient open-source software implementation, fastpathplanning.},
  keywords = {Collision avoidance,convex optimization,Costs,Heuristic algorithms,motion and path planning,optimization and optimal control,Planning,Robot kinematics,Robots,Safety,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/WYKL6GNP/Marcucci et al. - 2024 - Fast Path Planning Through Large Collections of Safe Boxes.pdf;/Users/kshitijgoel/Zotero/storage/NARJZACY/10612232.html}
}

@phdthesis{marcucci_graphs_2024,
  type = {Thesis},
  title = {Graphs of {{Convex Sets}} with {{Applications}} to {{Optimal Control}} and {{Motion Planning}}},
  author = {Marcucci, Tobia},
  year = {2024},
  month = may,
  url = {https://dspace.mit.edu/handle/1721.1/156598},
  urldate = {2025-08-13},
  abstract = {This thesis introduces a new class of problems at the interface of combinatorial and convex optimization. We consider graphs where each vertex is paired with a convex program, and each edge couples two programs through additional convex costs and constraints. We call such a graph a Graph of Convex Sets (GCS). Over a GCS we can formulate any optimization problem that we can formulate over an ordinary weighted graph, with scalar costs on the vertices and edges. In fact, for any fixed choice of the variables in the convex programs, a GCS reduces to a weighted graph where we can seek, e.g., a path, a matching, a tour, or a spanning tree of minimum cost. The challenge in a GCS problem lies in solving the discrete and the continuous components of the problem jointly. By combining the modelling power of graphs and convex optimization, GCSs are a flexible framework to formulate and solve many real-world problems. The graph and the combinatorial goal (e.g., finding a path or a tour) model the high-level discrete skeleton of a problem. The convex costs and constraints fill in the low-level continuous details. The primary contribution of this thesis is an efficient and unified method for solving any GCS problem. Starting from an integer-linear-programming formulation of an optimization problem over a weighted graph, this method formulates the corresponding GCS problem as an efficient Mixed-Integer Convex Program (MICP). This MICP can then be solved to global optimality using common branch-and-bound solvers, or approximately by rounding the solution of its convex relaxation. Importantly, both the formulation of the MICP and its solution are fully automatic, and a user of our framework does not need any expertise in mixed-integer optimization. We first describe the GCS framework and the formulation of our MICP in general terms, without presupposing the specific combinatorial problem to be solved over the GCS. We illustrate our techniques through multiple examples spanning logistics, transportation, scheduling, navigation, and computational geometry. Then we focus on the Shortest-Path Problem (SPP) in GCS. This problem is particularly interesting since it generalizes a wide variety of multi-stage decision-making problems and, using our techniques, it can be solved very effectively. We consider two main applications of the SPP in GCS: optimal control of dynamical systems and collision-free motion iplanning. In these two areas, our techniques either generalize or significantly improve upon algorithms and optimization methods that have been developed for decades and are widely used in academia and industry. Lastly, the techniques introduced in this thesis are implemented in the software packages Drake and gcspy. The former is a large and mature software for robotics. It is open-source and widely used by the community. The second is a very simple and lightweight Python package which is also open source. In this thesis, we will illustrate the usage of gcspy through multiple basic examples.},
  copyright = {In Copyright - Educational Use Permitted},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2024-09-03T21:10:34Z},
  file = {/Users/kshitijgoel/Zotero/storage/YTN3BUX4/Marcucci - 2024 - Graphs of Convex Sets with Applications to Optimal Control and Motion Planning.pdf}
}

@article{marcucci_motion_2023,
  title = {Motion Planning around Obstacles with Convex Optimization},
  author = {Marcucci, Tobia and Petersen, Mark and Von Wrangel, David and Tedrake, Russ},
  year = {2023},
  month = nov,
  journal = {Science Robotics},
  volume = {8},
  number = {84},
  pages = {eadf7843},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.adf7843},
  url = {https://www.science.org/doi/10.1126/scirobotics.adf7843},
  urldate = {2024-01-24},
  abstract = {From quadrotors delivering packages in urban areas to robot arms moving in confined warehouses, motion planning around obstacles is a core challenge in modern robotics. Planners based on optimization can design trajectories in high-dimensional spaces while satisfying the robot dynamics. However, in the presence of obstacles, these optimization problems become nonconvex and very hard to solve, even just locally. Thus, when facing cluttered environments, roboticists typically fall back to sampling-based planners that do not scale equally well to high dimensions and struggle with continuous differential constraints. Here, we present a framework that enables convex optimization to efficiently and reliably plan trajectories around obstacles. Specifically, we focus on collision-free motion planning with costs and constraints on the shape, the duration, and the velocity of the trajectory. Using recent techniques for finding shortest paths in Graphs of Convex Sets (GCS), we design a practical convex relaxation of the planning problem. We show that this relaxation is typically very tight, to the point that a cheap postprocessing of its solution is almost always sufficient to identify a collision-free trajectory that is globally optimal (within the parameterized class of curves). Through numerical and hardware experiments, we demonstrate that our planner, which we name GCS, can find better trajectories in less time than widely used sampling-based algorithms and can reliably design trajectories in high-dimensional complex environments.           ,              Convex optimization can reliably design optimal trajectories for robots moving in complex environments with obstacles.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KETIVZB4/Marcucci et al. - 2023 - Motion planning around obstacles with convex optim.pdf}
}

@book{mardia_directional_1999,
  title = {Directional {{Statistics}}},
  author = {Mardia, Kanti V. and Jupp, Peter E.},
  year = {1999},
  month = jan,
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9780470316979},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316979},
  urldate = {2024-06-27},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  isbn = {978-0-471-95333-3 978-0-470-31697-9},
  langid = {english}
}

@book{margalit_interactive_2019,
  title = {Interactive {{Linear Algebra}}},
  author = {Margalit, Dan and Rabinoff, Joseph},
  year = {2019},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8GKZ6538/Margalit and Rabinoff - Interactive Linear Algebra.pdf}
}

@inproceedings{markovic_bearingonly_2012,
  title = {Bearing-Only Tracking with a Mixture of von {{Mises}} Distributions},
  booktitle = {2012 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Markovi{\'c}, Ivan and Petrovi{\'c}, Ivan},
  year = {2012},
  month = oct,
  pages = {707--712},
  issn = {2153-0866},
  doi = {10.1109/IROS.2012.6385600},
  url = {https://ieeexplore.ieee.org/document/6385600},
  urldate = {2024-07-02},
  abstract = {This paper presents a novel method for Bayesian bearing-only tracking. Unlike the classical approaches, which involve using Gaussian distribution, the tracking procedure is completely covered with the von Mises distribution, including state representation, transitional probability, and measurement model, since it captures and models well the peculiarities of directional data. The state is represented with a mixture of von Mises distributions, thus offering advantages of being able to model multimodal distributions, handle nonlinear state transition and measurement models, and to completely cover the whole state space, all with a modest number of parameters. The tracking procedure is solved by convolution with a von Mises distribution (prediction step) and multiplication with a mixture representing the measurement model (update step). Since in the update step the number of mixture components grows exponentially, a method is presented for component reduction of a von Mises mixture. Furthermore, a closed-form solution is derived for quadratic R{\'e}nyi entropy of the von Mises mixture. The algorithm is tested and compared to a particle filter representation in a speaker tracking scenario on a synthetic data set and real-world recordings. The results supported the proposed approach and showed similar performance to the particle filter.},
  keywords = {Atmospheric measurements,Entropy,Gaussian distribution,Hidden Markov models,Kernel,Particle measurements,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/6N5FGIR7/Marković and Petrović - 2012 - Bearing-only tracking with a mixture of von Mises distributions.pdf;/Users/kshitijgoel/Zotero/storage/PP72QE6X/6385600.html}
}

@inproceedings{marks_precise_2022,
  title = {Precise {{3D Reconstruction}} of {{Plants}} from {{UAV Imagery Combining Bundle Adjustment}} and {{Template Matching}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Marks, Elias and Magistri, Federico and Stachniss, Cyrill},
  year = {2022},
  month = may,
  pages = {2259--2265},
  doi = {10.1109/ICRA46639.2022.9811358},
  abstract = {Monitoring individual plants and computing precise 3D reconstructions is highly relevant for crop breeding. In the conventional breeding approach, humans measure phenotypic traits by hand, requiring substantial manual labor. This paper addresses precise 3D plant reconstructions in a crop field or breeding plot based on UAV imagery. We explicitly address the challenges resulting from the thin structures of leaves and naturally occurring self-occlusions. We combine photogrammetric bundle adjustment with a template-based matching approach and produce accurate 3D models that allow us to derive common, geometric traits used by breeders to phenotype plants. We provide a thorough experimental evaluation on commercially used sugar beet breeding plots to illustrate the capabilities of our method as well as its real world applicability.},
  keywords = {Bundle adjustment,Crops,Image segmentation,Point cloud compression,Semantics,Shape,Solid modeling},
  file = {/Users/kshitijgoel/Zotero/storage/H9SKKJM5/Marks et al. - 2022 - Precise 3D Reconstruction of Plants from UAV Image.pdf;/Users/kshitijgoel/Zotero/storage/LCGP4H3K/9811358.html}
}

@article{marsaglia_evaluating_2004,
  title = {Evaluating the {{Normal Distribution}}},
  author = {Marsaglia, George},
  year = {2004},
  month = jul,
  journal = {Journal of Statistical Software},
  volume = {11},
  pages = {1--11},
  issn = {1548-7660},
  doi = {10.18637/jss.v011.i04},
  url = {https://doi.org/10.18637/jss.v011.i04},
  urldate = {2024-07-24},
  abstract = {This article provides a little table-free C function that evaluates the normal distribution with absolute error less than 8 x 10 -16 . A small extension provides relative error near the limit available in double precision: 14 to 16 digits, the limits determined mainly by the computer's ability to evaluate exp(-t) for large t. Results are compared with those provided by calls to erf or erfc functions, the best of which compare favorably, others do not, and all appear to be much more complicated than need be to get either absolute accuracy less than 10-15 or relative accuracy to the exp()-limited 14 to 16 digits. Also provided: A short history of the error function erf and its intended use, as well as, in the "browse files" attachment, various erf or erfc versions used for comparison.},
  copyright = {Copyright (c) 2004 George Marsaglia},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/N83UIGIK/Marsaglia - 2004 - Evaluating the Normal Distribution.pdf}
}

@article{marsaglia_ratios_1965,
  title = {Ratios of {{Normal Variables}} and {{Ratios}} of {{Sums}} of {{Uniform Variables}}},
  author = {Marsaglia, George},
  year = {1965},
  journal = {Journal of the American Statistical Association},
  volume = {60},
  number = {309},
  eprint = {2283145},
  eprinttype = {jstor},
  pages = {193--204},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2283145},
  url = {https://www.jstor.org/stable/2283145},
  urldate = {2024-07-24},
  abstract = {The principal part of this paper is devoted to the study of the distribution and density functions of the ratio of two normal random variables. It gives several representations of the distribution function in terms of the variate normal distribution of Nicholson's V function, both of which have been extensively studied, and for which tables and computational procedures are readily available. One of these representations leads to an easy derivation of the density function in terms of the Cauchy density and the normal density and integral. A number of graphs of the possible shapes of the density are given, together with an indication of when the density is unimodal or bimodal. The last part of the paper discusses the distribution of the ratio (u\textsubscript{1} + {$\cdots$} + u\textsubscript{n})/(v\textsubscript{1} + {$\cdots$} + v\textsubscript{m}) where the u's and v's are independent, uniform variables. The exact distribution for all n and m is given, and some approximations discussed.},
  file = {/Users/kshitijgoel/Zotero/storage/ELA9PK3S/Marsaglia - 1965 - Ratios of Normal Variables and Ratios of Sums of Uniform Variables.pdf}
}

@article{marsaglia_ratios_2006,
  title = {Ratios of {{Normal Variables}}},
  author = {Marsaglia, George},
  year = {2006},
  month = may,
  journal = {Journal of Statistical Software},
  volume = {16},
  pages = {1--10},
  issn = {1548-7660},
  doi = {10.18637/jss.v016.i04},
  url = {https://doi.org/10.18637/jss.v016.i04},
  urldate = {2024-07-24},
  abstract = {This article extends and amplifies on results from a paper of over forty years ago. It provides software for evaluating the density and distribution functions of the ratio z/w for any two jointly normal variates z,w, and provides details on methods for transforming a general ratio z/w into a standard form, (a+x)/(b+y) , with x and y independent standard normal and a, b non-negative constants. It discusses handling general ratios when, in theory, none of the moments exist yet practical considerations suggest there should be approximations whose adequacy can be verified by means of the included software. These approximations show that many of the ratios of normal variates encountered in practice can themselves be taken as normally distributed. A practical rule is developed: If a {$<$} 2.256 and 4 {$<$} b then the ratio (a+x)/(b+y) is itself approximately normally distributed with mean {$\mu$} = a/(1.01b - .2713) and variance {$\sigma$}2 = (a2 + 1)/(b2 + .108b - 3.795) {$\mu$}2.},
  copyright = {Copyright (c) 2006 George Marsaglia},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XDVC3CVT/Marsaglia - 2006 - Ratios of Normal Variables.pdf}
}

@misc{marsal_simple_2025,
  title = {A {{Simple}} yet {{Effective Test-Time Adaptation}} for {{Zero-Shot Monocular Metric Depth Estimation}}},
  author = {Marsal, R{\'e}mi and Chapoutot, Alexandre and Xu, Philippe and Filliat, David},
  year = {2025},
  month = mar,
  number = {arXiv:2412.14103},
  eprint = {2412.14103},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.14103},
  url = {http://arxiv.org/abs/2412.14103},
  urldate = {2025-08-09},
  abstract = {The recent development of foundation models for monocular depth estimation such as Depth Anything paved the way to zero-shot monocular depth estimation. Since it returns an affine-invariant disparity map, the favored technique to recover the metric depth consists in fine-tuning the model. However, this stage is not straightforward, it can be costly and time-consuming because of the training and the creation of the dataset. The latter must contain images captured by the camera that will be used at test time and the corresponding ground truth. Moreover, the fine-tuning may also degrade the generalizing capacity of the original model. Instead, we propose in this paper a new method to rescale Depth Anything predictions using 3D points provided by sensors or techniques such as low-resolution LiDAR or structure-from-motion with poses given by an IMU. This approach avoids fine-tuning and preserves the generalizing power of the original depth estimation model while being robust to the noise of the sparse depth or of the depth model. Our experiments highlight enhancements relative to zero-shot monocular metric depth estimation methods, competitive results compared to fine-tuned approaches and a better robustness than depth completion approaches. Code available at https://gitlab.ensta.fr/ssh/monocular-depth-rescaling.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/Q4A5YQVM/Marsal et al. - 2025 - A Simple yet Effective Test-Time Adaptation for Zero-Shot Monocular Metric Depth Estimation.pdf;/Users/kshitijgoel/Zotero/storage/XVHD5SDE/2412.html}
}

@book{marsden_introduction_1999,
  title = {Introduction to {{Mechanics}} and {{Symmetry}}: {{A Basic Exposition}} of {{Classical Mechanical Systems}}},
  shorttitle = {Introduction to {{Mechanics}} and {{Symmetry}}},
  author = {Marsden, Jerrold E. and Ratiu, Tudor S.},
  editor = {Marsden, Jerrold E. and Sirovich, L. and Golubitsky, M. and J{\"a}ger, W.},
  year = {1999},
  series = {Texts in {{Applied Mathematics}}},
  volume = {17},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-21792-5},
  url = {http://link.springer.com/10.1007/978-0-387-21792-5},
  urldate = {2024-07-21},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4419-3143-6 978-0-387-21792-5},
  langid = {english},
  keywords = {bifurcation,dynamical systems,Lagrangian mechanics,lie group,manifold,mathematics,mechanics,Rigid body,stability},
  file = {/Users/kshitijgoel/Zotero/storage/AVTEDQQA/Marsden and Ratiu - 1999 - Introduction to Mechanics and Symmetry A Basic Exposition of Classical Mechanical Systems.pdf}
}

@article{marshall_guidance_2021,
  title = {A {{Guidance System}} for {{Tactical Autonomous Unmanned Aerial Vehicles}}},
  author = {Marshall, Julius A. and Anderson, Robert B. and Chien, Wen-Yu and Johnson, Eric N. and L'Afflitto, Andrea},
  year = {2021},
  month = nov,
  journal = {Journal of Intelligent \& Robotic Systems},
  volume = {103},
  number = {4},
  pages = {71},
  issn = {1573-0409},
  doi = {10.1007/s10846-021-01526-8},
  url = {https://doi.org/10.1007/s10846-021-01526-8},
  urldate = {2025-01-03},
  abstract = {This paper presents an original guidance system able to confer a tactical behavior to multi-rotor unmanned aerial vehicles (UAVs), such as quadcopters, that operate in potentially hostile, unknown, cluttered environments. By applying this guidance system, UAVs complete the assigned tasks, such as reaching a goal set, while minimizing both their exposure to opponents, whose location is unknown, and the predictability of their trajectories. A taxonomy of flight behaviors is provided to help users tuning those parameters that characterize the UAV's level of cautiousness. This guidance system is supported by an original navigation system that exploits exclusively information gathered by onboard cameras and inertial measurement units. Numerical simulations and flight tests validate the applicability of the proposed guidance system in real-time, while performing all calculations aboard the UAV.},
  langid = {english},
  keywords = {Artificial Intelligence,Path planning,Tactical behavior,Trajectory planning,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/E8PMJZ24/Marshall et al. - 2021 - A Guidance System for Tactical Autonomous Unmanned Aerial Vehicles.pdf}
}

@article{martens_geometric_2017,
  title = {Geometric {{Priors}} for {{Gaussian Process Implicit Surfaces}}},
  author = {Martens, Wolfram and Poffet, Yannick and Soria, Pablo Ram{\'o}n and Fitch, Robert and Sukkarieh, Salah},
  year = {2017},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {2},
  pages = {373--380},
  issn = {2377-3766},
  doi = {10.1109/LRA.2016.2631260},
  abstract = {This paper presents an extension of Gaussian process implicit surfaces (GPIS) by the introduction of geometric object priors. The proposed method enhances the probabilistic reconstruction of objects from three-dimensional (3-D) pointcloud data, providing a rigorous way of incorporating prior knowledge about objects expected in a scene. The key ideas, including the systematic use of surface normal information, are illustrated with one-dimensional and two-dimensional examples, and then applied to simulated and real pointcloud data for 3-D objects. The performance of our method is demonstrated in two different application scenarios, using complete and partial surface observations. Qualitative and quantitative analysis of the results reveals the superiority of the proposed approach over existing GPIS configurations that do not exploit prior knowledge.},
  keywords = {Agricultural automation,categorization,Gaussian processes,object detection,Probabilistic logic,probability and statistical methods,rgb-d perception,Robots,segmentation,Shape,Surface reconstruction,Surface treatment,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/E5CS34YE/Martens et al. - 2017 - Geometric Priors for Gaussian Process Implicit Sur.pdf;/Users/kshitijgoel/Zotero/storage/ABEVL3Q5/7750586.html}
}

@article{martinelli_vision_2012,
  title = {Vision and {{IMU Data Fusion}}: {{Closed-Form Solutions}} for {{Attitude}}, {{Speed}}, {{Absolute Scale}}, and {{Bias Determination}}},
  shorttitle = {Vision and {{IMU Data Fusion}}},
  author = {Martinelli, Agostino},
  year = {2012},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {28},
  number = {1},
  pages = {44--60},
  issn = {1941-0468},
  doi = {10.1109/TRO.2011.2160468},
  url = {https://ieeexplore.ieee.org/abstract/document/5959226},
  urldate = {2024-12-17},
  abstract = {This paper investigates the problem of vision and inertial data fusion. A sensor assembling that is constituted by one monocular camera, three orthogonal accelerometers, and three orthogonal gyroscopes is considered. The first paper contribution is the analytical derivation of all the observable modes, i.e., all the physical quantities that can be determined by only using the information in the sensor data that are acquired during a short time interval. Specifically, the observable modes are the speed and attitude (roll and pitch angles), the absolute scale, and the biases that affect the inertial measurements. This holds even in the case when the camera only observes a single point feature. The analytical derivation of the aforementioned observable modes is based on a nonstandard observability analysis, which fully accounts for the system nonlinearities. The second contribution is the analytical derivation of closed-form solutions, which analytically express all the aforementioned observable modes in terms of the visual and inertial measurements that are collected during a very short time interval. This allows the introduction of a very simple and powerful new method that is able to simultaneously estimate all the observable modes with no need for any initialization or a priori knowledge. Both the observability analysis and the derivation of the closed-form solutions are carried out in several different contexts, including the case of biased and unbiased inertial measurements, the case of a single and multiple features, and in the presence and absence of gravity. In addition, in all these contexts, the minimum number of camera images that are necessary for the observability is derived. The performance of the proposed approach is evaluated via extensive Monte Carlo simulations and real experiments.},
  keywords = {Accelerometers,Aerial robotics,Cameras,Closed-form solution,computer vision,nonlinear observability,Observability,Robot sensing systems,sensor fusion,Vehicles,vision-aided inertial navigation},
  file = {/Users/kshitijgoel/Zotero/storage/IPA2JYB6/Martinelli - 2012 - Vision and IMU Data Fusion Closed-Form Solutions for Attitude, Speed, Absolute Scale, and Bias Dete.pdf}
}

@inproceedings{martinez-cantin_active_2008,
  title = {Active {{Map Learning}} for {{Robots}}: {{Insights}} into {{Statistical Consistency}}},
  shorttitle = {Active {{Map Learning}} for {{Robots}}},
  author = {{Martinez-Cantin}, Ruben},
  year = {2008},
  url = {https://www.semanticscholar.org/paper/Active-Map-Learning-for-Robots%3A-Insights-into-Martinez-Cantin/12ed176406d01dfa1b9d7814f5a96cb1a8fa182c},
  urldate = {2024-03-01},
  abstract = {The problem of learning unknown environments in mobile robotics is called SLAM (Simultaneous Localization and Mapping). Furthermore, if the robot has to take some decision, it is called active SLAM or just exploration. The current SLAM methods are rooted on the strong probabilistic formulation in the form of Bayesian filters. There are extensions of this formulation in the field of decision making in uncertain environments that allows to solve the problem in an active and autonomous way, using, for example, MDPs (Markov Decision Processes). On the one hand, the huge dimensionality of the SLAM problem (temporal, spacial and statistical), make it mathematically intractable. There is no optimal solution. However, there are suboptimal solutions presented in the current literature based on approximations of the Extended Kalman Filter (EKF) or in sampling methods, like the Rao-Blackwellized Particle Filter (RBPF), but they suffer from certain statistical inconsistency that results in corrupt or totally wrong solutions in the long term. On the other hand, that huge complexity also implies that current MDPs techniques -value iteration, policy iteration and trees or gradients based policy searchonly provide partial solutions or they can only solve unrealistic toy problems. In this thesis, we analize the statistical properties of the SLAM problem and the most extended algorithms, especially their error sources. In this way, we investigate the applicability of second order linear approximations like the Unscented Kalman Filter (UKF), advanced sampling methods like the Marginal Particle Filter (MPF) or stochastic approximation based estimation. In theory, these algorithms outperform the statistical consistency of the previous ones, this is validated in the corresponding experiments. Additionally, we investigate more efficient policy search algorithms to solve the complex problem of decision making. In this way, we work with efficient global optimization algorithms for policy search. This work is highly related with active parameter learning using Gaussian processes.},
  file = {/Users/kshitijgoel/Zotero/storage/PZKJIVE5/Martinez-Cantin - 2008 - Active Map Learning for Robots Insights into Stat.pdf}
}

@inproceedings{marza_multiobject_2023,
  title = {Multi-{{Object Navigation}} with Dynamically Learned Neural Implicit Representations},
  booktitle = {2023 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Marza, Pierre and Matignon, Laetitia and Simonin, Olivier and Wolf, Christian},
  year = {2023},
  month = oct,
  pages = {10970--10981},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICCV51070.2023.01010},
  url = {https://ieeexplore.ieee.org/document/10377220/},
  urldate = {2024-01-24},
  abstract = {Understanding and mapping a new environment are core abilities of any autonomously navigating agent. While classical robotics usually estimates maps in a stand-alone manner with SLAM variants, which maintain a topological or metric representation, end-to-end learning of navigation keeps some form of memory in a neural network. Networks are typically imbued with inductive biases, which can range from vectorial representations to birds-eye metric tensors or topological structures. In this work, we propose to structure neural networks with two neural implicit representations, which are learned dynamically during each episode and map the content of the scene: (i) the Semantic Finder predicts the position of a previously seen queried object; (ii) the Occupancy and Exploration Implicit Representation encapsulates information about explored area and obstacles, and is queried with a novel global read mechanism which directly maps from function space to a usable embedding space. Both representations are leveraged by an agent trained with Reinforcement Learning (RL) and learned online during each episode. We evaluate the agent on Multi-Object Navigation and show the high impact of using neural implicit representations as a memory source.},
  isbn = {979-8-3503-0718-4},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/699YSJWT/Marza et al. - 2023 - Multi-Object Navigation with dynamically learned n.pdf}
}

@inproceedings{marzouqi_covert_2005,
  title = {Covert Path Planning in Unknown Environments with Known or Suspected Sentry Location},
  booktitle = {2005 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Marzouqi, M. and Jarvis, R.A.},
  year = {2005},
  month = aug,
  pages = {1772--1778},
  issn = {2153-0866},
  doi = {10.1109/IROS.2005.1545483},
  url = {https://ieeexplore.ieee.org/document/1545483/},
  urldate = {2025-08-01},
  abstract = {This paper describes an approach for solving a visibility-based covert path planning problem. It is an extension to our research on covert robotics which aims to create robots with the ability to achieve different covert navigation missions. A promising method is presented that allows a mobile robot in a complex, initially unknown environment to discover a path to a nominated destination with minimum exposure to sentries' at known locations within the same environment. The sentries' locations are known initially, suspected, or discovered during navigation. The presented method estimates a cost value at each non-obstacle location that represents a risk of being visible, given the accumulated map knowledge. A global covert path is generated by propagating the estimated cost values using the distance transform algorithm. The approach has been evaluated on both simulated and real environments. A number of test cases are presented; each shows a generated path with considerable covertness compared to a short path (but perhaps risky) to the same destination.},
  keywords = {Costs,Humans,Intelligent robots,Mobile robots,Navigation,Observability,Orbital robotics,Path planning,Surveillance,Testing},
  file = {/Users/kshitijgoel/Zotero/storage/F3EDNMFH/Marzouqi and Jarvis - 2005 - Covert path planning in unknown environments with known or suspected sentry location.pdf}
}

@article{mascaro_scene_2024,
  title = {Scene {{Representations}} for {{Robotic Spatial Perception}}},
  author = {Mascaro, Ruben and Chli, Margarita},
  year = {2024},
  month = nov,
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  issn = {2573-5144},
  doi = {10.1146/annurev-control-040423-030709},
  url = {https://www.annualreviews.org/content/journals/10.1146/annurev-control-040423-030709},
  urldate = {2024-11-22},
  abstract = {The ability of a robot to build a persistent, accurate, and actionable model of its surroundings through sensor data in a timely manner is crucial for autonomous operation. While representing the world as a point cloud might be sufficient for localization, denser scene representations are required for obstacle avoidance. On the other hand, higher-level semantic information is often crucial for breaking down the necessary steps to autonomously complete a complex task, such as cooking. So the looming question is, What is a suitable scene representation for the robotic task at hand? This survey provides a comprehensive review of key approaches and frameworks driving progress in the field of robotic spatial perception, with a particular focus on the historical evolution and current trends in representation. By categorizing scene modeling techniques into three main types---metric, metric--semantic, and metric--semantic--topological---we discuss how spatial perception frameworks are transitioning from building purely geometric models of the world to more advanced data structures incorporating higher-level concepts, such as the notion of object instances and places. Special emphasis is placed on approaches for real-time simultaneous localization and mapping, their integration with deep learning for enhanced robustness and scene understanding, and their ability to handle scene dynamicity as some of the hottest topics of interest driving robotics research today. We conclude with a discussion of ongoing challenges and future research directions in the quest to develop robust and scalable spatial perception systems suitable for long-term autonomy.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IVR7U8RH/Mascaro and Chli - 2024 - Scene Representations for Robotic Spatial Perception.pdf}
}

@book{mathai_quadratic_1992,
  title = {Quadratic {{Forms}} in {{Random Variables}}: {{Theory}} and {{Applications}}},
  shorttitle = {Quadratic {{Forms}} in {{Random Variables}}},
  author = {Mathai, A. M. and Provost, S. B.},
  year = {1992},
  publisher = {Marcel Dek ker},
  langid = {english}
}

@inproceedings{matsuki_gaussian_2024,
  title = {Gaussian {{Splatting SLAM}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Matsuki, Hidenobu and Murai, Riku and Kelly, Paul H. J. and Davison, Andrew J.},
  year = {2024},
  pages = {18039--18048},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Matsuki_Gaussian_Splatting_SLAM_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/94ZUCQU2/Matsuki et al. - 2024 - Gaussian Splatting SLAM.pdf}
}

@inproceedings{matsumoto_realtime_2014,
  title = {Real-Time Enhancement of {{RGB-D}} Point Clouds Using Piecewise Plane Fitting},
  booktitle = {2014 5th {{European Workshop}} on {{Visual Information Processing}} ({{EUVIP}})},
  author = {Matsumoto, Kazuki and {de Sorbier}, Francois and Saito, Hideo},
  year = {2014},
  month = dec,
  pages = {1--6},
  doi = {10.1109/EUVIP.2014.7018365},
  url = {https://ieeexplore.ieee.org/document/7018365/?arnumber=7018365},
  urldate = {2025-01-09},
  abstract = {In this paper, we propose an efficient framework for reducing noise and holes in depth map captured with an RGB-D camera. This is performed by applying plane fitting to the groups of points assimilable to planar structures and filtering the curved surface points. We present a new method for finding global planar structures in a 3D scene by combining superpixel segmentation and graph component labeling. The superpixel segmentation is based on not only color information but also depth and normal maps. The labeling process is carried out by considering each normal in given superpixel's clusters. We evaluate the reliability of each plane structure and apply the plane fitting only to true planar surfaces. As a result, our system can reduce the noise of the depth map especially on planar area while preserving curved surfaces. The process is done in real-time thanks to GPGPU acceleration via CUDA architecture.},
  keywords = {Cameras,Clustering algorithms,GPU,Image color analysis,Joints,Labeling,Noise,Noise Reduction,Plane Fitting,RGB-D camera,Superpixel,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/SYUP6CVV/Matsumoto et al. - 2014 - Real-time enhancement of RGB-D point clouds using piecewise plane fitting.pdf;/Users/kshitijgoel/Zotero/storage/GJ2EPVR8/7018365.html}
}

@article{mattingly_maximizing_2018,
  title = {Maximizing the Information Learned from Finite Data Selects a Simple Model},
  author = {Mattingly, Henry H. and Transtrum, Mark K. and Abbott, Michael C. and Machta, Benjamin B.},
  year = {2018},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {8},
  pages = {1760--1765},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1715306115},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1715306115},
  urldate = {2024-04-25},
  abstract = {We use the language of uninformative Bayesian prior choice to study the selection of appropriately simple effective models. We advocate for the prior which maximizes the mutual information between parameters and predictions, learning as much as possible from limited data. When many parameters are poorly constrained by the available data, we find that this prior puts weight only on boundaries of the parameter space. Thus, it selects a lower-dimensional effective theory in a principled way, ignoring irrelevant parameter directions. In the limit where there are sufficient data to tightly constrain any number of parameters, this reduces to the Jeffreys prior. However, we argue that this limit is pathological when applied to the hyperribbon parameter manifolds generic in science, because it leads to dramatic dependence on effects invisible to experiment.},
  file = {/Users/kshitijgoel/Zotero/storage/W59ZD76G/Mattingly et al. - 2018 - Maximizing the information learned from finite dat.pdf}
}

@phdthesis{maurya_investigation_2022,
  title = {{{INVESTIGATION OF COMPOUND ROTORCRAFT AEROMECHANICS THROUGH WIND-TUNNEL TESTING AND ANALYSIS}}},
  author = {Maurya, Shashank},
  year = {2022},
  eprint = {1903/29552},
  eprinttype = {hdl},
  url = {http://hdl.handle.net/1903/29552},
  urldate = {2024-05-29},
  abstract = {The aeromechanics of a slowed-rotor compound rotorcraft is investigated through wind-tunnel testing and comprehensive analysis. The emphasis is on a lift-offset wing compound with a hingeless rotor configuration. A new Maryland Compound Rig is developed and instrumented for wind-tunnel testing and an in-house rotor comprehensive code is modified and expanded for compound rotorcraft analysis. The compound rig consists of a lift compound model and a propeller model. The lift compound model consists of an interchangeable hub (articulated or hingeless), a fuselage, a half-wing of 70\% rotor radius on the retreating side. The wing has a dedicated load cell and multiple attachment points relative to the rotor hub (16\%R, 24\%R, and 32\%R and 5\%R aft of the hub). The rotor diameter is 5.7-ft. The rotor has four blades with NACA 0012 airfoils with no twist and no taper. The wing incidence angle is variable between 0 to 12 degrees. The wing has a linearly varying thickness with symmetric airfoils NACA 0015 at the tip and NACA 0020 at the root. Sensors can measure rotor hub forces and moments, wing root forces and moments, blade pitch angles, structural loads (flap bending moment, lagbending moment, and torsional moment) at 25\%R, pitch link loads, and hub vibratory loads. Wind tunnel tests are conducted up to advance ratio 0.7 for lift compound with half-wing at wing incidence angles of 4 and 8 degrees and compared with an isolated rotor. Hover tests are conducted up to tip Mach number of 0.5 to measure download penalty with the wing at various positions. The University of Maryland Advanced Rotorcraft Code (UMARC) is modified for compound rotorcraft analysis code. Aerodynamic models for the wing and the propeller are integrated. A recently developed Maryland Free Wake model is integrated, which can model the wake interaction between unequal and inharmonic speed rotor, wing, and propeller. The analysis is then validated with the test data. The validated analysis is used to analyze the US Army hypothetical full-scale aircraft. The compound rotorcraft is categorized into multiple configurations in a systematic manner to find the extreme limits of speed and efficiency of each. The key conclusions are: 1) slowing the rotor or compounding the configuration provide no benefit individually; they must be accomplished together, 2) Half-Wing is more beneficial if a lift-offset hingeless rotor is used, 3) hover download penalty is only 3\% of net thrust, and this penalty can be predicted satisfactorily by free wake, 4) the main rotor wake interaction is more pronounced on the wing and less on the propeller, 5) the validated analysis indicates a speed of 240 knots may be possible with 20\% RPM reduction along with a wing and propeller, if structural weights allow, and 6) the oscillatory and vibratory lag moments and in-plane hub loads may be significantly reduced by compounding.},
  langid = {english},
  school = {University of Maryland, College Park},
  file = {/Users/kshitijgoel/Zotero/storage/AM8XCPMS/Maurya - 2022 - INVESTIGATION OF COMPOUND ROTORCRAFT AEROMECHANICS THROUGH WIND-TUNNEL TESTING AND ANALYSIS.pdf}
}

@misc{mcallister_flow_2025,
  title = {Flow {{Matching Policy Gradients}}},
  author = {McAllister, David and Ge, Songwei and Yi, Brent and Kim, Chung Min and Weber, Ethan and Choi, Hongsuk and Feng, Haiwen and Kanazawa, Angjoo},
  year = {2025},
  month = aug,
  number = {arXiv:2507.21053},
  eprint = {2507.21053},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.21053},
  url = {http://arxiv.org/abs/2507.21053},
  urldate = {2025-08-07},
  abstract = {Flow-based generative models, including diffusion models, excel at modeling continuous distributions in high-dimensional spaces. In this work, we introduce Flow Policy Optimization (FPO), a simple on-policy reinforcement learning algorithm that brings flow matching into the policy gradient framework. FPO casts policy optimization as maximizing an advantage-weighted ratio computed from the conditional flow matching loss, in a manner compatible with the popular PPO-clip framework. It sidesteps the need for exact likelihood computation while preserving the generative capabilities of flow-based models. Unlike prior approaches for diffusion-based reinforcement learning that bind training to a specific sampling method, FPO is agnostic to the choice of diffusion or flow integration at both training and inference time. We show that FPO can train diffusion-style policies from scratch in a variety of continuous control tasks. We find that flow-based models can capture multimodal action distributions and achieve higher performance than Gaussian policies, particularly in under-conditioned settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/MWD7G2QD/McAllister et al. - 2025 - Flow Matching Policy Gradients.pdf;/Users/kshitijgoel/Zotero/storage/PSLQSRV6/2507.html}
}

@book{mccullagh_tensor_2018,
  title = {Tensor Methods in Statistics},
  author = {McCullagh, P.},
  year = {2018},
  edition = {Second Dover edition},
  publisher = {Dover Publications},
  address = {Mineola, New York},
  isbn = {978-0-486-82378-2},
  lccn = {QA433 .M325 2018},
  keywords = {Calculus of tensors,Mathematical statistics},
  file = {/Users/kshitijgoel/Zotero/storage/XRAVKQMT/DoverEdition.pdf}
}

@inproceedings{mcfassel_every_2021,
  title = {Every {{Action-Based Sensor}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIV}}},
  author = {McFassel, Grace and Shell, Dylan A.},
  editor = {LaValle, Steven M. and Lin, Ming and Ojala, Timo and Shell, Dylan and Yu, Jingjin},
  year = {2021},
  pages = {176--193},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-66723-8_11},
  abstract = {In studying robots and planning problems, a basic question is what is the minimal information a robot must obtain to guarantee task completion. Erdmann's theory of action-based sensors is a classical approach to characterizing fundamental information requirements. That approach uses a plan to derive a type of virtual sensor which prescribes actions that make progress toward a goal. We show that the established theory is incomplete: the previous method for obtaining such sensors, using backchained plans, overlooks some sensors. Furthermore, there are plans, that are guaranteed to achieve goals, where the existing methods are unable to provide any action-based sensor. We identify the underlying feature common to all such plans. Then, we show how to produce action-based sensors even for plans where the existing treatment is inadequate, although for these cases they have no single canonical sensor. Consequently, the approach is generalized to produce sets of sensors. Finally, we show also that this is a complete characterization of action-based sensors for planning problems and discuss how an action-based sensor translates into the traditional conception of a sensor.},
  isbn = {978-3-030-66723-8},
  langid = {english},
  keywords = {Abstract sensors,Planning problems,Robot design problems},
  file = {/Users/kshitijgoel/Zotero/storage/GGHIMTWG/McFassel and Shell - 2021 - Every Action-Based Sensor.pdf}
}

@article{mcgrew_aircombat_2010,
  title = {Air-{{Combat Strategy Using Approximate Dynamic Programming}}},
  author = {McGrew, James S. and How, Jonathon P. and Williams, Brian and Roy, Nicholas},
  year = {2010},
  journal = {Journal of Guidance, Control, and Dynamics},
  volume = {33},
  number = {5},
  pages = {1641--1654},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0731-5090},
  doi = {10.2514/1.46815},
  url = {https://doi.org/10.2514/1.46815},
  urldate = {2025-08-12},
  file = {/Users/kshitijgoel/Zotero/storage/CCPBVUAT/McGrew et al. - 2010 - Air-Combat Strategy Using Approximate Dynamic Programming.pdf;/Users/kshitijgoel/Zotero/storage/AKP8HZGX/1.html}
}

@book{mclachlan_em_2008,
  title = {The {{EM Algorithm}} and {{Extensions}}, {{2E}}},
  author = {McLachlan, Geoffrey J. and Krishnan, Thriyambakam},
  year = {2008},
  month = feb,
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  publisher = {John Wiley \& Sons, Inc.},
  address = {Hoboken, NJ, USA},
  doi = {10.1002/9780470191613},
  url = {http://doi.wiley.com/10.1002/9780470191613},
  urldate = {2024-06-27},
  isbn = {978-0-470-19161-3 978-0-471-20170-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VU9FFXL7/McLachlan and Krishnan - 2008 - The EM Algorithm and Extensions, 2E.pdf}
}

@book{mclachlan_finite_2000,
  title = {Finite {{Mixture Models}}},
  author = {McLachlan, Geoffrey and Peel, David},
  year = {2000},
  month = sep,
  series = {Wiley {{Series}} in {{Probability}} and {{Statistics}}},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/0471721182},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/0471721182},
  urldate = {2024-06-27},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  isbn = {978-0-471-00626-8 978-0-471-72118-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AZKMH2UF/McLachlan and Peel - 2000 - Finite Mixture Models.pdf}
}

@article{mclachlan_finite_2019,
  title = {Finite {{Mixture Models}}},
  author = {McLachlan, Geoffrey J. and Lee, Sharon X. and Rathnayake, Suren I.},
  year = {2019},
  journal = {Annual Review of Statistics and Its Application},
  volume = {6},
  number = {1},
  pages = {355--378},
  doi = {10.1146/annurev-statistics-031017-100325},
  url = {https://doi.org/10.1146/annurev-statistics-031017-100325},
  urldate = {2023-04-21},
  abstract = {The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and general scientific literature. The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis. It has now been three decades since the publication of the monograph by McLachlan \& Basford (1988) with an emphasis on the potential usefulness of mixture models for inference and clustering. Since then, mixture models have attracted the interest of many researchers and have found many new and interesting fields of application. Thus, the literature on mixture models has expanded enormously, and as a consequence, the bibliography here can only provide selected coverage.},
  keywords = {EM algorithm,mixture proportions,mixtures of factor analyzers,model-based clustering,normal and t-mixture distributions},
  file = {/Users/kshitijgoel/Zotero/storage/ZE8EDHQY/McLachlan et al. - 2019 - Finite Mixture Models.pdf}
}

@article{mclachlan_number_2014,
  title = {On the Number of Components in a {{Gaussian}} Mixture Model: {{Number}} of Components in a {{Gaussian}} Mixture Model},
  shorttitle = {On the Number of Components in a {{Gaussian}} Mixture Model},
  author = {McLachlan, Geoffrey J. and Rathnayake, Suren},
  year = {2014},
  month = sep,
  journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume = {4},
  number = {5},
  pages = {341--355},
  issn = {19424787},
  doi = {10.1002/widm.1135},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/widm.1135},
  urldate = {2021-12-22},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PN6ZVMGJ/McLachlan and Rathnayake - 2014 - On the number of components in a Gaussian mixture .pdf}
}

@inproceedings{mcmahan_communicationefficient_2017,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  year = {2017},
  month = apr,
  pages = {1273--1282},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v54/mcmahan17a.html},
  urldate = {2024-11-06},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.  We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.  We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2W8IDRA7/McMahan et al. - 2017 - Communication-Efficient Learning of Deep Networks from Decentralized Data.pdf;/Users/kshitijgoel/Zotero/storage/4EQWP8AS/McMahan et al. - 2017 - Communication-Efficient Learning of Deep Networks from Decentralized Data.pdf}
}

@inproceedings{mei_overlapguided_2023,
  title = {Overlap-Guided {{Gaussian Mixture Models}} for {{Point Cloud Registration}}},
  booktitle = {2023 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Mei, Guofeng and Poiesi, Fabio and Saltori, Cristiano and Zhang, Jian and Ricci, Elisa and Sebe, Nicu},
  year = {2023},
  month = jan,
  pages = {4500--4509},
  publisher = {IEEE},
  address = {Waikoloa, HI, USA},
  doi = {10.1109/WACV56688.2023.00449},
  url = {https://ieeexplore.ieee.org/document/10030418/},
  urldate = {2024-02-04},
  isbn = {978-1-6654-9346-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KIWGXRWT/Mei et al. - 2023 - Overlap-guided Gaussian Mixture Models for Point C.pdf}
}

@inproceedings{meier_pixhawk_2011,
  title = {{{PIXHAWK}}: {{A}} System for Autonomous Flight Using Onboard Computer Vision},
  shorttitle = {{{PIXHAWK}}},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Meier, Lorenz and Tanskanen, Petri and Fraundorfer, Friedrich and Pollefeys, Marc},
  year = {2011},
  month = may,
  pages = {2992--2997},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980229},
  url = {https://ieeexplore.ieee.org/abstract/document/5980229},
  urldate = {2023-11-14},
  abstract = {We provide a novel hardware and software system for micro air vehicles (MAV) that allows high-speed, low-latency onboard image processing. It uses up to four cameras in parallel on a miniature rotary wing platform. The MAV navigates based on onboard processed computer vision in GPS-denied in- and outdoor environments. It can process in parallel images and inertial measurement information from multiple cameras for multiple purposes (localization, pattern recognition, obstacle avoidance) by distributing the images on a central, low-latency image hub. Furthermore the system can utilize low-bandwith radio links for communication and is designed and optimized to scale to swarm use. Experimental results show successful flight with a range of onboard computer vision algorithms, including localization, obstacle avoidance and pattern recognition.},
  file = {/Users/kshitijgoel/Zotero/storage/6P86RSHC/Meier et al. - 2011 - PIXHAWK A system for autonomous flight using onbo.pdf}
}

@misc{meijer_pushing_2024,
  title = {Pushing the {{Limits}} of {{Reactive Planning}}: {{Learning}} to {{Escape Local Minima}}},
  shorttitle = {Pushing the {{Limits}} of {{Reactive Planning}}},
  author = {Meijer, Isar and Pantic, Michael and Oleynikova, Helen and Siegwart, Roland},
  year = {2024},
  month = jul,
  number = {arXiv:2407.13530},
  eprint = {2407.13530},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.13530},
  url = {http://arxiv.org/abs/2407.13530},
  urldate = {2025-01-13},
  abstract = {When does a robot planner need a map? Reactive methods that use only the robot's current sensor data and local information are fast and flexible, but prone to getting stuck in local minima. Is there a middle-ground between fully reactive methods and map-based path planners? In this paper, we investigate feed forward and recurrent networks to augment a purely reactive sensor-based planner, which should give the robot geometric intuition about how to escape local minima. We train on a large number of extremely cluttered worlds auto-generated from primitive shapes, and show that our system zero-shot transfers to real 3D man-made environments, and can handle up to 30\% sensor noise without degeneration of performance. We also offer a discussion of what role network memory plays in our final system, and what insights can be drawn about the nature of reactive vs. map-based navigation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/89N5DI74/Meijer et al. - 2024 - Pushing the Limits of Reactive Planning Learning to Escape Local Minima.pdf;/Users/kshitijgoel/Zotero/storage/XXVDG2IF/2407.html}
}

@inproceedings{mellinger_minimum_2011,
  title = {Minimum Snap Trajectory Generation and Control for Quadrotors},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Mellinger, Daniel and Kumar, Vijay},
  year = {2011},
  month = may,
  pages = {2520--2525},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2011.5980409},
  url = {https://ieeexplore.ieee.org/document/5980409},
  urldate = {2024-11-15},
  abstract = {We address the controller design and the trajectory generation for a quadrotor maneuvering in three dimensions in a tightly constrained setting typical of indoor environments. In such settings, it is necessary to allow for significant excursions of the attitude from the hover state and small angle approximations cannot be justified for the roll and pitch. We develop an algorithm that enables the real-time generation of optimal trajectories through a sequence of 3-D positions and yaw angles, while ensuring safe passage through specified corridors and satisfying constraints on velocities, accelerations and inputs. A nonlinear controller ensures the faithful tracking of these trajectories. Experimental results illustrate the application of the method to fast motion (5--10 body lengths/second) in three-dimensional slalom courses.},
  keywords = {Acceleration,Aerodynamics,Angular velocity,Force,Optimization,Rotors,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/IQFZID85/Mellinger and Kumar - 2011 - Minimum snap trajectory generation and control for quadrotors.pdf}
}

@article{mellinger_trajectory_2012,
  title = {Trajectory {{Generation}} and {{Control}} for {{Quadrotors}}},
  author = {Mellinger, Daniel},
  year = {2012},
  month = jan,
  journal = {Publicly Accessible Penn Dissertations},
  url = {https://repository.upenn.edu/edissertations/547},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/thesis/mellinger_thesis.pdf;/Users/kshitijgoel/Zotero/storage/VIYSER8A/547.html}
}

@article{melnykov_finite_2010,
  title = {Finite Mixture Models and Model-Based Clustering},
  author = {Melnykov, Volodymyr and Maitra, Ranjan},
  year = {2010},
  month = jan,
  journal = {Statistics Surveys},
  volume = {4},
  number = {none},
  pages = {80--116},
  publisher = {{Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada}},
  issn = {1935-7516},
  doi = {10.1214/09-SS053},
  url = {https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/Finite-mixture-models-and-model-based-clustering/10.1214/09-SS053.full},
  urldate = {2024-07-11},
  abstract = {Finite mixture models have a long history in statistics, having been used to model population heterogeneity, generalize distributional assumptions, and lately, for providing a convenient yet formal framework for clustering and classification. This paper provides a detailed review into mixture models and model-based clustering. Recent trends as well as open problems in the area are also discussed.},
  keywords = {diagnostics,EM algorithm,magnitude magnetic resonance images,Model selection,proteomics,text mining,two-dimensional gel electrophoresis data,Variable selection},
  file = {/Users/kshitijgoel/Zotero/storage/KL5CE45F/Melnykov and Maitra - 2010 - Finite mixture models and model-based clustering.pdf}
}

@article{melzer_nonparametric_2007,
  title = {Non-Parametric Segmentation of {{ALS}} Point Clouds Using Mean Shift},
  author = {Melzer, Thomas},
  year = {2007},
  month = nov,
  volume = {1},
  number = {3},
  pages = {159--170},
  publisher = {De Gruyter},
  issn = {1862-9024},
  doi = {10.1515/jag.2007.018},
  url = {https://www.degruyter.com/document/doi/10.1515/jag.2007.018/html},
  urldate = {2025-02-26},
  abstract = {Segmentation is a key task in the processing of 3D point clouds as obtained from airborne laser scanners (ALS). However, most of the segmentation techniques currently employed require prior gridding of the data and thus do not respect the inherently three-dimensional geometry of more intricate structures such as power lines. By contrast, the mean shift procedure, a filtering and clustering approach which has recently found much interest in the image processing community, works directly on the original 3D point cloud; also, mean shift is a non-parametric technique (i.e., it does not depend on any geometric model assumptions) and can thus also be applied to vegetation structures. In this paper, we will give a self-contained derivation of the mean shift procedure, and discuss how it can be used to obtain a classification or segmentation of an unstructured 3D point cloud. Two application examples shall further illustrate its usefulness to ALS data processing.},
  chapter = {Journal of Applied Geodesy},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {airborne laser scanning,classification,clustering,mean shift,Segmentation},
  file = {/Users/kshitijgoel/Zotero/storage/5GI4248R/Melzer - 2007 - Non-parametric segmentation of ALS point clouds using mean shift.pdf}
}

@misc{merat_driftfree_2024,
  title = {Drift-Free {{Visual SLAM}} Using {{Digital Twins}}},
  author = {Merat, Roxane and Cioffi, Giovanni and Bauersfeld, Leonard and Scaramuzza, Davide},
  year = {2024},
  month = dec,
  number = {arXiv:2412.08496},
  eprint = {2412.08496},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.08496},
  url = {http://arxiv.org/abs/2412.08496},
  urldate = {2025-01-08},
  abstract = {Globally-consistent localization in urban environments is crucial for autonomous systems such as self-driving vehicles and drones, as well as assistive technologies for visually impaired people. Traditional Visual-Inertial Odometry (VIO) and Visual Simultaneous Localization and Mapping (VSLAM) methods, though adequate for local pose estimation, suffer from drift in the long term due to reliance on local sensor data. While GPS counteracts this drift, it is unavailable indoors and often unreliable in urban areas. An alternative is to localize the camera to an existing 3D map using visual-feature matching. This can provide centimeter-level accurate localization but is limited by the visual similarities between the current view and the map. This paper introduces a novel approach that achieves accurate and globally-consistent localization by aligning the sparse 3D point cloud generated by the VIO/VSLAM system to a digital twin using point-to-plane matching; no visual data association is needed. The proposed method provides a 6-DoF global measurement tightly integrated into the VIO/VSLAM system. Experiments run on a high-fidelity GPS simulator and real-world data collected from a drone demonstrate that our approach outperforms state-of-the-art VIO-GPS systems and offers superior robustness against viewpoint changes compared to the state-of-the-art Visual SLAM systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/5L9GVB58/Merat et al. - 2024 - Drift-free Visual SLAM using Digital Twins.pdf;/Users/kshitijgoel/Zotero/storage/BQTQBVB8/2412.html}
}

@misc{merlo_exploiting_2024,
  title = {Exploiting {{Information Theory}} for {{Intuitive Robot Programming}} of {{Manual Activities}}},
  author = {Merlo, Elena and Lagomarsino, Marta and Lamon, Edoardo and Ajoudani, Arash},
  year = {2024},
  month = oct,
  number = {arXiv:2410.23963},
  eprint = {2410.23963},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.23963},
  urldate = {2024-11-01},
  abstract = {Observational learning is a promising approach to enable people without expertise in programming to transfer skills to robots in a user-friendly manner, since it mirrors how humans learn new behaviors by observing others. Many existing methods focus on instructing robots to mimic human trajectories, but motion-level strategies often pose challenges in skills generalization across diverse environments. This paper proposes a novel framework that allows robots to achieve a {\textbackslash}textit\{higher-level\} understanding of human-demonstrated manual tasks recorded in RGB videos. By recognizing the task structure and goals, robots generalize what observed to unseen scenarios. We found our task representation on Shannon's Information Theory (IT), which is applied for the first time to manual tasks. IT helps extract the active scene elements and quantify the information shared between hands and objects. We exploit scene graph properties to encode the extracted interaction features in a compact structure and segment the demonstration into blocks, streamlining the generation of Behavior Trees for robot replicas. Experiments validated the effectiveness of IT to automatically generate robot execution plans from a single human demonstration. Additionally, we provide HANDSOME, an open-source dataset of HAND Skills demOnstrated by Multi-subjEcts, to promote further research and evaluation in this field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/PCH4XMDX/Merlo et al. - 2024 - Exploiting Information Theory for Intuitive Robot Programming of Manual Activities.pdf;/Users/kshitijgoel/Zotero/storage/XMS43ME6/2410.html}
}

@misc{merrill_visualinertial_2024,
  title = {Visual-{{Inertial SLAM}} as {{Simple}} as {{A}}, {{B}}, {{VINS}}},
  author = {Merrill, Nathaniel and Huang, Guoquan},
  year = {2024},
  month = sep,
  number = {arXiv:2406.05969},
  eprint = {2406.05969},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.05969},
  url = {http://arxiv.org/abs/2406.05969},
  urldate = {2025-01-08},
  abstract = {We present AB-VINS, a different kind of visual-inertial SLAM system. Unlike most popular VINS methods which only use hand-crafted techniques, AB-VINS makes use of three different deep neural networks. Instead of estimating sparse feature positions, AB-VINS only estimates the scale and bias parameters (a and b) of monocular depth maps, as well as other terms to correct the depth using multi-view information, which results in a compressed feature state. Despite being an optimization-based system, the front-end motion tracking thread of AB-VINS surpasses the efficiency of a state-of-the-art filtering-based method while also providing dense depth. When performing loop closures, standard keyframe-based SLAM systems need to relinearize a number of variables which is linear with respect to the number of keyframes. In contrast, the proposed AB-VINS can incorporate loop closures while only affecting a constant number of variables. This is thanks to a novel data structure called the memory tree, where keyframe poses are defined relative to each other rather than all in one global frame, allowing for all but a few states to be fixed. While AB-VINS might not be as accurate as state-of-the-art VINS algorithms, it is shown to be more robust.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/YLCTS4P3/Merrill and Huang - 2024 - Visual-Inertial SLAM as Simple as A, B, VINS.pdf;/Users/kshitijgoel/Zotero/storage/JKMK2MKW/2406.html}
}

@article{michael_collaborative_2012,
  title = {Collaborative Mapping of an Earthquake-Damaged Building via Ground and Aerial Robots},
  author = {Michael, Nathan and Shen, Shaojie and Mohta, Kartik and Mulgaonkar, Yash and Kumar, Vijay and Nagatani, Keiji and Okada, Yoshito and Kiribayashi, Seiga and Otake, Kazuki and Yoshida, Kazuya and Ohno, Kazunori and Takeuchi, Eijiro and Tadokoro, Satoshi},
  year = {2012},
  journal = {Journal of Field Robotics},
  volume = {29},
  number = {5},
  pages = {832--841},
  issn = {1556-4967},
  doi = {10.1002/rob.21436},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21436},
  urldate = {2023-01-20},
  abstract = {We report recent results from field experiments conducted with a team of ground and aerial robots engaged in the collaborative mapping of an earthquake-damaged building. The goal of the experimental exercise is the generation of three-dimensional maps that capture the layout of a multifloor environment. The experiments took place in the top three floors of a structurally compromised building at Tohoku University in Sendai, Japan that was damaged during the 2011 Tohoku earthquake. We provide details of the approach to the collaborative mapping and report results from the experiments in the form of maps generated by the individual robots and as a team. We conclude by discussing observations from the experiments and future research topics. {\copyright} 2012 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FAMWR39W/Michael et al. - 2012 - Collaborative mapping of an earthquake-damaged bui.pdf;/Users/kshitijgoel/Zotero/storage/7SLAIKLJ/rob.html}
}

@article{michael_grasp_2010,
  title = {The {{GRASP Multiple Micro-UAV Testbed}}},
  author = {Michael, Nathan and Mellinger, Daniel and Lindsey, Quentin and Kumar, Vijay},
  year = {2010},
  month = sep,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {17},
  number = {3},
  pages = {56--65},
  issn = {1558-223X},
  doi = {10.1109/MRA.2010.937855},
  url = {https://ieeexplore.ieee.org/document/5569026},
  urldate = {2024-11-15},
  abstract = {In the last five years, advances in materials, electronics, sensors, and batteries have fueled a growth in the development of microunmanned aerial vehicles (MAVs) that are between 0.1 and 0.5 m in length and 0.1--0.5 kg in mass [1]. A few groups have built and analyzed MAVs in the 10-cm range [2], [3]. One of the smallest MAV is the Picoflyer with a 60-mm propellor diameter and a mass of 3.3 g [4]. Platforms in the 50-cm range are more prevalent with several groups having built and flown systems of this size [5]--[7]. In fact, there are several commercially available radiocontrolled (RC) helicopters and research-grade helicopters in this size range [8].},
  keywords = {Acceleration,Mathematical model,Robot kinematics,Rotors,Software,Trajectory,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/6RTU3TNW/Michael et al. - 2010 - The GRASP Multiple Micro-UAV Testbed.pdf;/Users/kshitijgoel/Zotero/storage/BX8TZGGT/5569026.html}
}

@misc{michaux_lets_2024,
  title = {Let's {{Make}} a {{Splan}}: {{Risk-Aware Trajectory Optimization}} in a {{Normalized Gaussian Splat}}},
  shorttitle = {Let's {{Make}} a {{Splan}}},
  author = {Michaux, Jonathan and Isaacson, Seth and Adu, Challen Enninful and Li, Adam and Swayampakula, Rahul Kashyap and Ewen, Parker and Rice, Sean and Skinner, Katherine A. and Vasudevan, Ram},
  year = {2024},
  month = sep,
  number = {arXiv:2409.16915},
  eprint = {2409.16915},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.16915},
  urldate = {2024-09-28},
  abstract = {Neural Radiance Fields and Gaussian Splatting have transformed the field of computer vision by enabling photorealistic representation of complex scenes. Despite this success, they have seen only limited use in real-world robotics tasks such as trajectory optimization. Two key factors have contributed to this limited success. First, it is challenging to reason about collisions in radiance models. Second, it is difficult to perform inference of radiance models fast enough for real-time trajectory synthesis. This paper addresses these challenges by proposing SPLANNING, a risk-aware trajectory optimizer that operates in a Gaussian Splatting model. This paper first derives a method for rigorously upper-bounding the probability of collision between a robot and a radiance field. Second, this paper introduces a normalized reformulation of Gaussian Splatting that enables the efficient computation of the collision bound in a Gaussian Splat. Third, a method is presented to optimize trajectories while avoiding collisions with a scene represented by a Gaussian Splat. Experiments demonstrate that SPLANNING outperforms stateof-the-art methods in generating collision-free trajectories in highly cluttered environments. The proposed system is also tested on a real-world robot manipulator. A project page is available at https://roahmlab.github.io/splanning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/4S4CIHG6/Michaux et al. - 2024 - Let's Make a Splan Risk-Aware Trajectory Optimization in a Normalized Gaussian Splat.pdf}
}

@misc{milanfar_denoising_2024,
  title = {Denoising: {{A Powerful Building-Block}} for {{Imaging}}, {{Inverse Problems}}, and {{Machine Learning}}},
  shorttitle = {Denoising},
  author = {Milanfar, Peyman and Delbracio, Mauricio},
  year = {2024},
  month = dec,
  number = {arXiv:2409.06219},
  eprint = {2409.06219},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.06219},
  url = {http://arxiv.org/abs/2409.06219},
  urldate = {2024-12-11},
  abstract = {Denoising, the process of reducing random fluctuations in a signal to emphasize essential patterns, has been a fundamental problem of interest since the dawn of modern scientific inquiry. Recent denoising techniques, particularly in imaging, have achieved remarkable success, nearing theoretical limits by some measures. Yet, despite tens of thousands of research papers, the wide-ranging applications of denoising beyond noise removal have not been fully recognized. This is partly due to the vast and diverse literature, making a clear overview challenging. This paper aims to address this gap. We present a clarifying perspective on denoisers, their structure, and desired properties. We emphasize the increasing importance of denoising and showcase its evolution into an essential building block for complex tasks in imaging, inverse problems, and machine learning. Despite its long history, the community continues to uncover unexpected and groundbreaking uses for denoising, further solidifying its place as a cornerstone of scientific and engineering practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/kshitijgoel/Zotero/storage/KU6EDSYB/Milanfar and Delbracio - 2024 - Denoising A Powerful Building-Block for Imaging, Inverse Problems, and Machine Learning.pdf;/Users/kshitijgoel/Zotero/storage/C5M8WUM6/2409.html}
}

@article{milani_explainable_2024,
  title = {Explainable {{Reinforcement Learning}}: {{A Survey}} and {{Comparative Review}}},
  shorttitle = {Explainable {{Reinforcement Learning}}},
  author = {Milani, Stephanie and Topin, Nicholay and Veloso, Manuela and Fang, Fei},
  year = {2024},
  month = apr,
  journal = {ACM Comput. Surv.},
  volume = {56},
  number = {7},
  pages = {168:1--168:36},
  issn = {0360-0300},
  doi = {10.1145/3616864},
  url = {https://doi.org/10.1145/3616864},
  urldate = {2024-07-30},
  abstract = {Explainable reinforcement learning (XRL) is an emerging subfield of explainable machine learning that has attracted considerable attention in recent years. The goal of XRL is to elucidate the decision-making process of reinforcement learning (RL) agents in sequential decision-making settings. Equipped with this information, practitioners can better understand important questions about RL agents (especially those deployed in the real world), such as what the agents will do and why. Despite increased interest, there exists a gap in the literature for organizing the plethora of papers---especially in a way that centers the sequential decision-making nature of the problem. In this survey, we propose a novel taxonomy for organizing the XRL literature that prioritizes the RL setting. We propose three high-level categories: feature importance, learning process and Markov decision process, and policy-level. We overview techniques according to this taxonomy, highlighting challenges and opportunities for future work. We conclude by using these gaps to motivate and outline a roadmap for future work.},
  file = {/Users/kshitijgoel/Zotero/storage/FTFJCI3H/Milani et al. - 2024 - Explainable Reinforcement Learning A Survey and Comparative Review.pdf}
}

@inproceedings{mildenhall_nerf_2020,
  title = {{{NeRF}}: {{Representing Scenes}} as {{Neural Radiance Fields}} for {{View Synthesis}}},
  shorttitle = {{{NeRF}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2020},
  author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {405--421},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-58452-8_24},
  url = {https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460392.pdf},
  abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x,~y,~z) and viewing direction \$\$({\textbackslash}theta ,{\textbackslash}phi )\$\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for  convincing comparisons.},
  isbn = {978-3-030-58452-8},
  langid = {english},
  keywords = {3D deep learning,Image-based rendering,Scene representation,View synthesis,Volume rendering},
  file = {/Users/kshitijgoel/Zotero/storage/VZPIQLPV/Mildenhall et al. - 2020 - NeRF Representing Scenes as Neural Radiance Field.pdf}
}

@misc{millane_nvblox_2024,
  title = {Nvblox: {{GPU-Accelerated Incremental Signed Distance Field Mapping}}},
  shorttitle = {Nvblox},
  author = {Millane, Alexander and Oleynikova, Helen and Wirbel, Emilie and Steiner, Remo and Ramasamy, Vikram and Tingdahl, David and Siegwart, Roland},
  year = {2024},
  month = mar,
  number = {arXiv:2311.00626},
  eprint = {2311.00626},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2311.00626},
  urldate = {2024-05-23},
  abstract = {Dense, volumetric maps are essential to enable robot navigation and interaction with the environment. To achieve low latency, dense maps are typically computed onboard the robot, often on computationally constrained hardware. Previous works leave a gap between CPU-based systems for robotic mapping which, due to computation constraints, limit map resolution or scale, and GPU-based reconstruction systems which omit features that are critical to robotic path planning, such as computation of the Euclidean Signed Distance Field (ESDF). We introduce a library, nvblox, that aims to fill this gap, by GPU-accelerating robotic volumetric mapping. Nvblox delivers a significant performance improvement over the state of the art, achieving up to a 177{\texttimes} speed-up in surface reconstruction, and up to a 31{\texttimes} improvement in distance field computation, and is available open-source1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/YNEGZKRJ/Millane et al. - 2024 - nvblox GPU-Accelerated Incremental Signed Distance Field Mapping.pdf}
}

@misc{miller_objects_2024,
  title = {Objects as Volumes: {{A}} Stochastic Geometry View of Opaque Solids},
  shorttitle = {Objects as Volumes},
  author = {Miller, Bailey and Chen, Hanyu and Lai, Alice and Gkioulekas, Ioannis},
  year = {2024},
  month = apr,
  number = {arXiv:2312.15406},
  eprint = {2312.15406},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2312.15406},
  urldate = {2024-05-29},
  abstract = {We develop a theory for the representation of opaque solids as volumes. Starting from a stochastic representation of opaque solids as random indicator functions, we prove the conditions under which such solids can be modeled using exponential volumetric transport. We also derive expressions for the volumetric attenuation coefficient as a functional of the probability distributions of the underlying indicator functions. We generalize our theory to account for isotropic and anisotropic scattering at different parts of the solid, and for representations of opaque solids as stochastic implicit surfaces. We derive our volumetric representation from first principles, which ensures that it satisfies physical constraints such as reciprocity and reversibility. We use our theory to explain, compare, and correct previous volumetric representations, as well as propose meaningful extensions that lead to improved performance in 3D reconstruction tasks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/Y4HL8VPW/Miller et al. - 2024 - Objects as volumes A stochastic geometry view of opaque solids.pdf}
}

@article{miller_walkin_2024,
  title = {Walkin' {{Robin}}: {{Walk}} on {{Stars}} with {{Robin Boundary Conditions}}},
  shorttitle = {Walkin' {{Robin}}},
  author = {Miller, Bailey and Sawhney, Rohan and Crane, Keenan and Gkioulekas, Ioannis},
  year = {2024},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {4},
  pages = {41:1--41:18},
  issn = {0730-0301},
  doi = {10.1145/3658153},
  url = {https://doi.org/10.1145/3658153},
  urldate = {2024-07-26},
  abstract = {Numerous scientific and engineering applications require solutions to boundary value problems (BVPs) involving elliptic partial differential equations, such as the Laplace or Poisson equations, on geometrically intricate domains. We develop a Monte Carlo method for solving such BVPs with arbitrary first-order linear boundary conditions---Dirichlet, Neumann, and Robin. Our method directly generalizes the walk on stars (WoSt) algorithm, which previously tackled only the first two types of boundary conditions, with a few simple modifications. Unlike conventional numerical methods, WoSt does not need finite element meshing or global solves. Similar to Monte Carlo rendering, it instead computes pointwise solution estimates by simulating random walks along star-shaped regions inside the BVP domain, using efficient ray-intersection and distance queries. To ensure WoSt produces bounded-variance estimates in the presence of Robin boundary conditions, we show that it is sufficient to modify how WoSt selects the size of these star-shaped regions. Our generalized WoSt algorithm reduces estimation error by orders of magnitude relative to alternative grid-free methods such as the walk on boundary algorithm. We also develop bidirectional and boundary value caching strategies to further reduce estimation error. Our algorithm is trivial to parallelize, scales sublinearly with increasing geometric detail, and enables progressive and view-dependent evaluation.},
  file = {/Users/kshitijgoel/Zotero/storage/FM9HMYBE/Miller et al. - 2024 - Walkin’ Robin Walk on Stars with Robin Boundary Conditions.pdf}
}

@inproceedings{minka_expectation_2001,
  title = {Expectation Propagation for Approximate {{Bayesian}} Inference},
  booktitle = {Proceedings of the {{Seventeenth}} Conference on {{Uncertainty}} in Artificial Intelligence},
  author = {Minka, Thomas P.},
  year = {2001},
  month = aug,
  series = {{{UAI}}'01},
  pages = {362--369},
  publisher = {Morgan Kaufmann Publishers Inc.},
  address = {San Francisco, CA, USA},
  urldate = {2024-07-14},
  abstract = {This paper presents a new deterministic approximation technique in Bayesian networks. This method, "Expectation Propagation," unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models show Expectation Propagation to be donvincingly better than methods with similar computational cost: Laplace's method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers.},
  isbn = {978-1-55860-800-9}
}

@inproceedings{mirchev_prism_2023,
  title = {{{PRISM}}: {{Probabilistic Real-Time Inference}} in {{Spatial World Models}}},
  shorttitle = {{{PRISM}}},
  booktitle = {Proceedings of {{The}} 6th {{Conference}} on {{Robot Learning}}},
  author = {Mirchev, Atanas and Kayalibay, Baris and Agha, Ahmed and van der Smagt, Patrick and Cremers, Daniel and Bayer, Justin},
  year = {2023},
  month = mar,
  pages = {161--174},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v205/mirchev23a.html},
  urldate = {2023-04-16},
  abstract = {We introduce PRISM, a method for real-time filtering in a probabilistic generative model of agent motion and visual perception. Previous approaches either lack uncertainty estimates for the map and agent state, do not run in real-time, do not have a dense scene representation or do not model agent dynamics. Our solution reconciles all of these aspects. We start from a predefined state-space model which combines differentiable rendering and 6-DoF dynamics. Probabilistic inference in this model amounts to simultaneous localisation and mapping (SLAM) and is intractable. We use a series of approximations to Bayesian inference to arrive at probabilistic map and state estimates. We take advantage of well-established methods and closed-form updates, preserving accuracy and enabling real-time capability. The proposed solution runs at 10Hz real-time and is similarly accurate to state-of-the-art SLAM in small to medium-sized indoor environments, with high-speed UAV and handheld camera agents (Blackbird, EuRoC and TUM-RGBD).},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4RMBCESG/Mirchev et al. - 2023 - PRISM Probabilistic Real-Time Inference in Spatia.pdf;/Users/kshitijgoel/Zotero/storage/GXF7THKT/Mirchev et al. - 2023 - PRISM Probabilistic Real-Time Inference in Spatia.pdf}
}

@misc{mishra_information_2023,
  title = {Information {{Geometry}} for the {{Working Information Theorist}}},
  author = {Mishra, Kumar Vijay and Kumar, M. Ashok and Wong, Ting-Kam Leonard},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03884},
  eprint = {2310.03884},
  primaryclass = {cs, eess, math, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2310.03884},
  urldate = {2023-10-12},
  abstract = {Information geometry is a study of statistical manifolds, that is, spaces of probability distributions from a geometric perspective. Its classical information-theoretic applications relate to statistical concepts such as Fisher information, sufficient statistics, and efficient estimators. Today, information geometry has emerged as an interdisciplinary field that finds applications in diverse areas such as radar sensing, array signal processing, quantum physics, deep learning, and optimal transport. This article presents an overview of essential information geometry to initiate an information theorist, who may be unfamiliar with this exciting area of research. We explain the concepts of divergences on statistical manifolds, generalized notions of distances, orthogonality, and geodesics, thereby paving the way for concrete applications and novel theoretical investigations. We also highlight some recent information-geometric developments, which are of interest to the broader information theory community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Mathematics - Differential Geometry,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/RHCTPYWU/Mishra et al. - 2023 - Information Geometry for the Working Information T.pdf;/Users/kshitijgoel/Zotero/storage/FGXYMTI7/2310.html}
}

@article{miura_adaptive_2006,
  title = {Adaptive Robot Speed Control by Considering Map and Motion Uncertainty},
  author = {Miura, Jun and Negishi, Yoshiro and Shirai, Yoshiaki},
  year = {2006},
  month = feb,
  journal = {Robotics and Autonomous Systems},
  series = {Intelligent {{Autonomous Systems}}},
  volume = {54},
  number = {2},
  pages = {110--117},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2005.09.020},
  url = {https://www.sciencedirect.com/science/article/pii/S0921889005001491},
  urldate = {2022-06-07},
  abstract = {This paper describes an adaptive robot speed control method for safe and efficient navigation in unknown environments. Safety and efficiency are usually in a trade-off relationship. Moving quickly increases efficiency but decreases safety due to low reliability in localization and environment recognition; moving slowly decreases efficiency but increases safety. Speed control considering this trade-off is important in the following two cases. (1) When the robot enters a narrow free space, it needs to control the speed to avoid any collisions by considering the motion uncertainty. (2) When the robot enters a region whose vacancy (i.e., being free) has not been decided yet, it needs to control the speed so that it can observe the region sufficiently to be confident with the vacancy of the region. This paper proposes a simple but effective strategy for such a speed control that the robot selects the safest fast speed. To adopt this strategy, we define criteria for judging whether a speed is safe for the above two cases. The proposed method successfully makes, the robot move around in unknown static environments by adaptively controlling the speed.},
  langid = {english},
  keywords = {Adaptive speed control,Map generation,Mobile robot,Navigation in unknown environments},
  file = {/Users/kshitijgoel/Zotero/storage/TBB6CDT7/Miura et al. - 2006 - Adaptive robot speed control by considering map an.pdf;/Users/kshitijgoel/Zotero/storage/A3D2TGFM/S0921889005001491.html}
}

@article{moenne-loccoz_3d_2024,
  title = {{{3D Gaussian Ray Tracing}}: {{Fast Tracing}} of {{Particle Scenes}}},
  shorttitle = {{{3D Gaussian Ray Tracing}}},
  author = {{Moenne-Loccoz}, Nicolas and Mirzaei, Ashkan and Perel, Or and {de Lutio}, Riccardo and Martinez Esturo, Janick and State, Gavriel and Fidler, Sanja and Sharp, Nicholas and Gojcic, Zan},
  year = {2024},
  month = nov,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {6},
  pages = {232:1--232:19},
  issn = {0730-0301},
  doi = {10.1145/3687934},
  url = {https://dl.acm.org/doi/10.1145/3687934},
  urldate = {2025-01-08},
  abstract = {Particle-based representations of radiance fields such as 3D Gaussian Splatting have found great success for reconstructing and re-rendering of complex scenes. Most existing methods render particles via rasterization, projecting them to screen space tiles for processing in a sorted order. This work instead considers ray tracing the particles, building a bounding volume hierarchy and casting a ray for each pixel using high-performance GPU ray tracing hardware. To efficiently handle large numbers of semi-transparent particles, we describe a specialized rendering algorithm which encapsulates particles with bounding meshes to leverage fast ray-triangle intersections, and shades batches of intersections in depth-order. The benefits of ray tracing are well-known in computer graphics: processing incoherent rays for secondary lighting effects such as shadows and reflections, rendering from highly-distorted cameras common in robotics, stochastically sampling rays, and more. With our renderer, this flexibility comes at little cost compared to rasterization. Experiments demonstrate the speed and accuracy of our approach, as well as several applications in computer graphics and vision. We further propose related improvements to the basic Gaussian representation, including a simple use of generalized kernel functions which significantly reduces particle hit counts.},
  file = {/Users/kshitijgoel/Zotero/storage/QQQ2N8B2/Moenne-Loccoz et al. - 2024 - 3D Gaussian Ray Tracing Fast Tracing of Particle Scenes.pdf}
}

@article{monath_incremental_2022,
  title = {Incremental {{Non-Greedy Clustering}} at {{Scale}}},
  author = {Monath, Nicholas},
  year = {2022},
  month = feb,
  eprint = {20.500.14394/18755},
  eprinttype = {hdl},
  url = {https://hdl.handle.net/20.500.14394/18755},
  urldate = {2025-07-31},
  abstract = {Clustering is the task of organizing data into meaningful groups. Modern clustering applications such as entity resolution put several demands on clustering algorithms: (1) scalability to massive numbers of points as well as clusters, (2) incremental additions of data, (3) support for any user-specified similarity functions. Hierarchical clusterings are often desired as they represent multiple alternative flat clusterings (e.g., at different granularity levels). These tree-structured clusterings provide for both fine-grained clusters as well as uncertainty in the presence of newly arriving data. Previous work on hierarchical clustering does not fully address all three of the aforementioned desiderata. Work on incremental hierarchical clustering often makes greedy, irrevocable clustering decisions that are regretted in the presence of future data. Work on scalable hierarchical clustering does not support incremental additions or deletions. These methods often make requirements on the similarity functions used and/or empirically tend to over merge clusters, which can lead to inaccurate clusterings. In this thesis, we present incremental and scalable methods for hierarchical clustering to empirically satisfy the above desiderata. Our work aims to represent uncertainty and meaningful alternative clusterings, to efficiently reconsider past decisions in the incremental case, and to use parallelism to scale to massive datasets. Our method, Grinch, handles incrementally arriving data in a non-greedy fashion, by reconsidering past decisions using tree structure re-arrangements (e.g., rotations and grafts) invoked in accordance with the user's specified similarity function. To achieve scalability to massive datasets, our method, SCC, builds a hierarchical clusterings in a level-wise bottom-up manner. Certain clustering decisions are made independently in parallel within each level, and a global similarity threshold schedule prevents greedy over-merging. We show how SCC can be combined with the tree-structure re-arrangements in Grinch to form a mini-batch algorithm achieving both scalable and incremental performance. Lastly, we generalize our hierarchical clustering approaches to DAG-structured ones, which can better represent uncertainty in clustering by representing overlapping clusters. We introduce an efficient bottom-up method for DAG-structured clustering, Llama. For each of the proposed methods, we provide both a theoretical and empirical analysis. Empirically, our methods achieve state-of-the-art results on clustering benchmarks in both the batch and the incremental settings, including multiple point improvements in dendrogram purity and scalability to billions of points.},
  langid = {english}
}

@article{monica_surfelbased_2018,
  title = {Surfel-{{Based Next Best View Planning}}},
  author = {Monica, Riccardo and Aleotti, Jacopo},
  year = {2018},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {4},
  pages = {3324--3331},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2852778},
  url = {https://ieeexplore.ieee.org/document/8403267},
  urldate = {2024-06-10},
  abstract = {Next best view (NBV) planning is a central task for automated three-dimensional (3-D) reconstruction in robotics. The most expensive phase of NBV computation is the view simulation step, where the information gain of a large number of candidate sensor poses are estimated. Usually, information gain is related to the visibility of unknown space from the simulated viewpoint. A well-established technique is to adopt a volumetric representation of the environment and to compute the NBV from ray casting by maximizing the number of unknown visible voxels. This letter explores a novel approach for NBV planning based on surfel representation of the environment. Surfels are oriented surface elements, such as circular disks, without explicit connectivity. A new kind of surfel is introduced to represent the frontier between empty and unknown space. Surfels are extracted during 3-D reconstruction, with minimal overhead, from a KinectFusion volumetric representation. Surfel rendering is used to generate images from each simulated sensor pose. Experiments in a real robot setup are reported. The proposed approach achieves better performance than volumetric algorithms based on ray casting implemented on graphics processing unit (GPU), with comparable results in terms of reconstruction quality. Moreover, surfel-based NBV planning can be applied in larger environments as a volumetric representation is limited by GPU memory.},
  keywords = {Autonomous agents,Computational modeling,computer vision for other robotic applications,Graphics processing units,motion and path planning,Planning,range sensing,Robot sensing systems,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/J3TIECMX/Monica and Aleotti - 2018 - Surfel-Based Next Best View Planning.pdf;/Users/kshitijgoel/Zotero/storage/B2HA9MQF/8403267.html}
}

@inproceedings{montemerlo_largescale_2006,
  title = {Large-{{Scale Robotic}} 3-{{D Mapping}} of {{Urban Structures}}},
  booktitle = {Experimental {{Robotics IX}}},
  author = {Montemerlo, Michael and Thrun, Sebastian},
  editor = {Ang, Marcelo H. and Khatib, Oussama},
  year = {2006},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {141--150},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11552246_14},
  abstract = {This article presents results for building accurate 3-D maps of urban environments with a mobile robot based on the Segway scooter. The goal of this project is to use robotic systems to rapidly acquire accurate 3-D maps which seamlessly integrate indoor and outdoor structures. Our approach uses an efficient implementation of the global scan alignment algorithm of Lu and Milios in order to integrate GPS, IMU, and laser data into globally consistent maps. The 3-D models acquired by the robot are analyzed for navigability using a multi-resolution evidence grid approach, and visualized using a meshing algorithm adapted from the computer graphics literature. Results are presented for a number of environments which combine indoor and outdoor terrain.},
  isbn = {978-3-540-33014-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QHLFYDJD/Montemerlo and Thrun - 2006 - Large-Scale Robotic 3-D Mapping of Urban Structure.pdf}
}

@article{moon_expectationmaximization_1996,
  title = {The Expectation-Maximization Algorithm},
  author = {Moon, T.K.},
  year = {1996},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {13},
  number = {6},
  pages = {47--60},
  issn = {1558-0792},
  doi = {10.1109/79.543975},
  url = {https://ieeexplore.ieee.org/document/543975},
  urldate = {2024-11-15},
  abstract = {A common task in signal processing is the estimation of the parameters of a probability distribution function. Perhaps the most frequently encountered estimation problem is the estimation of the mean of a signal in noise. In many parameter estimation problems the situation is more complicated because direct access to the data necessary to estimate the parameters is impossible, or some of the data are missing. Such difficulties arise when an outcome is a result of an accumulation of simpler outcomes, or when outcomes are clumped together, for example, in a binning or histogram operation. There may also be data dropouts or clustering in such a way that the number of underlying data points is unknown (censoring and/or truncation). The EM (expectation-maximization) algorithm is ideally suited to problems of this sort, in that it produces maximum-likelihood (ML) estimates of parameters when there is a many-to-one mapping from an underlying distribution to the distribution governing the observation. The EM algorithm is presented at a level suitable for signal processing practitioners who have had some exposure to estimation theory.},
  keywords = {Convergence,Estimation theory,Hidden Markov models,Histograms,Image reconstruction,Maximum likelihood estimation,Parameter estimation,Phase detection,Probability distribution,Signal processing algorithms},
  file = {/Users/kshitijgoel/Zotero/storage/YMAJHBL4/Moon - 1996 - The expectation-maximization algorithm.pdf}
}

@inproceedings{moon_semanticsaware_2023,
  title = {Semantics-{{Aware Mission Adaptation}} for {{Autonomous Exploration}} in {{Urban Environments}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Moon, Sangwoo and Peltzer, Oriana and Ott, Joshua and Kim, Sung-Kyun and {Agha-Mohammadi}, Ali-Akbar},
  year = {2023},
  month = oct,
  pages = {2065--2070},
  publisher = {IEEE},
  address = {Detroit, MI, USA},
  doi = {10.1109/IROS55552.2023.10341632},
  url = {https://ieeexplore.ieee.org/document/10341632/},
  urldate = {2024-02-29},
  abstract = {Robust mission planning is an essential component for mission autonomy to perform complicated tasks in extreme environments. In this paper, we are interested in the role of semantic abstractions for guiding autonomous mission planning. In particular, we focus on how semantics can be leveraged to transition, at the mission level, in between individually robust task plans. We present a mission autonomy framework wherein a task plan adaptation policy leverages up-to-date semantics information in order to adapt to changes that occur during run-time, which endows the robot with better resiliency to unexpected events and improves the overall efficiency of mission operations. Under this new perspective, we provide a concrete and challenging application of autonomous exploration and radio source seeking in a complex multi-level building environment. Experimental results over simulations and real hardware tests demonstrate that the presented semantics-aware mission adaptation more effectively completes the mission with better qualitative results compared to a non-adaptive baseline.},
  isbn = {978-1-6654-9190-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/J4QK4EQY/Moon et al. - 2023 - Semantics-Aware Mission Adaptation for Autonomous .pdf}
}

@inproceedings{moravec_high_1985,
  title = {High Resolution Maps from Wide Angle Sonar},
  booktitle = {1985 {{IEEE International Conference}} on {{Robotics}} and {{Automation Proceedings}}},
  author = {Moravec, H. and Elfes, A.},
  year = {1985},
  month = mar,
  volume = {2},
  pages = {116--121},
  doi = {10.1109/ROBOT.1985.1087316},
  url = {https://ieeexplore.ieee.org/document/1087316},
  abstract = {We describe the use of multiple wide-angle sonar range measurements to map the surroundings of an autonomous mobile robot. A sonar range reading provides information concerning empty and occupied volumes in a cone (subtending 30 degrees in our case) in front of the sensor. The reading is modelled as probability profiles projected onto a rasterized map, where somewhere occupied and everywhere empty areas are represented. Range measurements from multiple points of view (taken from multiple sensors on the robot, and from the same sensors after robot moves) are systematically integrated in the map. Overlapping empty volumes re-inforce each other, and serve to condense the range of occupied volumes. The map definition improves as more readings are added. The final map shows regions probably occupied, probably unoccupied, and unknown areas. The method deals effectively with clutter, and can be used for motion planning and for extended landmark recognition. This system has been tested on the Neptune mobile robot at CMU.},
  keywords = {Area measurement,Laboratories,Mobile robots,Path planning,Robot sensing systems,Sensor arrays,Sensor systems,Sonar measurements,Sonar navigation,System testing},
  file = {/Users/kshitijgoel/Zotero/storage/AT8A9Y7I/Moravec and Elfes - 1985 - High resolution maps from wide angle sonar.pdf;/Users/kshitijgoel/Zotero/storage/QBWDAH86/1087316.html}
}

@article{morilla-cabello_sweepyourmap_2022,
  title = {Sweep-{{Your-Map}}: {{Efficient Coverage Planning}} for {{Aerial Teams}} in {{Large-Scale Environments}}},
  shorttitle = {Sweep-{{Your-Map}}},
  author = {{Morilla-Cabello}, David and Bartolomei, Luca and Teixeira, Lucas and Montijano, Eduardo and Chli, Margarita},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3194686},
  abstract = {The efficiency of path-planning in robot navigation is crucial in tasks such as search-and-rescue and disaster surveying, but this is emphasized even more when considering multirotor aerial robots due to the limited battery and flight time. In this spirit, this work proposes an efficient, hierarchical planner to achieve comprehensive visual coverage of large-scale outdoor scenarios for small drones. Following an initial reconnaissance flight, a coarse map of the scene gets built in real-time. Then, regions of the map that were not appropriately observed are identified and grouped by a novel perception-aware clustering process that enables the generation of continuous trajectories (sweeps) to cover them efficiently. Thanks to this partitioning of the map into a set of tasks, we can generalize the planning to an arbitrary number of drones and perform a well-balanced workload distribution among them. We compare our approach against a state-of-theart method for exploration and show the advantages of our pipeline in terms of efficiency for obtaining coverage in large environments. Video - https://youtu.be/V2UIrM91oQ8},
  keywords = {Aerial Systems: Perception and Autonomy,Drones,Mapping,Path Planning for Multiple Mobile Robots or Agents,Pipelines,Planning,Reconnaissance,Robots,Surface reconstruction,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/Z22U8V2T/Morilla-Cabello et al. - 2022 - Sweep-Your-Map Efficient Coverage Planning for Ae.pdf;/Users/kshitijgoel/Zotero/storage/DIQL8QD4/9844235.html}
}

@book{moser_advanced_2023,
  title = {Advanced {{Topics}} in {{Information Theory}}},
  author = {Moser, Stefan M},
  year = {2023},
  month = sep,
  edition = {5th Edition},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8PW6ABFD/tab_fig_atit_v55.pdf;/Users/kshitijgoel/Zotero/storage/GPN3SV8D/Moser - Advanced Topics in Information Theory.pdf}
}

@book{moser_information_2023,
  title = {Information {{Theory}} - {{Lecture Notes}}},
  author = {Moser, Stefan M.},
  year = {2023},
  month = sep,
  edition = {6th Edition},
  url = {https://moser-isi.ethz.ch/docs/it_script_v614.pdf},
  urldate = {2023-10-23},
  file = {/Users/kshitijgoel/Zotero/storage/65ERPF3U/it_script_v614.pdf;/Users/kshitijgoel/Zotero/storage/6JMJNPQV/tab_fig_it_v614.pdf}
}

@inproceedings{mostegel_active_2014,
  title = {Active Monocular Localization: {{Towards}} Autonomous Monocular Exploration for Multirotor {{MAVs}}},
  shorttitle = {Active Monocular Localization},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Mostegel, Christian and Wendel, Andreas and Bischof, Horst},
  year = {2014},
  month = may,
  pages = {3848--3855},
  publisher = {IEEE},
  address = {Hong Kong, China},
  doi = {10.1109/ICRA.2014.6907417},
  url = {http://ieeexplore.ieee.org/document/6907417/},
  urldate = {2023-10-26},
  abstract = {The main contribution of this paper is to bridge the gap between passive monocular SLAM and autonomous robotic systems. While passive monocular SLAM strives to reconstruct the scene and determine the current camera pose for any given camera motion, not every camera motion is equally suited for these tasks. In this work we propose methods to evaluate the quality of camera motions with respect to the generation of new useful map points and localization maintenance. In our experiments, we demonstrate the effectiveness of our measures using a low-cost quadrocopter. The proposed system only requires a single passive camera as exteroceptive sensor. Due to its explorative nature, the system achieves autonomous way-point navigation in challenging, unknown, GPS-denied environments.},
  isbn = {978-1-4799-3685-4},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AR2XW5QN/Mostegel et al. - 2014 - Active monocular localization Towards autonomous .pdf}
}

@inproceedings{mourikis_multistate_2007,
  title = {A {{Multi-State Constraint Kalman Filter}} for {{Vision-aided Inertial Navigation}}},
  booktitle = {Proceedings 2007 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Mourikis, Anastasios I. and Roumeliotis, Stergios I.},
  year = {2007},
  month = apr,
  pages = {3565--3572},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2007.364024},
  url = {https://ieeexplore.ieee.org/document/4209642},
  urldate = {2025-04-05},
  abstract = {In this paper, we present an extended Kalman filter (EKF)-based algorithm for real-time vision-aided inertial navigation. The primary contribution of this work is the derivation of a measurement model that is able to express the geometric constraints that arise when a static feature is observed from multiple camera poses. This measurement model does not require including the 3D feature position in the state vector of the EKF and is optimal, up to linearization errors. The vision-aided inertial navigation algorithm we propose has computational complexity only linear in the number of features, and is capable of high-precision pose estimation in large-scale real-world environments. The performance of the algorithm is demonstrated in extensive experimental results, involving a camera/IMU system localizing within an urban area.},
  keywords = {Cameras,Computational complexity,Inertial navigation,Large-scale systems,Motion estimation,Motion measurement,Position measurement,Simultaneous localization and mapping,Solid modeling,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/NKC5UPKJ/Mourikis and Roumeliotis - 2007 - A Multi-State Constraint Kalman Filter for Vision-aided Inertial Navigation.pdf}
}

@inproceedings{muhammadmahishafiullah_clipfields_2023,
  title = {{{CLIP-Fields}}: {{Weakly Supervised Semantic Fields}} for {{Robotic Memory}}},
  shorttitle = {{{CLIP-Fields}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Muhammad (Mahi)Shafiullah, Nur and Paxton, Chris and Pinto, Lerrel and Chintala, Soumith and Szlam, Arthur},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p074.html},
  urldate = {2024-01-24},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/GUS698J2/Muhammad (Mahi)Shafiullah et al. - 2023 - CLIP-Fields Weakly Supervised Semantic Fields for.pdf}
}

@article{mukherjee_automatic_2020,
  title = {Automatic {{Control}} of an {{Asymmetric Fighter Aircraft Performing Supermanoeuvres}}},
  author = {Mukherjee, Bijoy K. and Goel, Khsitij and Sinha, Manoranjan},
  year = {2020},
  month = mar,
  journal = {Advances in Military Technology},
  volume = {15},
  number = {1},
  pages = {163--178},
  issn = {2533-4123},
  doi = {10.3849/aimt.01314},
  url = {https://aimt.cz/index.php/aimt/article/view/1314},
  urldate = {2022-08-31},
  abstract = {Center-of-gravity (c.g.) of a combat aircraft may deviate significantly from the plane of symmetry due to asymmetric release of stores, leading to a highly coupled asymmetric six degree-of-freedom (6-DOF) dynamics. Additional nonlinearity and cross-coupling between the longitudinal and lateral-directional dynamics result when the aircraft attempts some supermanoeuvres under such asymmetric conditions. This renders nonlinear control implementation almost unavoidable for the safety of the aircraft. However, success of such control schemes heavily depends on the accurate onboard information of the actual asymmetric c.g. location. The present paper proposes a novel neural network aided sliding mode based hybrid control scheme which does not require such online c.g. information at all. The neural controller part is trained offline so that it can compensate for the deviations in the aircraft dynamics arising from the lateral mass asymmetry and the sliding controller is designed assuming the nominal or symmetrical dynamics to execute the intended manoeuvres. To validate the usefulness of the proposed control scheme, two well-known supermanoeuvres cobra and Herbst are simulated and it is shown that the manoeuvre performance does not get affected appreciably even under a wide range of lateral c.g. movements.},
  copyright = {Copyright (c) 2020 Advances in Military Technology},
  langid = {english},
  keywords = {centre-of-gravity,neural network,sliding mode,supermanoeuvre},
  file = {/Users/kshitijgoel/Zotero/storage/FHNUKEW4/Mukherjee et al. - 2020 - Automatic Control of an Asymmetric Fighter Aircraf.pdf}
}

@article{muller_continuous_1956,
  title = {Some {{Continuous Monte Carlo Methods}} for the {{Dirichlet Problem}}},
  author = {Muller, Mervin E.},
  year = {1956},
  month = sep,
  journal = {The Annals of Mathematical Statistics},
  volume = {27},
  number = {3},
  pages = {569--589},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177728169},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-3/Some-Continuous-Monte-Carlo-Methods-for-the-Dirichlet-Problem/10.1214/aoms/1177728169.full},
  urldate = {2023-09-21},
  abstract = {Monte Carlo techniques are introduced, using stochastic models which are Markov processes. This material includes the \$N\$-dimensional Spherical, General Spherical, and General Dirichlet Domain processes. These processes are proved to converge with probability 1, and thus to yield direct statistical estimates of the solution to the \$N\$-dimensional Dirichlet problem. The results are obtained without requiring any further restrictions on the boundary or the function defined on the boundary, in addition to those required for the existence and uniqueness of the solution to the Dirichlet problem. A detailed study is made for the \$N\$-dimensional Spherical process; this includes a study of the order of the average number of steps required for convergence. Asymptotic confidence intervals are obtained. When computing effort is measured in terms of the order of the average number of steps required for convergence, the often-made conjecture that the computing effort of a Monte Carlo procedure should be a linear function of the dimensionality of the problem is shown to be true for the cases considered. Comments are included regarding the application of these processes on digital computers, and truncation methods are suggested.},
  file = {/Users/kshitijgoel/Zotero/storage/Q68WLTNV/Muller - 1956 - Some Continuous Monte Carlo Methods for the Dirich.pdf}
}

@article{muller_robust_2023,
  title = {Robust and {{Efficient Depth-Based Obstacle Avoidance}} for {{Autonomous Miniaturized UAVs}}},
  author = {M{\"u}ller, Hanna and Niculescu, Vlad and Polonelli, Tommaso and Magno, Michele and Benini, Luca},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--17},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3315710},
  url = {https://ieeexplore.ieee.org/document/10272390/},
  urldate = {2023-11-29},
  abstract = {Nanosize drones hold enormous potential to explore unknown and complex environments. Their small size makes them agile and safe for operation close to humans and allows them to navigate through narrow spaces. However, their tiny size and payload restrict the possibilities for onboard computation and sensing, making fully autonomous flight extremely challenging. The first step toward full autonomy is reliable obstacle avoidance, which has proven to be challenging by itself in a generic indoor environment. Current approaches utilize vision-based or 1-D sensors to support nanodrone perception algorithms. This article presents a lightweight obstacle avoidance system based on a novel millimeter form factor 64 pixels multizone time-of-flight (ToF) sensor and a generalized model-free control policy. In-field tests are based on the Crazyflie 2.1, extended by a custom multizone ToF deck, featuring a total flight mass of 35 g. The algorithm only uses 0.3\% of the onboard processing power (210 {\textmu}s execution time) with a frame rate of 15 f/s. The presented autonomous nanosize drone reaches 100\% reliability at 0.5 m/s in a generic and previously unexplored indoor environment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MS9H4XTI/Müller et al. - 2023 - Robust and Efficient Depth-Based Obstacle Avoidanc.pdf}
}

@article{murai_distributed_2024,
  title = {Distributed {{Simultaneous Localisation}} and {{Auto-Calibration Using Gaussian Belief Propagation}}},
  author = {Murai, Riku and Alzugaray, Ignacio and Kelly, Paul H.J. and Davison, Andrew J.},
  year = {2024},
  month = mar,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {3},
  pages = {2136--2143},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2024.3352361},
  url = {https://ieeexplore.ieee.org/document/10387679/},
  urldate = {2024-01-31},
  abstract = {We present a novel scalable, fully distributed, and online method for simultaneous localisation and extrinsic calibration for multi-robot setups. Individual a priori unknown robot poses are probabilistically inferred as robots sense each other while simultaneously calibrating their sensors and markers extrinsic using Gaussian Belief Propagation. In the presented experiments, we show how our method not only yields accurate robot localisation and auto-calibration but also is able to perform under challenging circumstances such as highly noisy measurements, significant communication failures or limited communication range.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SNUKIDPH/Murai et al. - 2024 - Distributed Simultaneous Localisation and Auto-Cal.pdf}
}

@phdthesis{murali_perceptionaware_2024,
  type = {Thesis},
  title = {Perception-Aware Planning for Differentially Flat Robots},
  author = {Murali, Varun},
  year = {2024},
  month = feb,
  url = {https://dspace.mit.edu/handle/1721.1/153794},
  urldate = {2024-06-13},
  abstract = {The central question to this thesis can be stated as follows: ``Can we design computationally efficient algorithms that are capable of robustly navigating complex environments and unstructured environments at operational speeds." Visual inertial navigation in perceptually degraded environments is a challenging problem for robotic vehicles. With a camera, inertial measurement unit (IMU) pairing being ubiquitous to most consumer electronics, they form an ideal pairing for applications on the edge and have found applications ranging from large-scale search and rescue, autonomous driving to home robots such as robotic vacuum cleaners. In general, the navigation problem for robots can be written in the form of the sense-think-act framework for autonomy. The ``sensing" part is typically performed in this context as bearing measurements to visually salient locations in the environment; the ``planning" part then uses the estimate of the ego-state from the sensors and produces a (compactly represented) trajectory from the current location to the goal. Finally, the ``act" or controller follows the plan. This division leaves several interesting problems at the intersection of the parts of the framework. For instance, consider the problem of navigating in a relatively unknown environment; if the future percepts are not carefully planned, it is possible to enter a room with very few visual features that degrade the quality of state estimation, which in turn can result in poor closed-loop performance. Quadrotors are a class of robots that dictate further constraints on their sensors, namely size and weight. These constraints make camera-IMU pairings ideal for this type of aerial vehicle and bring further interesting challenges in terms of computational load for embedded systems. To this end, we first study the problem of modeling visibility on the camera canvas and incorporating these heuristics as an optimal-control problem. We then study the problem of optimizing the robot speed along the path with visible features such that the traversal time is minimized and the constraints are satisfied. As we hit the limit of optimization capability in a model-based fashion, we employ machine learning to jointly optimize the speed, uncertainty along the trajectory in a numerically stable fashion.},
  copyright = {In Copyright - Educational Use Permitted},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2024-03-15T19:24:29Z},
  file = {/Users/kshitijgoel/Zotero/storage/IRA5YC4W/Murali - 2024 - Perception-aware planning for differentially flat robots.pdf}
}

@incollection{murphy_disaster_2016,
  title = {Disaster {{Robotics}}},
  booktitle = {Springer {{Handbook}} of {{Robotics}}},
  author = {Murphy, Robin R. and Tadokoro, Satoshi and Kleiner, Alexander},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  year = {2016},
  series = {Springer {{Handbooks}}},
  pages = {1577--1604},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-32552-1_60},
  url = {https://doi.org/10.1007/978-3-319-32552-1_60},
  urldate = {2022-06-26},
  abstract = {Rescue robots have been used in at least 28 disasters in six countries since the first deployment to the 9/11 World Trade Center collapse. All types of robots have been used (land, sea, and aerial) and for all phases of a~disaster (prevention, response, and recovery). This chapter will cover the basic characteristics of disasters and their impact on robotic design, and describe the robots actually used in disasters to date, with a~special focus on Fukushima Daiichi, which is providing a~rich proving ground for robotics. The chapter covers promising robot designs (e.\,g., snakes, legged locomotion) and concepts (e.\,g., robot teams or swarms, sensor networks), as well as progress and open issues in autonomy. The methods of evaluation in benchmarks for rescue robotics are discussed and the chapter concludes with a~discussion of the fundamental problems and open issues facing rescue robotics, and their evolution from an interesting idea to widespread adoption.},
  isbn = {978-3-319-32552-1},
  langid = {english},
  keywords = {Autonomous Underwater Vehicle,Situation Awareness,Snake Robot,Unmanned Aerial Vehicle,World Trade Center},
  file = {/Users/kshitijgoel/Zotero/storage/QU6H5RAT/Murphy et al. - 2016 - Disaster Robotics.pdf}
}

@article{murphy_mobile_2009,
  title = {Mobile Robots in Mine Rescue and Recovery},
  author = {Murphy, Robin R and Kravitz, Jeffery and Stover, Samuel L and Shoureshi, Rahmat},
  year = {2009},
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {16},
  number = {2},
  pages = {91--103},
  publisher = {IEEE}
}

@book{murphy_probabilistic_2023,
  title = {Probabilistic Machine Learning: Advanced Topics},
  shorttitle = {Probabilistic Machine Learning},
  author = {Murphy, Kevin P.},
  year = {2023},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  abstract = {"An advanced book for researchers and graduate students working in machine learning and statistics that reflects the influence of deep learning"--},
  isbn = {978-0-262-37599-3 978-0-262-37600-6},
  lccn = {Q325.5},
  keywords = {Machine learning,Probabilities},
  file = {/Users/kshitijgoel/Zotero/storage/TL789YYC/Murphy - 2023 - Probabilistic machine learning advanced topics.pdf}
}

@article{murray_cue_2010,
  title = {Cue Combination on the Circle and the Sphere},
  author = {Murray, Richard F. and Morgenstern, Yaniv},
  year = {2010},
  month = sep,
  journal = {Journal of Vision},
  volume = {10},
  number = {11},
  pages = {15},
  issn = {1534-7362},
  doi = {10.1167/10.11.15},
  url = {https://doi.org/10.1167/10.11.15},
  urldate = {2024-07-10},
  abstract = {Bayesian cue combination models have been used to examine how human observers combine information from several cues to form estimates of linear quantities like depth. Here we develop an analogous theory for circular quantities like planar direction. The circular theory is broadly similar to the linear theory but differs in significant ways. First, in the circular theory the combined estimate is a nonlinear function of the individual cue estimates. Second, in the circular theory the mean of the combined estimate is affected not only by the means of individual cues and the weights assigned to individual cues but also by the variability of individual cues. Third, in the circular theory the combined estimate can be less certain than the individual estimates, if the individual estimates disagree with one another. Fourth, the circular theory does not have some of the closed-form expressions available in the linear theory, so data analysis requires numerical methods. We describe a vector sum model that gives a heuristic approximation to the circular theory's behavior. We also show how the theory can be extended to deal with spherical quantities like direction in three-dimensional space.},
  file = {/Users/kshitijgoel/Zotero/storage/AGDA94F7/Murray and Morgenstern - 2010 - Cue combination on the circle and the sphere.pdf;/Users/kshitijgoel/Zotero/storage/UCJ4QXF5/article.html}
}

@phdthesis{murray_patchlets_2003,
  title = {Patchlets : A Method of Interpreting Correlation Stereo {{3D}} Data},
  shorttitle = {Patchlets},
  author = {Murray, Donald R.},
  year = {2003},
  doi = {10.14288/1.0051745},
  url = {https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/831/items/1.0051745},
  urldate = {2024-06-30},
  abstract = {This thesis describes methods for fitting local planar surface elements, that we call patchlets, to 3D data obtained from correlation stereo images. We use these patchlets to robustly extract and estimate bounded planar surfaces from complex and noisy stereo scenes. The patchlet},
  langid = {english},
  school = {University of British Columbia},
  file = {/Users/kshitijgoel/Zotero/storage/GT2BRJ8W/patchlets.pdf}
}

@article{murray_using_2000,
  title = {Using {{Real-Time Stereo Vision}} for {{Mobile Robot Navigation}}},
  author = {Murray, Don and Little, James J.},
  year = {2000},
  month = apr,
  journal = {Autonomous Robots},
  volume = {8},
  number = {2},
  pages = {161--171},
  issn = {1573-7527},
  doi = {10.1023/A:1008987612352},
  url = {https://doi.org/10.1023/A:1008987612352},
  urldate = {2024-07-01},
  abstract = {This paper describes a working vision-based mobile robot that navigates and autonomously explores its environment while building occupancy grid maps of the environment. We present a method for reducing stereo vision disparity images to two-dimensional map information. Stereo vision has several attributes that set it apart from other sensors more commonly used for occupancy grid mapping. We discuss these attributes, the errors that some of them create, and how to overcome them. We reduce errors by segmenting disparity images based on continuous disparity surfaces to reject ``spikes'' caused by stereo mismatches. Stereo vision processing and map updates are done at 5 Hz and the robot moves at speeds of 300 cm/s.},
  langid = {english},
  keywords = {mobile robot navigation,stereo vision},
  file = {/Users/kshitijgoel/Zotero/storage/JH4WHB79/Murray and Little - 2000 - Using Real-Time Stereo Vision for Mobile Robot Navigation.pdf}
}

@article{murvanidze_enhanced_2022,
  title = {Enhanced {{GPIS Learning Based}} on {{Local}} and {{Global Focus Areas}}},
  author = {Murvanidze, Zuka and Deisenroth, Marc Peter and Bekiroglu, Yasemin},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3197905},
  abstract = {Implicit surface learning is one of the most widely used methods for 3D surface reconstruction from raw point cloud data. Current approaches employ deep neural networks or Gaussian process models with the trade-offs across computational performance, object fidelity, and generalization capabilities. We propose a novel method based on Gaussian process regression to build implicit surfaces for 3D surface reconstruction (GPIS), which leads to better accuracy in comparison to the standard GPIS formulation. Our approach encodes local and global shape information from the data to maintain the correct topology of the underlying shape. The proposed pipeline works on dense, sparse, and noisy raw point clouds and can be parallelized to improve computational efficiency. We evaluate our approach on synthetic and real point cloud datasets obtained from laser scans, synthetic CAD objects and robot visual and tactical sensors. Results show that our approach leads to high accuracy compared to baselines.},
  keywords = {Gaussian processes,Perception for Grasping and Manipulation,Point cloud compression,Shape,Surface reconstruction,Surface treatment,Three-dimensional displays,Training,Visual Learning},
  file = {/Users/kshitijgoel/Zotero/storage/DESXHWLL/Murvanidze et al. - 2022 - Enhanced GPIS Learning Based on Local and Global F.pdf}
}

@inproceedings{museth_openvdb_2013,
  title = {{{OpenVDB}}: An Open-Source Data Structure and Toolkit for High-Resolution Volumes},
  shorttitle = {{{OpenVDB}}},
  booktitle = {{{ACM SIGGRAPH}} 2013 {{Courses}}},
  author = {Museth, Ken and Lait, Jeff and Johanson, John and Budsberg, Jeff and Henderson, Ron and Alden, Mihai and Cucka, Peter and Hill, David and Pearce, Andrew},
  year = {2013},
  month = jul,
  series = {{{SIGGRAPH}} '13},
  pages = {1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2504435.2504454},
  url = {https://dl.acm.org/doi/10.1145/2504435.2504454},
  urldate = {2023-06-30},
  abstract = {OpenVDB has already been integrated into the next major release of the high-end 3D animation package Houdini, and there is anecdotal evidence that many of the major VFX and production houses are in the process of either evaluating or adopting VDB. This course presents a comprehensive overview of OpenVDB, an open-source C++ library comprising a novel hierarchical data structure and a suite of tools for efficient storage and manipulation of sparse volumetric data discretized on three-dimensional grids..},
  isbn = {978-1-4503-2339-0},
  file = {/Users/kshitijgoel/Zotero/storage/6UXKAJ6B/Museth et al. - 2013 - OpenVDB an open-source data structure and toolkit.pdf}
}

@article{museth_vdb_2013,
  title = {{{VDB}}: {{High-resolution}} Sparse Volumes with Dynamic Topology},
  shorttitle = {{{VDB}}},
  author = {Museth, Ken},
  year = {2013},
  month = jun,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {3},
  pages = {1--22},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2487228.2487235},
  url = {https://dl.acm.org/doi/10.1145/2487228.2487235},
  urldate = {2022-05-28},
  abstract = {We have developed a novel hierarchical data structure for the efficient representation of sparse, time-varying volumetric data discretized on a 3D grid. Our ``VDB'', so named because it is a Volumetric, Dynamic grid that shares several characteristics with B+trees, exploits spatial coherency of time-varying data to separately and compactly encode data values and grid topology. VDB models a virtually infinite 3D index space that allows for cache-coherent and fast data access into sparse volumes of high resolution. It imposes no topology restrictions on the sparsity of the volumetric data, and it supports fast (average               O               (1)) random access patterns when the data are inserted, retrieved, or deleted. This is in contrast to most existing sparse volumetric data structures, which assume either static or manifold topology and require specific data access patterns to compensate for slow random access. Since the VDB data structure is fundamentally hierarchical, it also facilitates adaptive grid sampling, and the inherent acceleration structure leads to fast algorithms that are well-suited for simulations. As such, VDB has proven useful for several applications that call for large, sparse, animated volumes, for example, level set dynamics and cloud modeling. In this article, we showcase some of these algorithms and compare VDB with existing, state-of-the-art data structures.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PI3IMIRU/Museth - 2013 - VDB High-resolution sparse volumes with dynamic t.pdf}
}

@article{musil_spheremap_2022,
  title = {{{SphereMap}}: {{Dynamic Multi-Layer Graph Structure}} for {{Rapid Safety-Aware UAV Planning}}},
  shorttitle = {{{SphereMap}}},
  author = {Musil, Tom{\'a}{\v s} and Petrl{\'i}k, Mat{\v e}j and Saska, Martin},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {11007--11014},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3195194},
  abstract = {A flexible topological representation consisting of a two-layer graph structure built on-board an Unmanned Aerial Vehicle (UAV) by continuously filling the free space of an occupancy map with intersecting spheres is proposed in this letter. Most state-of-the-art planning methods find the shortest paths while keeping the UAV at a pre-defined distance from obstacles. Planning over the proposed structure reaches this pre-defined distance only when necessary, maintaining a safer distance otherwise, while also being orders of magnitude faster than other state-of-the-art methods. Furthermore, we demonstrate how this graph representation can be converted into a lightweight shareable topological-volumetric map of the environment, which enables decentralized multi-robot cooperation. The proposed approach was successfully validated in several kilometers of real subterranean environments, such as caves, devastated industrial buildings, and in the harsh and complex setting of the final event of the DARPA SubT Challenge, which aims to mimic the conditions of real search and rescue missions as closely as possible, and where our approach achieved the 2\${\textasciicircum}{\textbackslash}mathrmnd\$ place in the virtual track.},
  keywords = {aerial systems: perception and autonomy,Autonomous aerial vehicles,Autonomous vehicle navigation,mapping,Navigation,Path planning,Planning,planning under uncertainty,Portals,robotics in hazardous fields,Robots,Safety},
  file = {/Users/kshitijgoel/Zotero/storage/MLNU943Q/Musil et al. - 2022 - SphereMap Dynamic Multi-Layer Graph Structure for.pdf;/Users/kshitijgoel/Zotero/storage/9CCALEU8/stamp.html}
}

@article{musslick_pushing_2023,
  title = {Pushing the {{Bounds}} of {{Bounded Optimality}} and {{Rationality}}},
  author = {Musslick, Sebastian and Mas{\'i}s, Javier},
  year = {2023},
  journal = {Cognitive Science},
  volume = {47},
  number = {4},
  pages = {e13259},
  issn = {1551-6709},
  doi = {10.1111/cogs.13259},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.13259},
  urldate = {2025-02-14},
  abstract = {All forms of cognition, whether natural or artificial, are subject to constraints of their computing architecture. This assumption forms the tenet of virtually all general theories of cognition, including those deriving from bounded optimality and bounded rationality. In this letter, we highlight an unresolved puzzle related to this premise: what are these constraints, and why are cognitive architectures subject to cognitive constraints in the first place? First, we lay out some pieces along the puzzle edge, such as computational tradeoffs inherent to neural architectures that give rise to rational bounds of cognition. We then outline critical next steps for characterizing cognitive bounds, proposing that some of these bounds can be subject to modification by cognition and, as such, are part of what is being optimized when cognitive agents decide how to allocate cognitive resources. We conclude that these emerging views may contribute to a more holistic perspective on the nature of cognitive bounds, as well as their alteration subject to cognition.},
  copyright = {{\copyright} 2023 Cognitive Science Society LLC.},
  langid = {english},
  keywords = {Bounded rationality,Cognitive constraints,Cognitive control,Learning,Meta-reasoning,Multitasking,Neural network architectures,Rational inattention},
  file = {/Users/kshitijgoel/Zotero/storage/MP4EB83E/Musslick and Masís - 2023 - Pushing the Bounds of Bounded Optimality and Rationality.pdf}
}

@inproceedings{nabarro_learning_2024,
  title = {Learning in {{Deep Factor Graphs}} with {{Gaussian Belief Propagation}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Nabarro, Seth and Wilk, Mark Van Der and Davison, Andrew},
  year = {2024},
  month = jul,
  pages = {37141--37163},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v235/nabarro24a.html},
  urldate = {2024-11-27},
  abstract = {We propose an approach to do learning in Gaussian factor graphs. We treat all relevant quantities (inputs, outputs, parameters, activations) as random variables in a graphical model, and view training and prediction as inference problems with different observed nodes. Our experiments show that these problems can be efficiently solved with belief propagation (BP), whose updates are inherently local, presenting exciting opportunities for distributed and asynchronous training. Our approach can be scaled to deep networks and provides a natural means to do continual learning: use the BP-estimated posterior of the current task as a prior for the next. On a video denoising task we demonstrate the benefit of learnable parameters over a classical factor graph approach and we show encouraging performance of deep factor graphs for continual image classification.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/87X8XAIR/Nabarro et al. - 2024 - Learning in Deep Factor Graphs with Gaussian Belief Propagation.pdf}
}

@misc{nacereddine_linear_2024,
  title = {Linear {{Anchored Gaussian Mixture Model}} for {{Location}} and {{Width Computations}} of {{Objects}} in {{Thick Line Shape}}},
  author = {Nacereddine, Nafaa and Goumeidane, Aicha Baya and Ziou, Djemel},
  year = {2024},
  month = may,
  number = {arXiv:2404.03043},
  eprint = {2404.03043},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2404.03043},
  urldate = {2024-11-10},
  abstract = {Accurate detection of the centerline of a thick linear structure and good estimation of its thickness are challenging topics in many real-world applications such X-ray imaging, remote sensing and lane marking detection in road traffic. Model-based approaches using Hough and Radon transforms are often used but, are not recommended for thick line detection, whereas methods based on image derivatives need further step-by-step processing making their efficiency dependent on each step outcome. In this paper, a novel paradigm to better detect thick linear objects is presented, where the 3D image gray level representation is considered as a finite mixture model of a statistical distribution, called linear anchored Gaussian distribution and parametrized by a scale factor to describe the structure thickness and radius and angle parameters to localize the structure centerline. Expectation-Maximization algorithm (Algo1) using the original image as input data is used to estimate the model parameters. To rid the data of irrelevant information brought by nonuniform and noisy background, a modified EM algorithm (Algo2) is detailed. In Experiments, the proposed algorithms show promising results on real-world images and synthetic images corrupted by blur and noise, where Algo2, using Hessian-based angle initialization, outperforms Algo1 and Algo2 with random angle initialization, in terms of running time and structure location and thickness computation accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/9BHLD7TS/Nacereddine et al. - 2024 - Linear Anchored Gaussian Mixture Model for Location and Width Computations of Objects in Thick Line.pdf;/Users/kshitijgoel/Zotero/storage/SMP6N82I/2404.html}
}

@article{naglik_gmmsampling_2023,
  title = {{{GMMSampling}}: A New Model-Based, Data Difficulty-Driven Resampling Method for Multi-Class Imbalanced Data},
  shorttitle = {{{GMMSampling}}},
  author = {Naglik, Iwo and Lango, Mateusz},
  year = {2023},
  month = nov,
  journal = {Machine Learning},
  issn = {1573-0565},
  doi = {10.1007/s10994-023-06416-8},
  url = {https://doi.org/10.1007/s10994-023-06416-8},
  urldate = {2023-11-23},
  abstract = {Learning from multi-class imbalanced data has still received limited research attention. Most of the proposed methods focus on the global class imbalance ratio only. In contrast, experimental studies demonstrated that the imbalance ratio itself is not the main difficulty in the imbalanced learning. It is the combination of the imbalance ratio with other data difficulty factors, such as class overlapping or minority class decomposition into various subconcepts, that significantly affects the classification performance. This paper presents GMMSampling---a new resampling method that exploits information about data difficulty factors to clear class overlapping regions from majority class instances and to simultaneously oversample each subconcept of the minority class. The experimental evaluation demonstrated that the proposed method achieves better results in terms of G-mean, balanced accuracy, macro-AP, MCC and F-score than other related methods.},
  langid = {english},
  keywords = {Data difficulty factors,Gaussian mixture model,Imbalanced data,Multi-class classification,Resampling methods},
  file = {/Users/kshitijgoel/Zotero/storage/ALLZH6EB/Naglik and Lango - 2023 - GMMSampling a new model-based, data difficulty-dr.pdf}
}

@inproceedings{nakagawa_estimating_2015,
  title = {Estimating {{Surface Normals}} with {{Depth Image Gradients}} for {{Fast}} and {{Accurate Registration}}},
  booktitle = {2015 {{International Conference}} on {{3D Vision}}},
  author = {Nakagawa, Yosuke and Uchiyama, Hideaki and Nagahara, Hajime and Taniguchi, Rin-Ichiro},
  year = {2015},
  month = oct,
  pages = {640--647},
  doi = {10.1109/3DV.2015.80},
  url = {https://ieeexplore.ieee.org/abstract/document/7335535},
  urldate = {2024-06-03},
  abstract = {We present a fast registration framework with estimating surface normals from depth images. The key component in the framework is to utilize adjacent pixels and compute the normal at each pixel on a depth image by following three steps. First, image gradients on a depth image are computed with a 2D differential filtering. Next, two 3D gradient vectors are computed from horizontal and vertical depth image gradients. Finally, the normal vector is obtained from the cross product of the 3D gradient vectors. Since horizontal and vertical adjacent pixels at each pixel are considered composing a local 3D plane, the 3D gradient vectors are equivalent to tangent vectors of the plane. Compared with existing normal estimation based on fitting a plane to a point cloud, our depth image gradients based normal estimation is extremely faster because it needs only a few mathematical operations. We apply it to normal space sampling based 3D registration and validate the effectiveness of our registration framework by evaluating its accuracy and computational cost with a public dataset.},
  keywords = {Accuracy,Cameras,Computational efficiency,Estimation,Surface treatment,Three-dimensional displays,Yttrium},
  file = {/Users/kshitijgoel/Zotero/storage/DSRA6BDQ/Nakagawa et al. - 2015 - Estimating Surface Normals with Depth Image Gradients for Fast and Accurate Registration.pdf;/Users/kshitijgoel/Zotero/storage/JADFVRTF/7335535.html}
}

@inproceedings{nakayama_global_2010,
  title = {Global {{Gaussian}} Approach for Scene Categorization Using Information Geometry},
  booktitle = {2010 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Nakayama, Hideki and Harada, Tatsuya and Kuniyoshi, Yasuo},
  year = {2010},
  month = jun,
  pages = {2336--2343},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2010.5539921},
  url = {https://ieeexplore.ieee.org/abstract/document/5539921},
  urldate = {2023-09-28},
  abstract = {Local features provide powerful cues for generic image recognition. An image is represented by a ``bag'' of local features, which form a probabilistic distribution in the feature space. The problem is how to exploit the distributions efficiently. One of the most successful approaches is the bag-of-keypoints scheme, which can be interpreted as sparse sampling of high-level statistics, in the sense that it describes a complex structure of a local feature distribution using a relatively small number of parameters. In this paper, we propose the opposite approach, dense sampling of low-level statistics. A distribution is represented by a Gaussian in the entire feature space. We define some similarity measures of the distributions based on an information geometry framework and show how this conceptually simple approach can provide a satisfactory performance, comparable to the bag-of-keypoints for scene classification tasks. Furthermore, because our method and bag-of-keypoints illustrate different statistical points, we can further improve classification performance by using both of them in kernels.},
  file = {/Users/kshitijgoel/Zotero/storage/EBQZKLVU/Nakayama et al. - 2010 - Global Gaussian approach for scene categorization .pdf}
}

@inproceedings{nalamothu_leveraging_2024,
  title = {Leveraging {{Augmented Reality}} for {{Improved Situational Awareness During UAV-Driven Search}} and {{Rescue Missions}}},
  booktitle = {2024 {{IEEE International Symposium}} on {{Safety Security Rescue Robotics}} ({{SSRR}})},
  author = {Nalamothu, Rushikesh and Sontha, Puneet and Karravula, Janardhan and Agrawal, Ankit},
  year = {2024},
  month = nov,
  pages = {221--228},
  issn = {2475-8426},
  doi = {10.1109/SSRR62954.2024.10770051},
  url = {https://ieeexplore.ieee.org/document/10770051/},
  urldate = {2025-06-01},
  abstract = {In the high-stakes domain of search-and-rescue missions, the deployment of Unmanned Aerial Vehicles (UAVs) has become increasingly pivotal. These missions require seam-less, real-time communication among diverse roles within response teams, particularly between Remote Operators (ROs) and On-Site Operators (OSOs). Traditionally, ROs and OSOs have relied on radio communication to exchange critical information, such as the geolocation of victims, hazardous areas, and points of interest. However, radio communication lacks in-formation visualization, suffers from noise, and requires mental effort to interpret information, leading to miscommunications and misunderstandings. To address these challenges, this paper presents VizCom-AR, an Augmented Reality system designed to facilitate visual communication between ROs and OSOs and their situational awareness during UAV-driven search-and-rescue missions. Our experiments, focus group sessions with police officers, and field study showed that VizCom-AR enhances spatial awareness of both ROs and OSOs, facilitate geolocation information exchange, and effectively complement existing communication tools in UAV-driven emergency re-sponse missions. Overall, VizCom-AR offers a fundamental framework for designing Augmented Reality systems for large scale UAV-driven rescue missions.},
  keywords = {Augmented reality,Geology,Noise,Radio communication,Real-time systems,Robots,Safety,Security,Visual communication,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/94A8F3M4/Nalamothu et al. - 2024 - Leveraging Augmented Reality for Improved Situational Awareness During UAV-Driven Search and Rescue.pdf}
}

@inproceedings{narr_streambased_2016,
  title = {Stream-Based {{Active Learning}} for Efficient and Adaptive Classification of {{3D}} Objects},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Narr, Alexander and Triebel, Rudolph and Cremers, Daniel},
  year = {2016},
  month = may,
  pages = {227--233},
  doi = {10.1109/ICRA.2016.7487138},
  url = {https://ieeexplore.ieee.org/document/7487138/?arnumber=7487138},
  urldate = {2025-02-20},
  abstract = {We present a new Active Learning approach for classifying objects from streams of 3D point cloud data. The major problems here are the non-uniform occurrence of class instances and the unbalanced numbers of samples per class. We show that standard online learning methods based on decision trees perform comparably bad for such data streams, which are however particularly relevant for mobile robots that need to learn semantics persistently. To address this, we use Mondrian forests (MF), a recent online learning algorithm that is independent on the data order. We present an extension of that algorithm and show that MF are less overconfident than standard Random Forests. In experiments on the KITTI benchmark, we show that this leads to a substantially improved classification performance for data streams, rendering our approach very attractive for lifelong robot learning applications.},
  keywords = {Learning systems,Robots,Semantics,Standards,Three-dimensional displays,Training,Training data},
  file = {/Users/kshitijgoel/Zotero/storage/YX2B25ND/Narr et al. - 2016 - Stream-based Active Learning for efficient and adaptive classification of 3D objects.pdf;/Users/kshitijgoel/Zotero/storage/78RTHZBF/7487138.html}
}

@article{navarrete_compression_2018,
  title = {Compression and Registration of {{3D}} Point Clouds Using {{GMMs}}},
  author = {Navarrete, Javier and Viejo, Diego and Cazorla, Miguel},
  year = {2018},
  month = jul,
  journal = {Pattern Recognition Letters},
  volume = {110},
  pages = {8--15},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2018.03.017},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865518300989},
  urldate = {2023-01-05},
  abstract = {3D data sensors provide an enormous amount of information. It is necessary to develop efficient methods to manage this information under certain time, bandwidth or storage space requirements. In this work, we propose a 3D compression and decompression method. This method also allows the use of the compressed data for a registration process. First, points are selected and grouped, using a 3D-model based on planar surfaces. Next, we use a fast variant of Gaussian Mixture Models and an Expectation-Maximization algorithm to replace the points grouped in the previous step with a set of Gaussian distributions. These learned models can be used as features to find matches between two consecutive poses and apply 3D pose registration using RANSAC. Finally, the 3D map can be obtained by decompressing the models.},
  langid = {english},
  keywords = {3D compression,3D registration},
  file = {/Users/kshitijgoel/Zotero/storage/PX58IA6A/Navarrete et al. - 2018 - Compression and registration of 3D point clouds us.pdf;/Users/kshitijgoel/Zotero/storage/H8BZ5SFQ/S0167865518300989.html}
}

@article{navarro_multivariate_2017,
  title = {The {{Multivariate Generalised}} von {{Mises Distribution}}: {{Inference}} and {{Applications}}},
  shorttitle = {The {{Multivariate Generalised}} von {{Mises Distribution}}},
  author = {Navarro, Alexandre and Frellsen, Jes and Turner, Richard},
  year = {2017},
  month = feb,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {31},
  number = {1},
  issn = {2374-3468},
  doi = {10.1609/aaai.v31i1.10943},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/10943},
  urldate = {2025-01-21},
  abstract = {Circular variables arise in a multitude of data-modelling contexts ranging from robotics to the social sciences, but they have been largely overlooked by the machine learning community. This paper partially redresses this imbalance by extending some standard probabilistic modelling tools to the circular domain. First we introduce a new multivariate distribution over circular variables, called the multivariate Generalised von Mises (mGvM) distribution. This distribution can be constructed by restricting and renormalising a general multivariate Gaussian distribution to the unit hyper-torus. Previously proposed multivariate circular distributions are shown to be special cases of this construction. Second, we introduce a new probabilistic model for circular regression inspired by Gaussian Processes, and a method for probabilistic Principal Component Analysis with circular hidden variables. These models can leverage standard modelling tools (e.g. kernel functions and automatic relevance determination). Third, we show that the posterior distribution in these models is a mGvM distribution which enables development of an efficient variational free-energy scheme for performing approximate inference and approximate maximum-likelihood learning.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {Approximate inference,Bayesian inference,Circular statistics,Gaussian Processes,Kernels},
  file = {/Users/kshitijgoel/Zotero/storage/IUY7G33X/Navarro et al. - 2017 - The Multivariate Generalised von Mises Distribution Inference and Applications.pdf}
}

@incollection{neal_view_1998,
  title = {A {{View}} of the {{Em Algorithm}} That {{Justifies Incremental}}, {{Sparse}}, and Other {{Variants}}},
  booktitle = {Learning in {{Graphical Models}}},
  author = {Neal, Radford M. and Hinton, Geoffrey E.},
  editor = {Jordan, Michael I.},
  year = {1998},
  pages = {355--368},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-011-5014-9_12},
  url = {https://doi.org/10.1007/978-94-011-5014-9_12},
  urldate = {2024-03-28},
  abstract = {The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible.},
  isbn = {978-94-011-5014-9},
  langid = {english},
  keywords = {Data Item,Incremental Algorithm,Incremental Variant,Standard Algorithm,Unobserved Variable},
  file = {/Users/kshitijgoel/Zotero/storage/7XMEKB4E/Neal and Hinton - 1998 - A View of the Em Algorithm that Justifies Incremen.pdf}
}

@book{needham_visual_2021,
  title = {Visual {{Differential Geometry}} and {{Forms}}: {{A Mathematical Drama}} in {{Five Acts}}},
  shorttitle = {Visual {{Differential Geometry}} and {{Forms}}},
  author = {Needham, Tristan},
  year = {2021},
  eprint = {j.ctv1cmsmx5},
  eprinttype = {jstor},
  publisher = {Princeton University Press},
  doi = {10.2307/j.ctv1cmsmx5},
  url = {https://www.jstor.org/stable/j.ctv1cmsmx5},
  urldate = {2024-11-12},
  abstract = {{$<$}strong{$>$}An inviting, intuitive, and visual{$<$}/strong{$>$} {$<$}strong{$>$}exploration of differential geometry and forms{$<$}/strong{$>$}  \emph{Visual Differential Geometry and Forms}  fulfills two principal goals. In the first four acts, Tristan Needham puts the geometry back into differential geometry \emph{.}  Using 235 hand-drawn diagrams, Needham deploys Newton's geometrical methods to provide geometrical explanations of the classical results. In the fifth act, he offers the first undergraduate introduction to differential forms that treats advanced topics in an intuitive and geometrical manner. Unique features of the first four acts include: four distinct geometrical proofs of the fundamentally important Global Gauss-Bonnet theorem, providing a stunning link between local geometry and global topology; a simple, geometrical proof of Gauss's famous Theorema Egregium; a complete geometrical treatment of the Riemann curvature tensor of an  \emph{n} -manifold; and a detailed geometrical treatment of Einstein's field equation, describing gravity as curved spacetime (General Relativity), together with its implications for gravitational waves, black holes, and cosmology. The final act elucidates such topics as the unification of all the integral theorems of vector calculus; the elegant reformulation of Maxwell's equations of electromagnetism in terms of 2-forms; de Rham cohomology; differential geometry via Cartan's method of moving frames; and the calculation of the Riemann tensor using curvature 2-forms. Six of the seven chapters of Act V can be read completely independently from the rest of the book. Requiring only basic calculus and geometry, {$<$}em{$>$}Visual Differential Geometry and Forms{$<$}/em{$>$} provocatively rethinks the way this important area of mathematics should be considered and taught.},
  isbn = {978-0-691-20369-0}
}

@article{nelson_environment_2018,
  title = {Environment Model Adaptation for Mobile Robot Exploration},
  author = {Nelson, Erik and Corah, Micah and Michael, Nathan},
  year = {2018},
  month = feb,
  journal = {Autonomous Robots},
  volume = {42},
  number = {2},
  pages = {257--272},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-017-9669-2},
  url = {http://link.springer.com/10.1007/s10514-017-9669-2},
  urldate = {2021-09-29},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M8K93MZW/Nelson et al. - 2018 - Environment model adaptation for mobile robot expl.pdf}
}

@techreport{nelson_sketching_,
  title = {Sketching {{Algorithms}}},
  author = {Nelson, Jelani},
  institution = {UC Berkeley},
  url = {https://www.sketchingbigdata.org/fall20/lec/notes.pdf},
  urldate = {2024-12-01},
  file = {/Users/kshitijgoel/Zotero/storage/IQMM26KQ/notes.pdf}
}

@inproceedings{nematollahi_robot_2022,
  title = {Robot {{Skill Adaptation}} via {{Soft Actor-Critic Gaussian Mixture Models}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Nematollahi, Iman and {Rosete-Beas}, Erick and R{\"o}fer, Adrian and Welschehold, Tim and Valada, Abhinav and Burgard, Wolfram},
  year = {2022},
  month = may,
  pages = {8651--8657},
  doi = {10.1109/ICRA46639.2022.9811770},
  abstract = {\$A\$ core challenge for an autonomous agent acting in the real world is to adapt its repertoire of skills to cope with its noisy perception and dynamics. To scale learning of skills to long-horizon tasks, robots should be able to learn and later refine their skills in a structured manner through trajectories rather than making instantaneous decisions individually at each time step. To this end, we propose the Soft Actor- Critic Gaussian Mixture Model (SAC-GMM), a novel hybrid approach that learns robot skills through a dynamical system and adapts the learned skills in their own trajectory distribution space through interactions with the environment. Our approach combines classical robotics techniques of learning from demonstration with the deep reinforcement learning framework and exploits their complementary nature. We show that our method utilizes sensors solely available during the execution of preliminarily learned skills to extract relevant features that lead to faster skill refinement. Extensive evaluations in both simulation and real-world environments demonstrate the effectiveness of our method in refining robot skills by leveraging physical interactions, high-dimensional sensory data, and sparse task completion rewards. Videos, code, and pre-trained models are available at http://sac-gmm.cs.uni-freiburg.de.},
  keywords = {Adaptation models,Noise measurement,Refining,Reinforcement learning,Robot sensing systems,Stability analysis,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/QKDZ9XCJ/Nematollahi et al. - 2022 - Robot Skill Adaptation via Soft Actor-Critic Gauss.pdf;/Users/kshitijgoel/Zotero/storage/WFIH3YBW/9811770.html}
}

@article{newaz_lcdrig_2024,
  title = {{{LCD-RIG}}: {{Limited Communication Decentralized Robotic Information Gathering Systems}}},
  shorttitle = {{{LCD-RIG}}},
  author = {Newaz, Abdullah Al Redwan and Padrao, Paulo and Fuentes, Jose and Alam, Tauhidul and Govindarajan, Ganesh and Bobadilla, Leonardo},
  year = {2024},
  month = nov,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {11},
  pages = {10034--10041},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3468167},
  url = {https://ieeexplore.ieee.org/document/10693516/?arnumber=10693516},
  urldate = {2024-11-29},
  abstract = {Effective data collection in collaborative information-gathering systems relies heavily on maintaining uninterrupted connectivity. Yet, real-world communication disruptions often pose challenges to information-gathering processes. To address this issue, we introduce a novel method ---a limited communication decentralized information gathering system for multiple robots to explore environmental phenomena characterized as unknown spatial fields. Our method leverages quadtree structures to ensure comprehensive workspace coverage and efficient exploration. Unlike traditional systems that depend on global and synchronous communication, our method enables robots to share local experiences within a limited transmission range and coordinate their tasks through pairwise and asynchronous communication. Information estimation is facilitated by a Gaussian Process with an Attentive Kernel, allowing adaptive capturing of crucial behavior and data patterns. Our proposed system is validated through simulated scalar field studies in non-stationary environments where multiple robots explore spatial fields. Theoretical guarantees ensure the convergence of distributed area coverage and the regret bounds of distributed online scalar field mapping. We also validate our method empirically in a water quality monitoring scenario featuring three Autonomous Surface Vehicles, tasked with constructing a spatial field.},
  keywords = {Collaboration,Collision avoidance,decentralized infor- mation gathering,Gaussian process,Gaussian processes,Limited communication,Planning,Probabilistic logic,Robot kinematics,Robots,spatial fields},
  file = {/Users/kshitijgoel/Zotero/storage/ARP5P46A/Newaz et al. - 2024 - LCD-RIG Limited Communication Decentralized Robotic Information Gathering Systems.pdf;/Users/kshitijgoel/Zotero/storage/AH9DEHH4/10693516.html}
}

@inproceedings{newcombe_kinectfusion_2011,
  title = {{{KinectFusion}}: {{Real-time}} Dense Surface Mapping and Tracking},
  shorttitle = {{{KinectFusion}}},
  booktitle = {2011 10th {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}}},
  author = {Newcombe, Richard A. and Fitzgibbon, Andrew and Izadi, Shahram and Hilliges, Otmar and Molyneaux, David and Kim, David and Davison, Andrew J. and Kohi, Pushmeet and Shotton, Jamie and Hodges, Steve},
  year = {2011},
  month = oct,
  pages = {127--136},
  publisher = {IEEE},
  address = {Basel},
  doi = {10.1109/ISMAR.2011.6092378},
  url = {https://ieeexplore.ieee.org/document/6162880/},
  urldate = {2022-02-06},
  isbn = {978-1-4577-2183-0 978-1-4577-2185-4},
  file = {/Users/kshitijgoel/Zotero/storage/9RK3DAXP/Newcombe et al. - 2011 - KinectFusion Real-time dense surface mapping and .pdf}
}

@inproceedings{newcombe_why_2014,
  title = {Why {{Amazon Chose TLA}}\,+},
  booktitle = {Abstract {{State Machines}}, {{Alloy}}, {{B}}, {{TLA}}, {{VDM}}, and {{Z}}},
  author = {Newcombe, Chris},
  editor = {Ait Ameur, Yamine and Schewe, Klaus-Dieter},
  year = {2014},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {25--39},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-43652-3_3},
  abstract = {Since 2011, engineers at Amazon have been using TLA\,+\, to help solve difficult design problems in critical systems. This paper describes the reasons why we chose TLA\,+\, instead of other methods, and areas in which we would welcome further progress.},
  isbn = {978-3-662-43652-3},
  langid = {english},
  keywords = {Linear Temporal Logic,Model Checker,Proof System,Safety Property,Temporal Logic},
  file = {/Users/kshitijgoel/Zotero/storage/H9GM93AW/Newcombe - 2014 - Why Amazon Chose TLA +.pdf}
}

@article{nguyen_flexible_2022,
  title = {Flexible and {{Resource-Efficient Multi-Robot Collaborative Visual-Inertial-Range Localization}}},
  author = {Nguyen, Thien Hoang and Nguyen, Thien-Minh and Xie, Lihua},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {928--935},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3136286},
  abstract = {In multi-robot systems, two important research problems are relative localization between the robots and global localization of all robots in a common frame. Traditional methods rely on detecting inter and intra-robot loop closures, which can be restrictive operation-wise since the robot must form loops. Ultra-wideband sensors, which provide direct distance measurements and robot ID, can replace loop closures in many applications. However, existing research on UWB-aided multi-robot state estimation often ignores the odometry drift which leads to inaccurate global position in the long run. In this work, we present a UWB-aided multi-robot localization system that does not rely on loop closure (flexible) and only requires odometry data from neighbors (resource-efficient). We propose a two-stage approach: 1) with a long sliding window, the relative transformation is refined based on range and odometry data, 2) onboard visual-inertial-range data are tightly fused in a short-term sliding window to provide more accurate local and global estimates. Simulation and real-life experiments with two quadrotors show that the system as a whole outperforms previous approaches as well as its individual parts.},
  keywords = {Cameras,Localization,Location awareness,multi-robot SLAM,Optimization,Robot kinematics,Robot sensing systems,sensor fusion,Sensors,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/3BW3VUJA/Nguyen et al. - 2022 - Flexible and Resource-Efficient Multi-Robot Collab.pdf;/Users/kshitijgoel/Zotero/storage/BTPLXZ27/9655461.html}
}

@inproceedings{nguyen_motion_2022,
  title = {Motion {{Primitives-based Navigation Planning}} Using {{Deep Collision Prediction}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Nguyen, Huan and Fyhn, Sondre Holm and De Petris, Paolo and Alexis, Kostas},
  year = {2022},
  month = may,
  pages = {9660--9667},
  publisher = {IEEE},
  address = {Philadelphia, PA, USA},
  doi = {10.1109/ICRA46639.2022.9812231},
  url = {https://ieeexplore.ieee.org/document/9812231/},
  urldate = {2024-01-24},
  abstract = {This paper contributes a method to design a novel navigation planner exploiting a learning-based collision prediction network. The neural network is tasked to predict the collision cost of each action sequence in a predefined motion primitives library in the robot's velocity-steering angle space, given only the current depth image and the estimated linear and angular velocities of the robot. Furthermore, we account for the uncertainty of the robot's partial state by utilizing the Unscented Transform and the uncertainty of the neural network model by using Monte Carlo dropout. The uncertainty-aware collision cost is then combined with the goal direction given by a global planner in order to determine the best action sequence to execute in a receding horizon manner. To demonstrate the method, we develop a resilient small flying robot integrating lightweight sensing and computing resources. A set of simulation and experimental studies, including a field deployment, in both cluttered and perceptually-challenging environments is conducted to evaluate the quality of the prediction network and the performance of the proposed planner.},
  isbn = {978-1-7281-9681-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MRK755WP/Nguyen et al. - 2022 - Motion Primitives-based Navigation Planning using .pdf}
}

@article{nguyen_multivariate_2025,
  title = {Multivariate {{Active Learning}} and {{Adaptive Sampling With Multi-Kernel Gaussian Processes}}},
  author = {Nguyen, Thien Hoang and Wallace, Nathan and Harrison, Nicholas and Sukkarieh, Salah},
  year = {2025},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {7},
  pages = {6584--6591},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3570127},
  url = {https://ieeexplore.ieee.org/document/11003577/},
  urldate = {2025-06-09},
  abstract = {In agriculture, understanding the distribution and relationship between different aspects of the environment is important for minimizing chemical use and reducing environmental impact. Traditionally, it is done by manually collecting samples on the field and then sending them to a laboratory for analysis. This is not only labor-intensive and costly, but the results will still be outdated. There is thus a growing interest in developing robotic systems to map these variables and uncover their correlations in real time. However, existing learning and sampling methods only focus on one quantity of interest (QoI) or make assumptions that might lead to sub-optimal results when there are multiple QoIs. In this work, we propose a multivariate active transfer learning and intelligent adaptive sampling system that can simultaneously learn the most accurate models for multiple QoIs as well as the relationship between them, and leverage that knowledge to select the next best locations to sample. Performance benchmarking against existing methods shows that QoIs are mapped more accurately, complex correlations between QoIs are identified more precisely, and travel routes are planned more efficiently.},
  keywords = {Accuracy,active transfer learning,Adaptation models,Adaptive sampling,Correlation,Covariance matrices,Data models,Gaussian processes,Kernel,multi-kernel Gaussian process,precision agriculture,Robots,Training,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/MIKXJYP3/Nguyen et al. - 2025 - Multivariate Active Learning and Adaptive Sampling With Multi-Kernel Gaussian Processes.pdf}
}

@article{nguyen_nonconservative_2025,
  title = {Non-{{Conservative Efficient Collision Checking}} and {{Depth Noise-Awareness}} for {{Trajectory Planning}}},
  author = {Nguyen, Binh and Murshed, Manzur and Choudhury, Tanveer and Keogh, Kathleen and Appuhamillage, Gayan Kahandawa and Nguyen, Linh},
  year = {2025},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3580318},
  url = {https://ieeexplore.ieee.org/document/11037478/},
  urldate = {2025-06-18},
  abstract = {This paper presents MIDI (Minimum dIstance-based and Depth-noIse-aware), a novel trajectory planner that introduces non-conservative collision checking and depth noise awareness for robust autonomous navigation. Unlike existing collision-checking approaches that rely on trajectory discretization or geometric approximations of free space, MIDI evaluates each depth pixel independently against an entire trajectory at once. Thus, it bypasses both the notorious grid-size problem in trajectory discretization and conservativeness inherent in free space geometric approximations. Leveraging polynomial trajectory properties to compute minimum distances and collision probabilities for all obstacle points in closed-form, MIDI facilitates both non-conservative and real-time trajectory collision checking. Moreover, to the best of our knowledge, MIDI is the first memoryless planner that explicitly incorporates depth uncertainty information into online trajectory planning. Extensive simulations show that MIDI outperforms state-of-the-art memoryless planners, maintaining robust performance even under severe depth noise, where competing methods show significant degradation. The algorithm's non-conservative nature enables better utilization of free space, resulting in notably lower incompletion rates in cluttered environments. Finally, real-world flight trials were conducted to validate the effectiveness of our approach in an actual quadrotor.},
  keywords = {Aerial Systems: Perception and Autonomy,Autonomous Vehicle Navigation,Cameras,Collision Avoidance,Noise,Planning,Planning under Uncertainty,Polynomials,RGB-D Perception,Robot kinematics,Robot vision systems,Three-dimensional displays,Trajectory,Trajectory planning,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/L5SM48NK/Nguyen et al. - 2025 - Non-Conservative Efficient Collision Checking and Depth Noise-Awareness for Trajectory Planning.pdf}
}

@inproceedings{nguyen_online_2024,
  title = {Online {{State-to-State Time-Optimal Trajectory Planning}} for {{Quadrotors}} in {{Unknown Cluttered Environments}}},
  booktitle = {2024 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Nguyen, Binh and Murshed, Manzur and Choudhury, Tanveer and Keogh, Kathleen and Appuhamillage, Gayan Kahandawa and Nguyen, Linh},
  year = {2024},
  month = jun,
  pages = {309--316},
  issn = {2575-7296},
  doi = {10.1109/ICUAS60882.2024.10556839},
  url = {https://ieeexplore.ieee.org/document/10556839/},
  urldate = {2025-06-18},
  abstract = {This paper introduces the first planner, called STAMINER (STAte-to-state tiMe-optImal memoryless planNER), which is able to real-time plan collision-free, local time-optimal trajectories in unknown and cluttered settings without the need for any maps or fused occupancy structures of the surrounding environment. Specifically, our method explores a library of state-to-state time-optimal trajectories in a memoryless collision-checking framework. It iteratively searches for the best trajectory with the longest projection on the direction to the goal. Results obtained from two different simulated cluttered scenarios demonstrate that our planner outperforms the state-of-the-art baselines concerning global finishing time. Furthermore, real-world flight trials were conducted to validate the effectiveness of our algorithm in an actual quadrotor. Finally, this paper also provides a mathematical proof of the solution characterization that is not available in the literature for the considered state-to-state time-optimal trajectory generation problem.},
  keywords = {Navigation,Planning,Real-time systems,Safety,Trajectory,Trajectory planning,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/EX2SJG9A/Nguyen et al. - 2024 - Online State-to-State Time-Optimal Trajectory Planning for Quadrotors in Unknown Cluttered Environme.pdf}
}

@article{nguyen_uncertaintyaware_2023,
  title = {Uncertainty-Aware Visually-Attentive Navigation Using Deep Neural Networks},
  author = {Nguyen, Huan and Andersen, Rasmus and Boukas, Evangelos and Alexis, Kostas},
  year = {2023},
  month = dec,
  journal = {The International Journal of Robotics Research},
  pages = {02783649231218720},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649231218720},
  url = {https://doi.org/10.1177/02783649231218720},
  urldate = {2024-02-09},
  abstract = {Autonomous navigation and information gathering in challenging environments are demanding since the robot?s sensors may be susceptible to non-negligible noise, its localization and mapping may be subject to significant uncertainty and drift, and performing collision-checking or evaluating utility functions using a map often requires high computational costs. We propose a learning-based method to efficiently tackle this problem without relying on a map of the environment or the robot?s position. Our method utilizes a Collision Prediction Network (CPN) for predicting the collision scores of a set of action sequences, and an Information gain Prediction Network (IPN) for estimating their associated information gain. Both networks assume access to a) the depth image (CPN) or the depth image and the detection mask from any visual method (IPN), b) the robot?s partial state (including its linear velocities, z-axis angular velocity, and roll/pitch angles), and c) a library of action sequences. Specifically, the CPN accounts for the estimation uncertainty of the robot?s partial state and the neural network?s epistemic uncertainty by using the Unscented Transform and an ensemble of neural networks. The outputs of the networks are combined with a goal vector to identify the next-best-action sequence. Simulation studies demonstrate the method?s robustness against noisy robot velocity estimates and depth images, alongside its advantages compared to state-of-the-art methods and baselines in (visually-attentive) navigation tasks. Lastly, multiple real-world experiments are presented, including safe flights at 2.5~m/s in a cluttered corridor, and missions inside a dense forest alongside visually-attentive navigation in industrial and university buildings.},
  file = {/Users/kshitijgoel/Zotero/storage/XPW9UUSK/Nguyen et al. - 2023 - Uncertainty-aware visually-attentive navigation us.pdf}
}

@phdthesis{ni_authoring_2024,
  type = {Thesis},
  title = {Authoring {{Conceptual Diagrams}} by {{Codifying Visual Representations}}},
  author = {Ni, Wode},
  year = {2024},
  month = dec,
  doi = {10.1184/R1/27969048.v1},
  url = {https://kilthub.cmu.edu/articles/thesis/Authoring_Conceptual_Diagrams_by_Codifying_Visual_Representations/27969048/1},
  urldate = {2025-01-03},
  abstract = {Visual representations like diagrams are powerful tools for thought. Diagrams are used extensively to understand abstract relationships, explain complex ideas, and solve difficult problems.I conducted an interview study to understand how domain experts create diagrams and identified key limitations in current tools. To illustrate concepts effectively, experts find appropriate visual representations and translate concepts into concrete shapes. This translation step is not supported explicitly by existing diagramming tools. Our participants reported how they create, adapt, and reuse visual representations using both sketches and digital tools. However, they had trouble using digital tools to transition from sketches and reuse components from earlier diagrams. Based on these results, we suggest four opportunities of diagramming tools---exploration support, representation salience, live engagement, and vocabulary correspondence---that together enable a natural diagramming experience.The findings from these studies informed the design of PENROSE, a language-based system that allows authors to codify domain-specific concepts and their visual representations. In PENROSE, the visual representation is user-defined in a constraint-based specification language; diagrams are then generated automatically via constrained numerical optimization. The system is designed to be user-extensible to many domains. In contrast to tools that specify diagrams via direct manipulation or low-level graphics programming, PENROSE enables rapid creation and exploration of diagrams that faithfully preserve the underlying visual representation. I demonstrate the effectiveness and generality of the system by showing how it can be used to illustrate a diverse set of concepts from various domains.Atop PENROSE, I built EDGEWORTH, a tool designed to help educators easily create visual problems. EDGEWORTH works in two main ways: firstly, it takes a single diagram from the user and systematically alters it to produce many variations, which the educator can then choose from to create multiple problems. Secondly, it automates the layout of diagrams, ensuring consistent high quality without the need for manual adjustments. I collected a dataset of diagrammatic multiple-choice problems to show that EDGEWORTH can create problems in three domains: geometry, chemistry, and discrete math. EDGEWORTH generated usable answer options within the first 10 diagram variations in 87\% of authored problems. I then performed a user study to measure authors' efficiency at creating translation problems using EDGEWORTH, compared with a conventional drawing tool. The results show that once authors make a correct diagram, they are about 3 times faster at making diagrammatic options for translation problems using EDGEWORTH compared to Google Drawings. Finally, in response to walkthrough demonstrations, expert educators gave positive feedback on EDGEWORTH's utility and the real-world applicability of its outputs.PENROSE and EDGEWORTH demonstrate that codifying visual representations allow diagrams authors to reuse their design effort, produce new diagrams faster, and thus make diagrams at a larger scale.},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/39BYFHJ5/Ni - 2024 - Authoring Conceptual Diagrams by Codifying Visual Representations.pdf;/Users/kshitijgoel/Zotero/storage/9NGTYIB5/Ni - 2024 - Authoring Conceptual Diagrams by Codifying Visual Representations.pdf}
}

@inproceedings{ni_ntfields_2022,
  title = {{{NTFields}}: {{Neural Time Fields}} for {{Physics-Informed Robot Motion Planning}}},
  shorttitle = {{{NTFields}}},
  booktitle = {The {{Eleventh International Conference}} on {{Learning Representations}}},
  author = {Ni, Ruiqi and Qureshi, Ahmed H.},
  year = {2022},
  month = sep,
  url = {https://openreview.net/forum?id=ApF0dmi1_9K},
  urldate = {2024-01-24},
  abstract = {Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have also led to physics-informed deep neural models capable of representing complex dynamical Partial Differential Equations (PDEs). Inspired by these developments, we propose Neural Time Fields (NTFields) for robot motion planning in cluttered scenarios. Our framework represents a wave propagation model generating continuous arrival time to find path solutions informed by a nonlinear first-order PDE called Eikonal Equation. We evaluate our method in various cluttered 3D environments, including the Gibson dataset, and demonstrate its ability to solve motion planning problems for 4-DOF and 6-DOF robot manipulators where the traditional grid-based Eikonal planners often face the curse of dimensionality. Furthermore, the results show that our method exhibits high success rates and significantly lower computational times than the state-of-the-art methods, including NMPs that require training data from classical planners.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6DWRZRAA/Ni and Qureshi - 2022 - NTFields Neural Time Fields for Physics-Informed .pdf}
}

@inproceedings{ni_progressive_2023,
  title = {Progressive {{Learning}} for {{Physics-informed Neural Motion Planning}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Ni, Ruiqi and Qureshi, Ahmed},
  year = {2023},
  month = jul,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2023.XIX.063},
  url = {http://www.roboticsproceedings.org/rss19/p063.pdf},
  urldate = {2024-01-24},
  abstract = {Motion planning (MP) is one of the core robotics problems requiring fast methods for finding a collision-free robot motion path connecting the given start and goal states. Neural motion planners (NMPs) demonstrate fast computational speed in finding path solutions but require a huge amount of expert trajectories for learning, thus adding a significant training computational load. In contrast, recent advancements have also led to a physics-informed NMP approach that directly solves the Eikonal equation for motion planning and does not require expert demonstrations for learning. However, experiments show that the physics-informed NMP approach performs poorly in complex environments and lacks scalability in multiple scenarios and highdimensional real robot settings. To overcome these limitations, this paper presents a novel and tractable Eikonal equation formulation and introduces a new progressive learning strategy to train neural networks without expert data in complex, cluttered, multiple high-dimensional robot motion planning scenarios. The results demonstrate that our method outperforms state-of-the-art traditional MP, data-driven NMP, and physics-informed NMP methods by a significant margin in terms of computational planning speed, path quality, and success rates. We also show that our approach scales to multiple complex, cluttered scenarios and the real robot set up in a narrow passage environment. The proposed method's videos and code implementations are available at https://github.com/ruiqini/P-NTFields.},
  isbn = {978-0-9923747-9-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DW72EKF9/Ni and Qureshi - 2023 - Progressive Learning for Physics-informed Neural M.pdf}
}

@misc{niculescu_ultralightweight_2024,
  title = {Ultra-{{Lightweight Collaborative Mapping}} for {{Robot Swarms}}},
  author = {Niculescu, Vlad and Polonelli, Tommaso and Magno, Michele and Benini, Luca},
  year = {2024},
  month = aug,
  number = {arXiv:2407.03136},
  eprint = {2407.03136},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.03136},
  urldate = {2024-10-14},
  abstract = {A key requirement in robotics is the ability to simultaneously self-localize and map a previously unknown environment, relying primarily on onboard sensing and computation. Achieving fully onboard accurate simultaneous localization and mapping (SLAM) is feasible for high-end robotic platforms, whereas small and inexpensive robots face challenges due to constrained hardware, therefore frequently resorting to external infrastructure for sensing and computation. The challenge is further exacerbated in swarms of robots, where coordination, scalability, and latency are crucial concerns. This work introduces a decentralized and lightweight collaborative SLAM approach that enables mapping on virtually any robot, even those equipped with low-cost hardware and only 1.5 MB of memory, including miniaturized insect-size devices. Moreover, the proposed solution supports large swarm formations with the capability to coordinate hundreds of agents. To substantiate our claims, we have successfully implemented collaborative SLAM on centimeter-size drones weighing 46 g. Remarkably, we achieve a mapping accuracy below 30 cm, a result comparable to high-end state-of-the-art solutions while reducing the cost, memory, and computation requirements by two orders of magnitude. Our approach is innovative in three main aspects. First, it enables onboard infrastructure-less collaborative mapping with a lightweight and cost-effective ({\textbackslash}\$20) solution in terms of sensing and computation. Second, we optimize the data traffic within the swarm to support hundreds of cooperative agents using standard wireless protocols such as ultra-wideband (UWB), Bluetooth, or WiFi. Last, we implement a distributed swarm coordination policy to decrease mapping latency and enhance accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/S6FR6I7D/Niculescu et al. - 2024 - Ultra-Lightweight Collaborative Mapping for Robot Swarms.pdf;/Users/kshitijgoel/Zotero/storage/SQAFB7CG/2407.html}
}

@inproceedings{nielsen_fisherrao_2023,
  title = {Fisher-{{Rao}} and Pullback {{Hilbert}} Cone Distances on the Multivariate {{Gaussian}} Manifold with Applications to Simplification and Quantization of Mixtures},
  booktitle = {Proceedings of 2nd {{Annual Workshop}} on {{Topology}}, {{Algebra}}, and {{Geometry}} in {{Machine Learning}} ({{TAG-ML}})},
  author = {Nielsen, Frank},
  year = {2023},
  month = sep,
  pages = {488--504},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v221/nielsen23b.html},
  urldate = {2024-03-13},
  abstract = {Data sets of multivariate normal distributions abound in many scientific areas like  diffusion tensor medical imaging, structure tensor computer vision, radar signal processing, machine learning, etc. In order to process those data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities and paths joining normal distributions.  The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information is such a principled distance which however is not known in closed-form excepts on a few particular cases. We first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between normal distributions. Second, we introduce a distance based on a diffeomorphic embedding of the Gaussian manifold into a submanifold of the higher-dimensional symmetric positive-definite cone.  We show that the projective Hilbert distance on the cone is a metric on the embedded Gaussian submanifold and pullback that distance with the straight line Hilbert cone geodesics to obtain a distance and paths between normal distributions. Compared to the Fisher-Rao distance approximation, the pullback Hilbert cone distance is computationally light since it requires to compute only extreme eigenvalues of matrices. Finally, we show how to use those distances in clustering tasks.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/F385FMT7/Nielsen - 2023 - Fisher-Rao and pullback Hilbert cone distances on .pdf}
}

@article{niessner_realtime_2013,
  title = {Real-Time {{3D}} Reconstruction at Scale Using Voxel Hashing},
  author = {Nie{\ss}ner, Matthias and Zollh{\"o}fer, Michael and Izadi, Shahram and Stamminger, Marc},
  year = {2013},
  month = nov,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {6},
  pages = {169:1--169:11},
  issn = {0730-0301},
  doi = {10.1145/2508363.2508374},
  url = {https://doi.org/10.1145/2508363.2508374},
  urldate = {2022-02-06},
  abstract = {Online 3D reconstruction is gaining newfound interest due to the availability of real-time consumer depth cameras. The basic problem takes live overlapping depth maps as input and incrementally fuses these into a single 3D model. This is challenging particularly when real-time performance is desired without trading quality or scale. We contribute an online system for large and fine scale volumetric reconstruction based on a memory and speed efficient data structure. Our system uses a simple spatial hashing scheme that compresses space, and allows for real-time access and updates of implicit surface data, without the need for a regular or hierarchical grid data structure. Surface data is only stored densely where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained details and large scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, camera pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art online systems, illustrating improved performance and reconstruction quality.},
  keywords = {data structure,GPU,real-time reconstruction,scalable},
  file = {/Users/kshitijgoel/Zotero/storage/ZVRE5XBI/Nießner et al. - 2013 - Real-time 3D reconstruction at scale using voxel h.pdf}
}

@article{niroui_deep_2019,
  title = {Deep {{Reinforcement Learning Robot}} for {{Search}} and {{Rescue Applications}}: {{Exploration}} in {{Unknown Cluttered Environments}}},
  shorttitle = {Deep {{Reinforcement Learning Robot}} for {{Search}} and {{Rescue Applications}}},
  author = {Niroui, Farzad and Zhang, Kaicheng and Kashino, Zendai and Nejat, Goldie},
  year = {2019},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {2},
  pages = {610--617},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2891991},
  abstract = {Rescue robots can be used in urban search and rescue (USAR) applications to perform the important task of exploring unknown cluttered environments. Due to the unpredictable nature of these environments, deep learning techniques can be used to perform these tasks. In this letter, we present the first use of deep learning to address the robot exploration task in USAR applications. In particular, we uniquely combine the traditional approach of frontier-based exploration with deep reinforcement learning to allow a robot to autonomously explore unknown cluttered environments. Experiments conducted with a mobile robot in unknown cluttered environments of varying sizes and layouts showed that the proposed exploration approach can effectively determine appropriate frontier locations to navigate to, while being robust to different environment layouts and sizes. Furthermore, a comparison study with other frontier exploration approaches showed that our learning-based frontier exploration technique was able to explore more of an environment earlier on, allowing for potential identification of a larger number of victims at the beginning of the time-critical exploration task.},
  keywords = {Autonomous agents,Computer architecture,deep learning in robotics and automation,Layout,Microprocessors,Navigation,Robot sensing systems,search and rescue robots,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/YYRCTAWX/Niroui et al. - 2019 - Deep Reinforcement Learning Robot for Search and R.pdf;/Users/kshitijgoel/Zotero/storage/CFMW65IE/stamp.html}
}

@inproceedings{nivel_anytime_2015,
  title = {Anytime {{Bounded Rationality}}},
  booktitle = {Artificial {{General Intelligence}}},
  author = {Nivel, Eric and Th{\'o}risson, Kristinn R. and Steunebrink, Bas and Schmidhuber, J{\"u}rgen},
  editor = {Bieger, Jordi and Goertzel, Ben and Potapov, Alexey},
  year = {2015},
  pages = {121--130},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-21365-1_13},
  abstract = {Dependable cyber-physical systems strive to deliver anticipative, multi-objective performance anytime, facing deluges of inputs with varying and limited resources. This is even more challenging for life-long learning rational agents as they also have to contend with the varying and growing know-how accumulated from experience. These issues are of crucial practical value, yet have been only marginally and unsatisfactorily addressed in AGI research. We present a value-driven computational model of anytime bounded rationality robust to variations of both resources and knowledge. It leverages continually learned knowledge to anticipate, revise and maintain concurrent courses of action spanning over arbitrary time scales for execution anytime necessary.},
  isbn = {978-3-319-21365-1},
  langid = {english},
  keywords = {Arbitrary Time Scale,Cognitive Cycle,Conjunctive Model,Disjunctive Model,Time Semantic},
  file = {/Users/kshitijgoel/Zotero/storage/ICV5K5LT/Nivel et al. - 2015 - Anytime Bounded Rationality.pdf}
}

@misc{noh_cloimapper_2024,
  title = {{{CLOi-Mapper}}: {{Consistent}}, {{Lightweight}}, {{Robust}}, and {{Incremental Mapper With Embedded Systems}} for {{Commercial Robot Services}}},
  shorttitle = {{{CLOi-Mapper}}},
  author = {Noh, DongKi and Lim, Hyungtae and Eoh, Gyuho and Choi, Duckyu and Choi, Jeongsik and Lim, Hyunjun and Baek, SeungMin and Myung, Hyun},
  year = {2024},
  month = jun,
  number = {arXiv:2406.19634},
  eprint = {2406.19634},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.19634},
  urldate = {2024-07-02},
  abstract = {In commercial autonomous service robots with several form factors, simultaneous localization and mapping (SLAM) is an essential technology for providing proper services such as cleaning and guidance. Such robots require SLAM algorithms suitable for specific applications and environments. Hence, several SLAM frameworks have been proposed to address various requirements in the past decade. However, we have encountered challenges in implementing recent innovative frameworks when handling service robots with low-end processors and insufficient sensor data, such as low-resolution 2D LiDAR sensors. Specifically, regarding commercial robots, consistent performance in different hardware configurations and environments is more crucial than the performance dedicated to specific sensors or environments. Therefore, we propose a) a multi-stage approach for global pose estimation in embedded systems; b) a graph generation method with zero constraints for synchronized sensors; and c) a robust and memory-efficient method for long-term pose-graph optimization. As verified in inhome and large-scale indoor environments, the proposed method yields consistent global pose estimation for services in commercial fields. Furthermore, the proposed method exhibits potential commercial viability considering the consistent performance verified via mass production and long-term ({$>$} 5 years) operation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/MG6DMAUD/Noh et al. - 2024 - CLOi-Mapper Consistent, Lightweight, Robust, and Incremental Mapper With Embedded Systems for Comme.pdf}
}

@article{noren_synchronized_2025,
  title = {A {{Synchronized Task Formulation}} for {{Robotic Convoy Operations}}},
  author = {Noren, Charles and Vundurthy, Bhaskar and Scherer, Sebastian and Choset, Howie and Travers, Matthew},
  year = {2025},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {7},
  pages = {6808--6815},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3570940},
  url = {https://ieeexplore.ieee.org/document/11005881/},
  urldate = {2025-06-09},
  abstract = {Future ground logistics missions will require multiple robots to travel in a convoy between locations. As each location may require a different number of robots (e.g. resupply vehicles), these missions will require a mutable convoy formation structure that may be divided to meet operational needs at each location. We model this mission type by modifying the vehicle routing problem with multiple synchronizations (VRPMS) to enforce convoy constraints (VRPMS-CC). This centralized approach to organizing and routing convoys is represented as a graph-based routing problem and then solved as a mixed integer program. A solution of the VRPMS-CC forms convoys by ensuring that agents participating in the same convoy remain spatially and temporally coupled, traversing the same edge of the graph simultaneously. We demonstrate our approach through numerical studies, where we route up to six simulated agents through twenty convoying tasks, and on robotic hardware. These demonstrations motivate two further contributions to specialize our approach to robotic systems. We introduce: 1) a warm-starting heuristic that improves solver times by up to eighty-nine percent and 2) an online multi-depot variant of the VRPMS-CC that responds to a priori unknown impassable environmental obstacles.},
  keywords = {formation routing,Indexes,Logistics,Mathematical models,multi-robot systems,planning,Robot kinematics,Routing,scheduling and coordination,Search problems,Silicon,Synchronization,Topology,Training,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/T5WRBY7L/Noren et al. - 2025 - A Synchronized Task Formulation for Robotic Convoy Operations.pdf}
}

@phdthesis{nowlan_soft_1991,
  title = {Soft Competitive Adaptation: Neural Network Learning Algorithms Based on Fitting Statistical Mixtures},
  shorttitle = {Soft Competitive Adaptation},
  author = {Nowlan, Steven J.},
  year = {1991},
  month = apr,
  address = {USA},
  abstract = {In this thesis, we consider learning algorithms for neural networks which are based on fitting a mixture probability density to a set of data. We begin with an unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms. Rather than updating only the parameters of the "winner" on each case, the parameters of all competitors are updated in proportion to their relative responsibility for the case. Use of such a "soft" competitive algorithm is shown to give better performance than the more traditional algorithms, with little additional cost.We then consider a supervised modular architecture in which a number of simple "expert" networks compete to solve distinct pieces of a large task. A soft competitive mechanism is used to determine how much an expert learns on a case, based on how well the expert performs relative to the other expert networks. At the same time, a separate gating network learns to weight the output of each expert according to a prediction of its relative performance based on the input to the system. Experiments on a number of tasks illustrate that this architecture is capable of uncovering interesting task decompositions and of generalizing better than a single network with small training sets.Finally, we consider learning algorithms in which we assume that the actual output of the network should fall into one of a small number of classes or clusters. The objective of learning is to make the variance of these classes as small as possible. In the classical decision-directed algorithm, we decide that an output belongs to the class it is closest to and minimize the squared distance between the output and the center (mean) of this closest class. In the "soft" version of this algorithm, we minimize the squared distance between the actual output and a weighted average of the means of all of the classes. The weighting factors are the relative probability that the output belongs to each class. This idea may also be used to model the weights of a network, to produce networks which generalize better from small training sets.},
  school = {Carnegie Mellon University},
  annotation = {UMI Order No. GAX91-26958}
}

@inproceedings{nunez_change_2010,
  title = {Change Detection in {{3D}} Environments Based on {{Gaussian Mixture Model}} and Robust Structural Matching for Autonomous Robotic Applications},
  booktitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {N{\'u}{\~n}ez, P. and Drews, P. and Bandera, A. and Rocha, R. and Campos, M. and Dias, J.},
  year = {2010},
  month = oct,
  pages = {2633--2638},
  issn = {2153-0866},
  doi = {10.1109/IROS.2010.5650573},
  abstract = {The ability to detect perceptions which were never experienced before, i.e. novelty detection, is an important component of autonomous robots working in real environments. It is achieved by comparing current data provided by its sensors with a previously known map of the environment. This often constitutes an extremely challenging task due to the large amounts of data that must be compared in real-time. With respect to previously proposed approaches, this paper detects changes in 3D environment based on probabilistic models, the Gaussian Mixture Model, and a fast and robust combined constraint matching algorithm. The matching allows to represent the scene view as a graph which emerges from the comparison between Mixtures of Gaussians. Finding the largest set of mutually consistent matches is equivalent to find the maximum clique on a graph. The proposed approach has been tested for mobile robotics purposes in real environments and compared to other matching algorithms. Experimental results demonstrate the performance of the proposal.},
  keywords = {Laser modes,Robot sensing systems,Robustness,Three dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/9EGAKTM2/Núñez et al. - 2010 - Change detection in 3D environments based on Gauss.pdf;/Users/kshitijgoel/Zotero/storage/29R36SH7/stamp.html}
}

@article{ocallaghan_gaussian_2012,
  title = {Gaussian Process Occupancy Maps},
  author = {O'Callaghan, Simon T and Ramos, Fabio T},
  year = {2012},
  month = jan,
  journal = {The International Journal of Robotics Research},
  volume = {31},
  number = {1},
  pages = {42--62},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364911421039},
  url = {http://journals.sagepub.com/doi/10.1177/0278364911421039},
  urldate = {2022-02-06},
  abstract = {We introduce a new statistical modelling technique for building occupancy maps. The problem of mapping is addressed as a classification task where the robot's environment is classified into regions of occupancy and free space. This is obtained by employing a modified Gaussian process as a non-parametric Bayesian learning technique to exploit the fact that real-world environments inherently possess structure. This structure introduces dependencies between points on the map which are not accounted for by many common mapping techniques such as occupancy grids. Our approach is an `anytime' algorithm that is capable of generating accurate representations of large environments at arbitrary resolutions to suit many applications. It also provides inferences with associated variances into occluded regions and between sensor beams, even with relatively few observations. Crucially, the technique can handle noisy data, potentially from multiple sources, and fuse it into a robust common probabilistic representation of the robot's surroundings. We demonstrate the benefits of our approach on simulated datasets with known ground truth and in outdoor urban environments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2ZKBVFJ5/O’Callaghan and Ramos - 2012 - Gaussian process occupancy maps.pdf}
}

@inproceedings{oechsle_unisurf_2021,
  title = {{{UNISURF}}: {{Unifying Neural Implicit Surfaces}} and {{Radiance Fields}} for {{Multi-View Reconstruction}}},
  shorttitle = {{{UNISURF}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Oechsle, Michael and Peng, Songyou and Geiger, Andreas},
  year = {2021},
  pages = {5589--5599},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Oechsle_UNISURF_Unifying_Neural_Implicit_Surfaces_and_Radiance_Fields_for_Multi-View_ICCV_2021_paper.html},
  urldate = {2023-04-04},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6HNTPVKB/Oechsle et al. - 2021 - UNISURF Unifying Neural Implicit Surfaces and Rad.pdf}
}

@book{oetiker_not_2023,
  title = {The {{Not So Short Introduction}} to {{LaTeX}}},
  author = {Oetiker, Tobias and Serwin, Marcin and Partl, Hubert and Hyna, Irene and Schlegl, Elisabeth},
  year = {2023},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IL68343S/Oetiker et al. - The Not So Short Introduction to LaTeX.pdf}
}

@article{oggier_algebraic_2004,
  title = {Algebraic {{Number Theory}} and {{Code Design}} for {{Rayleigh Fading Channels}}},
  author = {Oggier, F. and Viterbo, E.},
  year = {2004},
  month = dec,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {1},
  number = {3},
  pages = {333--415},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000003},
  url = {https://www.nowpublishers.com/article/Details/CIT-003},
  urldate = {2024-04-29},
  abstract = {Algebraic Number Theory and Code Design for Rayleigh Fading Channels},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KXGVNV4R/Oggier and Viterbo - 2004 - Algebraic Number Theory and Code Design for Raylei.pdf}
}

@article{ohradzansky_multiagent_2022,
  title = {Multi-{{Agent Autonomy}}: {{Advancements}} and {{Challenges}} in {{Subterranean Exploration}}},
  shorttitle = {Multi-{{Agent Autonomy}}},
  author = {Ohradzansky, Michael and Rush, Eugene and Riley, Danny and Mills, Andrew and Ahmad, Shakeeb and McGuire, Steve and Biggie, Harel and Harlow, Kyle and Miles, Michael and Frew, Eric and Heckman, Christoffer and Humbert, James},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {1068--1104},
  issn = {27713989},
  doi = {10.55417/fr.2022035},
  url = {https://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_35.pdf},
  urldate = {2023-01-26},
  abstract = {Artificial intelligence has undergone immense growth and maturation in recent years, though autonomous systems have traditionally struggled when fielded in diverse and previously unknown environments. DARPA is seeking to change that with the Subterranean Challenge, by providing roboticists the opportunity to support civilian and military first responders in complex and high-risk underground scenarios. The subterranean domain presents a handful of challenges, such as limited communication, diverse topology and terrain, and degraded sensing. Team MARBLE proposes a solution for autonomous exploration of unknown subterranean environments in which coordinated agents search for artifacts of interest. The team presents two navigation algorithms in the form of a metric-topological graph-based planner and a continuous frontier-based planner. To facilitate multi-agent coordination, agents share and merge new map information and candidate goal points. Agents deploy communication beacons at different points in the environment, extending the range at which maps and other information can be shared. Onboard autonomy reduces the load on human supervisors, allowing agents to detect and localize artifacts and explore autonomously outside established communication networks. Given the scale, complexity, and tempo of this challenge, a range of lessons was learned, most importantly, that frequent and comprehensive field testing in representative environments is key to rapidly refining system performance.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LH5MGUS3/Ohradzansky et al. - 2022 - Multi-Agent Autonomy Advancements and Challenges .pdf}
}

@book{oksendal_stochastic_2003,
  title = {Stochastic {{Differential Equations}}},
  author = {{\O}ksendal, Bernt},
  year = {2003},
  series = {Universitext},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-14394-6},
  url = {http://link.springer.com/10.1007/978-3-642-14394-6},
  urldate = {2023-10-20},
  isbn = {978-3-540-04758-2 978-3-642-14394-6},
  keywords = {Boundary value problem,differential equations,filtering problem,filtering theory,linear optimization,Martingale,mathematical finance,optimal filtering,partial differential equations,Random variable,Stochastic calculus,stochastic control,stochastic differential equations,Uniform integrability},
  file = {/Users/kshitijgoel/Zotero/storage/8WQY5GNB/Øksendal - 2003 - Stochastic Differential Equations.pdf}
}

@inproceedings{oleynikova_continuoustime_2016,
  title = {Continuous-Time Trajectory Optimization for Online {{UAV}} Replanning},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Oleynikova, Helen and Burri, Michael and Taylor, Zachary and Nieto, Juan and Siegwart, Roland and Galceran, Enric},
  year = {2016},
  month = oct,
  pages = {5332--5339},
  issn = {2153-0866},
  doi = {10.1109/IROS.2016.7759784},
  abstract = {Multirotor unmanned aerial vehicles (UAVs) are rapidly gaining popularity for many applications. However, safe operation in partially unknown, unstructured environments remains an open question. In this paper, we present a continuous-time trajectory optimization method for real-time collision avoidance on multirotor UAVs. We then propose a system where this motion planning method is used as a local replanner, that runs at a high rate to continuously recompute safe trajectories as the robot gains information about its environment. We validate our approach by comparing against existing methods and demonstrate the complete system avoiding obstacles on a multirotor UAV platform.},
  keywords = {Jacobian matrices,Linear programming,Planning,Real-time systems,Trajectory optimization,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/6LCETTCM/Oleynikova et al. - 2016 - Continuous-time trajectory optimization for online.pdf;/Users/kshitijgoel/Zotero/storage/83VQFWNP/7759784.html}
}

@phdthesis{oleynikova_mapping_2019,
  title = {Mapping and {{Planning}} for {{Safe Collision Avoidance On-board Micro-Aerial Vehicles}}},
  author = {Oleynikova, Helen},
  year = {2019},
  address = {Zurich},
  school = {ETH Zurich},
  file = {/Users/kshitijgoel/Zotero/storage/4ZMBPZKJ/_.pdf}
}

@article{oleynikova_opensource_2020,
  title = {An Open-Source System for Vision-Based Micro-Aerial Vehicle Mapping, Planning, and Flight in Cluttered Environments},
  author = {Oleynikova, Helen and Lanegger, Christian and Taylor, Zachary and Pantic, Michael and Millane, Alexander and Siegwart, Roland and Nieto, Juan},
  year = {2020},
  journal = {Journal of Field Robotics},
  volume = {37},
  number = {4},
  pages = {642--666},
  issn = {1556-4967},
  doi = {10.1002/rob.21950},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21950},
  urldate = {2022-05-20},
  abstract = {We present an open-source system for Micro-Aerial Vehicle (MAV) autonomous navigation from vision-based sensing. Our system focuses on dense mapping, safe local planning, and global trajectory generation, especially when using narrow field-of-view sensors in very cluttered environments. In addition, details about other necessary parts of the system and special considerations for applications in real-world scenarios are presented. We focus our experiments on evaluating global planning, path smoothing, and local planning methods on real maps made on MAVs in realistic search-and-rescue and industrial inspection scenarios. We also perform thousands of simulations in cluttered synthetic environments, and finally validate the complete system in real-world experiments.},
  langid = {english},
  keywords = {aerial robotics,GPS-denied operation,mapping,obstacle avoidance,planning},
  file = {/Users/kshitijgoel/Zotero/storage/IGC7IST4/Oleynikova et al. - 2020 - An open-source system for vision-based micro-aeria.pdf;/Users/kshitijgoel/Zotero/storage/SUDZ36WE/rob.html}
}

@inproceedings{oleynikova_voxblox_2017,
  title = {Voxblox: {{Incremental 3D Euclidean Signed Distance Fields}} for on-Board {{MAV}} Planning},
  shorttitle = {Voxblox},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Oleynikova, Helen and Taylor, Zachary and Fehr, Marius and Siegwart, Roland and Nieto, Juan},
  year = {2017},
  month = sep,
  pages = {1366--1373},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8202315},
  url = {https://ieeexplore.ieee.org/document/8202315},
  urldate = {2024-01-27},
  abstract = {Micro Aerial Vehicles (MAVs) that operate in unstructured, unexplored environments require fast and flexible local planning, which can replan when new parts of the map are explored. Trajectory optimization methods fulfill these needs, but require obstacle distance information, which can be given by Euclidean Signed Distance Fields (ESDFs). We propose a method to incrementally build ESDFs from Truncated Signed Distance Fields (TSDFs), a common implicit surface representation used in computer graphics and vision. TSDFs are fast to build and smooth out sensor noise over many observations, and are designed to produce surface meshes. We show that we can build TSDFs faster than Octomaps, and that it is more accurate to build ESDFs out of TSDFs than occupancy maps. Our complete system, called voxblox, is available as open source and runs in real-time on a single CPU core. We validate our approach on-board an MAV, by using our system with a trajectory optimization local planner, entirely on-board and in real-time.},
  keywords = {Buildings,Planning,Real-time systems,Robot sensing systems,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/5CERALDD/Oleynikova et al. - 2017 - Voxblox Incremental 3D Euclidean Signed Distance .pdf;/Users/kshitijgoel/Zotero/storage/A83ZK8HJ/8202315.html}
}

@article{ollero_present_2022,
  title = {Past, {{Present}}, and {{Future}} of {{Aerial Robotic Manipulators}}},
  author = {Ollero, Anibal and Tognon, Marco and Suarez, Alejandro and Lee, Dongjun and Franchi, Antonio},
  year = {2022},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {1},
  pages = {626--645},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3084395},
  abstract = {This article analyzes the evolution and current trends in aerial robotic manipulation, comprising helicopters, conventional underactuated multirotors, and multidirectional thrust platforms equipped with a wide variety of robotic manipulators capable of physically interacting with the environment. It also covers cooperative aerial manipulation and interconnected actuated multibody designs. The review is completed with developments in teleoperation, perception, and planning. Finally, a new generation of aerial robotic manipulators is presented with our vision of the future.},
  keywords = {Aerial manipulation,aerial robots physically interacting with the environment,End effectors,Force,Manipulator dynamics,Propellers,Robots,Task analysis,unmanned aerial vehicles,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/F55GYIBJ/Ollero et al. - 2022 - Past, Present, and Future of Aerial Robotic Manipu.pdf}
}

@misc{olsen_martian_2023,
  title = {Martian {{Lava Tube Exploration Using Jumping Legged Robots}}: {{A Concept Study}}},
  shorttitle = {Martian {{Lava Tube Exploration Using Jumping Legged Robots}}},
  author = {Olsen, J{\o}rgen Anker and Alexis, Kostas},
  year = {2023},
  month = oct,
  number = {arXiv:2310.14876},
  eprint = {2310.14876},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2310.14876},
  urldate = {2023-11-01},
  abstract = {In recent years, robotic exploration has become increasingly important in planetary exploration. One area of particular interest for exploration is Martian lava tubes, which have several distinct features of interest. First, it is theorized that they contain more easily accessible resources such as water ice, needed for in-situ utilization on Mars. Second, lava tubes of significant size can provide radiation and impact shelter for possible future human missions to Mars. Third, lava tubes may offer a protected and preserved view into Mars' geological and possible biological past. However, exploration of these lava tubes poses significant challenges due to their sheer size, geometric complexity, uneven terrain, steep slopes, collapsed sections, significant obstacles, and unstable surfaces. Such challenges may hinder traditional wheeled rover exploration. To overcome these challenges, legged robots and particularly jumping systems have been proposed as potential solutions. Jumping legged robots utilize legs to both walk and jump. This allows them to traverse uneven terrain and steep slopes more easily compared to wheeled or tracked systems. In the context of Martian lava tube exploration, jumping legged robots would be particularly useful due to their ability to jump over big boulders, gaps, and obstacles, as well as to descend and climb steep slopes. This would allow them to explore and map such caves, and possibly collect samples from areas that may otherwise be inaccessible. This paper presents the specifications, design, capabilities, and possible mission profiles for state-of-the-art legged robots tailored to space exploration. Additionally, it presents the design, capabilities, and possible mission profiles of a new jumping legged robot for Martian lava tube exploration that is being developed at the Norwegian University of Science and Technology.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/H97NKU2K/Olsen and Alexis - 2023 - Martian Lava Tube Exploration Using Jumping Legged.pdf}
}

@article{omeadhra_variable_2019,
  title = {Variable {{Resolution Occupancy Mapping Using Gaussian Mixture Models}}},
  author = {O'Meadhra, Cormac and Tabib, Wennie and Michael, Nathan},
  year = {2019},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {2},
  pages = {2015--2022},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2889348},
  url = {https://ieeexplore.ieee.org/document/8586902},
  urldate = {2024-01-27},
  abstract = {Occupancy mapping is fundamental for active perception systems to enable reasoning about known and unknown regions of the environment. The majority of occupancy mapping approaches enforce an a priori discretization on the environment, resulting in a fixed resolution map that limits the expressiveness of the representation. The proposed approach removes this a priori discretization, learns continuous representations for the evidence of occupied and free space to derive the probability of occupancy, and enables occupancy grid maps to be generated at arbitrary resolution. Efficient methods are also presented that accurately evaluate the probability of occupancy in individual cells and enable multi-resolution mapping and local occupancy evaluation. The efficacy of the approach is demonstrated by comparison to state-of-the-art discrete and continuous mapping techniques in both two dimensions and three dimensions. The core contribution of this work is a memory-efficient method for deriving occupancy that is amenable to small or large corrections in pose without the need to regenerate the entire map. The applications under considerations are low-bandwidth scenarios (e.g., multi-robot exploration) and operations in expansive environments, where storing an occupancy grid map of the entire environment would be prohibitive.},
  keywords = {Gaussian mixture model,Mapping,NASA,RGB-D perception,Robot sensing systems,Three-dimensional displays,Training,Two dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/SJU7SW4K/O’Meadhra et al. - 2019 - Variable Resolution Occupancy Mapping Using Gaussi.pdf;/Users/kshitijgoel/Zotero/storage/QJNK2XBY/8586902.html}
}

@article{orekhov_darpa_2022,
  title = {The {{DARPA Subterranean Challenge}}: {{A Synopsis}} of the {{Circuits Stage}}},
  shorttitle = {The {{DARPA Subterranean Challenge}}},
  author = {Orekhov, Viktor and Chung, Timothy},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {735--747},
  issn = {27713989},
  doi = {10.55417/fr.2022024},
  url = {https://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_24.pdf},
  urldate = {2023-01-26},
  abstract = {Complex underground environments present significant challenges for the autonomy, perception, networking, and mobility of robots operating in time-sensitive disaster response scenarios. In 2017, DARPA created the Subterranean Challenge to stimulate innovation and investment in solutions that can rapidly map, navigate, and search complex environments, including human-made tunnel systems, urban underground, and natural cave networks. The program is hosting a series of evaluations, namely, the three Circuit Events and the Final Event, which assess each competing team's approaches in representative subterranean environments. This paper provides an overview of the program and the results from the Circuits Stage of the competition},
  file = {/Users/kshitijgoel/Zotero/storage/PZ4JZZLH/Orekhov and Chung - 2022 - The DARPA Subterranean Challenge A Synopsis of th.pdf}
}

@article{orekhov_inspiring_2023,
  title = {Inspiring {{Field Robotics Advances}} through the {{Design}} of the {{DARPA Subterranean Challenge}}},
  author = {Orekhov, Viktor and Maio, Angela and Daniel, Roshan and Chung, Timothy},
  year = {2023},
  month = jan,
  journal = {Field Robotics},
  volume = {3},
  number = {1},
  pages = {560--604},
  issn = {27713989},
  doi = {10.55417/fr.2023018},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_3_files/Vol3_18.pdf},
  urldate = {2023-05-04},
  abstract = {As the latest Defense Advanced Research Projects Agency (DARPA) ``Grand Challenge,'' the Subterranean Challenge was a robotics competition that sought to stimulate innovation and investment in solutions that can rapidly map, navigate, and search complex environments, including human-made tunnel systems, urban underground spaces, and natural cave networks. The program hosted a series of evaluations, namely, three Circuit Events and a Final Event, which assessed each competing team's approaches in representative subterranean environments. This paper details the careful planning and intentional decisions that went into the design of the competition elements of the Final Event of the DARPA Subterranean Challenge. Intended to offer both insights and motivations, this paper comprehensively describes the official rules, scoring objectives, artifact selection, environment setup, and scenario configurations, all in the context of driving towards advancing key technologies of interest to DARPA and to the field robotics community.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DUBKDXH7/Orekhov et al. - 2023 - Inspiring Field Robotics Advances through the Desi.pdf}
}

@misc{ortega_informationtheoretic_2015,
  title = {Information-{{Theoretic Bounded Rationality}}},
  author = {Ortega, Pedro A. and Braun, Daniel A. and Dyer, Justin and Kim, Kee-Eung and Tishby, Naftali},
  year = {2015},
  month = dec,
  number = {arXiv:1512.06789},
  eprint = {1512.06789},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.06789},
  url = {http://arxiv.org/abs/1512.06789},
  urldate = {2025-02-14},
  abstract = {Bounded rationality, that is, decision-making and planning under resource limitations, is widely regarded as an important open problem in artificial intelligence, reinforcement learning, computational neuroscience and economics. This paper offers a consolidated presentation of a theory of bounded rationality based on information-theoretic ideas. We provide a conceptual justification for using the free energy functional as the objective function for characterizing bounded-rational decisions. This functional possesses three crucial properties: it controls the size of the solution space; it has Monte Carlo planners that are exact, yet bypass the need for exhaustive search; and it captures model uncertainty arising from lack of evidence or from interacting with other agents having unknown intentions. We discuss the single-step decision-making case, and show how to extend it to sequential decisions using equivalence transformations. This extension yields a very general class of decision problems that encompass classical decision rules (e.g. EXPECTIMAX and MINIMAX) as limit cases, as well as trust- and risk-sensitive planning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Systems and Control,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/48KQBRG2/Ortega et al. - 2015 - Information-Theoretic Bounded Rationality.pdf;/Users/kshitijgoel/Zotero/storage/UY8V5ZEU/1512.html}
}

@misc{orthey_samplingbased_2023,
  title = {Sampling-{{Based Motion Planning}}: {{A Comparative Review}}},
  shorttitle = {Sampling-{{Based Motion Planning}}},
  author = {Orthey, Andreas and Chamzas, Constantinos and Kavraki, Lydia E.},
  year = {2023},
  month = sep,
  number = {arXiv:2309.13119},
  eprint = {2309.13119},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.13119},
  url = {http://arxiv.org/abs/2309.13119},
  urldate = {2025-02-04},
  abstract = {Sampling-based motion planning is one of the fundamental paradigms to generate robot motions, and a cornerstone of robotics research. This comparative review provides an up-to-date guideline and reference manual for the use of sampling-based motion planning algorithms. This includes a history of motion planning, an overview about the most successful planners, and a discussion on their properties. It is also shown how planners can handle special cases and how extensions of motion planning can be accommodated. To put sampling-based motion planning into a larger context, a discussion of alternative motion generation frameworks is presented which highlights their respective differences to sampling-based motion planning. Finally, a set of sampling-based motion planners are compared on 24 challenging planning problems. This evaluation gives insights into which planners perform well in which situations and where future research would be required. This comparative review thereby provides not only a useful reference manual for researchers in the field, but also a guideline for practitioners to make informed algorithmic decisions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/D95MNETH/Orthey et al. - 2023 - Sampling-Based Motion Planning A Comparative Review.pdf;/Users/kshitijgoel/Zotero/storage/DDUSB6FD/2309.html}
}

@phdthesis{ortiz_gaussian_2023,
  title = {Gaussian {{Belief Propagation}} for {{Real-Time Decentralised Inference}}},
  author = {Ortiz, Joseph},
  year = {2023},
  month = feb,
  langid = {english},
  school = {Imperial College London},
  file = {/Users/kshitijgoel/Zotero/storage/PHHHNCKI/Ortiz - Gaussian Belief Propagation for Real-Time Decentra.pdf}
}

@inproceedings{ortiz_isdf_2022,
  title = {{{iSDF}}: {{Real-Time Neural Signed Distance Fields}} for {{Robot Perception}}},
  shorttitle = {{{iSDF}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Ortiz, Joseph and Clegg, Alexander and Dong, Jing and Sucar, Edgar and Novotny, David and Zollhoefer, Michael and Mukadam, Mustafa},
  year = {2022},
  month = jun,
  volume = {18},
  url = {https://www.roboticsproceedings.org/rss18/p012.html},
  urldate = {2023-10-31},
  isbn = {978-0-9923747-8-5},
  file = {/Users/kshitijgoel/Zotero/storage/VI8J937G/Ortiz et al. - 2022 - iSDF Real-Time Neural Signed Distance Fields for .pdf}
}

@article{ozaslan_autonomous_2017,
  title = {Autonomous {{Navigation}} and {{Mapping}} for {{Inspection}} of {{Penstocks}} and {{Tunnels With MAVs}}},
  author = {{\"O}zaslan, Tolga and Loianno, Giuseppe and Keller, James and Taylor, Camillo J. and Kumar, Vijay and Wozencraft, Jennifer M. and Hood, Thomas},
  year = {2017},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {3},
  pages = {1740--1747},
  issn = {2377-3766},
  doi = {10.1109/LRA.2017.2699790},
  abstract = {In this paper, we address the estimation, control, navigation and mapping problems to achieve autonomous inspection of penstocks and tunnels using aerial vehicles with on-board sensing and computation. Penstocks and tunnels have the shape of a generalized cylinder. They are generally dark and featureless. State estimation is challenging because range sensors do not yield adequate information and cameras do not work in the dark. We show that the six degrees of freedom (DOF) pose and velocity can be estimated by fusing information from an inertial measurement unit (IMU), a lidar and a set of cameras. This letter discusses in detail the range-based estimation part while leaving the details of vision component to our earlier work. The proposed algorithm relies only on a model of the generalized cylinder and is robust to changes in shape of the tunnel. The approach is validated through real experiments showing autonomous and shared control, state estimation and environment mapping in the penstock at Center Hill Dam, TN. To our knowledge, this is the first time autonomous navigation and mapping has been achieved in a penstock without any external infrastructure such GPS or external cameras.},
  keywords = {Aerial systems,Cameras,field robots,Inspection,Navigation,perception and autonomy,Robot vision systems,robotics in hazardous fields},
  file = {/Users/kshitijgoel/Zotero/storage/ZKDV6L8N/Özaslan et al. - 2017 - Autonomous Navigation and Mapping for Inspection o.pdf;/Users/kshitijgoel/Zotero/storage/IUW7ET9H/7914761.html}
}

@article{ozertem_locally_2011,
  title = {Locally {{Defined Principal Curves}} and {{Surfaces}}},
  author = {Ozertem, Umut and Erdogmus, Deniz},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  number = {34},
  pages = {1249--1286},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v12/ozertem11a.html},
  urldate = {2024-04-29},
  abstract = {Principal curves are defined as self-consistent smooth curves passing through the middle of the data, and they have been used in many applications of machine learning as a generalization, dimensionality reduction and a feature extraction tool. We redefine principal curves and surfaces in terms of the gradient and the Hessian of the probability density estimate. This provides a geometric understanding of the principal curves and surfaces, as well as a unifying view for clustering, principal curve fitting and manifold learning by regarding those as principal manifolds of different intrinsic dimensionalities. The theory does not impose any particular density estimation method can be used with any density estimator that gives continuous first and second derivatives. Therefore, we first present our principal curve/surface definition without assuming any particular density estimation method. Afterwards, we develop practical algorithms for the commonly used kernel density estimation (KDE) and Gaussian mixture models (GMM). Results of these algorithms are presented in notional data sets as well as real applications with comparisons to other approaches in the principal curve literature. All in all, we present a novel theoretical understanding of principal curves and surfaces, practical algorithms as general purpose machine learning tools, and applications of these algorithms to several practical problems.},
  file = {/Users/kshitijgoel/Zotero/storage/ZLE2NGG6/Ozertem and Erdogmus - 2011 - Locally Defined Principal Curves and Surfaces.pdf}
}

@phdthesis{pacelli_informationtheoretic_2023,
  title = {Information-{{Theoretic Necessary}} and {{Sufficient Conditions}} for the {{Task-Driven Control}} of {{Robots}}},
  author = {Pacelli, Vincent},
  year = {2023},
  address = {United States -- New Jersey},
  url = {https://www.proquest.com/docview/2827856535/abstract/392A998D53E444BEPQ/1},
  urldate = {2023-06-27},
  abstract = {The development of modern robotic systems has significantly benefited from the availability of high-fidelity sensors and efficient computational resources. Together, advances in these areas have led to a significant commercial interest in the applications of autonomous robots for complex tasks. However, while powerful, the high-dimensional sensors now common in robotics (e.g., cameras and LIDAR) pose several challenges for which traditional, general-purpose control and estimation are not well-suited. Specifically, these sensors lack tractable analytical models, and their high-dimensional output spaces are challenging to explore fully empirically or in simulation. Moreover, traditional approaches often result in an unnecessarily tight coupling between the sensing, estimation, and control components of the robot's feedback loop, causing performance degradation when deploying the robot in a new environment due to a shift in the distribution of sensor outputs --- even if the shift only modifies the outputs in a manner that is irrelevant to the robot's task. This dissertation addresses traditional control methods' limitations by establishing task-driven necessary and sufficient conditions for performant feedback control. Necessary conditions quantify how much information a sensor must provide the robot to achieve a performance criterion independent of the controller employed by the robot --- thereby providing a principled method to determine the necessary sensing capabilities of the robot for the task. Sufficient conditions guarantee that a robot will achieve a specific level of performance in new environments by limiting the controller to only depend on task-relevant information. Newly developed algorithms for their implementation accompany these conditions. Also included are demonstrations of the efficacy of these methods on problems on common robotics problems featuring high-dimensional sensors.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798379717346},
  langid = {english},
  school = {Princeton University},
  keywords = {High-fidelity sensors,Robotic systems,Robots,Sufficient conditions},
  file = {/Users/kshitijgoel/Zotero/storage/I4KNK8EE/Pacelli - 2023 - Information-Theoretic Necessary and Sufficient Con.pdf}
}

@article{paine_elliptically_2018,
  title = {An Elliptically Symmetric Angular {{Gaussian}} Distribution},
  author = {Paine, P. J. and Preston, S. P. and Tsagris, M. and Wood, Andrew T. A.},
  year = {2018},
  month = may,
  journal = {Statistics and Computing},
  volume = {28},
  number = {3},
  pages = {689--697},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-017-9756-4},
  url = {http://link.springer.com/10.1007/s11222-017-9756-4},
  urldate = {2024-07-24},
  abstract = {We define a distribution on the unit sphere Sd-1 called the elliptically symmetric angular Gaussian distribution. This distribution, which to our knowledge has not been studied before, is a subfamily of the angular Gaussian distribution closely analogous to the Kent subfamily of the general Fisher--Bingham distribution. Like the Kent distribution, it has ellipse-like contours, enabling modelling of rotational asymmetry about the mean direction, but it has the additional advantages of being simple and fast to simulate from, and having a density and hence likelihood that is easy and very quick to compute exactly. These advantages are especially beneficial for computationally intensive statistical methods, one example of which is a parametric bootstrap procedure for inference for the directional mean that we describe.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QKDIW8D5/Paine et al. - 2018 - An elliptically symmetric angular Gaussian distribution.pdf}
}

@article{palieri_locus_2021,
  title = {{{LOCUS}}: {{A Multi-Sensor Lidar-Centric Solution}} for {{High-Precision Odometry}} and {{3D Mapping}} in {{Real-Time}}},
  shorttitle = {{{LOCUS}}},
  author = {Palieri, Matteo and Morrell, Benjamin and Thakur, Abhishek and Ebadi, Kamak and Nash, Jeremy and Chatterjee, Arghya and Kanellakis, Christoforos and Carlone, Luca and Guaragnella, Cataldo and {Agha-mohammadi}, Ali-akbar},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {421--428},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.3044864},
  abstract = {A reliable odometry source is a prerequisite to enable complex autonomy behaviour in next-generation robots operating in extreme environments. In this work, we present a high-precision lidar odometry system to achieve robust and real-time operation under challenging perceptual conditions. LOCUS (Lidar Odometry for Consistent operation in Uncertain Settings), provides an accurate multi-stage scan matching unit equipped with an health-aware sensor integration module for seamless fusion of additional sensing modalities. We evaluate the performance of the proposed system against state-of-the-art techniques in perceptually challenging environments, and demonstrate top-class localization accuracy along with substantial improvements in robustness to sensor failures. We then demonstrate real-time performance of LOCUS on various types of robotic mobility platforms involved in the autonomous exploration of the Satsop power plant in Elma, WA where the proposed system was a key element of the CoSTAR team's solution that won first place in the Urban Circuit of the DARPA Subterranean Challenge.},
  keywords = {Localization,mapping,Mobile robots,Path planning,Real-time systems,robotics in hazardous fields,sensor fusion,Sensor fusion,Simultaneous localization and mapping,SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/I6MF82W7/Palieri et al. - 2021 - LOCUS A Multi-Sensor Lidar-Centric Solution for H.pdf;/Users/kshitijgoel/Zotero/storage/DGD6X9KT/stamp.html}
}

@inproceedings{pan_activenerf_2022,
  title = {{{ActiveNeRF}}: {{Learning Where}} to~{{See}} with~{{Uncertainty Estimation}}},
  shorttitle = {{{ActiveNeRF}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2022},
  author = {Pan, Xuran and Lai, Zihang and Song, Shiji and Huang, Gao},
  editor = {Avidan, Shai and Brostow, Gabriel and Ciss{\'e}, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {230--246},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-19827-4_14},
  abstract = {Recently, Neural Radiance Fields (NeRF) has shown promising performances on reconstructing 3D scenes and synthesizing novel views from a sparse set of 2D images. Albeit effective, the performance of NeRF is highly influenced by the quality of training samples. With limited posed images from the scene, NeRF fails to generalize well to novel views and may collapse to trivial solutions in unobserved regions. This makes NeRF impractical under resource-constrained scenarios. In this paper, we present a novel learning framework, ActiveNeRF, aiming to model a 3D scene with a constrained input budget. Specifically, we first incorporate uncertainty estimation into a NeRF model, which ensures robustness under few observations and provides an interpretation of how NeRF understands the scene. On this basis, we propose to supplement the existing training set with newly captured samples based on an active learning scheme. By evaluating the reduction of uncertainty given new inputs, we select the samples that bring the most information gain. In this way, the quality of novel view synthesis can be improved with minimal additional resources. Extensive experiments validate the performance of our model on both realistic and synthetic scenes, especially with scarcer training data.},
  isbn = {978-3-031-19827-4},
  langid = {english},
  keywords = {Active learning,Neural radiance fields,Uncertainty estimation},
  file = {/Users/kshitijgoel/Zotero/storage/DABMARSZ/Pan et al. - 2022 - ActiveNeRF Learning Where to See with Uncertainty.pdf}
}

@article{pan_fast_2016,
  title = {Fast Probabilistic Collision Checking for Sampling-Based Motion Planning Using Locality-Sensitive Hashing},
  author = {Pan, Jia and Manocha, Dinesh},
  year = {2016},
  month = oct,
  journal = {The International Journal of Robotics Research},
  volume = {35},
  number = {12},
  pages = {1477--1496},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364916640908},
  url = {https://doi.org/10.1177/0278364916640908},
  urldate = {2024-04-19},
  abstract = {We present a novel approach to perform fast probabilistic collision checking in high-dimensional configuration spaces to accelerate the performance of sampling-based motion planning. Our formulation stores the results of prior collision queries, and then uses such information to predict the collision probability for a new configuration sample. In particular, we perform an approximate k-NN (k-nearest neighbor) search to find prior query samples that are closest to the new query configuration. The new query sample's collision status is then estimated according to the collision checking results of these prior query samples, based on the fact that nearby configurations are likely to have the same collision status. We use locality-sensitive hashing techniques with sub-linear time complexity for approximate k-NN queries. We evaluate the benefit of our probabilistic collision checking approach by integrating it with a wide variety of sampling-based motion planners, including PRM (Probabilistic roadmaps), lazyPRM, RRT Rapidly exploring random trees, and RRT*. Our method can improve these planners in various manners, such as accelerating the local path validation, or computing an efficient order for the graph search on the roadmap. Experiments on a set of benchmarks demonstrate the performance of our method, and we observe up to 2x speedup in the performance of planners on rigid and articulated robots.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SAHWHISN/Pan and Manocha - 2016 - Fast probabilistic collision checking for sampling.pdf}
}

@inproceedings{pan_global_2024,
  title = {Global {{Structure-from-Motion Revisited}}},
  author = {Pan, Linfei and Bar{\'a}th, D{\'a}niel and Pollefeys, Marc and Sch{\"o}nberger, Johannes L},
  year = {2024},
  abstract = {Recovering 3D structure and camera motion from images has been a long-standing focus of computer vision research and is known as Structure-from-Motion (SfM). Solutions to this problem are categorized into incremental and global approaches. Until now, the most popular systems follow the incremental paradigm due to its superior accuracy and robustness, while global approaches are drastically more scalable and efficient. With this work, we revisit the problem of global SfM and propose GLOMAP as a new general-purpose system that outperforms the state of the art in global SfM. In terms of accuracy and robustness, we achieve results on-par or superior to COLMAP, the most widely used incremental SfM, while being orders of magnitude faster. We share our system as an open-source implementation at https://github.com/colmap/glomap.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KWMQ7D4Q/Pan et al. - Global Structure-from-Motion Revisited.pdf}
}

@inproceedings{pan_how_2024,
  title = {How {{Many Views Are Needed}} to {{Reconstruct}} an {{Unknown Object Using NeRF}}?},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Pan, Sicong and Jin, Liren and Hu, Hao and Popovi{\'c}, Marija and Bennewitz, Maren},
  year = {2024},
  month = may,
  pages = {12470--12476},
  doi = {10.1109/ICRA57147.2024.10610617},
  url = {https://ieeexplore.ieee.org/document/10610617/?arnumber=10610617},
  urldate = {2024-11-05},
  abstract = {Neural Radiance Fields (NeRFs) are gaining significant interest for online active object reconstruction due to their exceptional memory efficiency and requirement for only posed RGB inputs. Previous NeRF-based view planning methods exhibit computational inefficiency since they rely on an iterative paradigm, consisting of (1) retraining the NeRF when new images arrive; and (2) planning a path to the next best view only. To address these limitations, we propose a non-iterative pipeline based on the Prediction of the Required number of Views (PRV). The key idea behind our approach is that the required number of views to reconstruct an object depends on its complexity. Therefore, we design a deep neural network, named PRVNet, to predict the required number of views, allowing us to tailor the data acquisition based on the object complexity and plan a globally shortest path. To train our PRVNet, we generate supervision labels using the ShapeNet dataset. Simulated experiments show that our PRV-based view planning method outperforms baselines, achieving good reconstruction quality while significantly reducing movement cost and planning time. We further justify the generalization ability of our approach in a real-world experiment.},
  keywords = {Complexity theory,Costs,Data acquisition,Memory management,Neural radiance field,Pipelines,Planning},
  file = {/Users/kshitijgoel/Zotero/storage/AZEA7BXA/Pan et al. - 2024 - How Many Views Are Needed to Reconstruct an Unknown Object Using NeRF.pdf;/Users/kshitijgoel/Zotero/storage/RBIR6LCR/10610617.html}
}

@misc{pan_robust_2025,
  title = {Robust {{Trajectory Generation}} and {{Control}} for {{Quadrotor Motion Planning}} with {{Field-of-View Control Barrier Certification}}},
  author = {Pan, Lishuo and Catellani, Mattia and Sabattini, Lorenzo and Ayanian, Nora},
  year = {2025},
  month = feb,
  number = {arXiv:2502.01009},
  eprint = {2502.01009},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.01009},
  url = {http://arxiv.org/abs/2502.01009},
  urldate = {2025-02-04},
  abstract = {Many approaches to multi-robot coordination are susceptible to failure due to communication loss and uncertainty in estimation. We present a real-time communication-free distributed algorithm for navigating robots to their desired goals certified by control barrier functions, that model and control the onboard sensing behavior to keep neighbors in the limited field of view for position estimation. The approach is robust to temporary tracking loss and directly synthesizes control in real time to stabilize visual contact through control Lyapunov-barrier functions. The main contributions of this paper are a continuous-time robust trajectory generation and control method certified by control barrier functions for distributed multi-robot systems and a discrete optimization procedure, namely, MPC-CBF, to approximate the certified controller. In addition, we propose a linear surrogate of high-order control barrier function constraints and use sequential quadratic programming to solve MPC-CBF efficiently. We demonstrate results in simulation with 10 robots and physical experiments with 2 custom-built UAVs. To the best of our knowledge, this work is the first of its kind to generate a robust continuous-time trajectory and controller concurrently, certified by control barrier functions utilizing piecewise splines.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/L7CBY8C8/Pan et al. - 2025 - Robust Trajectory Generation and Control for Quadrotor Motion Planning with Field-of-View Control Ba.pdf;/Users/kshitijgoel/Zotero/storage/VSWM4WHJ/2502.html}
}

@inproceedings{pan_voxfield_2022,
  title = {Voxfield: {{Non-Projective Signed Distance Fields}} for {{Online Planning}} and {{3D Reconstruction}}},
  shorttitle = {Voxfield},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Pan, Yue and Kompis, Yves and Bartolomei, Luca and Mascaro, Ruben and Stachniss, Cyrill and Chli, Margarita},
  year = {2022},
  month = oct,
  pages = {5331--5338},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981318},
  abstract = {Creating accurate maps of complex, unknown environments is of utmost importance for truly autonomous navigation robot. However, building these maps online is far from trivial, especially when dealing with large amounts of raw sensor readings on a computation and energy constrained mobile system, such as a small drone. While numerous approaches tackling this problem have emerged in recent years, the mapping accuracy is often sacrificed as systematic approximation errors are tolerated for efficiency's sake. Motivated by these challenges, we propose Voxfield, a mapping framework that can generate maps online with higher accuracy and lower computational burden than the state of the art. Built upon the novel formulation of non-projective truncated signed distance fields (TSDFs), our approach produces more accurate and complete maps, suitable for surface reconstruction. Additionally, it enables efficient generation of Euclidean signed distance fields (ESDFs), useful e.g., for path planning, that does not suffer from typical approximation errors. Through a series of experiments with public datasets, both real-world and synthetic, we demonstrate that our method beats the state of the art in map coverage, accuracy and computational time. Moreover, we show that Voxfield can be utilized as a back-end in recent multi-resolution mapping frameworks, producing high quality maps even in large-scale experiments. Finally, we validate our method by running it onboard a quadrotor, showing it can generate accurate ESDF maps usable for real-time path planning and obstacle avoidance.},
  keywords = {Approximation error,Path planning,Real-time systems,Robot sensing systems,Surface reconstruction,Systematics,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/VHK8YP8Z/Pan et al. - 2022 - Voxfield Non-Projective Signed Distance Fields fo.pdf;/Users/kshitijgoel/Zotero/storage/DHDAMYG3/stamp.html}
}

@phdthesis{pangborn_scalable_2010,
  title = {Scalable Data Clustering Using {{GPUs}}},
  author = {Pangborn, Andrew D},
  year = {2010},
  month = may,
  url = {https://repository.rit.edu/theses/5464},
  langid = {english},
  school = {Rochester Institute of Technology},
  file = {/Users/kshitijgoel/Zotero/storage/KNRN7SSW/Pangborn - Scalable data clustering using GPUs.pdf;/Users/kshitijgoel/Zotero/storage/2HACVU8A/5464.html}
}

@article{pantic_mesh_2021,
  title = {Mesh {{Manifold Based Riemannian Motion Planning}} for {{Omnidirectional Micro Aerial Vehicles}}},
  author = {Pantic, Michael and Ott, Lionel and Cadena, Cesar and Siegwart, Roland and Nieto, Juan},
  year = {2021},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4790--4797},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3061869},
  url = {https://ieeexplore.ieee.org/document/9362167/?arnumber=9362167},
  urldate = {2024-07-22},
  abstract = {This letter presents a novel on-line path planning method that enables aerial robots to interact with surfaces. We present a solution to the problem of finding trajectories that drive a robot towards a surface and move along it. Triangular meshes are used as a surface map representation that is free of fixed discretization and allows for very large workspaces. We propose to leverage planar parametrization methods to obtain a lower-dimensional topologically equivalent representation of the original surface. Furthermore, we interpret the original surface and its lower-dimensional representation as manifold approximations that allow the use of Riemannian Motion Policies (RMPs), resulting in an efficient, versatile, and elegant motion generation framework. We compare against several Rapidly-exploring Random Tree (RRT) planners, a customized CHOMP variant, and the discrete geodesic algorithm. Using extensive simulations on real-world data we show that the proposed planner can reliably plan high-quality near-optimal trajectories at minimal computational cost. The accompanying multimedia attachment demonstrates feasibility on a real OMAV. The obtained paths show less than 10\% deviation from the theoretical optimum while facilitating reactive re-planning at kHz refresh rates, enabling flying robots to perform motion planning for interaction with complex surfaces.},
  keywords = {Aerial systems,Inspection,Manifolds,motion and path planning,Planning,Splines (mathematics),Three-dimensional displays,Trajectory,Two dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/3UMD7JE4/Pantic et al. - 2021 - Mesh Manifold Based Riemannian Motion Planning for Omnidirectional Micro Aerial Vehicles.pdf;/Users/kshitijgoel/Zotero/storage/4QVFD588/9362167.html}
}

@inproceedings{papachristos_uncertaintyaware_2017,
  title = {Uncertainty-Aware Receding Horizon Exploration and Mapping Using Aerial Robots},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Papachristos, Christos and Khattak, Shehryar and Alexis, Kostas},
  year = {2017},
  month = may,
  pages = {4568--4575},
  doi = {10.1109/ICRA.2017.7989531},
  url = {https://ieeexplore.ieee.org/document/7989531},
  urldate = {2024-11-15},
  abstract = {This paper presents a novel path planning algorithm for autonomous, uncertainty-aware exploration and mapping of unknown environments using aerial robots. The proposed planner follows a two-step, receding horizon, belief space-based approach. At first, in an online computed tree the algorithm finds the branch that optimizes the amount of space expected to be explored. The first viewpoint configuration of this branch is selected, but the path towards it is decided through a second planning step. Within that, a new tree is sampled, admissible branches arriving at the reference viewpoint are found and the robot belief about its state and the tracked landmarks of the environment is propagated. The branch that minimizes the expected localization and mapping uncertainty is selected, the corresponding path is executed by the robot and the whole process is iteratively repeated. The proposed planner is capable of running online onboard a small aerial robot and its performance is evaluated using experimental studies in a challenging environment.},
  keywords = {Collision avoidance,Planning,Simultaneous localization and mapping,Uncertainty,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/9JHQP299/Papachristos et al. - 2017 - Uncertainty-aware receding horizon exploration and mapping using aerial robots.pdf;/Users/kshitijgoel/Zotero/storage/CTYF8JMG/7989531.html}
}

@article{papalia_certifiably_2024,
  title = {Certifiably {{Correct Range-Aided SLAM}}},
  author = {Papalia, Alan and Fishberg, Andrew and O'Neill, Brendan W. and How, Jonathan P. and Rosen, David M. and Leonard, John J.},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {4265--4283},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3454430},
  url = {https://ieeexplore.ieee.org/document/10665918/},
  urldate = {2025-05-22},
  abstract = {We present the first algorithm to efficiently compute certifiably optimal solutions to range-aided simultaneous localization and mapping (RA-SLAM) problems. Robotic navigation systems increasingly incorporate point-to-point ranging sensors, leading to state estimation problems in the form of RA-SLAM. However, the RA-SLAM problem is significantly more difficult to solve than traditional pose-graph SLAM: Ranging sensor models introduce nonconvexity and single range measurements do not uniquely determine the transform between the involved sensors. As a result, RA-SLAM inference is sensitive to initial estimates yet lacks reliable initialization techniques. Our approach, certifiably correct RA-SLAM (CORA), leverages a novel quadratically constrained quadratic programming formulation of RA-SLAM to relax the RA-SLAM problem to a semidefinite program (SDP). CORA solves the SDP efficiently using the Riemannian Staircase methodology; the SDP solution provides both: 1) a lower bound on the RA-SLAM problem's optimal value and 2) an approximate solution of the RA-SLAM problem, which can be subsequently refined using local optimization. CORA applies to problems with arbitrary pose-pose, pose-landmark, and ranging measurements and, due to using convex relaxation, is insensitive to initialization. We evaluate CORA on several real-world problems. In contrast to state-of-the-art approaches, CORA is able to obtain high-quality solutions on all problems despite being initialized with random values. In addition, we study the tightness of the SDP relaxation with respect to important problem parameters: The number of: 1) robots; 2) landmarks; and 3) range measurements. These experiments demonstrate that the SDP relaxation is often tight and reveal relationships between graph connectivity and the tightness of the SDP relaxation.},
  keywords = {Algorithm design and analysis,Certifiable perception,Certification,Optimization,range-aided simultaneous localization and mapping (RA-SLAM),Relaxation methods,Riemannian Staircase,semidefinite programming,Semidefinite programming,Simultaneous localization and mapping,Ultra wideband technology,ultrawideband (UWB)},
  file = {/Users/kshitijgoel/Zotero/storage/J2R77YKQ/Papalia et al. - 2024 - Certifiably Correct Range-Aided SLAM.pdf}
}

@misc{papalia_overview_2024,
  title = {An {{Overview}} of the {{Burer-Monteiro Method}} for {{Certifiable Robot Perception}}},
  author = {Papalia, Alan and Tian, Yulun and Rosen, David M. and How, Jonathan P. and Leonard, John J.},
  year = {2024},
  month = sep,
  number = {arXiv:2410.00117},
  eprint = {2410.00117},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.00117},
  url = {http://arxiv.org/abs/2410.00117},
  urldate = {2024-12-19},
  abstract = {This paper presents an overview of the Burer-Monteiro method (BM), a technique that has been applied to solve robot perception problems to certifiable optimality in real-time. BM is often used to solve semidefinite programming relaxations, which can be used to perform global optimization for non-convex perception problems. Specifically, BM leverages the low-rank structure of typical semidefinite programs to dramatically reduce the computational cost of performing optimization. This paper discusses BM in certifiable perception, with three main objectives: (i) to consolidate information from the literature into a unified presentation, (ii) to elucidate the role of the linear independence constraint qualification (LICQ), a concept not yet well-covered in certifiable perception literature, and (iii) to share practical considerations that are discussed among practitioners but not thoroughly covered in the literature. Our general aim is to offer a practical primer for applying BM towards certifiable perception.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/YL464J6W/Papalia et al. - 2024 - An Overview of the Burer-Monteiro Method for Certifiable Robot Perception.pdf;/Users/kshitijgoel/Zotero/storage/N3D8G74Z/2410.html}
}

@article{papamakarios_normalizing_2021,
  title = {Normalizing {{Flows}} for {{Probabilistic Modeling}} and {{Inference}}},
  author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  year = {2021},
  journal = {Journal of Machine Learning Research},
  volume = {22},
  number = {57},
  pages = {1--64},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v22/19-1028.html},
  urldate = {2024-03-15},
  abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
  file = {/Users/kshitijgoel/Zotero/storage/J82QW3AU/Papamakarios et al. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf}
}

@inproceedings{papatheodorou_finding_2023,
  title = {Finding {{Things}} in the {{Unknown}}: {{Semantic Object-Centric Exploration}} with an {{MAV}}},
  shorttitle = {Finding {{Things}} in the {{Unknown}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Papatheodorou, Sotiris and Funk, Nils and Tzoumanikas, Dimos and Choi, Christopher and Xu, Binbin and Leutenegger, Stefan},
  year = {2023},
  month = may,
  pages = {3339--3345},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160490},
  url = {https://ieeexplore.ieee.org/document/10160490/},
  urldate = {2024-04-22},
  abstract = {Exploration of unknown space with an autonomous mobile robot is a well-studied problem. In this work we broaden the scope of exploration, moving beyond the pure geometric goal of uncovering as much free space as possible. We believe that for many practical applications, exploration should be contextualised with semantic and object-level understanding of the environment for task-specific exploration. Here, we study the task of both finding specific objects in unknown space as well as reconstructing them to a target level of detail. We therefore extend our environment reconstruction to not only consist of a background map, but also object-level and semantically fused submaps. Importantly, we adapt our previous objective function of uncovering as much free space as possible in as little time as possible with two additional elements: first, we require a maximum observation distance of background surfaces to ensure target objects are not missed by image-based detectors because they are too small to be detected. Second, we require an even smaller maximum distance to the found objects in order to reconstruct them with the desired accuracy. We further created a Micro Aerial Vehicle (MAV) semantic exploration simulator based on Habitat in order to quantitatively demonstrate how our framework can be used to efficiently find specific objects as part of exploration. Finally, we showcase this capability can be deployed in real-world scenes involving our drone equipped with an Intel RealSense D455 RGB-D camera.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G53AK68R/Papatheodorou et al. - 2023 - Finding Things in the Unknown Semantic Object-Cen.pdf}
}

@book{papoulis_probability_2002,
  title = {Probability, {{Random Variables}}, and {{Stochastic Processes}}},
  author = {Papoulis, Athanasios and Pillai, S. Unnikrishna},
  year = {2002},
  publisher = {McGraw-Hill},
  abstract = {The fourth edition of Probability, Random Variables and Stochastic Processes has been updated significantly from the previous edition, and it now includes co-author S. Unnikrishna Pillai of Polytechnic University. The book is intended for a senior/graduate level course in probability and is aimed at students in electrical engineering, math, and physics departments. The authors' approach is to develop the subject of probability theory and stochastic processes as a deductive discipline and to illustrate the theory with basic applications of engineering interest. Approximately 1/3 of the text is new material--this material maintains the style and spirit of previous editions. In order to bridge the gap between concepts and applications, a number of additional examples have been added for further clarity, as well as several new topics.},
  googlebooks = {k22UwAEACAAJ},
  isbn = {978-0-07-122661-5},
  langid = {english},
  keywords = {Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@article{paranjape_motion_2015,
  title = {Motion Primitives and {{3D}} Path Planning for Fast Flight through a           Forest},
  author = {Paranjape, Aditya A. and Meier, Kevin C. and Shi, Xichen and Chung, Soon-Jo and Hutchinson, Seth},
  year = {2015},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {34},
  number = {3},
  pages = {357--377},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364914558017},
  url = {https://doi.org/10.1177/0278364914558017},
  urldate = {2023-02-13},
  abstract = {This paper presents two families of motion primitives for enabling fast, agile flight through a dense obstacle field. The first family of primitives consists of a time-delay dependent 3D circular path between two points in space and the control inputs required to fly the path. In particular, the control inputs are calculated using algebraic equations which depend on the flight parameters and the location of the waypoint. Moreover, the transition between successive maneuver states, where each state is defined by a unique combination of constant control inputs, is modeled rigorously as an instantaneous switch between the two maneuver states following a time delay which is directly related to the agility of the robotic aircraft. The second family consists of aggressive turn-around (ATA) maneuvers which the robot uses to retreat from impenetrable pockets of obstacles. The ATA maneuver consists of an orchestrated sequence of three sets of constant control inputs. The duration of the first segment is used to optimize the ATA for the spatial constraints imposed by the turning volume. The motion primitives are validated experimentally and implemented in a simulated receding horizon control (RHC)-based motion planner. The paper concludes with inverse-design pointers derived from the primitives.},
  file = {/Users/kshitijgoel/Zotero/storage/ML39F8GV/Paranjape et al. - 2015 - Motion primitives and 3D path planning for fast fl.pdf}
}

@article{parekh_swing_2024,
  title = {Swing and Reverse Swing of a Cricket Ball: Laminar Separation Bubble, Secondary Vortex and Wing-Tip-like Vortices},
  shorttitle = {Swing and Reverse Swing of a Cricket Ball},
  author = {Parekh, Aman and Chaplot, Daksh and Mittal, Sanjay},
  year = {2024},
  month = mar,
  journal = {Journal of Fluid Mechanics},
  volume = {983},
  pages = {A23},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/jfm.2024.135},
  url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/swing-and-reverse-swing-of-a-cricket-ball-laminar-separation-bubble-secondary-vortex-and-wingtiplike-vortices/E490929622A6FE446650D7FB1D37866C},
  urldate = {2024-04-25},
  abstract = {, Large eddy simulation of flow past a cricket ball with its seam at 30{$\circ$}30{$\circ$}30{\textasciicircum}{\textbackslash}circ to the free stream is carried out for 5{\texttimes}104{$\leqRe\leq$}4.5{\texttimes}1055{\texttimes}104{$\leq$}Re{$\leq$}4.5{\texttimes}1055 {\textbackslash}times 10{\textasciicircum}4 {\textbackslash}le Re {\textbackslash}le 4.5 {\textbackslash}times 10{\textasciicircum}5. Three regimes of flow are identified on the basis of the time-averaged swing force coefficient ({$C$}{\textasciimacron}{$Z$}C{\textasciimacron}Z{\textbackslash}bar \{C\}\_Z) -- no swing (NS), conventional swing (CS, {$C$}{\textasciimacron}{$Z>$}0C{\textasciimacron}Z{$>$}0{\textbackslash}bar \{C\}\_Z{$>$}0) and reverse swing (RS, {$C$}{\textasciimacron}{$Z<$}0C{\textasciimacron}Z{$<$}0{\textbackslash}bar \{C\}\_Z{$<$}0). The effect of seam on the boundary layer is investigated. Contrary to the popular belief, the boundary layer does not transition to a turbulent state in the initial stages of CS. The seam energizes the laminar boundary layer and delays its separation. The delay is significantly larger in a region near the poles, whose extent increases with an increase in {$Re$}ReRe causing {$C$}{\textasciimacron}{$Z$}C{\textasciimacron}Z{\textbackslash}bar \{C\}\_Z to increase. Here {$C$}{\textasciimacron}{$Z$}C{\textasciimacron}Z{\textbackslash}bar \{C\}\_Z assumes a near constant value in the later stage of CS. The boundary layer transitions to a turbulent state via formation of a laminar separation bubble (LSB) in the equatorial region and directly, without a LSB, in the polar region. The extent of the LSB shrinks while the region of direct transition near the poles increases with an increase in {$Re$}ReRe. A LSB forms on the non-seam side of the ball in the RS regime. A secondary vortex is observed in the wake bubble. While it exists on the non-seam side for the entire range of {$Re$}ReRe considered, the mixing in the flow introduced by the seam causes it to disappear beyond a certain {$Re$}ReRe on the seam side. The pressure difference between the seam and non-seam sides sets up wing-tip-like vortices. Their polarity reverses with the switch from the CS to RS regime.},
  langid = {english},
  keywords = {turbulent transition,wakes},
  file = {/Users/kshitijgoel/Zotero/storage/86Q3SN2G/Parekh et al. - 2024 - Swing and reverse swing of a cricket ball laminar.pdf}
}

@inproceedings{park_deepsdf_2019,
  title = {{{DeepSDF}}: {{Learning Continuous Signed Distance Functions}} for {{Shape Representation}}},
  shorttitle = {{{DeepSDF}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  year = {2019},
  month = jun,
  pages = {165--174},
  publisher = {IEEE},
  address = {Long Beach, CA, USA},
  doi = {10.1109/CVPR.2019.00025},
  url = {https://ieeexplore.ieee.org/document/8954065/},
  urldate = {2024-01-25},
  abstract = {Computer graphics, 3D computer vision and robotics communities have produced multiple approaches to representing 3D geometry for rendering and reconstruction. These provide trade-offs across fidelity, efficiency and compression capabilities. In this work, we introduce DeepSDF, a learned continuous Signed Distance Function (SDF) representation of a class of shapes that enables high quality shape representation, interpolation and completion from partial and noisy 3D input data. DeepSDF, like its classical counterpart, represents a shape's surface by a continuous volumetric field: the magnitude of a point in the field represents the distance to the surface boundary and the sign indicates whether the region is inside (-) or outside (+) of the shape, hence our representation implicitly encodes a shape's boundary as the zero-level-set of the learned function while explicitly representing the classification of space as being part of the shapes' interior or not. While classical SDF's both in analytical or discretized voxel form typically represent the surface of a single shape, DeepSDF can represent an entire class of shapes. Furthermore, we show stateof-the-art performance for learned 3D shape representation and completion while reducing the model size by an order of magnitude compared with previous work.},
  isbn = {978-1-7281-3293-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/59VTGKH5/Park et al. - 2019 - DeepSDF Learning Continuous Signed Distance Funct.pdf}
}

@article{pathak_unified_2018,
  title = {A Unified Framework for Data Association Aware Robust Belief Space Planning and Perception},
  author = {Pathak, Shashank and Thomas, Antony and Indelman, Vadim},
  year = {2018},
  month = feb,
  journal = {The International Journal of Robotics Research},
  volume = {37},
  number = {2-3},
  pages = {287--315},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364918759606},
  url = {https://doi.org/10.1177/0278364918759606},
  urldate = {2023-11-16},
  abstract = {We develop a belief space planning approach that advances the state of the art by incorporating reasoning about data association within planning, while considering additional sources of uncertainty. Existing belief space planning approaches typically assume that data association is given and perfect, an assumption that can be harder to justify during operation in the presence of localization uncertainty, or in ambiguous and perceptually aliased environments. By contrast, our data association aware belief space planning (DA-BSP) approach explicitly reasons about data association within belief evolution owing to candidate actions, and as such can better accommodate these challenging real-world scenarios. In particular, we show that, owing to perceptual aliasing, a posterior belief can become a mixture of probability distribution functions and design cost functions, which measure the expected level of ambiguity and posterior uncertainty given candidate action. Furthermore, we also investigate more challenging situations, such as when prior belief is multimodal and when data association aware planning is performed over several look-ahead steps. Our framework models the belief as a Gaussian mixture model. Another unique aspect of this approach is that the number of components of this Gaussian mixture model can increase as well as decrease, thereby reflecting reality more accurately. Using these and standard costs (e.g. control penalty, distance to goal) within the objective function yields a general framework that reliably represents action impact and, in particular, is capable of active disambiguation. Our approach is thus applicable to both robust perception in a passive setting with data given a priori and in an active setting, such as in autonomous navigation in perceptually aliased environments. We demonstrate key aspects of DA-BSP in a theoretical example, in a Gazebo-based realistic simulation, and also on the real robotic platform using a Pioneer robot in an office environment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2EIB5KJ5/Pathak et al. - 2018 - A unified framework for data association aware rob.pdf}
}

@inproceedings{patil_estimating_2012,
  title = {Estimating Probability of Collision for Safe Motion Planning under {{Gaussian}} Motion and Sensing Uncertainty},
  booktitle = {2012 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Patil, Sachin and {van den Berg}, Jur and Alterovitz, Ron},
  year = {2012},
  month = may,
  pages = {3238--3244},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2012.6224727},
  url = {https://ieeexplore.ieee.org/document/6224727},
  urldate = {2024-10-24},
  abstract = {We present a fast, analytical method for estimating the probability of collision of a motion plan for a mobile robot operating under the assumptions of Gaussian motion and sensing uncertainty. Estimating the probability of collision is an integral step in many algorithms for motion planning under uncertainty and is crucial for characterizing the safety of motion plans. Our method is computationally fast, enabling its use in online motion planning, and provides conservative estimates to promote safety. To improve accuracy, we use a novel method to truncate estimated a priori state distributions to account for the fact that the probability of collision at each stage along a plan is conditioned on the previous stages being collision free. Our method can be directly applied within a variety of existing motion planners to improve their performance and the quality of computed plans. We apply our method to a car-like mobile robot with second order dynamics and to a steerable medical needle in 3D and demonstrate that our method for estimating the probability of collision is orders of magnitude faster than na{\"i}ve Monte Carlo sampling methods and reduces estimation error by more than 25\% compared to prior methods.},
  keywords = {Collision avoidance,Needles,Noise measurement,Robot sensing systems,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/U2ITYYWJ/Patil et al. - 2012 - Estimating probability of collision for safe motion planning under Gaussian motion and sensing uncer.pdf}
}

@inproceedings{patwardhan_distributed_2024,
  title = {A {{Distributed Multi-Robot Framework}} for {{Exploration}}, {{Information Acquisition}} and {{Consensus}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Patwardhan, Aalok and Davison, Andrew J.},
  year = {2024},
  month = may,
  pages = {12062--12068},
  doi = {10.1109/ICRA57147.2024.10610185},
  url = {https://ieeexplore.ieee.org/document/10610185/?arnumber=10610185},
  urldate = {2024-12-02},
  abstract = {The distributed coordination of robot teams performing complex tasks is challenging to formulate. The different aspects of a complete task such as local planning for obstacle avoidance, global goal coordination and collaborative mapping are often solved separately, when clearly each of these should influence the others for the most efficient behaviour. In this paper we use the example application of distributed information acquisition as a robot team explores a large space to show that we can formulate the whole problem as a single factor graph with multiple connected layers representing each aspect. We use Gaussian Belief Propagation (GBP) as the inference mechanism, which permits parallel, on-demand or asynchronous computation for efficiency when different aspects are more or less important. This is the first time that a distributed GBP multi-robot solver has been proven to enable intelligent collaborative behaviour rather than just guiding robots to individual, selfish goals. We encourage the reader to view our demos at https://aalpatya.github.io/gbpstack.},
  keywords = {Collaboration,Computational efficiency,Heuristic algorithms,Planning,Robot kinematics,Scalability,Space exploration},
  file = {/Users/kshitijgoel/Zotero/storage/3PUAUSJK/Patwardhan and Davison - 2024 - A Distributed Multi-Robot Framework for Exploration, Information Acquisition and Consensus.pdf;/Users/kshitijgoel/Zotero/storage/KBB3UG5L/10610185.html}
}

@article{patwardhan_distributing_2023,
  title = {Distributing {{Collaborative Multi-Robot Planning}} with {{Gaussian Belief Propagation}}},
  author = {Patwardhan, Aalok and Murai, Riku and Davison, Andrew J.},
  year = {2023},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {2},
  eprint = {2203.11618},
  primaryclass = {cs},
  pages = {552--559},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2022.3227858},
  url = {http://arxiv.org/abs/2203.11618},
  urldate = {2023-03-05},
  abstract = {Precise coordinated planning over a forward time window enables safe and highly efficient motion when many robots must work together in tight spaces, but this would normally require centralised control of all devices which is difficult to scale. We demonstrate GBP Planning, a new purely distributed technique based on Gaussian Belief Propagation for multi-robot planning problems, formulated by a generic factor graph defining dynamics and collision constraints over a forward time window. In simulations, we show that our method allows high performance collaborative planning where robots are able to cross each other in busy, intricate scenarios. They maintain shorter, quicker and smoother trajectories than alternative distributed planning techniques even in cases of communication failure. We encourage the reader to view the accompanying video demonstration at https://youtu.be/8VSrEUjH610.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/U8KTZWCV/Patwardhan et al. - 2023 - Distributing Collaborative Multi-Robot Planning wi.pdf;/Users/kshitijgoel/Zotero/storage/EBNAHJ3E/2203.html}
}

@article{pavliv_tracking_2021,
  title = {Tracking and {{Relative Localization}} of {{Drone Swarms With}} a {{Vision-Based Headset}}},
  author = {Pavliv, Maxim and Schiano, Fabrizio and Reardon, Christopher and Floreano, Dario and Loianno, Giuseppe},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1455--1462},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3051565},
  url = {https://ieeexplore.ieee.org/document/9324934/},
  urldate = {2025-05-13},
  abstract = {We address the detection, tracking, and relative localization of the agents of a drone swarm from a human perspective using a headset equipped with a single camera and an Inertial Measurement Unit (IMU). We train and deploy a deep neural network detector on image data to detect the drones. A joint probabilistic data association filter resolves the detection problems and couples this information with the headset IMU data to track the agents. In order to estimate the drones' relative poses in 3D space with respect to the human, we use an additional deep neural network that processes image regions of the drones provided by the tracker. Finally, to speed up the deep neural networks' training, we introduce an automated labeling process relying on a motion capture system. Several experimental results validate the effectiveness of the proposed approach. The approach is real-time, does not rely on any communication between the human and the drones, and can scale to a large number of agents, often called swarms. It can be used to spatially task a swarm of drones and also employed without a headset for formation control and coordination of terrestrial vehicles.},
  keywords = {Aerial systems,applications,Cameras,Drones,Headphones,human-centered robotics,localization,Location awareness,Robot kinematics,Tracking,Training},
  file = {/Users/kshitijgoel/Zotero/storage/8N3G5UZT/Pavliv et al. - 2021 - Tracking and Relative Localization of Drone Swarms With a Vision-Based Headset.pdf}
}

@article{pearson_vii_1896,
  title = {{{VII}}. {{Mathematical}} Contributions to the Theory of Evolution.---{{III}}. {{Regression}}, Heredity, and Panmixia},
  author = {Pearson, Karl},
  year = {1896},
  month = dec,
  journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
  volume = {187},
  pages = {253--318},
  issn = {0264-3952, 2053-9258},
  doi = {10.1098/rsta.1896.0007},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsta.1896.0007},
  urldate = {2024-07-24},
  abstract = {There are few branches of the Theory of Evolution which appear to the mathematical statistician so much in need of exact treatment as those of Regression, Heredity, and Panmixia. Round the notion of panmixia much obscurity has accumulated, owing to the want of precise definition and quantitative measurement. The problems of regression and heredity have been dealt with by Mr. Francis Galton in his epochmaking work on `Natural Inheritance,' but, although he has shown exact methods of dealing, both experimentally and mathematically, with the problems of inheritance, it does not appear that mathematicians have hitherto developed his treatment, or that biologists and medical men have yet fully appreciated that he has really shown how many of the problems which perplex them may receive at any rate a partial answer. A considerable portion of the present memoir will be devoted to the expansion and fuller development of Mr. Galton's ideas, particularly their application to the problem of               bi-parental inheritance               . At the same time I shall endeavour to point out how the results apply to some current biological and medical problems. In the first place, we must definitely free our minds, in the present state of our knowledge of the mechanism of inheritance and reproduction, of any hope of reaching a mathematical relation expressing the degree of correlation between individual parent and individual offspring. The causes in any individual case of inheritance are far too complex to admit of exact treatment; and up to the present the classification of the circumstances under which greater or less degrees of correlation between special groups of parents and offspring may be expected has made but little progress. This is largely owing to a certain prevalence of almost metaphysical speculation as to the causes of heredity, which has usurped the place of that careful collection and elaborate experiment by which alone sufficient data might have been accumulated, with a view to ultimately narrowing and specialising the circumstances under which correlation was measured. We must proceed from inheritance in the mass to inheritance in narrower and narrwoer classes, rather than attempt to build up general rules on the observation of individual instances. Shortly, we must proceed by the method of statistics, rather than by the consideration of typical cases. It may seem discouraging to the medical practitioner, with the problem before him of inheritance in a particular family, to be told that nothing but averages, means, and probabilities with regard to large classes can as yet be scientifically dealt with ; but the very nature of the distribution of variation, whether healthy or morhid, seems to indicate that we are dealing with that sphere of indefinitely numerous small causes, which in so many other instances has shown itself only amenable to the calculus of chance, and not to any analysis of the individual instance. On the other hand, the mathematical theory wall be of assistance to the medical man by answering, inter alia, in its discussion of regression the problem as to the average effect upon the offspring of given degrees of morbid variation in the parents. It may enable the physician, in many cases, to state a belief based on a high degree of probability, if it offers no ground for dogma in individual cases. One of the most noteworthy results of Mr. Francis Galton's researches is his discovery of the mode in which a population actually reproduces itself by regression and fraternal variation. It is with some expansion and fuller mathematical treatment of these ideas that this memoir commences.},
  copyright = {https://royalsociety.org/journals/ethics-policies/data-sharing-mining/},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/D7SW9KUL/Pearson and Henrici - 1997 - VII. Mathematical contributions to the theory of evolution.—III. Regression, heredity, and panmixia.pdf}
}

@inproceedings{peharz_einsum_2020,
  title = {Einsum {{Networks}}: {{Fast}} and {{Scalable Learning}} of {{Tractable Probabilistic Circuits}}},
  shorttitle = {Einsum {{Networks}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Peharz, Robert and Lang, Steven and Vergari, Antonio and Stelzner, Karl and Molina, Alejandro and Trapp, Martin and Broeck, Guy Van Den and Kersting, Kristian and Ghahramani, Zoubin},
  year = {2020},
  month = nov,
  pages = {7563--7574},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/peharz20a.html},
  urldate = {2025-03-01},
  abstract = {Probabilistic circuits (PCs) are a promising avenue for probabilistic modeling, as they permit a wide range of exact and efficient inference routines. Recent ``deep-learning-style'' implementations of PCs strive for a better scalability, but are still difficult to train on real-world data, due to their sparsely connected computational graphs. In this paper, we propose Einsum Networks (EiNets), a novel implementation design for PCs, improving prior art in several regards. At their core, EiNets combine a large number of arithmetic operations in a single monolithic einsum-operation, leading to speedups and memory savings of up to two orders of magnitude, in comparison to previous implementations. As an algorithmic contribution, we show that the implementation of Expectation-Maximization (EM) can be simplified for PCs, by leveraging automatic differentiation. Furthermore, we demonstrate that EiNets scale well to datasets which were previously out of reach, such as SVHN and CelebA, and that they can be used as faithful generative image models.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4YDTE8UB/Peharz et al. - 2020 - Einsum Networks Fast and Scalable Learning of Tractable Probabilistic Circuits.pdf}
}

@article{penalverbenavent_learning_2009,
  title = {Learning {{Gaussian Mixture Models With Entropy-Based Criteria}}},
  author = {Penalver Benavent, Antonio and Escolano Ruiz, Francisco and Saez, Juan Manuel},
  year = {2009},
  month = nov,
  journal = {IEEE Transactions on Neural Networks},
  volume = {20},
  number = {11},
  pages = {1756--1771},
  issn = {1941-0093},
  doi = {10.1109/TNN.2009.2030190},
  url = {https://ieeexplore.ieee.org/document/5247027},
  urldate = {2024-06-07},
  abstract = {In this paper, we address the problem of estimating the parameters of Gaussian mixture models. Although the expectation--maximization (EM) algorithm yields the maximum-likelihood (ML) solution, its sensitivity to the selection of the starting parameters is well-known and it may converge to the boundary of the parameter space. Furthermore, the resulting mixture depends on the number of selected components, but the optimal number of kernels may be unknown beforehand. We introduce the use of the entropy of the probability density function (pdf) associated to each kernel to measure the quality of a given mixture model with a fixed number of kernels. We propose two methods to approximate the entropy of each kernel and a modification of the classical EM algorithm in order to find the optimum number of components of the mixture. Moreover, we use two stopping criteria: a novel global mixture entropy-based criterion called Gaussianity deficiency (GD) and a minimum description length (MDL) principle-based one. Our algorithm, called entropy-based EM (EBEM), starts with a unique kernel and performs only splitting by selecting the worst kernel attending to GD. We have successfully tested it in probability density estimation, pattern classification, and color image segmentation. Experimental results improve the ones of other state-of-the-art model order selection methods.},
  keywords = {Clustering,Density measurement,EM algorithm,Entropy,entropy estimation,Gaussian processes,Kernel,Maximum likelihood estimation,minimum description length (MDL) criterion,mixture models,model order selection,Parameter estimation,Pattern classification,Performance evaluation,Probability density function,Testing},
  file = {/Users/kshitijgoel/Zotero/storage/ZJA7YPYN/Penalver Benavent et al. - 2009 - Learning Gaussian Mixture Models With Entropy-Based Criteria.pdf;/Users/kshitijgoel/Zotero/storage/CCL25IYC/5247027.html}
}

@inproceedings{peng_adaptive_2019,
  title = {Adaptive {{View Planning}} for {{Aerial 3D Reconstruction}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Peng, Cheng and Isler, Volkan},
  year = {2019},
  month = may,
  pages = {2981--2987},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8793532},
  url = {https://ieeexplore.ieee.org/document/8793532/?arnumber=8793532},
  urldate = {2024-11-06},
  abstract = {With the proliferation of small aerial vehicles, acquiring close up imagery for high quality reconstruction is gaining importance. We present an adaptive view planning method to collect such images in an automated fashion. We first start by sampling a small set of views to build a coarse proxy to the scene. We then present (i) a method that builds a set of adaptive viewing planes for efficient view selection and (ii) an algorithm to plan a trajectory that guarantees high reconstruction quality which does not deviate too much from the optimal one. The vehicle then follows the trajectory to cover the scene, and the procedure is repeated until reconstruction quality converges or a desired level of quality is achieved. The set of viewing planes provides an effective compromise between using the entire 3D free space and using a single view hemisphere to select the views. We compare our algorithm to existing methods in three challenging scenes. Our algorithm generates views which produce the least reconstruction error comparing to three different baseline approaches.},
  keywords = {Drones,Feature extraction,Image reconstruction,Image resolution,Planning,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/GS5TRQXF/Peng and Isler - 2019 - Adaptive View Planning for Aerial 3D Reconstruction.pdf;/Users/kshitijgoel/Zotero/storage/36H24VTW/8793532.html}
}

@article{pennec_intrinsic_2006,
  title = {Intrinsic {{Statistics}} on {{Riemannian Manifolds}}: {{Basic Tools}} for {{Geometric Measurements}}},
  shorttitle = {Intrinsic {{Statistics}} on {{Riemannian Manifolds}}},
  author = {Pennec, Xavier},
  year = {2006},
  month = jul,
  journal = {Journal of Mathematical Imaging and Vision},
  volume = {25},
  number = {1},
  pages = {127--154},
  issn = {1573-7683},
  doi = {10.1007/s10851-006-6228-4},
  url = {https://doi.org/10.1007/s10851-006-6228-4},
  urldate = {2024-07-12},
  abstract = {In medical image analysis and high level computer vision, there is an intensive use of geometric features like orientations, lines, and geometric transformations ranging from simple ones (orientations, lines, rigid body or affine transformations, etc.) to very complex ones like curves, surfaces, or general diffeomorphic transformations. The measurement of such geometric primitives is generally noisy in real applications and we need to use statistics either to reduce the uncertainty (estimation), to compare observations, or to test hypotheses. Unfortunately, even simple geometric primitives often belong to manifolds that are not vector spaces. In previous works [1, 2], we investigated invariance requirements to build some statistical tools on transformation groups and homogeneous manifolds that avoids paradoxes. In this paper, we consider finite dimensional manifolds with a Riemannian metric as the basic structure. Based on this metric, we develop the notions of mean value and covariance matrix of a random element, normal law, Mahalanobis distance and {$\chi$}2 law. We provide a new proof of the characterization of Riemannian centers of mass and an original gradient descent algorithm to efficiently compute them. The notion of Normal law we propose is based on the maximization of the entropy knowing the mean and covariance of the distribution. The resulting family of pdfs spans the whole range from uniform (on compact manifolds) to the point mass distribution. Moreover, we were able to provide tractable approximations (with their limits) for small variances which show that we can effectively implement and work with these definitions.},
  langid = {english},
  keywords = {computing on manifolds,covariance,Frechet mean,geometry,Riemannian manifolds,statistics},
  file = {/Users/kshitijgoel/Zotero/storage/7W8Q2JBL/Pennec - 2006 - Intrinsic Statistics on Riemannian Manifolds Basic Tools for Geometric Measurements.pdf}
}

@phdthesis{perekrestenko_deep_2021,
  title = {Deep {{Neural Network Approximation Theory}}},
  author = {Perekrestenko, Dmytro},
  year = {2021},
  eprint = {20.500.11850/500071},
  eprinttype = {hdl},
  pages = {218 p.},
  doi = {10.3929/ETHZ-B-000500071},
  url = {http://hdl.handle.net/20.500.11850/500071},
  urldate = {2024-04-23},
  collaborator = {{B{\"o}lcskei, Helmut} and {Yarotsky, Dmitry}},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/, info:eu-repo/semantics/openAccess},
  langid = {english},
  school = {[object Object]},
  keywords = {Approximation Theory,Data processing computer science,Deep learning,FOS: Mathematics,Generative networks,info:eu-repo/classification/ddc/004,info:eu-repo/classification/ddc/510,Mathematics,Neural networks,Space-filling curves},
  file = {/Users/kshitijgoel/Zotero/storage/J54ZXGXQ/Deep_neural_network_approximation_theory.pdf}
}

@article{perkins_core_2020,
  title = {Core {{Concept}}: {{Lava}} Tubes May Be Havens for Ancient Alien Life and Future Human Explorers},
  shorttitle = {Core {{Concept}}},
  author = {Perkins, Sid},
  year = {2020},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {117},
  number = {30},
  pages = {17461--17464},
  issn = {0027-8424},
  doi = {10.1073/pnas.2012176117},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7395488/},
  urldate = {2023-06-01},
  pmcid = {PMC7395488},
  pmid = {32641500},
  file = {/Users/kshitijgoel/Zotero/storage/Q8KD5WIB/Perkins - 2020 - Core Concept Lava tubes may be havens for ancient.pdf}
}

@article{petracek_largescale_2021,
  title = {Large-{{Scale Exploration}} of {{Cave Environments}} by {{Unmanned Aerial Vehicles}}},
  author = {Petr{\'a}{\v c}ek, Pavel and Kr{\'a}tk{\'y}, V{\'i}t and Petrl{\'i}k, Mat{\v e}j and B{\'a}{\v c}a, Tom{\'a}{\v s} and Kratochv{\'i}l, Radim and Saska, Martin},
  year = {2021},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {4},
  pages = {7596--7603},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3098304},
  abstract = {This letter presents a self-contained system for the robust utilization of aerial robots in the autonomous exploration of cave environments to help human explorers, first responders, and speleologists. The proposed system is generally applicable to an arbitrary exploration task within an unknown and unstructured subterranean environment and interconnects crucial robotic subsystems to provide full autonomy of the robots. Such subsystems primarily include mapping, path and trajectory planning, localization, control, and decision making. Due to the diversity, complexity, and structural uncertainty of natural cave environments, the proposed system allows for the possible use of any arbitrary exploration strategy for a single robot, as well as for a cooperating team. A multi-robot cooperation strategy that maximizes the limited flight time of each aerial robot is proposed for exploration and search \& rescue scenarios where the homing of all deployed robots back to an initial location is not required. The entire system is validated in a comprehensive experimental analysis comprising of hours of flight time in a real-world cave environment, as well as by hundreds of hours within a state-of-the-art virtual testbed that was developed for the DARPA Subterranean Challenge robotic competition. Among others, experimental results include multiple real-world exploration flights traveling over 470 m on a single battery in a demanding unknown cave environment.},
  keywords = {Aerial systems: applications,aerial systems: perception and autonomy,Cameras,field robots,Laser radar,Location awareness,mapping,multi-robot systems,Robot kinematics,Robots,Unmanned aerial vehicles,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/N54ZBXEF/Petráček et al. - 2021 - Large-Scale Exploration of Cave Environments by Un.pdf;/Users/kshitijgoel/Zotero/storage/CQKR44WE/stamp.html}
}

@article{petracek_new_2024,
  title = {New {{Era}} in {{Cultural Heritage Preservation}}: {{Cooperative Aerial Autonomy}} for {{Fast Digitalization}} of {{Difficult-to-Access Interiors}} of {{Historical Monuments}}},
  shorttitle = {New {{Era}} in {{Cultural Heritage Preservation}}},
  author = {Petracek, Pavel and Kratky, Vit and Baca, Tomas and Petrlik, Matej and Saska, Martin},
  year = {2024},
  month = jun,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {31},
  number = {2},
  pages = {8--25},
  issn = {1558-223X},
  doi = {10.1109/MRA.2023.3244423},
  url = {https://ieeexplore.ieee.org/document/10056379/?arnumber=10056379},
  urldate = {2024-11-27},
  abstract = {Digital documentation of large interiors of historical buildings is an exhausting task as most of the areas of interest are beyond typical human reach. We advocate the use of fully autonomous teams of cooperating multirotor UAVs to speed up the documentation process by several orders of magnitude while allowing for a repeatable, accurate, and condition-independent solution capable of precise, collision-free operation at great heights. In particular, we present a universal autonomy for unmanned aerial vehicles (UAVs) cooperating aerially within a team while documenting the interiors of historical buildings for the purposes of restoration planning and documentation works as well as for assessing the structural state of aging historical sites. We show that the proposed approach of active multirobot cooperation enables performing documentation tasks requiring dynamic scene illumination in large-scale real-world scenarios, a process previously applicable only manually in areas easily accessible by humans.},
  keywords = {Architecture,Autonomous aerial vehicles,Buildings,Cultural aspects,Documentation,History,Image restoration,Photography,Robots,Satellite images,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/9FWE42I7/Petracek et al. - 2024 - New Era in Cultural Heritage Preservation Cooperative Aerial Autonomy for Fast Digitalization of Di.pdf;/Users/kshitijgoel/Zotero/storage/X9DV54I3/10056379.html}
}

@article{petrlik_uavs_2023,
  title = {{{UAVs Beneath}} the {{Surface}}: {{Cooperative Autonomy}} for {{Subterranean Search}} and {{Rescue}} in {{DARPA SubT}}},
  shorttitle = {{{UAVs Beneath}} the {{Surface}}},
  author = {Petrlik, Matej and Petr{\'a}{\v c}ek, Pavel and Kr{\'a}tk{\'y}, V{\'i}t and Musil, Tom{\'a}{\v s} and Stasinchuk, Yurii and Vrba, Matou{\v s} and B{\'a}{\v c}a, Tom{\'a}{\v s} and He{\v r}t, Daniel and Pecka, Martin and Svoboda, Tom{\'a}{\v s} and Saska, Martin},
  year = {2023},
  month = jan,
  journal = {Field Robotics},
  volume = {3},
  number = {1},
  pages = {1--68},
  issn = {27713989},
  doi = {10.55417/fr.2023001},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_3_files/Vol3_01.pdf},
  urldate = {2023-03-23},
  abstract = {This paper presents a novel approach for autonomous cooperating UAVs in search and rescue operations in subterranean domains with complex topology. The proposed system was ranked second in the Virtual Track of the DARPA SubT Finals as part of the team CTU-CRAS-NORLAB. In contrast to the winning solution that was developed specifically for the Virtual Track, the proposed solution also proved to be a robust system for deployment onboard physical UAVs flying in the extremely harsh and confined environment of the real-world competition. The proposed approach enables fully autonomous and decentralized deployment of a UAV team with seamless simulation-toworld transfer, and proves its advantage over less mobile UGV teams in the flyable space of diverse environments. The main contributions of the paper are present in the mapping and navigation pipelines. The mapping approach employs novel map representations---SphereMap for efficient risk-aware long-distance planning, FacetMap for surface coverage, and the compressed topologicalvolumetric LTVMap for allowing multirobot cooperation under low-bandwidth communication. These representations are used in navigation together with novel methods for visibility-constrained informed search in a general 3D environment with no assumptions about the environment structure, while balancing deep exploration with sensor-coverage exploitation. The proposed solution also includes a visual-perception pipeline for on-board detection and localization of objects of interest in four RGB stream at 5 Hz each without a dedicated GPU. Apart from participation in the DARPA SubT, the performance of the UAV system is supported by extensive experimental verification in diverse environments with both qualitative and quantitative evaluation.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UEIQXLMR/Petrlik et al. - 2023 - UAVs Beneath the Surface Cooperative Autonomy for.pdf}
}

@book{petrunin_pigtikal_2023,
  title = {{{PIGTIKAL}}},
  author = {Petrunin, Anton},
  year = {2023},
  url = {https://amathr.org/wp-content/uploads/2022/10/Petrunin_AMRResMonograghs2Ed1.pdf#page=77.09},
  urldate = {2024-04-29},
  file = {/Users/kshitijgoel/Zotero/storage/EYEPM47V/Petrunin_AMRResMonograghs2Ed1.pdf}
}

@article{pewsey_recent_2021,
  title = {Recent Advances in Directional Statistics},
  author = {Pewsey, Arthur and {Garc{\'i}a-Portugu{\'e}s}, Eduardo},
  year = {2021},
  month = mar,
  journal = {TEST},
  volume = {30},
  number = {1},
  pages = {1--58},
  issn = {1863-8260},
  doi = {10.1007/s11749-021-00759-x},
  url = {https://doi.org/10.1007/s11749-021-00759-x},
  urldate = {2024-06-27},
  abstract = {Mainstream statistical methodology is generally applicable to data observed in Euclidean space. There are, however, numerous contexts of considerable scientific interest in which the natural supports for the data under consideration are Riemannian manifolds like the unit circle, torus, sphere, and their extensions. Typically, such data can be represented using one or more directions, and directional statistics is the branch of statistics that deals with their analysis. In this paper, we provide a review of the many recent developments in the field since the publication of Mardia and Jupp (Wiley 1999), still the most comprehensive text on directional statistics. Many of those developments have been stimulated by interesting applications in fields as diverse as astronomy, medicine, genetics, neurology, space situational awareness, acoustics, image analysis, text mining, environmetrics, and machine learning. We begin by considering developments for the exploratory analysis of directional data before progressing to distributional models, general approaches to inference, hypothesis testing, regression, nonparametric curve estimation, methods for dimension reduction, classification and clustering, and the modelling of time series, spatial and spatio-temporal data. An overview of currently available software for analysing directional data is also provided, and potential future developments are discussed.},
  langid = {english},
  keywords = {62H11,Classification,Clustering,Dimension reduction,Distributional models,Exploratory data analysis,Hypothesis tests,Nonparametric methods,Regression,Serial dependence,Software,Spatial statistics},
  file = {/Users/kshitijgoel/Zotero/storage/8F3ZMKFE/Pewsey and García-Portugués - 2021 - Recent advances in directional statistics.pdf}
}

@misc{peyre_computational_2020,
  title = {Computational {{Optimal Transport}}},
  author = {Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2020},
  month = mar,
  number = {arXiv:1803.00567},
  eprint = {1803.00567},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1803.00567},
  url = {http://arxiv.org/abs/1803.00567},
  urldate = {2023-09-27},
  abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/UW46U54S/Peyré and Cuturi - 2020 - Computational Optimal Transport.pdf;/Users/kshitijgoel/Zotero/storage/94ID9QNC/1803.html}
}

@inproceedings{pfeifer_expectationmaximization_2019,
  title = {Expectation-{{Maximization}} for {{Adaptive Mixture Models}} in {{Graph Optimization}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Pfeifer, Tim and Protzel, Peter},
  year = {2019},
  month = may,
  pages = {3151--3157},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2019.8793601},
  abstract = {Non-Gaussian and multimodal distributions are an important part of many recent robust sensor fusion algorithms. In difference to robust cost functions, they are probabilistically founded and have good convergence properties. Since their robustness depends on a close approximation of the real error distribution, their parametrization is crucial. We propose a novel approach that allows to adapt a multi-modal Gaussian mixture model to the error distribution of a sensor fusion problem. By combining expectation-maximization and non-linear least squares optimization, we are able to provide a computationally efficient solution with well-behaved convergence properties. We demonstrate the performance of these algorithms on several real-world GNSS and indoor localization datasets. The proposed adaptive mixture algorithm outperforms state-of-the-art approaches with static parametrization. Source code and datasets are available under https://mytuc.org/libRSF.},
  keywords = {Adaptation models,Convergence,Estimation,Global navigation satellite system,Optimization,Robot sensing systems,Sensor fusion},
  file = {/Users/kshitijgoel/Zotero/storage/PW4PD5ZD/Pfeifer and Protzel - 2019 - Expectation-Maximization for Adaptive Mixture Mode.pdf;/Users/kshitijgoel/Zotero/storage/32P9LQGP/8793601.html}
}

@inproceedings{pfister_surfels_2000,
  title = {Surfels: Surface Elements as Rendering Primitives},
  shorttitle = {Surfels},
  booktitle = {Proceedings of the 27th Annual Conference on {{Computer}} Graphics and Interactive Techniques  - {{SIGGRAPH}} '00},
  author = {Pfister, Hanspeter and Zwicker, Matthias and {van Baar}, Jeroen and Gross, Markus},
  year = {2000},
  pages = {335--342},
  publisher = {ACM Press},
  address = {Not Known},
  doi = {10.1145/344779.344936},
  url = {http://portal.acm.org/citation.cfm?doid=344779.344936},
  urldate = {2022-08-12},
  abstract = {Surface elements (surfels) are a powerful paradigm to efficiently render complex geometric objects at interactive frame rates. Unlike classical surface discretizations, i.e., triangles or quadrilateral meshes, surfels are point primitives without explicit connectivity. Surfel attributes comprise depth, texture color, normal, and others. As a pre-process, an octree-based surfel representation of a geometric object is computed. During sampling, surfel positions and normals are optionally perturbed, and different levels of texture colors are prefiltered and stored per surfel. During rendering, a hierarchical forward warping algorithm projects surfels to a z-buffer. A novel method called visibility splatting determines visible surfels and holes in the z-buffer. Visible surfels are shaded using texture filtering, Phong illumination, and environment mapping using per-surfel normals. Several methods of image reconstruction, including supersampling, offer flexible speed-quality tradeoffs. Due to the simplicity of the operations, the surfel rendering pipeline is amenable for hardware implementation. Surfel objects offer complex shape, low rendering cost and high image quality, which makes them specifically suited for low-cost, real-time graphics, such as games.},
  isbn = {978-1-58113-208-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/GMW5TLLP/Pfister et al. - 2000 - Surfels surface elements as rendering primitives.pdf}
}

@inproceedings{pfulb_overcoming_2021,
  title = {Overcoming {{Catastrophic Forgetting}} with {{Gaussian Mixture Replay}}},
  booktitle = {2021 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Pf{\"u}lb, Benedikt and Gepperth, Alexander},
  year = {2021},
  month = jul,
  pages = {1--9},
  issn = {2161-4407},
  doi = {10.1109/IJCNN52387.2021.9533880},
  url = {https://ieeexplore.ieee.org/abstract/document/9533880},
  urldate = {2024-01-28},
  abstract = {We present Gaussian Mixture Replay (GMR), a rehearsal-based approach for continual learning (CL) based on Gaussian Mixture Models (GMM). CL approaches are intended to tackle the problem of catastrophic forgetting (CF), which occurs for Deep Neural Networks (DNNs) when sequentially training them on successive sub-tasks. GMR mitigates CF by generating samples from previous tasks and merging them with current training data. GMMs serve several purposes here: sample generation, density estimation (e.g., for detecting outliers or recognizing task boundaries) and providing a high-level feature representation for classification. GMR has several conceptual advantages over existing replay-based CL approaches. First of all, GMR achieves sample generation, classification and density estimation in a single network structure with strongly reduced memory requirements. Secondly, it can be trained at constant time complexity w.r.t. the number of sub-tasks, making it particularly suitable for life-long learning. Furthermore, GMR minimizes a differentiable loss function and seems to avoid mode collapse. In addition, task boundaries can be detected by applying GMM density estimation. Lastly, GMR does not require access to sub-tasks lying in the future for hyper-parameter tuning, allowing CL under real-world constraints. We evaluate GMR on multiple image datasets, which are divided into class-disjoint sub-tasks.},
  keywords = {Continual Learning,Estimation,Gaussian Mixture Models,Incremental Learning,Life-long Learning,Memory management,Merging,Neural networks,Pseudo-Rehearsal,Task analysis,Training,Training data},
  file = {/Users/kshitijgoel/Zotero/storage/H3JGIN8E/Pfülb and Gepperth - 2021 - Overcoming Catastrophic Forgetting with Gaussian M.pdf;/Users/kshitijgoel/Zotero/storage/CFF3ULU8/9533880.html}
}

@article{phillips-lander_mars_2021,
  title = {Mars {{Astrobiological Cave}} and {{Internal}} Habitability {{Explorer}} ({{MACIE}}): {{A New Frontiers Mission Concept}}},
  shorttitle = {Mars {{Astrobiological Cave}} and {{Internal}} Habitability {{Explorer}} ({{MACIE}})},
  author = {{Phillips-Lander}, Charity and {Agha-mohamamdi}, A. and Wynne, J. and Titus, T. and Chanover, N. and {Demirel-Floyd}, C. and Uckert, K. and Williams, K. and Wyrick, D. and Blank, J. and Boston, P. and Mitchell, K. and Kereszturi, A. and {Martin-Torres}, J. and Shkolyar, S. and Bardabelias, N. and Datta, S. and Retherford, K. and Sam, L. and Bhardwaj, A. and Fair{\'e}n, A. and Flannery, D. and Wiens, R.},
  year = {2021},
  month = mar,
  journal = {Bulletin of the AAS},
  volume = {53},
  number = {4},
  doi = {10.3847/25c2cfeb.cf124da3},
  url = {https://baas.aas.org/pub/2021n4i347},
  urldate = {2023-06-21},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DKYVQA53/Phillips-Lander et al. - 2021 - Mars Astrobiological Cave and Internal habitabilit.pdf}
}

@inproceedings{philomin_quasirandom_2000,
  title = {Quasi-{{Random Sampling}} for {{Condensation}}},
  booktitle = {Computer {{Vision}} --- {{ECCV}} 2000},
  author = {Philomin, Vasanth and Duraiswami, Ramani and Davis, Larry},
  editor = {Vernon, David},
  year = {2000},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {134--149},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45053-X_9},
  abstract = {The problem of tracking pedestrians from a moving car is a challenging one. The Condensation tracking algorithm is appealing for its generality and potential for real-time implementation. However, the conventional Condensation tracker is known to have difficulty with high-dimensional state spaces and unknown motion models. This paper presents an improved algorithm that addresses these problems by using a simplified motion model, and employing quasi-Monte Carlo techniques to efficiently sample the resulting tracking problem in the high-dimensional state space. For N sample points, these techniques achieve sampling errors of O(N-1), as opposed to O(N-1/2) for conventional Monte Carlo techniques. We illustrate the algorithm by tracking objects in both synthetic and real sequences, and show that it achieves reliable tracking and significant speed-ups over conventional Monte Carlo techniques.},
  isbn = {978-3-540-45053-5},
  langid = {english},
  keywords = {IEEE International Conf,Importance Sampling,Pedestrian Detection,Process Noise,Standard Deviation Error},
  file = {/Users/kshitijgoel/Zotero/storage/28N6EZFN/Philomin et al. - 2000 - Quasi-Random Sampling for Condensation.pdf}
}

@inproceedings{pisutsin_omnidronedet_2024,
  title = {Omnidrone-{{Det}}: {{Omnidirectional 3D Drone Detection}} in {{Flight}}},
  shorttitle = {Omnidrone-{{Det}}},
  booktitle = {2024 {{IEEE}} 20th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Pisutsin, Phumrapee and Xiao, Jiaping and Feroskhan, Mir},
  year = {2024},
  month = aug,
  pages = {2409--2414},
  issn = {2161-8089},
  doi = {10.1109/CASE59546.2024.10711367},
  url = {https://ieeexplore.ieee.org/document/10711367/?arnumber=10711367},
  urldate = {2024-12-16},
  abstract = {The widespread use of drones in applications like delivery, search-and-rescue, and warehouse management has intensified the need for advanced object detection in 3D space, which is crucial for collision avoidance and safe navigation. However, the structural constraints of drones, such as their limited weight and size, restrict the use of sophisticated sensors and processors, posing challenges for effective object detection and tracking within a wide field of view (FOV). Addressing these limitations, this paper introduces a flexible two-stage omnidirectional 3D object detection approach tailored for on-board processors. Specifically, fisheye cameras are utilized to capture omnidirectional images, which are then flattened with a rectification module. Our 3D drone detection system combines a YOLOv7-based drone detector, fine-tuned on a self-collected drone dataset, with a monocular depth estimation model and a supervised depth corrector module. By leveraging fisheye cameras, our system efficiently achieves 3D localization of drones in flight, providing a lightweight yet effective solution for both static and dynamic environments.},
  keywords = {Accuracy,Cameras,Detectors,Drones,Navigation,Object detection,Program processors,Search problems,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/JFL42C6D/Pisutsin et al. - 2024 - Omnidrone-Det Omnidirectional 3D Drone Detection in Flight.pdf;/Users/kshitijgoel/Zotero/storage/JH425BIQ/10711367.html}
}

@book{pitman_probability_1993,
  title = {Probability},
  author = {Pitman, Jim},
  year = {1993},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-4374-8},
  url = {http://link.springer.com/10.1007/978-1-4612-4374-8},
  urldate = {2025-06-02},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-94594-1 978-1-4612-4374-8},
  langid = {english},
  keywords = {Binomial distribution,Conditional probability,correlation,Poisson distribution,Random variable,standard deviation,Variance},
  file = {/Users/kshitijgoel/Zotero/storage/J64BHPFW/Pitman - 1993 - Probability.pdf}
}

@article{pito_solution_1999,
  title = {A Solution to the next Best View Problem for Automated Surface Acquisition},
  author = {Pito, R.},
  year = {1999},
  month = oct,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {21},
  number = {10},
  pages = {1016--1030},
  issn = {1939-3539},
  doi = {10.1109/34.799908},
  url = {https://ieeexplore.ieee.org/abstract/document/799908},
  urldate = {2024-06-10},
  abstract = {A solution to the "next best view" (NBV) problem for automated surface acquisition is presented. The NBV problem is to determine which areas of a scanner's viewing volume need to be scanned to sample all of the visible surfaces of an a priori unknown object and where to position/control the scanner to sample them. A method for determining the unscanned areas of the viewing volume is presented. In addition, a novel representation, positional space, is presented which facilitates a solution to the NBV problem by representing what must be and what can be scanned in a single data structure. The number of costly computations needed to determine if an area of the viewing volume would be occluded from some scanning position is decoupled from the number of positions considered for the NBV, thus reducing the computational cost of choosing one. An automated surface acquisition systems designed to scan all visible surfaces of an a priori unknown object is demonstrated on real objects.},
  keywords = {Automatic control,Computational efficiency,Computer graphics,Data structures,Image sensors,Optical imaging,Physics,Reverse engineering,Sampling methods,Solid modeling},
  file = {/Users/kshitijgoel/Zotero/storage/DUW4P2HH/Pito - 1999 - A solution to the next best view problem for automated surface acquisition.pdf;/Users/kshitijgoel/Zotero/storage/KP7XBDA9/799908.html}
}

@inproceedings{pivtoraiko_autonomous_2009,
  title = {Autonomous Robot Navigation Using Advanced Motion Primitives},
  booktitle = {2009 {{IEEE Aerospace}} Conference},
  author = {Pivtoraiko, Mihail and Nesnas, Issa A.D. and Kelly, Alonzo},
  year = {2009},
  month = mar,
  pages = {1--7},
  issn = {1095-323X},
  doi = {10.1109/AERO.2009.4839309},
  url = {https://ieeexplore.ieee.org/document/4839309},
  urldate = {2024-11-15},
  abstract = {We present an approach to efficient navigation of autonomous wheeled robots operating in cluttered natural environments. The approach builds upon a popular method of autonomous robot navigation, where desired robot motions are computed using local and global motion planners operating in tandem. A conventional approach to designing the local planner in this setting is to evaluate a fixed number of constant-curvature arc motions and pick one that is the best balance between the quality of obstacle avoidance and minimizing traversed path length to the goal (or a similar measure of operation cost). The presented approach proposes a different set of motion alternatives considered by the local planner. Important performance improvement is achieved by relaxing the assumption that motion alternatives are constant-curvature arcs. We first present a method to measure the quality of local planners in this setting. Further, we identify general techniques of designing improved sets of motion alternatives. By virtue of a minor modification, solely replacing the motions considered by the local planner, our approach offers a measurable performance improvement of dual-planner navigation systems.},
  keywords = {Aircraft navigation,Mars,Mobile robots,Motion measurement,Motion planning,Orbital robotics,Propulsion,Robot kinematics,Robot motion,Space exploration},
  file = {/Users/kshitijgoel/Zotero/storage/58BLNR4P/Pivtoraiko et al. - 2009 - Autonomous robot navigation using advanced motion primitives.pdf;/Users/kshitijgoel/Zotero/storage/Y5C3K2RC/4839309.html}
}

@inproceedings{pivtoraiko_differentially_2008,
  title = {Differentially Constrained Motion Replanning Using State Lattices with Graduated Fidelity},
  booktitle = {2008 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Pivtoraiko, Mihail and Kelly, Alonzo},
  year = {2008},
  month = sep,
  pages = {2611--2616},
  issn = {2153-0866},
  doi = {10.1109/IROS.2008.4651220},
  abstract = {This paper presents an approach to differentially constrained robot motion planning and efficient re-planning. Satisfaction of differential constraints is guaranteed by the state lattice, a search space which consists of motions that satisfy the constraints by construction. Any systematic replanning algorithm, e.g. D*, can be utilized to search the state lattice to find a motion plan that satisfies the differential constraints, and to repair it efficiently in the event of a change in the environment. Further efficiency is obtained by varying the fidelity of representation of the planning problem. High fidelity is utilized where it matters most, while it is lowered in the areas that do not affect the quality of the plan significantly. The paper presents a method to modify the fidelity between replans, thereby enabling dynamic flexibility of the search space, while maintaining its compatibility with replanning algorithms. The approach is especially suited for mobile robotics applications in unknown challenging environments. In this setting, we applied the planner successfully to the navigation of research prototype rovers in JPL Mars Yard.},
  keywords = {Conferences,Intelligent robots},
  file = {/Users/kshitijgoel/Zotero/storage/EWDMIAJF/Pivtoraiko and Kelly - 2008 - Differentially constrained motion replanning using.pdf}
}

@inproceedings{pivtoraiko_generating_2005,
  title = {Generating near Minimal Spanning Control Sets for Constrained Motion Planning in Discrete State Spaces},
  booktitle = {2005 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Pivtoraiko, M. and Kelly, A.},
  year = {2005},
  month = aug,
  pages = {3231--3237},
  issn = {2153-0866},
  doi = {10.1109/IROS.2005.1545046},
  abstract = {We propose a principled method to create a search space for constrained motion planning, which efficiently encodes only feasible motion plans. The space of possible paths is encoded implicitly in the connections between states, but only feasible and only local connections are allowed. Furthermore, we propose a systematic method to generate a near-minimal set of spatially distinct motion alternatives. This set of motion primitives preserves the connectivity of the representation while eliminating redundancy - leading to a very efficient structure for motion planning at the chosen resolution.},
  keywords = {Control systems,Kinematics,Lattices,Motion control,Orbital robotics,Road accidents,Sampling methods,Space exploration,State-space methods,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/TDQ58H4D/Pivtoraiko and Kelly - 2005 - Generating near minimal spanning control sets for .pdf}
}

@inproceedings{pivtoraiko_incremental_2013,
  title = {Incremental Micro-{{UAV}} Motion Replanning for Exploring Unknown Environments},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Pivtoraiko, Mihail and Mellinger, Daniel and Kumar, Vijay},
  year = {2013},
  month = may,
  pages = {2452--2458},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6630910},
  abstract = {This paper describes an approach to motion generation for quadrotor micro-UAV's navigating cluttered and partially known environments. We pursue a graph search method that, despite the high dimensionality of the problem, the complex dynamics of the system and the continuously changing environment model is capable of generating dynamically feasible motions in real-time. This is enabled by leveraging the differential flatness property of the system and by developing a structured search space based on state lattice motion primitives. We suggest a greedy algorithm to generate these primitives off-line automatically, given the robot's motion model. The process samples the reachability of the system and reduces it to a set of representative, canonical motions that are compatible with the state lattice structure, which guarantees that any incremental replanning algorithm is able to produce smooth dynamically feasible motion plans while reusing previous computation between replans. Simulated and physical experimental results demonstrate real-time replanning due to the inevitable and frequent world model updates during micro-UAV motion in partially known environments.},
  keywords = {Aerospace electronics,Planning,Robot sensing systems,Trajectory,Vehicle dynamics,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/ZKU9SC9Q/Pivtoraiko et al. - 2013 - Incremental micro-UAV motion replanning for explor.pdf;/Users/kshitijgoel/Zotero/storage/BT8VGNCC/stamp.html}
}

@inproceedings{pivtoraiko_kinodynamic_2011,
  title = {Kinodynamic Motion Planning with State Lattice Motion Primitives},
  booktitle = {2011 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Pivtoraiko, Mihail and Kelly, Alonzo},
  year = {2011},
  month = sep,
  pages = {2172--2179},
  issn = {2153-0866},
  doi = {10.1109/IROS.2011.6094900},
  abstract = {This paper presents a type of motion primitives that can be used for building efficient kinodynamic motion planners. The primitives are pre-computed to meet two objective: to capture the mobility constraints of the robot as well as possible and to establish a state sampling policy that is conductive to efficient search. The first objective allows encoding mobility constraints into primitives, thereby enabling fast unconstrained search to produce feasible solutions. The second objective enables high quality (lattice) sampling of state space, further speeding up exploration during search. We further discuss several novel results enabled by using such motion primitives for kinodynamic planning, including incremental search, efficient bi-directional search and incremental sampling.},
  keywords = {Aerospace electronics,Algorithm design and analysis,Bidirectional control,Lattices,Planning,Robots,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/DJ8SC4Q5/Pivtoraiko and Kelly - 2011 - Kinodynamic motion planning with state lattice mot.pdf;/Users/kshitijgoel/Zotero/storage/7HQUN48P/stamp.html}
}

@inproceedings{placed_fast_2021,
  title = {Fast {{Autonomous Robotic Exploration Using}} the {{Underlying Graph Structure}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Placed, Julio A. and Castellanos, Jose A.},
  year = {2021},
  month = sep,
  pages = {6672--6679},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/IROS51168.2021.9636148},
  url = {https://ieeexplore.ieee.org/document/9636148/},
  urldate = {2023-10-18},
  abstract = {In this work, we fully define the existing relationships between traditional optimality criteria and the connectivity of the underlying pose-graph in Active SLAM, characterizing, therefore, the connection between Graph Theory and the Theory Optimal Experimental Design. We validate the proposed relationships in 2D and 3D graph SLAM datasets, showing a remarkable relaxation of the computational load when using the graph structure. Furthermore, we present a novel Active SLAM framework which outperforms traditional methods by successfully leveraging the graphical facet of the problem so as to autonomously explore an unknown environment.},
  isbn = {978-1-6654-1714-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UYCX5T4W/Placed and Castellanos - 2021 - Fast Autonomous Robotic Exploration Using the Unde.pdf}
}

@article{placed_general_2023,
  title = {A {{General Relationship Between Optimality Criteria}} and {{Connectivity Indices}} for {{Active Graph-SLAM}}},
  author = {Placed, Julio A. and Castellanos, Jose A.},
  year = {2023},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {2},
  pages = {816--823},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2022.3233230},
  url = {https://ieeexplore.ieee.org/document/10003990/},
  urldate = {2023-10-18},
  abstract = {Quantifying uncertainty is a key stage in active simultaneous localization and mapping (SLAM), as it allows to identify the most informative actions to execute. However, dealing with full covariance or even Fisher information matrices (FIMs) is computationally heavy and easily becomes intractable for online systems. In this letter, we study the paradigm of active graph-SLAM formulated over the special Euclidean group SE(n), and propose a general relationship between the FIM of the system and the Laplacian matrix of the underlying pose-graph. This link makes possible to use graph connectivity indices as utility functions with optimality guarantees, since they approximate the well-known optimality criteria that stem from optimal design theory. Experimental validation demonstrates that the proposed method leads to equivalent decisions for active SLAM in a fraction of the time.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3JR7KNZW/Placed and Castellanos - 2023 - A General Relationship Between Optimality Criteria.pdf}
}

@article{placed_survey_2023,
  title = {A {{Survey}} on {{Active Simultaneous Localization}} and {{Mapping}}: {{State}} of the {{Art}} and {{New Frontiers}}},
  shorttitle = {A {{Survey}} on {{Active Simultaneous Localization}} and {{Mapping}}},
  author = {Placed, Julio A. and Strader, Jared and Carrillo, Henry and Atanasov, Nikolay and Indelman, Vadim and Carlone, Luca and Castellanos, Jos{\'e} A.},
  year = {2023},
  month = jun,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {3},
  pages = {1686--1705},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3248510},
  url = {https://ieeexplore.ieee.org/document/10075065/},
  urldate = {2024-02-10},
  abstract = {Active simultaneous localization and mapping (SLAM) is the problem of planning and controlling the motion of a robot to build the most accurate and complete model of the surrounding environment. Since the first foundational work in active perception appeared, more than three decades ago, this field has received increasing attention across different scientific communities. This has brought about many different approaches and formulations, and makes a review of the current trends necessary and extremely valuable for both new and experienced researchers. In this article, we survey the state of the art in active SLAM and take an in-depth look at the open challenges that still require attention to meet the needs of modern applications. After providing a historical perspective, we present a unified problem formulation and review the well-established modular solution scheme, which decouples the problem into three stages that identify, select, and execute potential navigation actions. We then analyze alternative approaches, including belief-space planning and deep reinforcement learning techniques, and review related work on multirobot coordination. This article concludes with a discussion of new research directions, addressing reproducible research, active spatial perception, and practical applications, among other topics.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/8FUIS7CX/Placed et al. - 2023 - A Survey on Active Simultaneous Localization and M.pdf}
}

@inproceedings{platt_belief_2010,
  title = {Belief Space Planning Assuming Maximum Likelihood Observations},
  booktitle = {Robotics: {{Science}} and {{Systems VI}}},
  author = {Platt, R. and Tedrake, R. and Kaelbling, L. and {Lozano-Perez}, T.},
  year = {2010},
  month = jun,
  volume = {06},
  url = {https://www.roboticsproceedings.org/rss06/p37.html},
  urldate = {2023-10-23},
  isbn = {978-0-262-51681-5},
  file = {/Users/kshitijgoel/Zotero/storage/YCQDAT2U/Platt et al. - 2010 - Belief space planning assuming maximum likelihood .pdf}
}

@article{pliska_safe_2024,
  title = {Towards {{Safe Mid-Air Drone Interception}}: {{Strategies}} for {{Tracking}} \& {{Capture}}},
  shorttitle = {Towards {{Safe Mid-Air Drone Interception}}},
  author = {Pliska, Michal and Vrba, Matou{\v s} and B{\'a}{\v c}a, Tom{\'a}{\v s} and Saska, Martin},
  year = {2024},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {10},
  pages = {8810--8817},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3451768},
  url = {https://ieeexplore.ieee.org/document/10659110/},
  urldate = {2025-06-27},
  abstract = {A unique approach for mid-air autonomous aerial interception of non-cooperating Uncrewed Aerial Vehicles by a flying robot equipped with a net is presented in this paper. A novel interception guidance method dubbed Fast Response Proportional Navigation (FRPN) is proposed, designed to catch agile maneuvering targets while relying on onboard state estimation and tracking. The proposed method is compared with state-of-the-art approaches in simulations using 100 different trajectories of the target with varying complexity comprising almost {\textbackslash}text14 {\textbackslash},{\textbackslash}texth of flight data, and Fast Response Proportional Navigation (FRPN) demonstrates the shortest response time and the highest number of interceptions, which are key parameters of agile interception. To enable a robust transfer from theory and simulation to a real-world implementation, we aim to avoid overfitting to specific assumptions about the target, and to tackle interception of a target following an unknown general trajectory. Furthermore, we identify several often overlooked problems related to tracking and estimation of the target's state that can have a significant influence on the overall performance of the system. We propose the use of a novel state estimation filter based on the Interacting Multiple Model filter and a new measurement model. Simulated experiments show that the proposed solution provides significant improvements in estimation accuracy over the commonly employed Kalman Filter approaches when considering general trajectories. Based on these results, we employ the proposed filtering and guidance methods to implement a complete autonomous interception system, which is thoroughly evaluated in realistic simulations and tested in real-world experiments with a maneuvering target going far beyond the performance of any state-of-the-art solution.},
  keywords = {Accuracy,Aerial systems: Perception and autonomy,Autonomous aerial vehicles,field robots,Navigation,reactive and sensor-based planning,State estimation,Target tracking,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/4VR8364Q/Pliska et al. - 2024 - Towards Safe Mid-Air Drone Interception Strategies for Tracking & Capture.pdf}
}

@article{popovic_informative_2020,
  title = {An Informative Path Planning Framework for {{UAV-based}} Terrain Monitoring},
  author = {Popovi{\'c}, Marija and {Vidal-Calleja}, Teresa and Hitz, Gregory and Chung, Jen Jen and Sa, Inkyu and Siegwart, Roland and Nieto, Juan},
  year = {2020},
  month = jul,
  journal = {Autonomous Robots},
  volume = {44},
  number = {6},
  pages = {889--911},
  issn = {1573-7527},
  doi = {10.1007/s10514-020-09903-2},
  url = {https://doi.org/10.1007/s10514-020-09903-2},
  urldate = {2023-04-11},
  abstract = {Unmanned aerial vehicles represent a new frontier in a wide range of monitoring and research applications. To fully leverage their potential, a key challenge is planning missions for efficient data acquisition in complex environments. To address this issue, this article introduces a general informative path planning framework for monitoring scenarios using an aerial robot, focusing on problems in which the value of sensor information is unevenly distributed in a target area and unknown a priori. The approach is capable of learning and focusing on regions of interest via adaptation to map either discrete or continuous variables on the terrain using variable-resolution data received from probabilistic sensors. During a mission, the terrain maps built online are used to plan information-rich trajectories in continuous 3-D space by optimizing initial solutions obtained by a coarse grid search. Extensive simulations show that our approach is more efficient than existing methods. We also demonstrate its real-time application on a photorealistic mapping scenario using a publicly available dataset and a proof of concept for an agricultural monitoring task.},
  langid = {english},
  keywords = {Aerial robotics,Environmental monitoring,Informative path planning,Remote sensing},
  file = {/Users/kshitijgoel/Zotero/storage/VIWR637V/Popović et al. - 2020 - An informative path planning framework for UAV-bas.pdf}
}

@inproceedings{poppinga_fast_2008,
  title = {Fast Plane Detection and Polygonalization in Noisy {{3D}} Range Images},
  booktitle = {2008 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Poppinga, Jann and Vaskevicius, Narunas and Birk, Andreas and Pathak, Kaustubh},
  year = {2008},
  month = sep,
  pages = {3378--3383},
  issn = {2153-0866},
  doi = {10.1109/IROS.2008.4650729},
  abstract = {A fast but nevertheless accurate approach for surface extraction from noisy 3D point clouds is presented. It consists of two parts, namely a plane fitting and a polygonalization step. Both exploit the sequential nature of 3D data acquisition on mobile robots in form of range images. For the plane fitting, this is used to revise the standard mathematical formulation to an incremental version, which allows a linear computation. For the polygonalization, the neighborhood relation in range images is exploited. Experiments are presented using a time-of-flight range camera in form of a Swissranger SR-3000. Results include lab scenes as well as data from two runs of the rescue robot league at the RoboCup German Open 2007 with 1,414, respectively 2,343 sensor snapshots. The 36ldr106, respectively 59ldr106 points from the two point clouds are reduced to about 14ldr103, respectively 23ldr103 planes with only about 0.2 sec of total computation time per snapshot while the robot moves along. Uncertainty analysis of the computed plane parameters is presented as well.},
  keywords = {Cameras,Distance measurement,Fitting,Meteorology,Robot sensing systems,Robots,Three dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/LD7HKGJW/Poppinga et al. - 2008 - Fast plane detection and polygonalization in noisy.pdf;/Users/kshitijgoel/Zotero/storage/45BFLI3R/4650729.html}
}

@article{porta_active_2005,
  title = {Active {{Appearance-Based Robot Localization Using Stereo Vision}}},
  author = {Porta, J.M. and Verbeek, J.J. and Kr{\"o}se, B.J.A.},
  year = {2005},
  month = jan,
  journal = {Autonomous Robots},
  volume = {18},
  number = {1},
  pages = {59--80},
  issn = {1573-7527},
  doi = {10.1023/B:AURO.0000047287.00119.b6},
  url = {https://doi.org/10.1023/B:AURO.0000047287.00119.b6},
  urldate = {2024-06-13},
  abstract = {A vision-based robot localization system must be robust: able to keep track of the position of the robot at any time even if illumination conditions change and, in the extreme case of a failure, able to efficiently recover the correct position of the robot. With this objective in mind, we enhance the existing appearance-based robot localization framework in two directions by exploiting the use of a stereo camera mounted on a pan-and-tilt device. First, we move from the classical passive appearance-based localization framework to an active one where the robot sometimes executes actions with the only purpose of gaining information about its location in the environment. Along this line, we introduce an entropy-based criterion for action selection that can be efficiently evaluated in our probabilistic localization system. The execution of the actions selected using this criterion allows the robot to quickly find out its position in case it gets lost. Secondly, we introduce the use of depth maps obtained with the stereo cameras. The information provided by depth maps is less sensitive to changes of illumination than that provided by plain images. The main drawback of depth maps is that they include missing values: points for which it is not possible to reliably determine depth information. The presence of missing values makes Principal Component Analysis (the standard method used to compress images in the appearance-based framework) unfeasible. We describe a novel Expectation-Maximization algorithm to determine the principal components of a data set including missing values and we apply it to depth maps. The experiments we present show that the combination of the active localization with the use of depth maps gives an efficient and robust appearance-based robot localization system.},
  langid = {english},
  keywords = {active vision,appearance-based modeling,depth maps,localization,stereo vision},
  file = {/Users/kshitijgoel/Zotero/storage/24EICI28/Porta et al. - 2005 - Active Appearance-Based Robot Localization Using Stereo Vision.pdf}
}

@article{posner_epsilon_1971,
  title = {Epsilon {{Entropy}} and {{Data Compression}}},
  author = {Posner, Edward C. and Rodemich, Eugene R.},
  year = {1971},
  journal = {The Annals of Mathematical Statistics},
  volume = {42},
  number = {6},
  eprint = {2240137},
  eprinttype = {jstor},
  pages = {2079--2125},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  url = {https://www.jstor.org/stable/2240137},
  urldate = {2024-04-25},
  abstract = {This article studies efficient data transmission, or "data compression", from the standpoint of the theory of epsilon entropy. The notion of the entropy of a "data source" is defined. This quantity gives a precise measure of the amount of channel capacity necessary to describe a data source to within a given fidelity, epsilon, with probability one, when each separate "experiment" must be transmitted without storage from experiment to experiment. We also define the absolute epsilon entropy of a source, which is the amount of capacity needed when storage of experiments is allowed before transmission. The absolute epsilon entropy is shown to be equal to Shannon's rate distortion function evaluated for zero distortion, when suitable identifications are made. The main result is that the absolute epsilon entropy and the epsilon entropy have ratio close to one if either is large. Thus, very little can be saved by storing the results of independent experiments before transmission.},
  file = {/Users/kshitijgoel/Zotero/storage/WY4EX2LM/Posner and Rodemich - 1971 - Epsilon Entropy and Data Compression.pdf}
}

@misc{prabhat_optimal_2024,
  title = {Optimal {{State Estimation}} in the {{Presence}} of {{Non-Gaussian Uncertainty}} via {{Wasserstein Distance Minimization}}},
  author = {Prabhat, Himanshu and Bhattacharya, Raktim},
  year = {2024},
  month = mar,
  number = {arXiv:2403.13828},
  eprint = {2403.13828},
  primaryclass = {cs, eess, math, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.13828},
  urldate = {2024-06-13},
  abstract = {This paper presents a novel distributionagnostic Wasserstein distance-based estimation framework. The goal is to determine an optimal map combining prior estimate with measurement likelihood such that posterior estimation error optimally reaches the Dirac delta distribution with minimal effort. The Wasserstein metric is used to quantify the effort of transporting from one distribution to another. We hypothesize that minimizing the Wasserstein distance between the posterior error and the Dirac delta distribution results in optimal information fusion and posterior state uncertainty. Framework validation is demonstrated by the successful recovery of the classical Kalman filter for linear systems with Gaussian uncertainties. Notably, the proposed Wasserstein filter does not rely on particle representation of uncertainty. Furthermore, the classical result for the Gaussian Sum Filter (GSF) is retrieved from the Wasserstein framework. This approach analytically exhibits the suboptimality of GSF and enables the use of nonlinear optimization techniques to enhance the accuracy of the Gaussian sum estimator.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Electrical Engineering and Systems Science - Systems and Control,Mathematics - Statistics Theory},
  file = {/Users/kshitijgoel/Zotero/storage/XEFPF44S/Prabhat and Bhattacharya - 2024 - Optimal State Estimation in the Presence of Non-Gaussian Uncertainty via Wasserstein Distance Minimi.pdf}
}

@article{pragr_autonomous_2023,
  title = {Autonomous Exploration with Online Learning of Traversable yet Visually Rigid Obstacles},
  author = {Pr{\'a}gr, Milo{\v s} and Bayer, Jan and Faigl, Jan},
  year = {2023},
  month = feb,
  journal = {Autonomous Robots},
  volume = {47},
  number = {2},
  pages = {161--180},
  issn = {1573-7527},
  doi = {10.1007/s10514-022-10075-4},
  url = {https://doi.org/10.1007/s10514-022-10075-4},
  urldate = {2023-03-10},
  abstract = {This paper concerns online learning of terrain properties combining haptic perception with exteroceptive sensing to reason about forces needed to pass through terrains that visually appear as untraversable obstacles. Terrain learning is studied within the context of autonomous exploration. We propose predicting the traversability of potentially obstructing terrains by active perception to establish a connection between the observed geometric environment model and deliberately sampled forces to pass through the terrain using a haptic sensor that probes the terrain in front of the robot. The developed solution uses a Gaussian Process regressor in online learning and force prediction. The robot is navigated by following the information gain to improve traversability and spatial models. The proposed approach has been experimentally verified in fully autonomous exploration with a multi-legged walking robot. The robot is navigated through visually looking obstacles and explores ``hidden'' areas while following the expected information gain to explore the terrain properties of the mission area.},
  langid = {english},
  keywords = {Active perception,Exploration,Gaussian Process regression,Haptic sensing,Mobile robot},
  file = {/Users/kshitijgoel/Zotero/storage/BXBKSJ2W/Prágr et al. - 2023 - Autonomous exploration with online learning of tra.pdf}
}

@book{principe_information_2010,
  title = {Information Theoretic Learning: {{Renyi}}'s Entropy and Kernel Perspectives},
  shorttitle = {Information Theoretic Learning},
  author = {Principe, J. C.},
  year = {2010},
  series = {Information Science and Statistics},
  publisher = {Springer},
  address = {New York},
  url = {https://link.springer.com/book/10.1007/978-1-4419-1570-2},
  isbn = {978-1-4419-1569-6},
  keywords = {Algorithms,Information science and statistics,Machine learning,Mathematical statistics},
  file = {/Users/kshitijgoel/Zotero/storage/WHZHLWF6/Principe - 2010 - Information theoretic learning Renyi's entropy an.pdf}
}

@inproceedings{proenca_optimizing_2022,
  title = {Optimizing {{Terrain Mapping}} and {{Landing Site Detection}} for {{Autonomous UAVs}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Proen{\c c}a, Pedro F. and Delaune, Jeff and {Rol} and {Brockers}},
  year = {2022},
  month = may,
  pages = {9668--9674},
  doi = {10.1109/ICRA46639.2022.9811789},
  url = {https://ieeexplore.ieee.org/abstract/document/9811789},
  urldate = {2024-02-09},
  abstract = {The next generation of Mars rotorcrafts requires on-board autonomous hazard avoidance landing. To this end, this work proposes a system that performs continuous multi-resolution height map reconstruction and safe landing spot detection. Structure-from-Motion measurements are aggregated in a pyramid structure using a novel Optimal Mixture of Gaus-sians formulation that provides a comprehensive uncertainty model. Our multiresolution pyramid is built more efficiently and accurately than past work by decoupling pyramid filling from the measurement updates of different resolutions. To detect the safest landing location, after an optimized hazard segmentation, we use a mean shift algorithm on multiple distance transform peaks to account for terrain roughness and uncertainty. The benefits of our contributions are evaluated on real and synthetic flight data.},
  keywords = {Automation,Filling,Hazards,Measurement uncertainty,Terrain mapping,Transforms,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/FHBLKEJY/Proença et al. - 2022 - Optimizing Terrain Mapping and Landing Site Detect.pdf;/Users/kshitijgoel/Zotero/storage/ERVN5F7S/9811789.html}
}

@article{proenca_probabilistic_2018,
  title = {Probabilistic {{RGB-D}} Odometry Based on Points, Lines and Planes under Depth Uncertainty},
  author = {Proen{\c c}a, Pedro F. and Gao, Yang},
  year = {2018},
  month = jun,
  journal = {Robotics and Autonomous Systems},
  volume = {104},
  pages = {25--39},
  issn = {09218890},
  doi = {10.1016/j.robot.2018.02.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889017303378},
  urldate = {2024-06-02},
  abstract = {This work proposes a robust visual odometry method for structured environments that combines point features with line and plane segments, extracted through an RGB-D camera. Noisy depth maps are processed by a probabilistic depth fusion framework based on Mixtures of Gaussians to denoise and derive the depth uncertainty, which is then propagated throughout the visual odometry pipeline. Probabilistic 3D plane and line fitting solutions are used to model the uncertainties of the feature parameters and pose is estimated by combining the three types of primitives based on their uncertainties.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6KJ8HQ8Q/Proença and Gao - 2018 - Probabilistic RGB-D odometry based on points, lines and planes under depth uncertainty.pdf}
}

@misc{qi_projecting_2024,
  title = {Projecting {{Gaussian Ellipsoids While Avoiding Affine Projection Approximation}}},
  author = {Qi, Han and Cai, Tao and Han, Xiyue},
  year = {2024},
  month = nov,
  number = {arXiv:2411.07579},
  eprint = {2411.07579},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2411.07579},
  urldate = {2024-11-13},
  abstract = {Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its real-time rendering speed and state-of-the-art rendering quality. However, during the rendering process, the use of the Jacobian of the affine approximation of the projection transformation leads to inevitable errors, resulting in blurriness, artifacts and a lack of scene consistency in the final rendered images. To address this issue, we introduce an ellipsoid-based projection method to calculate the projection of Gaussian ellipsoid on the image plane, witch is the primitive of 3D Gaussian Splatting. As our proposed ellipsoid-based projection method cannot handle Gaussian ellipsoids with camera origins inside them or parts lying below \$z=0\$ plane in the camera space, we designed a pre-filtering strategy. Experiments over multiple widely adopted benchmark datasets show that using our ellipsoid-based projection method can enhance the rendering quality of 3D Gaussian Splatting and its extensions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/D9JZGYVV/Qi et al. - 2024 - Projecting Gaussian Ellipsoids While Avoiding Affine Projection Approximation.pdf;/Users/kshitijgoel/Zotero/storage/YY6ZEECX/2411.html}
}

@inproceedings{qian_pocd_2022,
  title = {{{POCD}}: {{Probabilistic Object-Level Change Detection}} and {{Volumetric Mapping}} in {{Semi-Static Scenes}}},
  shorttitle = {{{POCD}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVIII}}},
  author = {Qian, Jingxing and Chatrath, Veronica and Yang, Jun and Servos, James and Schoellig, Angela P. and Waslander, Steven L.},
  year = {2022},
  month = jun,
  volume = {18},
  url = {http://www.roboticsproceedings.org/rss18/p013.html},
  urldate = {2022-07-27},
  isbn = {978-0-9923747-8-5},
  file = {/Users/kshitijgoel/Zotero/storage/GXVRQYCG/Qian et al. - 2022 - POCD Probabilistic Object-Level Change Detection .pdf;/Users/kshitijgoel/Zotero/storage/N44L8A8P/p013.html}
}

@inproceedings{qin_langsplat_2024,
  title = {{{LangSplat}}: {{3D Language Gaussian Splatting}}},
  shorttitle = {{{LangSplat}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Qin, Minghan and Li, Wanhua and Zhou, Jiawei and Wang, Haoqian and Pfister, Hanspeter},
  year = {2024},
  pages = {20051--20060},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Qin_LangSplat_3D_Language_Gaussian_Splatting_CVPR_2024_paper.html},
  urldate = {2024-12-01},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4MW9TSNJ/Qin et al. - 2024 - LangSplat 3D Language Gaussian Splatting.pdf}
}

@inproceedings{qin_robust_2017,
  title = {Robust Initialization of Monocular Visual-Inertial Estimation on Aerial Robots},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Qin, Tong and Shen, Shaojie},
  year = {2017},
  month = sep,
  pages = {4225--4232},
  issn = {2153-0866},
  doi = {10.1109/IROS.2017.8206284},
  abstract = {In this paper, we propose a robust on-the-fly estimator initialization algorithm to provide high-quality initial states for monocular visual-inertial systems (VINS). Due to the non-linearity of VINS, a poor initialization can severely impact the performance of either filtering-based or graph-based methods. Our approach starts with a vision-only structure from motion (SfM) to build the up-to-scale structure of camera poses and feature positions. By loosely aligning this structure with pre-integrated IMU measurements, our approach recovers the metric scale, velocity, gravity vector, and gyroscope bias, which are treated as initial values to bootstrap the nonlinear tightly-coupled optimization framework. We highlight that our approach can perform on-the-fly initialization in various scenarios without using any prior information about system states and movement. The performance of the proposed approach is verified through the public UAV dataset and real-time onboard experiment. We make our implementation open source, which is the initialization part integrated in the VINS-Mono1.},
  keywords = {Acceleration,Cameras,Gravity,Gyroscopes,Velocity measurement,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/2E6CIL5Z/Qin and Shen - 2017 - Robust initialization of monocular visual-inertial.pdf;/Users/kshitijgoel/Zotero/storage/EJTL3Q2J/8206284.html}
}

@article{qin_vinsmono_2018,
  title = {{{VINS-Mono}}: {{A Robust}} and {{Versatile Monocular Visual-Inertial State Estimator}}},
  shorttitle = {{{VINS-Mono}}},
  author = {Qin, Tong and Li, Peiliang and Shen, Shaojie},
  year = {2018},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {34},
  number = {4},
  pages = {1004--1020},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2853729},
  url = {https://ieeexplore.ieee.org/document/8421746},
  urldate = {2024-11-15},
  abstract = {One camera and one low-cost inertial measurement unit (IMU) form a monocular visual-inertial system (VINS), which is the minimum sensor suite (in size, weight, and power) for the metric six degrees-of-freedom (DOF) state estimation. In this paper, we present VINS-Mono: a robust and versatile monocular visual-inertial state estimator. Our approach starts with a robust procedure for estimator initialization. A tightly coupled, nonlinear optimization-based method is used to obtain highly accurate visual-inertial odometry by fusing preintegrated IMU measurements and feature observations. A loop detection module, in combination with our tightly coupled formulation, enables relocalization with minimum computation. We additionally perform 4-DOF pose graph optimization to enforce the global consistency. Furthermore, the proposed system can reuse a map by saving and loading it in an efficient way. The current and previous maps can be merged together by the global pose graph optimization. We validate the performance of our system on public datasets and real-world experiments and compare against other state-of-the-art algorithms. We also perform an onboard closed-loop autonomous flight on the microaerial-vehicle platform and port the algorithm to an iOS-based demonstration. We highlight that the proposed work is a reliable, complete, and versatile system that is applicable for different applications that require high accuracy in localization. We open source our implementations for both PCs (https://github.com/HKUST-Aerial-Robotics/VINS-Mono) and iOS mobile devices ( https://github.com/HKUST-Aerial-Robotics/VINS-Mobile).},
  keywords = {Cameras,Feature extraction,Monocular visual-inertial systems (VINSs),Optimization,Robot sensing systems,Robustness,sensor fusion,simultaneous localization and mapping,state estimation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/8EHWA8M4/Qin et al. - 2018 - VINS-Mono A Robust and Versatile Monocular Visual-Inertial State Estimator.pdf}
}

@inproceedings{qiu_local_2015,
  title = {Local {{Adaptive}} and {{Incremental Gaussian Mixture}} for {{Online Density Estimation}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Qiu, Tianyu and Shen, Furao and Zhao, Jinxi},
  editor = {Cao, Tru and Lim, Ee-Peng and Zhou, Zhi-Hua and Ho, Tu-Bao and Cheung, David and Motoda, Hiroshi},
  year = {2015},
  pages = {418--428},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-18038-0_33},
  abstract = {In this paper, we propose an incremental and local adaptive gaussian mixture for online density estimation (LAIM). Using a similarity threshold based criterion, the method is able to allocate components incrementally to accommodate novel data points without affecting previously learned components. A local adaptive learning strategy is presented for estimating density with complex structure in an online way. We also adopt a denoising scheme to make the algorithm more robust to noise. We compared the LAIM to the state-of-art methods for density estimation in both artificial and real data sets, the results show that our method outperforms the compared online counterpart and produces comparable results to the compared batch algorithms.},
  isbn = {978-3-319-18038-0},
  langid = {english},
  keywords = {Gaussian mixture,Incremental learning,Local adaptive,Online density estimation},
  file = {/Users/kshitijgoel/Zotero/storage/D5LHP2R7/Qiu et al. - 2015 - Local Adaptive and Incremental Gaussian Mixture for Online Density Estimation.pdf}
}

@inproceedings{quan_evaplanner_2021,
  title = {{{EVA-Planner}}: {{Environmental Adaptive Quadrotor Planning}}},
  shorttitle = {{{EVA-Planner}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Quan, Lun and Zhang, Zhiwei and Zhong, Xingguang and Xu, Chao and Gao, Fei},
  year = {2021},
  month = may,
  pages = {398--404},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561759},
  url = {https://ieeexplore.ieee.org/document/9561759},
  urldate = {2024-11-15},
  abstract = {The quadrotor is popularly used in challenging environments due to its superior agility and flexibility. In these scenarios, trajectory planning plays a vital role in generating safe motions to avoid obstacles while ensuring flight smoothness. Although many works on quadrotor planning have been proposed, a research gap exists in incorporating self-adaptation into a planning framework to enable a drone to automatically fly slower in denser environments and increase its speed in a safer area. In this paper, we propose an environmental adaptive planner to adjust the flight aggressiveness effectively based on the obstacle distribution and quadrotor state. Firstly, we design an environmental adaptive safety aware method to assign the priority of the surrounding obstacles according to the environmental risk level and instantaneous motion tendency. Then, we apply it into a multi-layered model predictive contouring control (Multi-MPCC) framework to generate adaptive, safe, and dynamical feasible local trajectories. Extensive simulations and real-world experiments verify the efficiency and robustness of our planning framework. Benchmark comparison also shows superior performances of our method with another advanced environmental adaptive planning algorithm. Moreover, we release our planning framework as open-source ros-packages1 .},
  keywords = {Adaptation models,Heuristic algorithms,Planning,Prediction algorithms,Predictive models,Robustness,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/Z2235HJC/Quan et al. - 2021 - EVA-Planner Environmental Adaptive Quadrotor Planning.pdf;/Users/kshitijgoel/Zotero/storage/KX84RZK9/9561759.html}
}

@article{quan_robust_2023,
  title = {Robust and {{Efficient Trajectory Planning}} for {{Formation Flight}} in {{Dense Environments}}},
  author = {Quan, Lun and Yin, Longji and Zhang, Tingrui and Wang, Mingyang and Wang, Ruilin and Zhong, Sheng and Zhou, Xin and Cao, Yanjun and Xu, Chao and Gao, Fei},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3301295},
  abstract = {Formation flight has a vast potential for aerial robot swarms in various applications. However, the existing methods lack the capability to achieve fully autonomous large-scale formation flight in dense environments. To bridge the gap, we present a complete formation flight system that effectively integrates real-world constraints into aerial formation navigation. This article proposes a differentiable graph-based metric to quantify the overall similarity error between formations. This metric is invariant to rotation, translation, and scaling, providing more freedom for formation coordination. We design a distributed trajectory optimization framework that considers formation similarity, obstacle avoidance, and dynamic feasibility. The optimization is decoupled to make large-scale formation flights computationally feasible. To improve the elasticity of formation navigation in highly constrained scenes, we present a swarm reorganization method that adaptively adjusts the formation parameters and task assignments by generating local navigation goals. A novel swarm agreement strategy called global-remap-local-replan and a formation-level path planner is proposed in this article to coordinate the global planning and local trajectory optimizations.To validate the proposed method, we design comprehensive benchmarks and simulations with other cutting-edge works in terms of adaptability, predictability, elasticity, resilience, and efficiency. Finally, integrated with palm-sized swarm platforms with onboard computers and sensors, the proposed method demonstrates its efficiency and robustness by achieving the largest scale formation flight in dense outdoor environments.},
  keywords = {Aerial swarms,Collision avoidance,distributed trajectory optimization,formation flight,motion planning,Navigation,obstacle avoidance,Optimization,Robots,Shape,Task analysis,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/DXDWT38S/Quan et al. - 2023 - Robust and Efficient Trajectory Planning for Forma.pdf;/Users/kshitijgoel/Zotero/storage/IFBU2H5T/10219410.html}
}

@inproceedings{radford_learning_2021,
  title = {Learning {{Transferable Visual Models From Natural Language Supervision}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  year = {2021},
  month = jul,
  pages = {8748--8763},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/radford21a.html},
  urldate = {2024-12-19},
  abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6CDGMHCV/Radford et al. - 2021 - Learning Transferable Visual Models From Natural Language Supervision.pdf;/Users/kshitijgoel/Zotero/storage/WLIW6XWE/Radford et al. - 2021 - Learning Transferable Visual Models From Natural Language Supervision.pdf}
}

@inproceedings{raghunathan_learning_2017,
  title = {Learning {{Mixture}} of {{Gaussians}} with {{Streaming Data}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Raghunathan, Aditi and Jain, Prateek and Krishnawamy, Ravishankar},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2017/hash/f24ad6f72d6cc4cb51464f2b29ab69d3-Abstract.html},
  urldate = {2024-12-19},
  file = {/Users/kshitijgoel/Zotero/storage/C8AGG66D/Raghunathan et al. - 2017 - Learning Mixture of Gaussians with Streaming Data.pdf}
}

@article{rajwade_image_2013,
  title = {Image {{Denoising Using}} the {{Higher Order Singular Value Decomposition}}},
  author = {Rajwade, Ajit and Rangarajan, Anand and Banerjee, Arunava},
  year = {2013},
  month = apr,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {4},
  pages = {849--862},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2012.140},
  url = {https://ieeexplore.ieee.org/document/6226423/?arnumber=6226423},
  urldate = {2024-07-25},
  abstract = {In this paper, we propose a very simple and elegant patch-based, machine learning technique for image denoising using the higher order singular value decomposition (HOSVD). The technique simply groups together similar patches from a noisy image (with similarity defined by a statistically motivated criterion) into a 3D stack, computes the HOSVD coefficients of this stack, manipulates these coefficients by hard thresholding, and inverts the HOSVD transform to produce the final filtered image. Our technique chooses all required parameters in a principled way, relating them to the noise model. We also discuss our motivation for adopting the HOSVD as an appropriate transform for image denoising. We experimentally demonstrate the excellent performance of the technique on grayscale as well as color images. On color images, our method produces state-of-the-art results, outperforming other color image denoising algorithms at moderately high noise levels. A criterion for optimal patch-size selection and noise variance estimation from the residual images (after denoising) is also presented.},
  keywords = {coefficient thresholding,higher order singular value decomposition (HOSVD),Image denoising,learning orthonormal bases,Noise measurement,Noise reduction,patch similarity,PSNR,Singular value decomposition,singular value decomposition (SVD),Transforms},
  file = {/Users/kshitijgoel/Zotero/storage/ALNHDE4M/Rajwade et al. - 2013 - Image Denoising Using the Higher Order Singular Value Decomposition.pdf;/Users/kshitijgoel/Zotero/storage/SWTTPMAW/6226423.html}
}

@phdthesis{rajwade_probabilistic_2010,
  title = {Probabilistic Approaches to Image Registration and Denoising},
  author = {Rajwade, Ajit},
  year = {2010},
  address = {United States -- Florida},
  url = {https://www.proquest.com/docview/920672180/abstract/5B2F3D2D015B45B1PQ/1},
  urldate = {2024-07-25},
  abstract = {We present probabilistically driven approaches to two major applications in computer vision and image processing: image alignment (registration) and filtering of intensity values corrupted by noise. Some existing methods for these applications require the estimation of the probability density of the intensity values defined on the image domain. Most of the contemporary density estimation techniques employ different types of kernel functions for smoothing the estimated density values. These kernels are unrelated to the structure or geometry of the image. The present work chooses to depart from this conventional approach to one which seeks to approximate the image as a continuous or piecewise continuous function of the spatial coordinates, and subsequently expresses the probability density in terms of some key geometric properties of the image, such as its gradients and iso-intensity level sets. This framework, which regards an image as a signal as opposed to a bunch of samples, is then extended to the case of joint probability densities between two or more images and for different domains (2D and 3D). A biased density estimate that expressly favors the higher gradient regions of the image is also presented. These techniques for probability density estimation are used (1) for the task of affine registration of images drawn from different sensing modalities, and (2) to build neighborhood filters in the well-known mean shift framework, for the denoising of corrupted gray-scale and color images, chromaticity fields and gray-scale video. Using our new density estimators, we demonstrate improvement in the performance of these applications. A new approach for the estimation of the probability density of spherical data is also presented, taking into account the fact that the source of such data are commonly known or assumed to be Euclidean, particularly within the field of image analysis. We also develop two patch-based image denoising algorithms that revisit the old patch-based singular value decomposition (SVD) technique proposed in the seventies. Noise does not affect only the singular values of an image patch, but also severely affects its SVD bases leading to poor quality denoising if those bases are used. With this in mind, we provide motivation for manipulating the SVD bases of the image patches for improving denoising performance. To this end, we develop a probabilistic non-local framework which learns spatially adaptive orthonormal bases that are derived by exploiting the similarity between patches from different regions of an image. These bases act as a common SVD for the group of patches similar to any reference patch in the image. The reference image patches are then filtered by projection onto these learned bases, manipulation of the transform coefficients and inversion of the transform. We present or use principled criteria for the notion of similarity between patches under noise and manipulation of the coefficients, assuming a fixed known noise model. The several experimental results reported show that our method is simple and efficient, it yields excellent performance as measured by standard image quality metrics, and has principled parameter settings driven by statistical properties of the natural images and the assumed noise models. We term this technique the non-local SVD (NL-SVD) and extend it to produce a second, improved algorithm based upon the higher order singular value decomposition (HOSVD). The HOSVD-based technique filters similar patches jointly and produces denoising results that are better than most existing popular methods and very close to the state of the art technique in the field of image denoising.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9781267146946},
  langid = {english},
  school = {University of Florida},
  keywords = {Applied mathematics,Applied sciences,Computer engineering,Computer science,Image denoising,Image registration,Machine learning,Probability density estimation,Transform bases},
  file = {/Users/kshitijgoel/Zotero/storage/6QSKUSP8/Rajwade - Probabilistic approaches to image registration and denoising.pdf}
}

@misc{ramakrishnan_does_2024,
  title = {Does {{Spatial Cognition Emerge}} in {{Frontier Models}}?},
  author = {Ramakrishnan, Santhosh Kumar and Wijmans, Erik and Kraehenbuehl, Philipp and Koltun, Vladlen},
  year = {2024},
  month = oct,
  number = {arXiv:2410.06468},
  eprint = {2410.06468},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.06468},
  urldate = {2024-10-13},
  abstract = {Not yet. We present SPACE, a benchmark that systematically evaluates spatial cognition in frontier models. Our benchmark builds on decades of research in cognitive science. It evaluates large-scale mapping abilities that are brought to bear when an organism traverses physical environments, smaller-scale reasoning about object shapes and layouts, and cognitive infrastructure such as spatial attention and memory. For many tasks, we instantiate parallel presentations via text and images, allowing us to benchmark both large language models and large multimodal models. Results suggest that contemporary frontier models fall short of the spatial intelligence of animals, performing near chance level on a number of classic tests of animal cognition.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/GY24RQQ9/Ramakrishnan et al. - 2024 - Does Spatial Cognition Emerge in Frontier Models.pdf;/Users/kshitijgoel/Zotero/storage/HW9SJLRJ/2410.html}
}

@inproceedings{ramesh_picture_2023,
  title = {A {{Picture}} of the {{Space}} of {{Typical Learnable Tasks}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Ramesh, Rahul and Mao, Jialin and Griniasty, Itay and Yang, Rubing and Teoh, Han Kheng and Transtrum, Mark and Sethna, James and Chaudhari, Pratik},
  year = {2023},
  month = jul,
  pages = {28680--28700},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/ramesh23a.html},
  urldate = {2023-07-24},
  abstract = {We develop information geometric techniques to understand the representations learned by deep networks when they are trained on different tasks using supervised, meta-, semi-supervised and contrastive learning. We shed light on the following phenomena that relate to the structure of the space of tasks: (1) the manifold of probabilistic models trained on different tasks using different representation learning methods is effectively low-dimensional; (2) supervised learning on one task results in a surprising amount of progress even on seemingly dissimilar tasks; progress on other tasks is larger if the training task has diverse classes; (3) the structure of the space of tasks indicated by our analysis is consistent with parts of the Wordnet phylogenetic tree; (4) episodic meta-learning algorithms and supervised learning traverse different trajectories during training but they fit similar models eventually; (5) contrastive and semi-supervised learning methods traverse trajectories similar to those of supervised learning. We use classification tasks constructed from the CIFAR-10 and Imagenet datasets to study these phenomena. Code is available at https://github.com/grasp-lyrl/picture\_of\_space\_of\_tasks.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SWN9RWAI/Ramesh et al. - 2023 - A Picture of the Space of Typical Learnable Tasks.pdf}
}

@article{ramkumar_codes_2022,
  title = {Codes for {{Distributed Storage}}},
  author = {Ramkumar, Vinayak and Balaji, S. B. and Sasidharan, Birenjith and Vajha, Myna and Krishnan, M. Nikhil and Kumar, P. Vijay},
  year = {2022},
  month = may,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {19},
  number = {4},
  pages = {547--813},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000115},
  url = {https://www.nowpublishers.com/article/Details/CIT-115},
  urldate = {2024-04-29},
  abstract = {Codes for Distributed Storage},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/WGYQJJX6/Ramkumar et al. - 2022 - Codes for Distributed Storage.pdf}
}

@article{ramos_hilbert_2016,
  title = {Hilbert Maps: {{Scalable}} Continuous Occupancy Mapping with Stochastic Gradient Descent},
  shorttitle = {Hilbert Maps},
  author = {Ramos, Fabio and Ott, Lionel},
  year = {2016},
  month = dec,
  journal = {The International Journal of Robotics Research},
  volume = {35},
  number = {14},
  pages = {1717--1730},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364916684382},
  url = {http://journals.sagepub.com/doi/10.1177/0278364916684382},
  urldate = {2022-02-06},
  abstract = {The vast amount of data robots can capture today motivates the development of fast and scalable statistical tools to model the space the robot operates in. We devise a new technique for environment representation through continuous occupancy mapping that improves on the popular occupancy grip maps in two fundamental aspects: (1) it does not assume an a priori discrimination of the world into grid cells and therefore can provide maps at an arbitrary resolution; (2) it captures spatial relationships between measurements naturally, thus being more robust to outliers and possessing better generalization performance. The technique, named Hilbert maps, is based on the computation of fast kernel approximations that project the data in a Hilbert space where a logistic regression classifier is learnt. We show that this approach allows for efficient stochastic gradient optimization where each measurement is only processed once during learning in an online manner. We present results with three types of approximations: random Fourier; Nystr{\"o}m; and a novel sparse projection. We also extend the approach to accept probability distributions as inputs, for example, due to uncertainty over the position of laser scans due to sensor or localization errors. In this extended version, experiments were conducted in two dimensions and three dimensions, using popular benchmark datasets. Furthermore, an analysis of the adaptive capabilities of the technique to handle large changes in the data, such as trajectory update before and after loop closure during simultaneous localization and mapping, is also included.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MSSMK54A/Ramos and Ott - 2016 - Hilbert maps Scalable continuous occupancy mappin.pdf}
}

@article{ran_neurar_2023,
  title = {{{NeurAR}}: {{Neural Uncertainty}} for {{Autonomous 3D Reconstruction With Implicit Neural Representations}}},
  shorttitle = {{{NeurAR}}},
  author = {Ran, Yunlong and Zeng, Jing and He, Shibo and Chen, Jiming and Li, Lincheng and Chen, Yingfeng and Lee, Gimhee and Ye, Qi},
  year = {2023},
  month = feb,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {2},
  pages = {1125--1132},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3235686},
  abstract = {Implicit neural representations have shown compelling results in offline 3D reconstruction and also recently demonstrated the potential for online SLAM systems. However, applying them to autonomous 3D reconstruction, where a robot is required to explore a scene and plan a view path for the reconstruction, has not been studied. In this paper, we explore for the first time the possibility of using implicit neural representations for autonomous 3D scene reconstruction by addressing two key challenges: 1) seeking a criterion to measure the quality of the candidate viewpoints for the view planning based on the new representations, and 2) learning the criterion from data that can generalize to different scenes instead of a hand-crafting one. To solve the challenges, firstly, a proxy of Peak Signal-to-Noise Ratio (PSNR) is proposed to quantify a viewpoint quality; secondly, the proxy is optimized jointly with the parameters of an implicit neural network for the scene. With the proposed view quality criterion from neural networks (termed as Neural Uncertainty), we can then apply implicit representations to autonomous 3D reconstruction. Our method demonstrates significant improvements on various metrics for the rendered image quality and the geometry quality of the reconstructed 3D models when compared with variants using TSDF or reconstruction without view planning.},
  keywords = {Computer vision for automation,Image color analysis,Image reconstruction,motion and path planning,Planning,planning under uncertainty,Robots,Surface reconstruction,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/UK4YPF75/Ran et al. - 2023 - NeurAR Neural Uncertainty for Autonomous 3D Recon.pdf;/Users/kshitijgoel/Zotero/storage/7Q4TSTXJ/stamp.html}
}

@article{rao_mean_2009,
  title = {Mean Shift: {{An}} Information Theoretic Perspective},
  shorttitle = {Mean Shift},
  author = {Rao, Sudhir and {de Medeiros Martins}, Allan and Pr{\'i}ncipe, Jos{\'e} C.},
  year = {2009},
  month = feb,
  journal = {Pattern Recognition Letters},
  volume = {30},
  number = {3},
  pages = {222--230},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2008.09.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865508002924},
  urldate = {2024-11-15},
  abstract = {This paper develops a new understanding of mean shift algorithms from an information theoretic perspective. We show that the Gaussian blurring mean shift (GBMS) directly minimizes the Renyi's quadratic entropy of the dataset and hence is unstable by definition. Further, its stable counterpart, the Gaussian mean shift (GMS), minimizes the Renyi's ``cross'' entropy where the local stationary solutions are modes of the dataset. By doing so, we aptly answer the question ``What does mean shift algorithms optimize?'', thus highlighting naturally the properties of these algorithms. A consequence of this new understanding is the superior performance of GMS over GBMS which we show in a wide variety of applications ranging from mode finding to clustering and image segmentation.},
  keywords = {Information theoretic learning,Mean shift,Renyi's entropy},
  file = {/Users/kshitijgoel/Zotero/storage/BUVV5WV7/Rao et al. - 2009 - Mean shift An information theoretic perspective.pdf;/Users/kshitijgoel/Zotero/storage/35QS6KMC/S0167865508002924.html}
}

@book{rasmussen_gaussian_2005,
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year = {2005},
  month = nov,
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/3206.001.0001},
  url = {https://direct.mit.edu/books/book/2320/Gaussian-Processes-for-Machine-Learning},
  urldate = {2023-09-08},
  abstract = {A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machi},
  isbn = {978-0-262-25683-4},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z9NX3XBQ/Rasmussen and Williams - 2005 - Gaussian Processes for Machine Learning.pdf;/Users/kshitijgoel/Zotero/storage/9KNMD8GC/Gaussian-Processes-for-Machine-Learning.html}
}

@inproceedings{rasmussen_infinite_1999,
  title = {The {{Infinite Gaussian Mixture Model}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Rasmussen, Carl},
  year = {1999},
  volume = {12},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper/1999/hash/97d98119037c5b8a9663cb21fb8ebf47-Abstract.html},
  urldate = {2023-09-29},
  abstract = {In a Bayesian mixture model it is not necessary a priori to limit the num(cid:173) ber of components to be finite.  In this paper an infinite Gaussian mixture  model is  presented which neatly sidesteps the difficult problem of find(cid:173) ing the "right" number of mixture components. Inference in the model is  done using an efficient parameter-free Markov Chain that relies entirely  on Gibbs sampling.},
  file = {/Users/kshitijgoel/Zotero/storage/M3GT7DV3/Rasmussen - 1999 - The Infinite Gaussian Mixture Model.pdf}
}

@inproceedings{ratliff_chomp_2009,
  title = {{{CHOMP}}: {{Gradient}} Optimization Techniques for Efficient Motion Planning},
  shorttitle = {{{CHOMP}}},
  booktitle = {2009 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Ratliff, Nathan and Zucker, Matt and Bagnell, J. Andrew and Srinivasa, Siddhartha},
  year = {2009},
  month = may,
  pages = {489--494},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2009.5152817},
  url = {https://ieeexplore.ieee.org/document/5152817},
  urldate = {2024-01-27},
  abstract = {Existing high-dimensional motion planning algorithms are simultaneously overpowered and underpowered. In domains sparsely populated by obstacles, the heuristics used by sampling-based planners to navigate ``narrow passages'' can be needlessly complex; furthermore, additional post-processing is required to remove the jerky or extraneous motions from the paths that such planners generate. In this paper, we present CHOMP, a novel method for continuous path refinement that uses covariant gradient techniques to improve the quality of sampled trajectories. Our optimization technique both optimizes higher-order dynamics and is able to converge over a wider range of input paths relative to previous path optimization strategies. In particular, we relax the collision-free feasibility prerequisite on input paths required by those strategies. As a result, CHOMP can be used as a standalone motion planner in many real-world planning queries. We demonstrate the effectiveness of our proposed method in manipulation planning for a 6-DOF robotic arm as well as in trajectory generation for a walking quadruped robot.},
  keywords = {Legged locomotion,Motion planning,Optimal control,Optimization methods,Orbital robotics,Path planning,Robotics and automation,Robots,Space technology,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/TCAGE7UM/Ratliff et al. - 2009 - CHOMP Gradient optimization techniques for effici.pdf;/Users/kshitijgoel/Zotero/storage/ZTJGTKDK/5152817.html}
}

@inproceedings{ravichandran_hierarchical_2022,
  title = {Hierarchical {{Representations}} and {{Explicit Memory}}: {{Learning Effective Navigation Policies}} on {{3D Scene Graphs}} Using {{Graph Neural Networks}}},
  shorttitle = {Hierarchical {{Representations}} and {{Explicit Memory}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ravichandran, Zachary and Peng, Lisa and Hughes, Nathan and Griffith, J. Daniel and Carlone, Luca},
  year = {2022},
  month = may,
  pages = {9272--9279},
  doi = {10.1109/ICRA46639.2022.9812179},
  abstract = {Representations are crucial for a robot to learn effective navigation policies. Recent work has shown that mid-level perceptual abstractions, such as depth estimates or 2D semantic segmentation, lead to more effective policies when provided as observations in place of raw sensor data (e.g., RGB images). However, such policies must still learn latent three-dimensional scene properties from mid-level abstractions. In contrast, high-level, hierarchical representations such as 3D scene graphs explicitly provide a scene's geometry, topology, and semantics, making them compelling representations for navigation. In this work, we present a reinforcement learning framework that leverages high-level hierarchical representations to learn navigation policies. Towards this goal, we propose a graph neural network architecture and show how to embed a 3D scene graph into an agent-centric feature space, which enables the robot to learn policies that map 3D scene graphs to a platform-agnostic control space (e.g., go straight, turn left). For each node in the scene graph, our method uses features that capture occupancy and semantic content, while explicitly retaining memory of the robot trajectory. We demonstrate the effectiveness of our method against commonly used visuomotor policies in a challenging multi-object search task. These experiments and supporting ablation studies show that our method leads to more effective object search behaviors, exhibits improved long-term memory, and successfully leverages hierarchical information to guide its navigation objectives.},
  keywords = {Aerospace electronics,Graph neural networks,Navigation,Robot sensing systems,Search problems,Semantics,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/NULWSDHS/Ravichandran et al. - 2022 - Hierarchical Representations and Explicit Memory .pdf;/Users/kshitijgoel/Zotero/storage/LF9MGU5E/9812179.html}
}

@article{ray_topography_2005,
  title = {The {{Topography}} of {{Multivariate Normal Mixtures}}},
  author = {Ray, Surajit and Lindsay, Bruce G.},
  year = {2005},
  journal = {The Annals of Statistics},
  volume = {33},
  number = {5},
  eprint = {3448634},
  eprinttype = {jstor},
  pages = {2042--2065},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/3448634},
  urldate = {2024-04-25},
  abstract = {Multivariate normal mixtures provide a flexible method of fitting high-dimensional data. It is shown that their topography, in the sense of their key features as a density, can be analyzed rigorously in lower dimensions by use of a ridgeline manifold that contains all critical points, as well as the ridges of the density. A plot of the elevations on the ridgeline shows the key features of the mixed density. In addition, by use of the ridgeline, we uncover a function that determines the number of modes of the mixed density when there are two components being mixed. A followup analysis then gives a curvature function that can be used to prove a set of modality theorems.},
  file = {/Users/kshitijgoel/Zotero/storage/85NEHV84/Ray and Lindsay - 2005 - The Topography of Multivariate Normal Mixtures.pdf}
}

@article{redner_mixture_1984,
  title = {Mixture {{Densities}}, {{Maximum Likelihood}} and the {{EM Algorithm}}},
  author = {Redner, Richard A. and Walker, Homer F.},
  year = {1984},
  month = apr,
  journal = {SIAM Review},
  volume = {26},
  number = {2},
  pages = {195--239},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/1026034},
  url = {https://epubs.siam.org/doi/10.1137/1026034},
  urldate = {2024-06-03},
  abstract = {Suppose Y1,{\dots},Yn have a joint distribution that is known up to a parameter, or set of parameters. For example, we could know that the sample is from a normal population, but we don't know the mean and variance. We might have a random sample from a gamma distribution, but we don't know the shape and scale parameters, or a random sample from a geometric distribution, and we want to estimate p. In this chapter we find the maximum likelihood estimator (MLE) for the unknown parameter or parameters.},
  file = {/Users/kshitijgoel/Zotero/storage/BJMNHRAC/Redner and Walker - 1984 - Mixture Densities, Maximum Likelihood and the EM Algorithm.pdf}
}

@inproceedings{reijgwart_efficient_2023,
  title = {Efficient Volumetric Mapping of Multi-Scale Environments Using Wavelet-Based Compression},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {Reijgwart, Victor and Cadena, Cesar and Siegwart, Roland and Ott, Lionel},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p065.html},
  urldate = {2023-06-29},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/7EF8KIFX/Reijgwart et al. - 2023 - Efficient volumetric mapping of multi-scale enviro.pdf}
}

@phdthesis{reijgwart_multiresolution_2024,
  type = {Doctoral {{Thesis}}},
  title = {Multi-{{Resolution}} for {{Efficient}}, {{Scalable}} and {{Accurate Volumetric Mapping}} and {{Planning}} in {{Robotics}}},
  author = {Reijgwart, Victor Johan Freerk},
  year = {2024},
  doi = {10.3929/ethz-b-000679133},
  url = {https://www.research-collection.ethz.ch/handle/20.500.11850/679133?locale-attribute=de},
  urldate = {2024-11-05},
  abstract = {As robots evolve beyond industrial settings to address broader challenges, such as autonomous inspection, home assistance, and search and rescue, there is a growing demand for them to autonomously navigate and perform meaningful tasks in increasingly large, unstructured, and unknown environments. Despite improvements in hardware, sensing, and computational technologies enabling greater robot agility and perception, a significant bottleneck remains in their software, particularly in autonomous mapping and navigation capabilities. Volumetric maps offer a general, safe, and task-agnostic representation of the environment but are hindered by their excessive computational and memory demands, limiting their practical use on small and affordable robots.  This doctoral thesis investigates the use of adaptive representations as a solution to these challenges, focusing on enhancing the scalability, efficiency, and accuracy of volumetric maps. Recognizing that the value of volumetric maps is determined by the benefits they bring to downstream tasks, we study local and global planning as two representative applications. Leveraging hierarchical, multi-resolution approaches, this work aims to dynamically balance the trade-off between detail and computational cost, tailored to the mission's needs.  The main contribution of this thesis is the development of a mathematically rigorous multi-resolution mapping framework, named wavemap, that adjusts the map's resolution based on the environment's geometry without reliance on heuristics. The MRA theory guarantees that using wavelet decomposition, new observations can safely and efficiently be integrated into the map in a coarse-to-fine manner. The resulting gains in computational efficiency, together with early stopping criteria for the integrator, allow us to use a more complex measurement model that improves the capture of thin objects, thereby enhancing the safety and reliability of robotic operations. The framework is extensively evaluated on synthetic and real data, and shown to efficiently reconstruct large-scale environments while accurately capturing fine details. Beyond significant improvements in terms of scalability and map quality, the framework's flexibility facilitates its use across a wide range of sensors and applications.   Our second and third contributions are efficient methods for reactive obstacle avoidance and deterministic global path planning, utilizing hierarchical representations and algorithms alongside the wavemap framework to enable rapid, reliable navigation through complex environments. Experimental evaluations on maps of diverse, real environments and deployments on a micro aerial vehicle demonstrate the superiority of these approaches over existing methods in terms of efficiency, accuracy, and flexibility, underscoring their potential to significantly advance the field of robotic mapping and navigation.  In sum, this doctoral thesis presents a comprehensive solution to the challenges of volumetric mapping and planning in robotics, paving the way for more autonomous, efficient, and versatile robotic systems capable of operating in diverse and changing environments.},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
  langid = {english},
  school = {ETH Zurich},
  annotation = {Accepted: 2024-06-20T05:55:00Z},
  file = {/Users/kshitijgoel/Zotero/storage/QFRIIVE8/Reijgwart - 2024 - Multi-Resolution for Efficient, Scalable and Accurate Volumetric Mapping and Planning in Robotics.pdf}
}

@article{reijgwart_voxgraph_2020,
  title = {Voxgraph: {{Globally Consistent}}, {{Volumetric Mapping Using Signed Distance Function Submaps}}},
  shorttitle = {Voxgraph},
  author = {Reijgwart, Victor and Millane, Alexander and Oleynikova, Helen and Siegwart, Roland and Cadena, Cesar and Nieto, Juan},
  year = {2020},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {1},
  pages = {227--234},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2953859},
  url = {https://ieeexplore.ieee.org/document/8903279},
  urldate = {2024-11-15},
  abstract = {Globally consistent dense maps are a key requirement for long-term robot navigation in complex environments. While previous works have addressed the challenges of dense mapping and global consistency, most require more computational resources than may be available on-board small robots. We propose a framework that creates globally consistent volumetric maps on a CPU and is lightweight enough to run on computationally constrained platforms. Our approach represents the environment as a collection of overlapping signed distance function (SDF) submaps and maintains global consistency by computing an optimal alignment of the submap collection. By exploiting the underlying SDF representation, we generate correspondence-free constraints between submap pairs that are computationally efficient enough to optimize the global problem each time a new submap is added. We deploy the proposed system on a hexacopter micro aerial vehicle (MAV) with an Intel i7-8650 U CPU in two realistic scenarios: mapping a large-scale area using a 3D LiDAR and mapping an industrial space using an RGB-D camera. In the large-scale outdoor experiments, the system optimizes a 120 {\texttimes} 80 m map in less than 4 s and produces absolute trajectory RMSEs of less than 1 m over 400 m trajectories. Our complete system, called voxgraph, is available as open source.11https://github.com/ethz-asl/voxgraph.},
  keywords = {aerial systems: perception and autonomy,Autonomous aerial vehicles,Mapping,Navigation,Optimization,Simultaneous localization and mapping,SLAM,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/PUY2SPXF/Reijgwart et al. - 2020 - Voxgraph Globally Consistent, Volumetric Mapping Using Signed Distance Function Submaps.pdf;/Users/kshitijgoel/Zotero/storage/Z4B4NSUN/8903279.html}
}

@misc{reijgwart_waverider_2024,
  title = {Waverider: {{Leveraging Hierarchical}}, {{Multi-Resolution Maps}} for {{Efficient}} and {{Reactive Obstacle Avoidance}}},
  shorttitle = {Waverider},
  author = {Reijgwart, Victor and Pantic, Michael and Siegwart, Roland and Ott, Lionel},
  year = {2024},
  month = may,
  number = {arXiv:2405.13617},
  eprint = {2405.13617},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.13617},
  url = {http://arxiv.org/abs/2405.13617},
  urldate = {2024-05-24},
  abstract = {Fast and reliable obstacle avoidance is an important task for mobile robots. In this work, we propose an efficient reactive system that provides high-quality obstacle avoidance while running at hundreds of hertz with minimal resource usage. Our approach combines wavemap, a hierarchical volumetric map representation, with a novel hierarchical and parallelizable obstacle avoidance algorithm formulated through Riemannian Motion Policies (RMP). Leveraging multi-resolution obstacle avoidance policies, the proposed navigation system facilitates precise, low-latency (36ms), and extremely efficient obstacle avoidance with a very large perceptive radius (30m). We perform extensive statistical evaluations on indoor and outdoor maps, verifying that the proposed system compares favorably to fixed-resolution RMP variants and CHOMP. Finally, the RMP formulation allows the seamless fusion of obstacle avoidance with additional objectives, such as goal-seeking, to obtain a fully-fledged navigation system that is versatile and robust. We deploy the system on a Micro Aerial Vehicle and show how it navigates through an indoor obstacle course. Our complete implementation, called waverider, is made available as open source.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/F47E6MTP/Reijgwart et al. - 2024 - Waverider Leveraging Hierarchical, Multi-Resolution Maps for Efficient and Reactive Obstacle Avoida.pdf;/Users/kshitijgoel/Zotero/storage/Q9YMTBNB/2405.html}
}

@article{reinke_locus_2022,
  title = {{{LOCUS}} 2.0: {{Robust}} and {{Computationally Efficient Lidar Odometry}} for {{Real-Time 3D Mapping}}},
  shorttitle = {{{LOCUS}} 2.0},
  author = {Reinke, Andrzej and Palieri, Matteo and Morrell, Benjamin and Chang, Yun and Ebadi, Kamak and Carlone, Luca and {Agha-Mohammadi}, Ali-Akbar},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {9043--9050},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3181357},
  abstract = {Lidar odometry has attracted considerable attention as a robust localization method for autonomous robots operating in complex GNSS-denied environments. However, achieving reliable and efficient performance on heterogeneous platforms in large-scale environments remains an open challenge due to the limitations of onboard computation and memory resources needed for autonomous operation. In this work, we present LOCUS 2.0, a robust and computationally-efficient lidar odometry system for real-time underground 3D mapping. LOCUS 2.0 includes a novel normals-based Generalized Iterative Closest Point (GICP) formulation that reduces the computation time of point cloud alignment, an adaptive voxel grid filter that maintains the desired computation load regardless of the environment's geometry, and a sliding-window map approach that bounds the memory consumption. The proposed approach is shown to be suitable to be deployed on heterogeneous robotic platforms involved in large-scale explorations under severe computation and memory constraints. We demonstrate LOCUS 2.0, a key element of the CoSTAR team's entry in the DARPA Subterranean Challenge, across various underground scenarios. We release LOCUS 2.0 as an open-source library and also release a lidar-based odometry dataset in challenging and large-scale underground environments. The dataset features legged and wheeled platforms in multiple environments including fog, dust, darkness, and geometrically degenerate surroundings with a total of \${\textbackslash}text11{\textbackslash};{\textbackslash}texth\$ of operations and \${\textbackslash}text16{\textbackslash};{\textbackslash}textkm\$ of distance traveled.},
  keywords = {data sets for SLAM,Laser radar,Memory management,Point cloud compression,Real-time systems,Robot sensing systems,robotics in under-resourced settings,Robots,sensor fusion,SLAM,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/J9Z3LM25/Reinke et al. - 2022 - LOCUS 2.0 Robust and Computationally Efficient Li.pdf}
}

@inproceedings{reizenstein_common_2021,
  title = {Common {{Objects}} in {{3D}}: {{Large-Scale Learning}} and {{Evaluation}} of {{Real-Life 3D Category Reconstruction}}},
  shorttitle = {Common {{Objects}} in {{3D}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Reizenstein, Jeremy and Shapovalov, Roman and Henzler, Philipp and Sbordone, Luca and Labatut, Patrick and Novotny, David},
  year = {2021},
  pages = {10901--10911},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Reizenstein_Common_Objects_in_3D_Large-Scale_Learning_and_Evaluation_of_Real-Life_ICCV_2021_paper.html},
  urldate = {2023-10-08},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IBJR8ZWI/Reizenstein et al. - 2021 - Common Objects in 3D Large-Scale Learning and Eva.pdf}
}

@inproceedings{ren_bubble_2022,
  title = {Bubble {{Planner}}: {{Planning High-speed Smooth Quadrotor Trajectories}} Using {{Receding Corridors}}},
  shorttitle = {Bubble {{Planner}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ren, Yunfan and Zhu, Fangcheng and Liu, Wenyi and Wang, Zhepei and Lin, Yi and Gao, Fei and Zhang, Fu},
  year = {2022},
  month = oct,
  pages = {6332--6339},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9981518},
  url = {https://ieeexplore.ieee.org/document/9981518},
  urldate = {2024-02-06},
  abstract = {Quadrotors are agile platforms. With human experts, they can perform extremely high-speed flights in cluttered environments. However, fully autonomous flight at high speed remains a significant challenge. In this work, we propose a motion planning algorithm based on the corridor-constrained minimum control effort trajectory optimization (MINCO) framework. Specifically, we use a series of overlapping spheres to represent the free space of the environment and propose two novel designs that enable the algorithm to plan high-speed quadrotor trajectories in real-time. One is a sampling-based corridor generation method that generates spheres with large overlapped areas (hence overall corridor size) between two neighboring spheres. The second is a Receding Horizon Corridors (RHC) strategy, where part of the previously generated corridor is reused in each replan. Together, these two designs enlarge the corridor spaces in accordance with the quadrotor's current state and hence allow the quadrotor to maneuver at high speeds. We benchmark our algorithm against other state-of-the-art planning methods to show its superiority in simulation. Comprehensive ablation studies are also conducted to show the necessity of the two designs. The proposed method is finally evaluated on an autonomous LiDAR-navigated quadrotor UAV in woods environments, achieving flight speeds over 13.7m/s without any prior map of the environment or external localization facility.},
  keywords = {Aerospace electronics,Benchmark testing,Intelligent robots,Location awareness,Planning,Real-time systems,Trajectory optimization},
  file = {/Users/kshitijgoel/Zotero/storage/XCEA6BMW/Ren et al. - 2022 - Bubble Planner Planning High-speed Smooth Quadrot.pdf;/Users/kshitijgoel/Zotero/storage/QH45SA39/9981518.html}
}

@inproceedings{ren_online_2023,
  title = {Online {{Whole-Body Motion Planning}} for {{Quadrotor}} Using {{Multi-Resolution Search}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ren, Yunfan and Liang, Siqi and Zhu, Fangcheng and Lu, Guozheng and Zhang, Fu},
  year = {2023},
  month = may,
  pages = {1594--1600},
  doi = {10.1109/ICRA48891.2023.10160767},
  abstract = {In this paper, we address the problem of online quadrotor whole-body motion planning (SE(3) planning) in unknown and unstructured environments. We propose a novel multi-resolution search method, which discovers narrow areas requiring full pose planning and normal areas requiring only position planning. As a consequence, a quadrotor planning problem is decomposed into several SE(3) (if necessary) and R3 sub-problems. To fly through the discovered narrow areas, a carefully designed corridor generation strategy for narrow areas is proposed, which significantly increases the planning success rate. The overall problem decomposition and hierarchical planning framework substantially accelerate the planning process, making it possible to work online with fully onboard sensing and computation in unknown environments. Extensive simulation benchmark comparisons show that the proposed method is one to several orders of magnitude faster than the state-of-the-art methods in computation time while maintaining high planning success rate. The proposed method is finally integrated into a LiDAR-based autonomous quadrotor, and various real-world experiments in unknown and unstructured environments are conducted to demonstrate the outstanding performance of the proposed method.},
  keywords = {Automation,Benchmark testing,Computational modeling,Planning,Robot sensing systems,Search methods,Sensors},
  file = {/Users/kshitijgoel/Zotero/storage/D44Z98VY/Ren et al. - 2023 - Online Whole-Body Motion Planning for Quadrotor us.pdf}
}

@article{ren_robot_2023,
  title = {Robot {{Active Neural Sensing}} and {{Planning}} in {{Unknown Cluttered Environments}}},
  author = {Ren, Hanwen and Qureshi, Ahmed H.},
  year = {2023},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {4},
  pages = {2738--2750},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3262114},
  abstract = {Active sensing and planning in unknown, cluttered environments is an open challenge for robots intending to provide home service, search and rescue, narrow-passage inspection, and medical assistance. Although many active sensing methods exist, they often consider open spaces, assume known settings, or mostly do not generalize to real-world scenarios. In this article, we present the active neural sensing approach that generates the kinematically feasible viewpoint sequences for the robot manipulator with an in-hand camera to gather the minimum number of observations needed to reconstruct the underlying environment. Our framework actively collects the visual RGBD observations, aggregates them into scene representation, and performs object shape inference to avoid unnecessary robot interactions with the environment. We train our approach on synthetic data with domain randomization and demonstrate its successful execution via sim-to-real transfer in reconstructing narrow, covered, real-world cabinet environments cluttered with unknown objects. The natural cabinet scenarios impose significant challenges for robot motion and scene reconstruction due to surrounding obstacles and low ambient lighting conditions. However, despite unfavorable settings, our method exhibits high performance compared to its baselines in terms of various environment reconstruction metrics, including planning speed, the number of viewpoints, and overall scene coverage.},
  keywords = {Active sensing,Cameras,deep learning,Manipulators,Planning,planning and control,Robot vision systems,Robots,scene reconstruction,Sensors,unknown environments,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/DRGLVK4D/Ren and Qureshi - 2023 - Robot Active Neural Sensing and Planning in Unknow.pdf;/Users/kshitijgoel/Zotero/storage/7MYA3CB5/10101696.html}
}

@article{renyi_foundations_1965,
  title = {On the {{Foundations}} of {{Information Theory}}},
  author = {R{\'e}nyi, A.},
  year = {1965},
  journal = {Revue de l'Institut International de Statistique / Review of the International Statistical Institute},
  volume = {33},
  number = {1},
  eprint = {1401301},
  eprinttype = {jstor},
  pages = {1--14},
  publisher = {[International Statistical Institute (ISI), Wiley]},
  issn = {0373-1138},
  doi = {10.2307/1401301},
  url = {https://www.jstor.org/stable/1401301},
  urldate = {2023-06-29},
  abstract = {L'auteur expose les diff{\'e}rentes d{\'e}finitions de la quantit{\'e} d'information. On peut distinguer deux types de d{\'e}finitions. Les d{\'e}finitions axiomatiques partent de certaines propri{\'e}t{\'e}s plausibles qu'une mesure d'information raisonnable doit poss{\'e}der; ensuite intervient le probl{\`e}me d'ordre purement math{\'e}matique de trouver les expressions ayant les propri{\'e}t{\'e}s postul{\'e}es. Les autres d{\'e}finitions peuvent {\^e}tres appell{\'e}es des d{\'e}finitions pragmatiques: on prend comme point de d{\'e}part certains probl{\`e}mes concr{\`e}ts de la th{\'e}orie de l'information; en resolvant ces probl{\`e}mes, on constate que certaines expressions figurent dans la solution, et par cons{\'e}quent on consid{\`e}re ces expressions comme des quantit{\'e}s d'information. L'auteur montre que les deux points de vue ne sont pas antagonistes; bien plus, ils se compl{\`e}tent l'un l'autre, et l'on peut arriver {\`a} la quantit{\'e} d'information de Shannon, ainsi qu'aux quantit{\'e}s d'information d'ordre {$\alpha$} introduites par l'auteur, en partant aussi bien du point de vue axiomatique, que du point de vue pragmatique.},
  file = {/Users/kshitijgoel/Zotero/storage/D6E4ZDHF/Rényi - 1965 - On the Foundations of Information Theory.pdf}
}

@misc{reuel_open_2024,
  title = {Open {{Problems}} in {{Technical AI Governance}}},
  author = {Reuel, Anka and Bucknall, Ben and Casper, Stephen and Fist, Tim and Soder, Lisa and Aarne, Onni and Hammond, Lewis and Ibrahim, Lujain and Chan, Alan and Wills, Peter and Anderljung, Markus and Garfinkel, Ben and Heim, Lennart and Trask, Andrew and Mukobi, Gabriel and Schaeffer, Rylan and Baker, Mauricio and Hooker, Sara and Solaiman, Irene and Luccioni, Alexandra Sasha and Rajkumar, Nitarshan and Mo{\"e}s, Nicolas and Ladish, Jeffrey and Guha, Neel and Newman, Jessica and Bengio, Yoshua and South, Tobin and Pentland, Alex and Koyejo, Sanmi and Kochenderfer, Mykel J. and Trager, Robert},
  year = {2024},
  month = jul,
  number = {arXiv:2407.14981},
  eprint = {2407.14981},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.14981},
  urldate = {2024-07-26},
  abstract = {AI progress is creating a growing range of risks and opportunities, but it is often unclear how they should be navigated. In many cases, the barriers and uncertainties faced are at least partly technical. Technical AI governance, referring to technical analysis and tools for supporting the effective governance of AI, seeks to address such challenges. It can help to (a) identify areas where intervention is needed, (b) identify and assess the efficacy of potential governance actions, and (c) enhance governance options by designing mechanisms for enforcement, incentivization, or compliance. In this paper, we explain what technical AI governance is, why it is important, and present a taxonomy and incomplete catalog of its open problems. This paper is intended as a resource for technical researchers or research funders looking to contribute to AI governance.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/kshitijgoel/Zotero/storage/PNGZGGWI/Reuel et al. - 2024 - Open Problems in Technical AI Governance.pdf}
}

@article{richardson_bayesian_1997,
  title = {On {{Bayesian Analysis}} of {{Mixtures}} with an {{Unknown Number}} of {{Components}} (with Discussion)},
  author = {Richardson, {\relax Sylvia}. and Green, Peter J.},
  year = {1997},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {59},
  number = {4},
  pages = {731--792},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00095},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00095},
  urldate = {2024-02-11},
  abstract = {New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough presentation of many aspects of the posterior distribution. The methodology is applied here to the analysis of univariate normal mixtures, using a hierarchical prior model that offers an approach to dealing with weak prior information while avoiding the mathematical pitfalls of using improper priors in the mixture context.},
  copyright = {1997 Royal Statistical Society},
  langid = {english},
  keywords = {Birth-and-death process,Classification,Galaxy data,Heterogeneity,Lake acidity data,Markov chain Monte Carlo method,Normal mixtures,Predictive distribution,Reversible jump algorithms,Sensitivity analysis},
  file = {/Users/kshitijgoel/Zotero/storage/V8UMGC3K/Richardson and Green - 1997 - On Bayesian Analysis of Mixtures with an Unknown N.pdf;/Users/kshitijgoel/Zotero/storage/SDA79J8K/1467-9868.html}
}

@article{riegler_lossy_2023,
  title = {Lossy Compression of General Random Variables},
  author = {Riegler, Erwin and Koliander, G{\"u}nther and B{\"o}lcskei, Helmut},
  year = {2023},
  month = sep,
  journal = {Information and Inference: A Journal of the IMA},
  volume = {12},
  number = {3},
  pages = {1759--1829},
  issn = {2049-8772},
  doi = {10.1093/imaiai/iaac035},
  url = {https://doi.org/10.1093/imaiai/iaac035},
  urldate = {2024-04-23},
  abstract = {This paper is concerned with the lossy compression of general random variables, specifically with rate-distortion theory and quantization of random variables taking values in general measurable spaces such as, e.g. manifolds and fractal sets. Manifold structures are prevalent in data science, e.g. in compressed sensing, machine learning, image processing and handwritten digit recognition. Fractal sets find application in image compression and in the modeling of Ethernet traffic. Our main contributions are bounds on the rate-distortion function and the quantization error. These bounds are very general and essentially only require the existence of reference measures satisfying certain regularity conditions in terms of small ball probabilities. To illustrate the wide applicability of our results, we particularize them to random variables taking values in (i) manifolds, namely, hyperspheres and Grassmannians and (ii) self-similar sets characterized by iterated function systems satisfying the weak separation property.},
  file = {/Users/kshitijgoel/Zotero/storage/2U7EN5MF/Riegler et al. - 2023 - Lossy compression of general random variables.pdf}
}

@article{rimon_obstacle_1997,
  title = {Obstacle {{Collision Detection Using Best Ellipsoid Fit}}},
  author = {Rimon, Elon and Boyd, Stephen P.},
  year = {1997},
  month = feb,
  journal = {Journal of Intelligent and Robotic Systems},
  volume = {18},
  number = {2},
  pages = {105--126},
  issn = {1573-0409},
  doi = {10.1023/A:1007960531949},
  url = {https://doi.org/10.1023/A:1007960531949},
  urldate = {2023-11-09},
  abstract = {This paper describes a method for estimating the distance between a robot and its surrounding environment using best ellipsoid fit. The method consists of the following two stages. First we approximate the detailed geometry of the robot and its environment by minimum-volume enclosing ellipsoids. The computation of these ellipsoids is a convex optimization problem, for which efficient algorithms are known. Then we compute a conservative distance estimate using an important but little known formula for the distance of a point from and n-dimensional ellipse. The computation of the distance estimate (and its gradient vector) is shown to be an eigenvalue problem, whose solution can be rapidly found using standard techniques. We also present an incremental version of the distance computation, which takes place along a continuous trajectory taken by the robot. We have implemented the proposed approach and present some preliminary results.},
  langid = {english},
  keywords = {collision detection,ellipsoid fit,geometric approximation},
  file = {/Users/kshitijgoel/Zotero/storage/LQR4M8XT/Rimon and Boyd - 1997 - Obstacle Collision Detection Using Best Ellipsoid .pdf}
}

@article{rissanen_universal_1984,
  title = {Universal Coding, Information, Prediction, and Estimation},
  author = {Rissanen, J.},
  year = {1984},
  month = jul,
  journal = {IEEE Transactions on Information Theory},
  volume = {30},
  number = {4},
  pages = {629--636},
  issn = {1557-9654},
  doi = {10.1109/TIT.1984.1056936},
  url = {https://ieeexplore.ieee.org/document/1056936},
  urldate = {2024-04-29},
  abstract = {A connection between universal codes and the problems of prediction and statistical estimation is established. A known lower bound for the mean length of universal codes is sharpened and generalized, and optimum universal codes constructed. The bound is defined to give the information in strings relative to the considered class of processes. The earlier derived minimum description length criterion for estimation of parameters, including their number, is given a fundamental information, theoretic justification by showing that its estimators achieve the information in the strings. It is also shown that one cannot do prediction in Gaussian autoregressive moving average (ARMA) processes below a bound, which is determined by the information in the data.},
  file = {/Users/kshitijgoel/Zotero/storage/DIXTCRQK/Rissanen - 1984 - Universal coding, information, prediction, and est.pdf;/Users/kshitijgoel/Zotero/storage/I7Q8VIC8/1056936.html}
}

@article{robbins_stochastic_1951,
  title = {A {{Stochastic Approximation Method}}},
  author = {Robbins, Herbert and Monro, Sutton},
  year = {1951},
  month = sep,
  journal = {The Annals of Mathematical Statistics},
  volume = {22},
  number = {3},
  pages = {400--407},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177729586},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-22/issue-3/A-Stochastic-Approximation-Method/10.1214/aoms/1177729586.full},
  urldate = {2024-06-01},
  abstract = {Let \$M(x)\$ denote the expected value at level \$x\$ of the response to a certain experiment. \$M(x)\$ is assumed to be a monotone function of \$x\$ but is unknown to the experimenter, and it is desired to find the solution \$x = {\textbackslash}theta\$ of the equation \$M(x) = {\textbackslash}alpha\$, where \${\textbackslash}alpha\$ is a given constant. We give a method for making successive experiments at levels \$x\_1,x\_2,{\textbackslash}cdots\$ in such a way that \$x\_n\$ will tend to \${\textbackslash}theta\$ in probability.},
  file = {/Users/kshitijgoel/Zotero/storage/T6CLLQN8/Robbins and Monro - 1951 - A Stochastic Approximation Method.pdf}
}

@inproceedings{robert-nicoud_intrinsic_2024,
  title = {Intrinsic {{Gaussian Vector Fields}} on {{Manifolds}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {{Robert-Nicoud}, Daniel and Krause, Andreas and Borovitskiy, Viacheslav},
  year = {2024},
  month = apr,
  pages = {1306--1314},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/robert-nicoud24a.html},
  urldate = {2024-04-18},
  abstract = {Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat{\'e}rn Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ideal" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2D4N2GCP/Robert-Nicoud et al. - 2024 - Intrinsic Gaussian Vector Fields on Manifolds.pdf}
}

@book{roberts_principles_2022,
  title = {The {{Principles}} of {{Deep Learning Theory}}},
  author = {Roberts, Daniel A. and Yaida, Sho and Hanin, Boris},
  year = {2022},
  month = may,
  eprint = {2106.10165},
  primaryclass = {cs},
  doi = {10.1017/9781009023405},
  url = {http://arxiv.org/abs/2106.10165},
  urldate = {2025-05-24},
  abstract = {This book develops an effective theory approach to understanding deep neural networks of practical relevance. Beginning from a first-principles component-level picture of networks, we explain how to determine an accurate description of the output of trained networks by solving layer-to-layer iteration equations and nonlinear learning dynamics. A main result is that the predictions of networks are described by nearly-Gaussian distributions, with the depth-to-width aspect ratio of the network controlling the deviations from the infinite-width Gaussian description. We explain how these effectively-deep networks learn nontrivial representations from training and more broadly analyze the mechanism of representation learning for nonlinear models. From a nearly-kernel-methods perspective, we find that the dependence of such models' predictions on the underlying learning algorithm can be expressed in a simple and universal way. To obtain these results, we develop the notion of representation group flow (RG flow) to characterize the propagation of signals through the network. By tuning networks to criticality, we give a practical solution to the exploding and vanishing gradient problem. We further explain how RG flow leads to near-universal behavior and lets us categorize networks built from different activation functions into universality classes. Altogether, we show that the depth-to-width ratio governs the effective model complexity of the ensemble of trained networks. By using information-theoretic techniques, we estimate the optimal aspect ratio at which we expect the network to be practically most useful and show how residual connections can be used to push this scale to arbitrary depths. With these tools, we can learn in detail about the inductive bias of architectures, hyperparameters, and optimizers.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,High Energy Physics - Theory,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/48LEZZJ5/Roberts et al. - 2022 - The Principles of Deep Learning Theory.pdf;/Users/kshitijgoel/Zotero/storage/9R7D32G6/2106.html}
}

@inproceedings{rodrigues_clutterresilient_2023,
  title = {Clutter-{{Resilient Autonomous Mobile Robot Navigation}} with {{Computationally Efficient Free-Space Features}}},
  booktitle = {Robotics {{Research}}},
  author = {Rodrigues, R{\^o}mulo T. and Tsiogkas, Nikolaos and Huebel, Nico and Bruyninckx, Herman},
  editor = {Billard, Aude and Asfour, Tamim and Khatib, Oussama},
  year = {2023},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {522--537},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-25555-7_35},
  abstract = {This paper proposes free-space motion tubes, a motion primitive for the local navigation of mobile robots equipped with range sensors. The geometry of a candidate motion tube captures the free-space required such that the robot may execute a maneuver without colliding with obstacles. Computational efficiency is achieved by selecting meaningful samples of the tube and evaluating them at run-time in the sensor space. Increasing the sensor resolution or the number of obstacles do not have any impact in the computational cost. Experimental results with a mobile platform show that free-space motion tubes are well-suited for navigating in cluttered environments and narrow passages.},
  isbn = {978-3-031-25555-7},
  langid = {english},
  keywords = {Free space,Local navigation,Motion tube,Obstacle avoidance},
  file = {/Users/kshitijgoel/Zotero/storage/UE2MH2YP/Rodrigues et al. - 2023 - Clutter-Resilient Autonomous Mobile Robot Navigati.pdf}
}

@article{romer_visionbased_2023,
  title = {Vision-{{Based Uncertainty-Aware Motion Planning Based}} on {{Probabilistic Semantic Segmentation}}},
  author = {R{\"o}mer, Ralf and Lederer, Armin and Tesfazgi, Samuel and Hirche, Sandra},
  year = {2023},
  month = nov,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {11},
  pages = {7825--7832},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3322899},
  url = {https://ieeexplore.ieee.org/document/10274109/footnotes#footnotes},
  urldate = {2024-01-24},
  abstract = {For safe operation, a robot must be able to avoid collisions in uncertain environments. Existing approaches for motion planning under uncertainties often assume parametric obstacle representations and Gaussian uncertainty, which can be inaccurate. While visual perception can deliver a more accurate representation of the environment, its use for safe motion planning is limited by the inherent miscalibration of neural networks and the challenge of obtaining adequate datasets. To address these limitations, we propose to employ ensembles of deep semantic segmentation networks trained with massively augmented datasets to ensure reliable probabilistic occupancy information. To avoid conservatism during motion planning, we directly employ the probabilistic perception in a scenario-based path planning approach. A velocity scheduling scheme is applied to the path to ensure a safe motion despite tracking inaccuracies. We demonstrate the effectiveness of the massive data augmentation in combination with deep ensembles and the proposed scenario-based planning approach in comparisons to state-of-the-art methods and validate our framework in an experiment with a human hand as an obstacle.},
  keywords = {deep learning for visual perception,object detection,Planning,Planning under uncertainty,Probabilistic logic,Robots,segmentation and categorization,Semantic segmentation,Training,Uncertainty,Visual perception},
  file = {/Users/kshitijgoel/Zotero/storage/9EYRRPKA/Römer et al. - 2023 - Vision-Based Uncertainty-Aware Motion Planning Bas.pdf;/Users/kshitijgoel/Zotero/storage/F89LIJTT/footnotes.html}
}

@article{rosen_advances_2021,
  title = {Advances in {{Inference}} and {{Representation}} for {{Simultaneous Localization}} and {{Mapping}}},
  author = {Rosen, David M. and Doherty, Kevin J. and Ter{\'a}n Espinoza, Antonio and Leonard, John J.},
  year = {2021},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {4},
  number = {1},
  pages = {215--242},
  doi = {10.1146/annurev-control-072720-082553},
  url = {https://doi.org/10.1146/annurev-control-072720-082553},
  urldate = {2023-04-27},
  abstract = {Simultaneous localization and mapping (SLAM) is the process of constructing a global model of an environment from local observations of it; this is a foundational capability for mobile robots, supporting such core functions as planning, navigation, and control. This article reviews recent progress in SLAM, focusing on advances in the expressive capacity of the environmental models used in SLAM systems (representation) and the performance of the algorithms used to estimate these models from data (inference). A prominent theme of recent SLAM research is the pursuit of environmental representations (including learned representations) that go beyond the classical attributes of geometry and appearance to model properties such as hierarchical organization, affordance, dynamics, and semantics; these advances equip autonomous agents with a more comprehensive understanding of the world, enabling more versatile and intelligent operation. A second major theme is a revitalized interest in the mathematical properties of the SLAM estimation problem itself (including its computational and information-theoretic performance limits); this work has led to the development of novel classes of certifiable and robust inference methods that dramatically improve the reliability of SLAM systems in real-world operation. We survey these advances with an emphasis on their ramifications for achieving robust, long-duration autonomy, and conclude with a discussion of open challenges and a perspective on future research directions.},
  file = {/Users/kshitijgoel/Zotero/storage/YP6AG73W/Rosen et al. - 2021 - Advances in Inference and Representation for Simul.pdf}
}

@article{rosen_sesync_2019,
  title = {{{SE-Sync}}: {{A}} Certifiably Correct Algorithm for Synchronization over the Special {{Euclidean}} Group},
  shorttitle = {{{SE-Sync}}},
  author = {Rosen, David M and Carlone, Luca and Bandeira, Afonso S and Leonard, John J},
  year = {2019},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {38},
  number = {2-3},
  pages = {95--125},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364918784361},
  url = {https://doi.org/10.1177/0278364918784361},
  urldate = {2025-05-22},
  abstract = {Many important geometric estimation problems naturally take the form of synchronization over the special Euclidean group: estimate the values of a set of unknown group elements x1,{\dots},xn{$\in$}SE(d) given noisy measurements of a subset of their pairwise relative transforms xi-1xj. Examples of this class include the foundational problems of pose-graph simultaneous localization and mapping (SLAM) (in robotics), camera motion estimation (in computer vision), and sensor network localization (in distributed sensing), among others. This inference problem is typically formulated as a non-convex maximum-likelihood estimation that is computationally hard to solve in general. Nevertheless, in this paper we present an algorithm that is able to efficiently recover certifiably globally optimal solutions of the special Euclidean synchronization problem in a non-adversarial noise regime. The crux of our approach is the development of a semidefinite relaxation of the maximum-likelihood estimation (MLE) whose minimizer provides an exact maximum-likelihood estimate so long as the magnitude of the noise corrupting the available measurements falls below a certain critical threshold; furthermore, whenever exactness obtains, it is possible to verify this fact a posteriori, thereby certifying the optimality of the recovered estimate. We develop a specialized optimization scheme for solving large-scale instances of this semidefinite relaxation by exploiting its low-rank, geometric, and graph-theoretic structure to reduce it to an equivalent optimization problem defined on a low-dimensional Riemannian manifold, and then design a Riemannian truncated-Newton trust-region method to solve this reduction efficiently. Finally, we combine this fast optimization approach with a simple rounding procedure to produce our algorithm, SE-Sync. Experimental evaluation on a variety of simulated and real-world pose-graph SLAM datasets shows that SE-Sync is capable of recovering certifiably globally optimal solutions when the available measurements are corrupted by noise up to an order of magnitude greater than that typically encountered in robotics and computer vision applications, and does so significantly faster than the Gauss--Newton-based approach that forms the basis of current state-of-the-art techniques.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LJPY8Y85/Rosen et al. - 2019 - SE-Sync A certifiably correct algorithm for synchronization over the special Euclidean group.pdf}
}

@article{rosenblatt_remarks_1956,
  title = {Remarks on {{Some Nonparametric Estimates}} of a {{Density Function}}},
  author = {Rosenblatt, Murray},
  year = {1956},
  month = sep,
  journal = {The Annals of Mathematical Statistics},
  volume = {27},
  number = {3},
  pages = {832--837},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177728190},
  url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-3/Remarks-on-Some-Nonparametric-Estimates-of-a-Density-Function/10.1214/aoms/1177728190.full},
  urldate = {2024-06-27},
  abstract = {This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymptotic mean square error of a particular class of estimates is evaluated.},
  file = {/Users/kshitijgoel/Zotero/storage/YGJ4354D/Rosenblatt - 1956 - Remarks on Some Nonparametric Estimates of a Density Function.pdf}
}

@article{rosinol_kimera_2021,
  title = {Kimera: {{From SLAM}} to Spatial Perception with {{3D}} Dynamic Scene Graphs},
  shorttitle = {Kimera},
  author = {Rosinol, Antoni and Violette, Andrew and Abate, Marcus and Hughes, Nathan and Chang, Yun and Shi, Jingnan and Gupta, Arjun and Carlone, Luca},
  year = {2021},
  month = dec,
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {12-14},
  pages = {1510--1546},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649211056674},
  url = {https://doi.org/10.1177/02783649211056674},
  urldate = {2025-01-08},
  abstract = {Humans are able to form a complex mental model of the environment they move in. This mental model captures geometric and semantic aspects of the scene, describes the environment at multiple levels of abstractions (e.g., objects, rooms, buildings), includes static and dynamic entities and their relations (e.g., a person is in a room at a given time). In contrast, current robots' internal representations still provide a partial and fragmented understanding of the environment, either in the form of a sparse or dense set of geometric primitives (e.g., points, lines, planes, and voxels), or as a collection of objects. This article attempts to reduce the gap between robot and human perception by introducing a novel representation, a 3D dynamic scene graph (DSG), that seamlessly captures metric and semantic aspects of a dynamic environment. A DSG is a layered graph where nodes represent spatial concepts at different levels of abstraction, and edges represent spatiotemporal relations among nodes. Our second contribution is Kimera, the first fully automatic method to build a DSG from visual--inertial data. Kimera includes accurate algorithms for visual--inertial simultaneous localization and mapping (SLAM), metric--semantic 3D reconstruction, object localization, human pose and shape estimation, and scene parsing. Our third contribution is a comprehensive evaluation of Kimera in real-life datasets and photo-realistic simulations, including a newly released dataset, uHumans2, which simulates a collection of crowded indoor and outdoor scenes. Our evaluation shows that Kimera achieves competitive performance in visual--inertial SLAM, estimates an accurate 3D metric--semantic mesh model in real-time, and builds a DSG of a complex indoor environment with tens of objects and humans in minutes. Our final contribution is to showcase how to use a DSG for real-time hierarchical semantic path-planning. The core modules in Kimera have been released open source.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/TCJKXYH2/Rosinol et al. - 2021 - Kimera From SLAM to spatial perception with 3D dynamic scene graphs.pdf}
}

@article{roth-tabak_building_1989,
  title = {Building an Environment Model Using Depth Information},
  author = {{Roth-Tabak}, Y. and Jain, R.},
  year = {1989},
  month = jun,
  journal = {Computer},
  volume = {22},
  number = {6},
  pages = {85--90},
  issn = {1558-0814},
  doi = {10.1109/2.30724},
  abstract = {The environment model's volumetric level, where information about free and occupied space is represented explicitly, is considered. At this model level, updating operations use raw sensory data from range sensors or processed data from any stereo or other depth recovery technique. In addition, this type of model can be used directly by path planning and navigation modules as well as for object recognition and manipulation modules. A system that uses the sensor-built model mode, in which there is initially little or no knowledge available about the domain and a model is incrementally constructed using the information provided by a sensor, is demonstrated. This mode of operation makes it possible to deal with unknown or dynamic environments.{$<>$}},
  keywords = {Autonomous agents,Intelligent robots,Intelligent systems,Layout,Navigation,Object recognition,Power generation,Power system modeling,Sensor systems,Sonar},
  file = {/Users/kshitijgoel/Zotero/storage/5MNN4VEA/Roth-Tabak and Jain - 1989 - Building an environment model using depth informat.pdf;/Users/kshitijgoel/Zotero/storage/EW4YXCIC/citations.html}
}

@inproceedings{rotstein_multimodal_2022,
  title = {Multimodal {{Colored Point Cloud}} to {{Image Alignment}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Rotstein, Noam and Bracha, Amit and Kimmel, Ron},
  year = {2022},
  pages = {6656--6666},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.html},
  urldate = {2022-09-02},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/THMVFLHY/Rotstein et al. - 2022 - Multimodal Colored Point Cloud to Image Alignment.pdf;/Users/kshitijgoel/Zotero/storage/C7WJAMDH/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.html}
}

@article{roucek_system_2022,
  title = {System for Multi-Robotic Exploration of Underground Environments {{CTU-CRAS-NORLAB}} in the {{DARPA Subterranean Challenge}}},
  author = {Rou{\v c}ek, Tom{\'a}{\v s} and Pecka, Martin and {\v C}{\'i}{\v z}ek, Petr and Pet{\v r}{\'i}{\v c}ek, Tom{\'a}{\v s} and Bayer, Jan and {\v S}alansk{\'y}, Vojt{\v e}ch and Azayev, Teymur and He{\v r}t, Daniel and Petrl{\'i}k, Mat{\v e}j and B{\'a}{\v c}a, Tom{\'a}{\v s} and Spurn{\'y}, Vojtech and Kr{\'a}tk{\'y}, V{\'i}t and Petr{\'a}{\v c}ek, Pavel and Baril, Dominic and Vaidis, Maxime and Kubelka, Vladim{\'i}r and Pomerleau, Fran{\c c}ois and Faigl, Jan and Zimmermann, Karel and Saska, Martin and Svoboda, Tom{\'a}{\v s} and Krajn{\'i}k, Tom{\'a}{\v s}},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {1779--1818},
  issn = {27713989},
  doi = {10.55417/fr.2022055},
  url = {http://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_55.pdf},
  urldate = {2023-01-26},
  abstract = {We present a field report of the CTU-CRAS-NORLAB team from the Subterranean Challenge (SubT) organized by the Defense Advanced Research Projects Agency (DARPA). The contest seeks to advance technologies that would improve the safety and efficiency of search-andrescue operations in GPS-denied environments. During the contest rounds, teams of mobile robots have to find specific objects while operating in environments with limited radio communication, e.g., mining tunnels, underground stations or natural caverns. We present a heterogeneous exploration robotic system of the CTU-CRAS-NORLAB team, which achieved the third rank at the SubT Tunnel and Urban Circuit rounds and surpassed the performance of all other non-DARPA-funded teams. The field report describes the team's hardware, sensors, algorithms and strategies, and discusses the lessons learned by participating at the DARPA SubT contest.},
  file = {/Users/kshitijgoel/Zotero/storage/ISLHA8A6/Rouček et al. - 2022 - System for multi-robotic exploration of undergroun.pdf}
}

@article{rougier_scientific_,
  title = {Scientific {{Visualization}}: {{Python}} + {{Matplotlib}}},
  author = {Rougier, Nicolas P},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/TUD7M7Z3/Rougier - Scientific Visualization Python + Matplotlib.pdf}
}

@inproceedings{roychoudhury_plane_2021,
  title = {Plane {{Segmentation}} in {{Organized Point Clouds}} Using {{Flood Fill}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Roychoudhury, Arindam and Missura, Marcell and Bennewitz, Maren},
  year = {2021},
  month = may,
  pages = {13532--13538},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561325},
  url = {https://ieeexplore.ieee.org/document/9561325/?arnumber=9561325},
  urldate = {2025-01-09},
  abstract = {The segmentation of a point cloud into planar primitives is a popular approach to first-line scene interpretation and is particularly useful in mobile robotics for the extraction of drivable or walkable surfaces and for tabletop segmentation for manipulation purposes. Unfortunately, the planar segmentation task becomes particularly challenging when the point clouds are obtained from an inherently noisy, robot-mounted sensor that is often in motion, therefor requiring real time processing capabilities. We present a real time-capable plane segmentation technique based on a region growing algorithm that exploits the organized structure of point clouds obtained from RGB-D sensors. In order to counteract the sensor noise, we invest into careful selection of seeds that start the region growing and avoid the computation of surface normals whenever possible. We implemented our algorithm in C++ and thoroughly tested it in both simulated and real-world environments where we are able to compare our approach against existing state-of-the-art methods implemented in the Point Cloud Library. The experiments presented here suggest that our approach is accurate and fast, even in the presence of considerable sensor noise.},
  keywords = {Image segmentation,Legged locomotion,Libraries,Merging,Motion segmentation,Real-time systems,Robot sensing systems},
  file = {/Users/kshitijgoel/Zotero/storage/BZDX6KP5/Roychoudhury et al. - 2021 - Plane Segmentation in Organized Point Clouds using Flood Fill.pdf;/Users/kshitijgoel/Zotero/storage/PHKIVC79/9561325.html}
}

@article{ruan_collision_2022,
  title = {Collision {{Detection}} for {{Unions}} of {{Convex Bodies With Smooth Boundaries Using Closed-Form Contact Space Parameterization}}},
  author = {Ruan, Sipu and Wang, Xiaoli and Chirikjian, Gregory S.},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {9485--9492},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2022.3190629},
  url = {https://ieeexplore.ieee.org/document/9829274/},
  urldate = {2023-11-26},
  abstract = {This paper studies the narrow phase collision detection problem for two general unions of convex bodies encapsulated by smooth surfaces. The approach, namely CFC (Closed-Form Contact space), is based on parameterizing their contact space in closed-form. The first body is dilated to form the contact space while the second is shrunk to a point. Then, the collision detection is formulated as finding the closest point on the parametric contact space with the center of the second body. Numerical solutions are proposed based on the point-to-surface distance as well as the common-normal concept. Furthermore, when the two bodies are moving or under linear deformations, their first time of contact is solved continuously along the time-parameterized trajectories. Benchmark studies are conducted for the proposed algorithms in terms of solution stability and computational cost. Applications of the sampling-based motion planning for robot manipulators are demonstrated.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BVBFXY5R/Ruan et al. - 2022 - Collision Detection for Unions of Convex Bodies Wi.pdf}
}

@inproceedings{ruan_efficient_2019,
  title = {Efficient {{Exact Collision Detection}} between {{Ellipsoids}} and {{Superquadrics}} via {{Closed-form Minkowski Sums}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ruan, Sipu and Poblete, Karen L. and Li, Yingke and Lin, Qian and Ma, Qianli and Chirikjian, Gregory S.},
  year = {2019},
  month = may,
  pages = {1765--1771},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8793496},
  url = {https://ieeexplore.ieee.org/document/8793496/},
  urldate = {2023-11-26},
  abstract = {Collision detection has attracted attention of researchers for decades in the field of computer graphics, robot motion planning, computer aided design, etc. A large number of successful algorithms have been proposed and applied, which make use of convex polytopes and bounding volumes as primitives. However, algorithms for those shapes rely significantly on the complexity of the meshes. This paper deals with collision detection for shapes with simple and exact mathematical descriptions, such as ellipsoids and superquadrics. These primitives have a wide range of applications in representing complex objects and have much fewer parameters than meshes. The foundation of the proposed collision detection scheme relies on the closed-form Minkowski sums between ellipsoids and superquadrics in n-dimensional Euclidean space. The basic idea here is to shrink the ellipsoid into a point and expand each superquadric into a new offset surface with closed-form parametric expression. The solutions for detecting relative positions between a point and a general convex differentiable parametric surface in both 2D and 3D are derived, leading to an algorithm for exact collision detection. To compare between exact and inexact algorithms, an accuracy metric is introduced based on the Principal Kinematic Formula (PKF). The proposed algorithm is then compared with existing wellknown algorithms: Gilbert-Johnson-Keerthi (GJK) and Algebraic Separation Conditions (ASC). The results show that the proposed algorithm performs competitively with these efficient checkers.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IL787SH8/Ruan et al. - 2019 - Efficient Exact Collision Detection between Ellips.pdf}
}

@article{ruan_efficient_2023,
  title = {Efficient {{Path Planning}} in {{Narrow Passages}} for {{Robots With Ellipsoidal Components}}},
  author = {Ruan, Sipu and Poblete, Karen L. and Wu, Hongtao and Ma, Qianli and Chirikjian, Gregory S.},
  year = {2023},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {1},
  pages = {110--127},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3187818},
  url = {https://ieeexplore.ieee.org/document/9841604},
  urldate = {2024-01-27},
  abstract = {Path planning has long been one of the major research areas in robotics, with probabilistic roadmap (PRM) and rapidly-exploring random trees (RRT) being two of the most effective classes of planners. Though generally very efficient, these sampling-based planners can become computationally expensive in the important case of ``narrow passages.'' This article develops a path planning paradigm specifically formulated for narrow passage problems. The core is based on planning for rigid-body robots encapsulated by unions of ellipsoids. Each environmental feature is represented geometrically using a strictly convex body with a {\textbackslash}mathcal C{\textasciicircum}1 boundary (e.g., superquadric). The main benefit of doing this is that configuration-space obstacles can be parameterized explicitly in closed form, thereby allowing prior knowledge to be used to avoid sampling infeasible configurations. Then, by characterizing a tight volume bound for multiple ellipsoids, robot transitions involving rotations are guaranteed to be collision free without needing to perform traditional collision detection. Furthermore, by combining with a stochastic sampling strategy, the proposed planning framework can be extended to solving higher dimensional problems, in which the robot has a moving base and articulated appendages. Benchmark results show that the proposed framework often outperforms the sampling-based planners in terms of computational time and success rate in finding a path through narrow corridors for both single-body robots and those with higher dimensional configuration spaces. Physical experiments using the proposed framework are further demonstrated on a humanoid robot that walks in several cluttered environments with narrow passages.},
  keywords = {Bridges,Collision avoidance,computational geometry,Ellipsoids,Legged locomotion,Minkowski sums,Motion and path planning,Path planning,Planning,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/6SJKYNYZ/Ruan et al. - 2023 - Efficient Path Planning in Narrow Passages for Rob.pdf;/Users/kshitijgoel/Zotero/storage/5ZA62FIK/9841604.html}
}

@inproceedings{ruan_path_2020,
  title = {Path {{Planning}} for {{Ellipsoidal Robots}} and {{General Obstacles}} via {{Closed-Form Characterization}} of {{Minkowski Operations}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIII}}},
  author = {Ruan, Sipu and Ma, Qianli and Poblete, Karen L. and Yan, Yan and Chirikjian, Gregory S.},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {3--18},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-44051-0_1},
  abstract = {Path planning has long been one of the major research areas in robotics, with PRM and RRT being two of the most effective path planners. Though they are generally very efficient, these two sample-based planners can become computationally expensive in the important special case of narrow passage problems. This paper develops a path planning paradigm which uses ellipsoids and superquadrics to respectively encapsulate the rigid parts of the robot and obstacles. The main benefit in doing this is that configuration-space obstacles can be parameterized in closed form, thereby allowing prior knowledge to be used to avoid sampling infeasible configurations, in order to solve the narrow passage problem efficiently. Benchmark results for single-body robots show that, remarkably, the proposed method outperforms the sample-based planners in terms of the computational time in searching for a path through narrow corridors. Feasible extensions that integrate with sample-based planners to further solve the high dimensional multi-body problems are discussed, which will require substantial additional theoretical development in the future.},
  isbn = {978-3-030-44051-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/QCM84XPT/Ruan et al. - 2020 - Path Planning for Ellipsoidal Robots and General O.pdf}
}

@article{ruan_primp_2024,
  title = {{{PRIMP}}: {{PRobabilistically-Informed Motion Primitives}} for {{Efficient Affordance Learning}} from {{Demonstration}}},
  shorttitle = {{{PRIMP}}},
  author = {Ruan, Sipu and Liu, Weixiao and Wang, Xiaoli and Meng, Xin and Chirikjian, Gregory S.},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3390052},
  url = {https://ieeexplore.ieee.org/document/10502164},
  urldate = {2024-05-06},
  abstract = {This paper proposes a learning-from-demonstration (LfD) method using probability densities on the workspaces of robot manipulators. The method, named PRobabilistically-Informed Motion Primitives (PRIMP), learns the probability distribution of the end effector trajectories in the 6D workspace that includes both positions and orientations. It is able to adapt to new situations such as novel via points with uncertainty and a change of viewing frame. The method itself is robot-agnostic, in that the learned distribution can be transferred to another robot with the adaptation to its workspace density. Workspace-STOMP, a new version of the existing STOMP motion planner, is also introduced, which can be used as a post-process to improve the performance of PRIMP and any other reachability-based LfD method. The combination of PRIMP and Workspace-STOMP can further help the robot avoid novel obstacles that are not present during the demonstration process. The proposed methods are evaluated with several sets of benchmark experiments. PRIMP runs more than 5 times faster than existing state-of-the-art methods while generalizing trajectories more than twice as close to both the demonstrations and novel desired poses. They are then combined with our lab's robot imagination method that learns object affordances, illustrating the applicability to learn tool use through physical experiments.},
  keywords = {Affordances,Learning from Demonstration,Manifolds,Motion and Path Planning,Planning,Probabilistic logic,Probability and Statistical Methods,Robots,Service Robots,Task analysis,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/X26P3NMZ/Ruan et al. - 2024 - PRIMP PRobabilistically-Informed Motion Primitives for Efficient Affordance Learning from Demonstra.pdf;/Users/kshitijgoel/Zotero/storage/CJ6KK9LF/10502164.html}
}

@article{rubner_earth_2000,
  title = {The {{Earth Mover}}'s {{Distance}} as a {{Metric}} for {{Image Retrieval}}},
  author = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J.},
  year = {2000},
  month = nov,
  journal = {International Journal of Computer Vision},
  volume = {40},
  number = {2},
  pages = {99--121},
  issn = {1573-1405},
  doi = {10.1023/A:1026543900054},
  url = {https://doi.org/10.1023/A:1026543900054},
  urldate = {2022-05-24},
  abstract = {We investigate the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval. The EMD is based on the minimal cost that must be paid to transform one distribution into the other, in a precise sense, and was first proposed for certain vision problems by Peleg, Werman, and Rom. For image retrieval, we combine this idea with a representation scheme for distributions that is based on vector quantization. This combination leads to an image comparison framework that often accounts for perceptual similarity better than other previously proposed methods. The EMD is based on a solution to the transportation problem from linear optimization, for which efficient algorithms are available, and also allows naturally for partial matching. It is more robust than histogram matching techniques, in that it can operate on variable-length representations of the distributions that avoid quantization and other binning problems typical of histograms. When used to compare distributions with the same overall mass, the EMD is a true metric. In this paper we focus on applications to color and texture, and we compare the retrieval performance of the EMD with that of other distances.},
  langid = {english},
  keywords = {color,Earth Mover's Distance,image retrieval,perceptual metrics,texture},
  file = {/Users/kshitijgoel/Zotero/storage/SN2S5B8S/Rubner et al. - 2000 - The Earth Mover's Distance as a Metric for Image R.pdf}
}

@article{ruckin_informative_2023,
  title = {An {{Informative Path Planning Framework}} for {{Active Learning}} in {{UAV-Based Semantic Mapping}}},
  author = {R{\"u}ckin, Julius and Magistri, Federico and Stachniss, Cyrill and Popovi{\'c}, Marija},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--18},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3313811},
  url = {https://ieeexplore.ieee.org/document/10264196/},
  urldate = {2023-11-29},
  abstract = {Unmanned aerial vehicles (UAVs) are frequently used for aerial mapping and general monitoring tasks. Recent progress in deep learning enabled automated semantic segmentation of imagery to facilitate the interpretation of large-scale complex environments. Commonly used supervised deep learning for segmentation relies on large amounts of pixelwise labeled data, which is tedious and costly to annotate. The domain-specific visual appearance of aerial environments often prevents the usage of models pretrained on publicly available datasets. To address this, we propose a novel general planning framework for UAVs to autonomously acquire informative training images for model retraining. We leverage multiple acquisition functions and fuse them into probabilistic terrain maps. Our framework combines the mapped acquisition function information into the UAV's planning objectives. In this way, the UAV adaptively acquires informative aerial images to be manually labeled for model retraining. Experimental results on real-world data and in a photorealistic simulation show that our framework maximizes model performance and drastically reduces labeling efforts. Our map-based planners outperform state-of-the-art local planning.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BT4ETGVM/Rückin et al. - 2023 - An Informative Path Planning Framework for Active .pdf}
}

@inproceedings{rudin_learning_2022,
  title = {Learning to {{Walk}} in {{Minutes Using Massively Parallel Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  author = {Rudin, Nikita and Hoeller, David and Reist, Philipp and Hutter, Marco},
  year = {2022},
  month = jan,
  pages = {91--100},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v164/rudin22a.html},
  urldate = {2025-02-28},
  abstract = {In this work, we present and study a training set-up that achieves fast policy generation for real-world robotic tasks by using massive parallelism on a single workstation GPU. We analyze and discuss the impact of different training algorithm components in the massively parallel regime on the final policy performance and training times. In addition, we present a novel game-inspired curriculum that is well suited for training with thousands of simulated robots in parallel. We evaluate the approach by training the quadrupedal robot ANYmal to walk on challenging terrain. The parallel approach allows training policies for flat terrain in under four minutes, and in twenty minutes for uneven terrain. This represents a speedup of multiple orders of magnitude compared to previous work. Finally, we transfer the policies to the real robot to validate the approach. We open-source our training code to help accelerate further research in the field of learned legged locomotion: https://leggedrobotics.github.io/legged\_gym/.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KKLN7KIS/Rudin et al. - 2022 - Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning.pdf}
}

@article{runnalls_kullbackleibler_2007,
  title = {Kullback-{{Leibler Approach}} to {{Gaussian Mixture Reduction}}},
  author = {Runnalls, A.R.},
  year = {2007},
  month = jul,
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  volume = {43},
  number = {3},
  pages = {989--999},
  issn = {1557-9603},
  doi = {10.1109/TAES.2007.4383588},
  url = {https://ieeexplore.ieee.org/document/4383588},
  urldate = {2024-07-14},
  abstract = {A common problem in multi-target tracking is to approximate a Gaussian mixture by one containing fewer components; similar problems can arise in integrated navigation. A common approach is successively to merge pairs of components, replacing the pair with a single Gaussian component whose moments up to second order match those of the merged pair. Salmond [1] and Williams [2, 3] have each proposed algorithms along these lines, but using different criteria for selecting the pair to be merged at each stage. The paper shows how under certain circumstances each of these pair-selection criteria can give rise to anomalous behaviour, and proposes that a key consideration should the the Kullback-Leibler (KL) discrimination of the reduced mixture with respect to the original mixture. Although computing this directly would normally be impractical, the paper shows how an easily computed upper bound can be used as a pair-selection criterion which avoids the anomalies of the earlier approaches. The behaviour of the three algorithms is compared using a high-dimensional example drawn from terrain-referenced navigation.},
  keywords = {Distributed computing,Electronic mail,Gaussian distribution,Inertial navigation,Merging,Probability,Statistical analysis,Target tracking,Upper bound},
  file = {/Users/kshitijgoel/Zotero/storage/V69562FG/Runnalls - 2007 - Kullback-Leibler Approach to Gaussian Mixture Reduction.pdf;/Users/kshitijgoel/Zotero/storage/KUWRHNNQ/4383588.html}
}

@article{russell_provably_1994,
  title = {Provably {{Bounded-Optimal Agents}}},
  author = {Russell, S. J. and Subramanian, D.},
  year = {1994},
  journal = {Journal of Artificial Intelligence Research},
  volume = {2},
  pages = {575--609},
  issn = {1076-9757},
  doi = {10.1613/jair.133},
  url = {https://www.jair.org/index.php/jair/article/view/10134},
  urldate = {2025-02-14},
  abstract = {Since its inception, artificial intelligence has relied  upon a theoretical foundation centered around  perfect rationality  as   the desired property of intelligent systems. We argue, as others have   done, that this foundation is inadequate because it imposes   fundamentally unsatisfiable requirements. As a result, there has   arisen a wide gap between theory and practice in AI, hindering   progress in the field. We propose instead a property called  bounded   optimality. Roughly speaking, an agent is bounded-optimal if its   program is a solution to the constrained optimization problem   presented by its architecture and the task environment. We show how to   construct agents with this property for a simple class of machine   architectures in a broad class of real-time environments. We   illustrate these results using a simple model of an automated mail   sorting facility.  We also define a weaker property,  asymptotic   bounded optimality (ABO), that generalizes the notion of optimality in   classical complexity theory.  We then construct  universal  ABO   programs, i.e., programs that are ABO no matter what real-time   constraints are applied.  Universal ABO programs can be used as   building blocks for more complex systems. We conclude with a   discussion of the prospects for bounded optimality as a theoretical   basis for AI, and relate it to similar trends in philosophy,   economics, and game theory.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IDGKQFR3/Russell and Subramanian - 1994 - Provably Bounded-Optimal Agents.pdf}
}

@inproceedings{ryll_semantic_2020,
  title = {Semantic {{Trajectory Planning}} for {{Long-Distant Unmanned Aerial Vehicle Navigation}} in {{Urban Environments}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ryll, Markus and Ware, John and Carter, John and Roy, Nick},
  year = {2020},
  month = oct,
  pages = {1551--1558},
  publisher = {IEEE},
  address = {Las Vegas, NV, USA},
  doi = {10.1109/IROS45743.2020.9341441},
  url = {https://ieeexplore.ieee.org/document/9341441/},
  urldate = {2024-02-23},
  abstract = {There has been a considerable amount of recent work on high-speed micro-aerial vehicle flight in unknown and unstructured environments. Generally these approaches either use active sensing or fly slowly enough to ensure a safe braking distance with the relatively short sensing range of passive sensors. The former generally requires carrying large and heavy LIDARs and the latter only allows flight far away from the dynamic limits of the vehicle. One of the significant challenges for high-speed flight is the computational demand of trajectory planning at sufficiently high rates and length scales required in outdoor environments. We tackle both problems in this work by leveraging semantic information derived from an RGB camera on-board the vehicle. We first describe how to use semantic information to increase the effective range of perception on certain environment classes. Second, we present a sparse representation of the environment that is sufficiently lightweight for long distance path planning. We show how our approach outperforms more traditional metric planners which seek the shortest path, demonstrate the semantic planner's capabilities in a set of simulated and excessive real-world autonomous quadrotor flights in an urban environment.},
  isbn = {978-1-7281-6212-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/TXWJZU49/Ryll et al. - 2020 - Semantic Trajectory Planning for Long-Distant Unma.pdf}
}

@article{saarinen_3d_2013,
  title = {{{3D}} Normal Distributions Transform Occupancy Maps: {{An}} Efficient Representation for Mapping in Dynamic Environments},
  shorttitle = {{{3D}} Normal Distributions Transform Occupancy Maps},
  author = {Saarinen, Jari P. and Andreasson, Henrik and Stoyanov, Todor and Lilienthal, Achim J.},
  year = {2013},
  month = dec,
  journal = {The International Journal of Robotics Research},
  volume = {32},
  number = {14},
  pages = {1627--1644},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364913499415},
  url = {https://doi.org/10.1177/0278364913499415},
  urldate = {2022-03-25},
  abstract = {In order to enable long-term operation of autonomous vehicles in industrial environments numerous challenges need to be addressed. A basic requirement for many applications is the creation and maintenance of consistent 3D world models. This article proposes a novel 3D spatial representation for online real-world mapping, building upon two known representations: normal distributions transform (NDT) maps and occupancy grid maps. The proposed normal distributions transform occupancy map (NDT-OM) combines the advantages of both representations; compactness of NDT maps and robustness of occupancy maps. One key contribution in this article is that we formulate an exact recursive updates for NDT-OMs. We show that the recursive update equations provide natural support for multi-resolution maps. Next, we describe a modification of the recursive update equations that allows adaptation in dynamic environments. As a second key contribution we introduce NDT-OMs and formulate the occupancy update equations that allow to build consistent maps in dynamic environments. The update of the occupancy values are based on an efficient probabilistic sensor model that is specially formulated for NDT-OMs. In several experiments with a total of 17 hours of data from a milk factory we demonstrate that NDT-OMs enable real-time performance in large-scale, long-term industrial setups.},
  langid = {english},
  keywords = {3D mapping,Mobile robotics,normal distributions transform,occupancy mapping},
  file = {/Users/kshitijgoel/Zotero/storage/BYN8JK8W/Saarinen et al. - 2013 - 3D normal distributions transform occupancy maps .pdf}
}

@inproceedings{saarinen_fast_2013,
  title = {Fast {{3D}} Mapping in Highly Dynamic Environments Using Normal Distributions Transform Occupancy Maps},
  booktitle = {2013 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Saarinen, Jari and Stoyanov, Todor and Andreasson, Henrik and Lilienthal, Achim J.},
  year = {2013},
  month = nov,
  pages = {4694--4701},
  issn = {2153-0866},
  doi = {10.1109/IROS.2013.6697032},
  abstract = {Autonomous vehicles operating in real-world industrial environments have to overcome numerous challenges, chief among which is the creation and maintenance of consistent 3D world models. This paper focuses on a particularly important challenge: mapping in dynamic environments. We introduce several improvements to the recently proposed Normal Distributions Transform Occupancy Map (NDT-OM) aimed for efficient mapping in dynamic environments. A careful consistency analysis is given based on convergence and similarity metrics specifically designed for evaluation of NDT maps in dynamic environments. We show that in the context of mapping with known poses the proposed method results in improved consistency and in superior runtime performance, when compared against 3D occupancy grids at the same size and resolution. Additionally, we demonstrate that NDT-OM features real-time performance in a highly dynamic 3D mapping and tracking scenario with centimeter accuracy over a 1.5km trajectory.},
  keywords = {Accuracy,Gaussian distribution,Robots,Sensors,Three-dimensional displays,Transforms,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/7HNWBGBW/Saarinen et al. - 2013 - Fast 3D mapping in highly dynamic environments usi.pdf;/Users/kshitijgoel/Zotero/storage/XACDZR2A/6697032.html}
}

@inproceedings{saarinen_normal_2013,
  title = {Normal {{Distributions Transform Occupancy Maps}}: {{Application}} to Large-Scale Online {{3D}} Mapping},
  shorttitle = {Normal {{Distributions Transform Occupancy Maps}}},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Saarinen, Jari and Andreasson, Henrik and Stoyanov, Todor and {Ala-Luhtala}, Juha and Lilienthal, Achim J.},
  year = {2013},
  month = may,
  pages = {2233--2238},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6630878},
  abstract = {Autonomous vehicles operating in real-world industrial environments have to overcome numerous challenges, chief among which is the creation and maintenance of consistent 3D world models. This paper proposes to address the challenges of online real-world mapping by building upon previous work on compact spatial representation and formulating a novel 3D mapping approach - the Normal Distributions Transform Occupancy Map (NDT-OM). The presented algorithm enables accurate real-time 3D mapping in large-scale dynamic environments employing a recursive update strategy. In addition, the proposed approach can seamlessly provide maps at multiple resolutions allowing for fast utilization in high-level functions such as localization or path planning. Compared to previous approaches that use the NDT representation, the proposed NDT-OM formulates an exact and efficient recursive update formulation and models the full occupancy of the map.},
  keywords = {Accuracy,Erbium,Gaussian distribution,Real-time systems,Sensors,Three-dimensional displays,Transforms},
  file = {/Users/kshitijgoel/Zotero/storage/KXEEMIDJ/Saarinen et al. - 2013 - Normal Distributions Transform Occupancy Maps App.pdf;/Users/kshitijgoel/Zotero/storage/J77Q6EPB/6630878.html}
}

@inproceedings{sachdeva_autonomy_2022,
  title = {Autonomy and {{Perception}} for {{Space Mining}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Sachdeva, Ragav and Hammond, Ravi and Bockman, James and Arthur, Alec and Smart, Brandon and Craggs, Dustin and Doan, Anh-Dzung and Rowntree, Thomas and Schutz, Elijah and Orenstein, Adrian and Yu, Andy and Chin, Tat-Jun and Reid, Ian},
  year = {2022},
  month = may,
  pages = {4087--4093},
  doi = {10.1109/ICRA46639.2022.9811661},
  abstract = {Future Moon bases will likely be constructed using resources mined from the surface of the Moon. The difficulty of maintaining a human workforce on the Moon and communications lag with Earth means that mining will need to be conducted using collaborative robots with a high degree of autonomy. In this paper, we describe our solution for Phase 2 of the NASA Space Robotics Challenge, which provided a simulated lunar environment in which teams were tasked to develop software systems to achieve autonomous collaborative robots for mining on the Moon. Our 3rd place and innovation award winning solution shows how machine learning-enabled vision could alleviate major challenges posed by the lunar environment towards autonomous space mining, chiefly the lack of satellite positioning systems, hazardous terrain, and delicate robot interactions. A robust multi-robot coordinator was also developed to achieve long-term operation and effective collaboration between robots11A recording of our robots in action is available at [1]..},
  keywords = {Collaboration,Moon,NASA,Robot kinematics,Semantics,Software systems,Technological innovation},
  file = {/Users/kshitijgoel/Zotero/storage/MNRAPAPV/Sachdeva et al. - 2022 - Autonomy and Perception for Space Mining.pdf;/Users/kshitijgoel/Zotero/storage/B7STJ5XN/9811661.html}
}

@inproceedings{sajedi_new_2023,
  title = {A {{New Probabilistic Distance Metric}} with {{Application}} in {{Gaussian Mixture Reduction}}},
  booktitle = {{{ICASSP}} 2023 - 2023 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Sajedi, Ahmad and Lawryshyn, Yuri A. and Plataniotis, Konstantinos N.},
  year = {2023},
  month = jun,
  pages = {1--5},
  doi = {10.1109/ICASSP49357.2023.10096094},
  abstract = {This paper presents a new distance metric to compare two continuous probability density functions. The main advantage of this metric is that, unlike other statistical measurements, it can provide an analytic, closed-form expression for a mixture of Gaussian distributions while satisfying all metric properties. These characteristics enable fast, stable, and efficient calculations, which are highly desirable in real-world signal processing applications. The application in mind is Gaussian Mixture Reduction (GMR), which is widely used in density estimation, recursive tracking, and belief propagation. To address this problem, we developed a novel algorithm dubbed the Optimization-based Greedy GMR (OGGMR), which employs our metric as a criterion to approximate a high-order Gaussian mixture with a lower order. Experimental results show that the OGGMR algorithm is significantly faster and more efficient than state-of-the-art GMR algorithms while retaining the geometric shape of the original mixture.},
  keywords = {Closed-form solutions,Measurement,Mixture of Gaussian,Mixture of Gaussian Reduction,Probabilistic logic,Probabilistic Metric Distance,Probability density function,Shape,Signal processing,Signal processing algorithms},
  file = {/Users/kshitijgoel/Zotero/storage/MWRU3BG5/Sajedi et al. - 2023 - A New Probabilistic Distance Metric with Applicati.pdf;/Users/kshitijgoel/Zotero/storage/NA24Y2SD/stamp.html}
}

@misc{sanborn_euclid_2024,
  title = {Beyond {{Euclid}}: {{An Illustrated Guide}} to {{Modern Machine Learning}} with {{Geometric}}, {{Topological}}, and {{Algebraic Structures}}},
  shorttitle = {Beyond {{Euclid}}},
  author = {Sanborn, Sophia and Mathe, Johan and Papillon, Mathilde and Buracas, Domas and Lillemark, Hansen J. and Shewmake, Christian and Bertics, Abby and Pennec, Xavier and Miolane, Nina},
  year = {2024},
  month = jul,
  number = {arXiv:2407.09468},
  eprint = {2407.09468},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.09468},
  url = {http://arxiv.org/abs/2407.09468},
  urldate = {2025-06-12},
  abstract = {The enduring legacy of Euclidean geometry underpins classical machine learning, which, for decades, has been primarily developed for data lying in Euclidean space. Yet, modern machine learning increasingly encounters richly structured data that is inherently nonEuclidean. This data can exhibit intricate geometric, topological and algebraic structure: from the geometry of the curvature of space-time, to topologically complex interactions between neurons in the brain, to the algebraic transformations describing symmetries of physical systems. Extracting knowledge from such non-Euclidean data necessitates a broader mathematical perspective. Echoing the 19th-century revolutions that gave rise to non-Euclidean geometry, an emerging line of research is redefining modern machine learning with non-Euclidean structures. Its goal: generalizing classical methods to unconventional data types with geometry, topology, and algebra. In this review, we provide an accessible gateway to this fast-growing field and propose a graphical taxonomy that integrates recent advances into an intuitive unified framework. We subsequently extract insights into current challenges and highlight exciting opportunities for future development in this field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/7E3Y7WWS/Sanborn et al. - 2024 - Beyond Euclid An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Alge.pdf;/Users/kshitijgoel/Zotero/storage/X6EX3R7U/2407.html}
}

@misc{sanborn_illustrated_2024,
  title = {An {{Illustrated Guide}} to {{Modern Machine Learning}} with {{Geometric}}, {{Topological}}, and {{Algebraic Structures}}},
  author = {Sanborn, Sophia and Mathe, Johan and Papillon, Mathilde and Buracas, Domas and Lillemark, Hansen J and Shewmake, Christian and Bertics, Abby and Pennec, Xavier and Miolane, Nina},
  year = {2024},
  abstract = {The enduring legacy of Euclidean geometry underpins classical machine learning, which, for decades, has been primarily developed for data lying in Euclidean space. Yet, modern machine learning increasingly encounters richly structured data that is inherently nonEuclidean. This data can exhibit intricate geometric, topological and algebraic structure: from the geometry of the curvature of space-time, to topologically complex interactions between neurons in the brain, to the algebraic transformations describing symmetries of physical systems. Extracting knowledge from such non-Euclidean data necessitates a broader mathematical perspective. Echoing the 19th-century revolutions that gave rise to non-Euclidean geometry, an emerging line of research is redefining modern machine learning with non-Euclidean structures. Its goal: generalizing classical methods to unconventional data types with geometry, topology, and algebra. In this review, we provide an accessible gateway to this fast-growing field and propose a graphical taxonomy that integrates recent advances into an intuitive unified framework. We subsequently extract insights into current challenges and highlight exciting opportunities for future development in this field.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DD4S842R/Sanborn et al. - An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structure.pdf}
}

@article{sanchezmiralles_global_2004,
  title = {Global {{Path Planning}} in {{Gaussian Probabilistic Maps}}},
  author = {S{\'a}nchez Miralles, {\'A}lvaro and Sanz Bobi, Miguel {\'A}ngel},
  year = {2004},
  month = may,
  journal = {Journal of Intelligent and Robotic Systems},
  volume = {40},
  number = {1},
  pages = {89--102},
  issn = {1573-0409},
  doi = {10.1023/B:JINT.0000034339.13257.e6},
  url = {https://doi.org/10.1023/B:JINT.0000034339.13257.e6},
  urldate = {2023-10-17},
  abstract = {This paper is focused on path planning in environments modelled using continuous probabilistic maps, in particular, maps where obstacles are modelled using the sum of Gaussian distributions. Potential field and roadmap based methods are suitable for these type of maps, but they have some disadvantages. In order to attenuate the disadvantages of the previous methods, a new method has been proposed which is a mixture of them. It performs path planning based on a potential field taking into account a roadmap as a source of potential. Moreover, some experiments have been done in order to compare the performance of them.},
  langid = {english},
  keywords = {Gaussian distribution,neural network,path planning,potential field,probabilistic maps,roadmap},
  file = {/Users/kshitijgoel/Zotero/storage/Q3GQB9NR/Sánchez Miralles and Sanz Bobi - 2004 - Global Path Planning in Gaussian Probabilistic Map.pdf}
}

@inproceedings{sandstrom_pointslam_2023,
  title = {Point-{{SLAM}}: {{Dense Neural Point Cloud-based SLAM}}},
  shorttitle = {Point-{{SLAM}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Sandstr{\"o}m, Erik and Li, Yue and Van Gool, Luc and Oswald, Martin R.},
  year = {2023},
  pages = {18433--18444},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.html},
  urldate = {2024-04-22},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z9KEY986/Sandström et al. - 2023 - Point-SLAM Dense Neural Point Cloud-based SLAM.pdf}
}

@misc{sandstrom_splatslam_2024,
  title = {Splat-{{SLAM}}: {{Globally Optimized RGB-only SLAM}} with {{3D Gaussians}}},
  shorttitle = {Splat-{{SLAM}}},
  author = {Sandstr{\"o}m, Erik and Tateno, Keisuke and Oechsle, Michael and Niemeyer, Michael and Van Gool, Luc and Oswald, Martin R. and Tombari, Federico},
  year = {2024},
  month = may,
  number = {arXiv:2405.16544},
  eprint = {2405.16544},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.16544},
  urldate = {2024-05-28},
  abstract = {3D Gaussian Splatting has emerged as a powerful representation of geometry and appearance for RGB-only dense Simultaneous Localization and Mapping (SLAM), as it provides a compact dense map representation while enabling efficient and high-quality map rendering. However, existing methods show significantly worse reconstruction quality than competing methods using other 3D representations, e.g. neural points clouds, since they either do not employ global map and pose optimization or make use of monocular depth. In response, we propose the first RGB-only SLAM system with a dense 3D Gaussian map representation that utilizes all benefits of globally optimized tracking by adapting dynamically to keyframe pose and depth updates by actively deforming the 3D Gaussian map. Moreover, we find that refining the depth updates in inaccurate areas with a monocular depth estimator further improves the accuracy of the 3D reconstruction. Our experiments on the Replica, TUM-RGBD, and ScanNet datasets indicate the effectiveness of globally optimized 3D Gaussians, as the approach achieves superior or on par performance with existing RGB-only SLAM methods methods in tracking, mapping and rendering accuracy while yielding small map sizes and fast runtimes. The source code is available at https://github.com/eriksandstroem/Splat-SLAM.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/T8X8I2HD/Sandström et al. - 2024 - Splat-SLAM Globally Optimized RGB-only SLAM with 3D Gaussians.pdf}
}

@inproceedings{sangani_discrete_2023,
  title = {Discrete {{Continuous Optimization Framework}} for {{Simultaneous Clustering}} and {{Training}} in {{Mixture Models}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Sangani, Parth Vipul and Kashettiwar, Arjun Shashank and Chakraborty, Pritish and Gangula, Bhuvan Reddy and S, Durga and Ramakrishnan, Ganesh and Iyer, Rishabh K. and De, Abir},
  year = {2023},
  month = jul,
  pages = {29950--29970},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v202/sangani23a.html},
  urldate = {2024-05-06},
  abstract = {We study a new framework of learning mixture models via automatic clustering called PRESTO, wherein we optimize a joint objective function on the model parameters and the partitioning, with each model tailored to perform well on its specific cluster. In contrast to prior work, we do not assume any generative model for the data. We convert our training problem to a joint parameter estimation cum a subset selection problem, subject to a matroid span constraint. This allows us to reduce our problem into a constrained set function minimization problem, where the underlying objective is monotone and approximately submodular. We then propose a new joint discrete-continuous optimization algorithm that achieves a bounded approximation guarantee for our problem. We show that PRESTO outperforms several alternative methods. Finally, we study PRESTO in the context of resource-efficient deep learning, where we train smaller resource-constrained models on each partition and show that it outperforms existing data partitioning and model pruning/knowledge distillation approaches, which in contrast to PRESTO, require large initial (teacher) models.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Y5EY4588/Sangani et al. - 2023 - Discrete Continuous Optimization Framework for Simultaneous Clustering and Training in Mixture Model.pdf}
}

@inproceedings{sanket_morpheyes_2021,
  title = {{{MorphEyes}}: {{Variable Baseline Stereo For Quadrotor Navigation}}},
  shorttitle = {{{MorphEyes}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Sanket, Nitin J. and Singh, Chahat Deep and Asthana, Varun and Ferm{\"u}ller, Cornelia and Aloimonos, Yiannis},
  year = {2021},
  month = may,
  pages = {413--419},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561116},
  abstract = {Morphable design and depth-based visual control are two upcoming trends leading to advancements in the field of quadrotor autonomy. Stereo-cameras have struck the perfect balance of weight and accuracy of depth estimation but suffer from the problem of depth range being limited and dictated by the baseline chosen at design time. In this paper, we present a framework for quadrotor navigation based on a stereo camera system whose baseline can be adapted on-the-fly. We present a method to calibrate the system at a small number of discrete baselines and interpolate the parameters for the entire baseline range. We present an extensive theoretical analysis of calibration and synchronization errors. We showcase three different applications of such a system for quadrotor navigation: (a) flying through a forest, (b) flying through an unknown shaped/location static/dynamic gap, and (c) accurate 3D pose detection of an independently moving object. We show that our variable baseline system is more accurate and robust in all three scenarios. To our knowledge, this is the first work that applies the concept of morphable design to achieve a variable baseline stereo vision system on a quadrotor.},
  keywords = {Calibration,Forestry,Navigation,Philosophical considerations,Robot sensing systems,Three-dimensional displays,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/T2ZCY8V6/Sanket et al. - 2021 - MorphEyes Variable Baseline Stereo For Quadrotor .pdf;/Users/kshitijgoel/Zotero/storage/EGDNQ8U3/stamp.html}
}

@article{santilli_multirobot_2022,
  title = {Multirobot {{Field}} of {{View Control With Adaptive Decentralization}}},
  author = {Santilli, Matteo and Mukherjee, Pratik and Williams, Ryan K. and Gasparri, Andrea},
  year = {2022},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {4},
  pages = {2131--2150},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3142660},
  abstract = {In this article, we address the problem of coordinating the motion of a team of robots with limited field of view (FOV), which induces asymmetry in their interactions. In this context, we first propose a general coordinated motion framework for multirobot systems with triangular FOV capable of guaranteeing stability under asymmetric (directed) interactions. In deriving this framework, we illustrate that asymmetry in multirobot interactions can lead to degenerate configurations for which a fully decentralized controller may be insufficient to achieve coordination. Thus, we introduce a switching control mechanism that achieves adaptive decentralization, enabling collaborative behaviors that seek support of a centralized planner for situations that are inherently unstable (degenerate). To demonstrate the generality of our framework we provide a case study involving varying team objectives, such as topology control, that the robots can achieve with limited FOV, while remaining stable. Experimental and numerical validations based on the previously discussed case study are provided to corroborate the theoretical findings},
  keywords = {Collision avoidance,Cooperative robots,Laplace equations,limited field of view (FOV),Multi-robot systems,multirobot systems,Numerical stability,Robot kinematics,Robot sensing systems,Sensors,switching control},
  file = {/Users/kshitijgoel/Zotero/storage/QZGAUX6A/Santilli et al. - 2022 - Multirobot Field of View Control With Adaptive Dec.pdf;/Users/kshitijgoel/Zotero/storage/3VB3ZGEY/9698245.html}
}

@inproceedings{sarkka_linear_2011,
  title = {Linear {{Operators}} and {{Stochastic Partial Differential Equations}} in {{Gaussian Process Regression}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} -- {{ICANN}} 2011},
  author = {S{\"a}rkk{\"a}, Simo},
  editor = {Honkela, Timo and Duch, W{\l}odzis{\l}aw and Girolami, Mark and Kaski, Samuel},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {151--158},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-21738-8_20},
  abstract = {In this paper we shall discuss an extension to Gaussian process (GP) regression models, where the measurements are modeled as linear functionals of the underlying GP and the estimation objective is a general linear operator of the process. We shall show how this framework can be used for modeling physical processes involved in measurement of the GP and for encoding physical prior information into regression models in form of stochastic partial differential equations (SPDE). We shall also illustrate the practical applicability of the theory in a simulated application.},
  isbn = {978-3-642-21738-8},
  langid = {english},
  keywords = {Gaussian process regression,inverse problem,linear operator,stochastic partial differential equation},
  file = {/Users/kshitijgoel/Zotero/storage/MZJENQ7J/Särkkä - 2011 - Linear Operators and Stochastic Partial Differenti.pdf}
}

@inproceedings{sasaki_mode_2022,
  title = {Mode Estimation on Matrix Manifolds: {{Convergence}} and Robustness},
  shorttitle = {Mode Estimation on Matrix Manifolds},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Sasaki, Hiroaki and Hirayama, Jun-Ichiro and Kanamori, Takafumi},
  year = {2022},
  month = may,
  pages = {8056--8079},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v151/sasaki22a.html},
  urldate = {2024-06-22},
  abstract = {Data on matrix manifolds are ubiquitous on a wide range of research fields. The key issue is estimation of the modes (i.e., maxima) of the probability density function underlying the data. For instance, local modes (i.e., local maxima) can be used for clustering, while the global mode (i.e., the global maximum) is a robust alternative to the Frechet mean. Previously, to estimate the modes, an iterative method has been proposed based on a Riemannian gradient estimator and empirically showed the superior performance in clustering (Ashizawa et al., 2017). However, it has not been theoretically investigated if the iterative method is able to capture the modes based on the gradient estimator. In this paper, we propose simple iterative methods for mode estimation on matrix manifolds based on the Euclidean metric. A key contribution is to perform theoretical analysis and establish sufficient conditions for the monotonic ascending and convergence of the proposed iterative methods. In addition, for the previous method, we prove the monotonic ascending property towards a mode. Thus, our work can be also regarded as compensating for the lack of theoretical analysis in the previous method. Furthermore, the robustness of the iterative methods is theoretically investigated in terms of the breakdown point. Finally, the proposed methods are experimentally demonstrated to work well in clustering and robust mode estimation on matrix manifolds.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9HNKBSKN/Sasaki et al. - 2022 - Mode estimation on matrix manifolds Convergence and robustness.pdf}
}

@article{sassen_repulsive_2024,
  title = {Repulsive {{Shells}}},
  author = {Sassen, Josua and Schumacher, Henrik and Rumpf, Martin and Crane, Keenan},
  year = {2024},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {4},
  pages = {140:1--140:22},
  issn = {0730-0301},
  doi = {10.1145/3658174},
  url = {https://doi.org/10.1145/3658174},
  urldate = {2024-07-26},
  abstract = {This paper develops a shape space framework for collision-aware geometric modeling, where basic geometric operations automatically avoid inter-penetration. Shape spaces are a powerful tool for surface modeling, shape analysis, nonrigid motion planning, and animation, but past formulations permit nonphysical intersections. Our framework augments an existing shape space using a repulsive energy such that collision avoidance becomes a first-class property, encoded in the Riemannian metric itself. In turn, tasks like intersection-free shape interpolation or motion extrapolation amount to simply computing geodesic paths via standard numerical algorithms. To make optimization practical, we develop an adaptive collision penalty that prevents mesh self-intersection, and converges to a meaningful limit energy under refinement. The final algorithms apply to any category of shape, and do not require a dataset of examples, training, rigging, nor any other prior information. For instance, to interpolate between two shapes we need only a single pair of meshes with the same connectivity. We evaluate our method on a variety of challenging examples from modeling and animation.},
  file = {/Users/kshitijgoel/Zotero/storage/A673P94H/Sassen et al. - 2024 - Repulsive Shells.pdf}
}

@phdthesis{sassen_riemannian_2023,
  type = {Thesis},
  title = {Riemannian {{Calculus}} and {{Shape Optimization}} on the {{Space}} of {{Discrete Surfaces}}},
  author = {Sassen, Josua Raphael},
  year = {2023},
  month = jul,
  url = {https://bonndoc.ulb.uni-bonn.de/xmlui/handle/20.500.11811/10960?locale-attribute=en},
  urldate = {2024-06-19},
  abstract = {This thesis makes contributions to shape spaces and shape optimization of discrete surfaces. Discrete surfaces are triangle meshes with certain regularity and are ubiquitous in many applications in computer graphics, geometric design, and computational anatomy to name only a few. {$<$}br /{$>$} We consider the space of all immersions of a fixed discrete surface. Heeren et al. [HRS+14] used a physically-inspired metric derived from an elastic shell model to introduce the structure of a Riemannian manifold on this space resulting in the shape space of discrete shells. Rumpf and Wirth [RW15] introduced the time-discrete geodesic calculus used for this shape space. {$<$}br /{$>$} In this thesis, we show that this space can be represented as an implicit submanifold by considering the Nonlinear Rotation-Invariant Coordinates (NRIC) consisting of the vector stacking edge lengths and dihedral angles. To this end, we exploit discrete integrability conditions akin to the famous Gau{\ss}--Codazzi equations introduced by Wang, Liu, and Tong [WLT12], leading to the implicit description. Furthermore, we also show that NRIC are helpful to phrase and numerically solve geometric variational problems on discrete surfaces, especially if they involve isometry constraints. {$<$}br /{$>$} Based on the implicit representation, we propose a new method to construct submanifolds from shape datasets. We augment Principal Geodesic Analysis, an algorithm from Riemannian statistics, by a sparsity-inducing regularization leading to Sparse Principal Geodesic Analysis. The resulting sparse nonlinear modes of variation span a shape submanifold we can equip with a product structure based on decoupling modes. We propose two efficient parametrizations of this submanifold: One based on a grid-based multilinear interpolation of the Riemannian exponential map on individual factors combined affinely and one based on neural networks with an architecture and training procedure incorporating the product structure. These parametrizations are useful for (near) real-time applications in computer graphics, as demonstrated by numerical examples. {$<$}br /{$>$} Finally, we introduce a modification of the metric that moves surfaces with self-intersections infinitely far away from ones without. We will do so by leveraging the tangent-point energy, a repulsive nonlocal curvature energy for which Yu et al. [YBSC21] recently introduced an efficient discretization and numerical tools for its application in computer graphics. Our principal insight is that the graph of this energy over the space of discrete shells yields a metric as desired while retaining the appeal that geodesics provide physically-sound interpolations. This leads to the space of repulsive shells. We also propose numerical methods to compute geodesics and exponential maps on it.{$<$}br /{$>$} Additionally, we consider two shape optimization problems on discrete surfaces outside the realm of shape spaces. First, we introduce an approach to stochastic bilevel shape optimization that models, figuratively speaking, a design engineer optimizing shape parameters, a test engineer devising worst-cased load scenarios, and stochastic manufacturing inaccuracies. We develop numerical algorithms to compute solutions of the corresponding mathematical model and apply it to optimize thickness distributions on a discrete shell modeling roof-type structures. {$<$}br /{$>$} Furthermore, we consider a phase-field model for surface segmentation into equally sized parts with minimal interface length and distortion when conformally mapping the segments to the plane. To compute the distortion, we adopt the approach of Sharp and Crane [SC18] and introduce a diffuse version of the Yamabe equation used as a PDE-constraint. Finally, we discretize the resulting variational problems using finite elements and standard algorithms for nonlinear optimization.},
  copyright = {In Copyright},
  langid = {english},
  school = {Universit{\"a}ts- und Landesbibliothek Bonn},
  annotation = {Accepted: 2023-07-27T14:44:19Z},
  file = {/Users/kshitijgoel/Zotero/storage/9BJD47YG/Sassen - 2023 - Riemannian Calculus and Shape Optimization on the Space of Discrete Surfaces.pdf}
}

@inproceedings{saulnier_information_2020,
  title = {Information {{Theoretic Active Exploration}} in {{Signed Distance Fields}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Saulnier, Kelsey and Atanasov, Nikolay and Pappas, George J. and Kumar, Vijay},
  year = {2020},
  month = may,
  pages = {4080--4085},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196882},
  abstract = {This paper focuses on exploration and occupancy mapping of unknown environments using a mobile robot. While a truncated signed distance field (TSDF) is a popular, efficient, and highly accurate representation of occupancy, few works have considered optimizing robot sensing trajectories for autonomous TSDF mapping. We propose an efficient approach for maintaining TSDF uncertainty and predicting its evolution from potential future sensor measurements without actually receiving them. Efficient uncertainty prediction is critical for long-horizon optimization of potential sensing trajectories. We develop a deterministic tree-search algorithm that evaluates the information gain between the TSDF distribution and potential observations along sequences of robot motion primitives. Efficient planning is achieved by branch-and-bound pruning of uninformative sensing trajectories. The effectiveness of our active TSDF mapping approach is evaluated in several simulated environments with complex visibility constraints.},
  keywords = {Measurement uncertainty,Robot sensing systems,Standards,Trajectory,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/GT9X6RXR/Saulnier et al. - 2020 - Information Theoretic Active Exploration in Signed.pdf;/Users/kshitijgoel/Zotero/storage/Q3TEAH4I/9196882.html}
}

@phdthesis{saulnier_resilient_2022,
  title = {Resilient {{Information Theoretic Active Exploration}} for {{Multi-Robot Teams}}},
  author = {Saulnier, Kelsey L. C.},
  year = {2022},
  address = {United States -- Pennsylvania},
  url = {https://www.proquest.com/docview/2780903222/abstract/DFAE48FC68224DCCPQ/1},
  urldate = {2023-11-01},
  abstract = {Over the past decades we have seen robots move from constrained and heavily designed industrial environments out into the unstructured world. This shift drives a need for smaller, safer, and less expensive robots which can collaboratively complete tasks autonomously. For such teams to function, they must be able to reach a shared understanding of their task and environment while accommodating unreliable sensors, and also to recover gracefully from individual failures without requiring centralized coordination. These challenges are the focus of this thesis which lays the groundwork for multi-robot active mapping that is resilient to faulty or malfunctioning sensors. Such algorithms have wide ranging applicability, from persistent monitoring tasks such as those found in agriculture to time critical tasks such as search and rescue. First we present two map representations designed specifically for autonomous information theoretic mapping. For each method, we develop an information theoretic value function which can be used to choose actions to maximize the information gained about the map. We present a principled method for accounting for both information gained by exploring new areas, as well as information gained by further inspection of the existing map to account for sensor uncertainty. To address the vulnerability of local planning methods to local minima, we develop a strategy to maintain a long horizon planning tree over time. Second, we extend a highly distributed approach to resilient consensus for static networks to applications with multi-robot teams. This approach has been largely limited to small static networks or strict formations. First we develop a method which can be used for teams with time-varying range-based communication which is suitable for tasks where robots are not required to spread out in the environment. We then present a method that is well suited to mapping and coverage applications which uses a well known communication structure to guarantee successful resilient consensus. Finally we present examples of how these tools can be used to enable resilient active mapping and coverage for teams of robots with faulty or malfunctioning sensors.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798374412475},
  langid = {english},
  school = {University of Pennsylvania},
  keywords = {Exploration,Mapping,Resilience,Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/XK5JWMMW/Saulnier - 2022 - Resilient Information Theoretic Active Exploration.pdf}
}

@misc{saviolo_reactive_2024,
  title = {Reactive {{Collision Avoidance}} for {{Safe Agile Navigation}}},
  author = {Saviolo, Alessandro and Picello, Niko and Verma, Rishabh and Loianno, Giuseppe},
  year = {2024},
  month = sep,
  number = {arXiv:2409.11962},
  eprint = {2409.11962},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.11962},
  url = {http://arxiv.org/abs/2409.11962},
  urldate = {2024-12-16},
  abstract = {Reactive collision avoidance is essential for agile robots navigating complex and dynamic environments, enabling real-time obstacle response. However, this task is inherently challenging because it requires a tight integration of perception, planning, and control, which traditional methods often handle separately, resulting in compounded errors and delays. This paper introduces a novel approach that unifies these tasks into a single reactive framework using solely onboard sensing and computing. Our method combines nonlinear model predictive control with adaptive control barrier functions, directly linking perception-driven constraints to real-time planning and control. Constraints are determined by using a neural network to refine noisy RGB-D data, enhancing depth accuracy, and selecting points with the minimum time-to-collision to prioritize the most immediate threats. To maintain a balance between safety and agility, a heuristic dynamically adjusts the optimization process, preventing overconstraints in real time. Extensive experiments with an agile quadrotor demonstrate effective collision avoidance across diverse indoor and outdoor environments, without requiring environment-specific tuning or explicit mapping.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/XTKLTVA8/Saviolo et al. - 2024 - Reactive Collision Avoidance for Safe Agile Navigation.pdf;/Users/kshitijgoel/Zotero/storage/KH9682HS/2409.html}
}

@inproceedings{saviolo_unifying_2024,
  title = {Unifying {{Foundation Models}} with {{Quadrotor Control}} for {{Visual Tracking Beyond Object Categories}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Saviolo, Alessandro and Rao, Pratyaksh and Radhakrishnan, Vivek and Xiao, Jiuhong and Loianno, Giuseppe},
  year = {2024},
  month = may,
  pages = {7389--7396},
  doi = {10.1109/ICRA57147.2024.10610111},
  url = {https://ieeexplore.ieee.org/document/10610111/?arnumber=10610111},
  urldate = {2025-02-04},
  abstract = {Visual control enables quadrotors to adaptively navigate using real-time sensory data, bridging perception with action. Yet, challenges persist, including generalization across scenarios, maintaining reliability, and ensuring real-time responsiveness. This paper introduces a perception framework grounded in foundation models for universal object detection and tracking, moving beyond specific training categories. Integral to our approach is a multi-layered tracker integrated with the foundation detector, ensuring continuous target visibility, even when faced with motion blur, abrupt light shifts, and occlusions. Complementing this, we introduce a model-free controller tailored for resilient quadrotor visual tracking. Our system operates efficiently on limited hardware, relying solely on an onboard camera and an inertial measurement unit. Through extensive validation in diverse challenging indoor and outdoor environments, we demonstrate our system's effectiveness and adaptability. In conclusion, our research represents a step forward in quadrotor visual tracking, moving from task-specific methods to more versatile and adaptable operations.},
  keywords = {Object detection,Real-time systems,Reliability,Robot sensing systems,Target tracking,Training,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/YY4UHFEG/Saviolo et al. - 2024 - Unifying Foundation Models with Quadrotor Control for Visual Tracking Beyond Object Categories.pdf;/Users/kshitijgoel/Zotero/storage/M4ML5V7N/10610111.html}
}

@article{sawhney_gridfree_2022,
  title = {Grid-Free {{Monte Carlo}} for {{PDEs}} with Spatially Varying Coefficients},
  author = {Sawhney, Rohan and Seyb, Dario and Jarosz, Wojciech and Crane, Keenan},
  year = {2022},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {41},
  number = {4},
  pages = {53:1--53:17},
  issn = {0730-0301},
  doi = {10.1145/3528223.3530134},
  url = {https://dl.acm.org/doi/10.1145/3528223.3530134},
  urldate = {2024-02-15},
  abstract = {Partial differential equations (PDEs) with spatially varying coefficients arise throughout science and engineering, modeling rich heterogeneous material behavior. Yet conventional PDE solvers struggle with the immense complexity found in nature, since they must first discretize the problem---leading to spatial aliasing, and global meshing/sampling that is costly and error-prone. We describe a method that approximates neither the domain geometry, the problem data, nor the solution space, providing the exact solution (in expectation) even for problems with extremely detailed geometry and intricate coefficients. Our main contribution is to extend the walk on spheres (WoS) algorithm from constant- to variable-coefficient problems, by drawing on techniques from volumetric rendering. In particular, an approach inspired by null-scattering yields unbiased Monte Carlo estimators for a large class of 2nd order elliptic PDEs, which share many attractive features with Monte Carlo rendering: no meshing, trivial parallelism, and the ability to evaluate the solution at any point without solving a global system of equations.},
  keywords = {integral equations,Monte Carlo methods},
  file = {/Users/kshitijgoel/Zotero/storage/JSTN6N8V/Sawhney et al. - 2022 - Grid-free Monte Carlo for PDEs with spatially vary.pdf}
}

@article{sawhney_monte_2020,
  title = {Monte {{Carlo}} Geometry Processing: A Grid-Free Approach to {{PDE-based}} Methods on Volumetric Domains},
  shorttitle = {Monte {{Carlo}} Geometry Processing},
  author = {Sawhney, Rohan and Crane, Keenan},
  year = {2020},
  month = aug,
  journal = {ACM Transactions on Graphics},
  volume = {39},
  number = {4},
  pages = {123:123:1--123:123:18},
  issn = {0730-0301},
  doi = {10.1145/3386569.3392374},
  url = {https://dl.acm.org/doi/10.1145/3386569.3392374},
  urldate = {2023-09-21},
  abstract = {This paper explores how core problems in PDE-based geometry processing can be efficiently and reliably solved via grid-free Monte Carlo methods. Modern geometric algorithms often need to solve Poisson-like equations on geometrically intricate domains. Conventional methods most often mesh the domain, which is both challenging and expensive for geometry with fine details or imperfections (holes, self-intersections, etc.). In contrast, grid-free Monte Carlo methods avoid mesh generation entirely, and instead just evaluate closest point queries. They hence do not discretize space, time, nor even function spaces, and provide the exact solution (in expectation) even on extremely challenging models. More broadly, they share many benefits with Monte Carlo methods from photorealistic rendering: excellent scaling, trivial parallel implementation, view-dependent evaluation, and the ability to work with any kind of geometry (including implicit or procedural descriptions). We develop a complete "black box" solver that encompasses integration, variance reduction, and visualization, and explore how it can be used for various geometry processing tasks. In particular, we consider several fundamental linear elliptic PDEs with constant coefficients on solid regions of Rn. Overall we find that Monte Carlo methods significantly broaden the horizons of geometry processing, since they easily handle problems of size and complexity that are essentially hopeless for conventional methods.},
  keywords = {numerical methods,stochastic solvers},
  file = {/Users/kshitijgoel/Zotero/storage/HCGSLEPD/Sawhney and Crane - 2020 - Monte Carlo geometry processing a grid-free appro.pdf}
}

@phdthesis{sawhney_monte_2024,
  title = {Monte {{Carlo Geometry Processing}}: {{A Grid-Free Approach}} to {{Solving Partial Differential Equations}} on {{Volumetric Domains}}},
  author = {Sawhney, Rohan},
  year = {2024},
  month = may,
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/X6DATTF2/Sawhney - Monte Carlo Geometry Processing A Grid-Free Approach to Solving Partial Differential Equations on V.pdf}
}

@article{sawhney_walk_2023,
  title = {Walk on {{Stars}}: {{A Grid-Free Monte Carlo Method}} for {{PDEs}} with {{Neumann Boundary Conditions}}},
  shorttitle = {Walk on {{Stars}}},
  author = {Sawhney, Rohan and Miller, Bailey and Gkioulekas, Ioannis and Crane, Keenan},
  year = {2023},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {42},
  number = {4},
  pages = {80:1--80:20},
  issn = {0730-0301},
  doi = {10.1145/3592398},
  url = {https://dl.acm.org/doi/10.1145/3592398},
  urldate = {2023-09-21},
  abstract = {Grid-free Monte Carlo methods based on the walk on spheres (WoS) algorithm solve fundamental partial differential equations (PDEs) like the Poisson equation without discretizing the problem domain or approximating functions in a finite basis. Such methods hence avoid aliasing in the solution, and evade the many challenges of mesh generation. Yet for problems with complex geometry, practical grid-free methods have been largely limited to basic Dirichlet boundary conditions. We introduce the walk on stars (WoSt) algorithm, which solves linear elliptic PDEs with arbitrary mixed Neumann and Dirichlet boundary conditions. The key insight is that one can efficiently simulate reflecting Brownian motion (which models Neumann conditions) by replacing the balls used by WoS with star-shaped domains. We identify such domains via the closest point on the visibility silhouette, by simply augmenting a standard bounding volume hierarchy with normal information. Overall, WoSt is an easy modification of WoS, and retains the many attractive features of grid-free Monte Carlo methods such as progressive and view-dependent evaluation, trivial parallelization, and sublinear scaling to increasing geometric detail.},
  keywords = {Monte Carlo methods,walk on spheres},
  file = {/Users/kshitijgoel/Zotero/storage/BFRLW58N/Sawhney et al. - 2023 - Walk on Stars A Grid-Free Monte Carlo Method for .pdf}
}

@inproceedings{scaramuzza_learning_2023,
  title = {Learning {{Agile}}, {{Vision-Based Drone Flight}}: {{From Simulation}} to~{{Reality}}},
  shorttitle = {Learning {{Agile}}, {{Vision-Based Drone Flight}}},
  booktitle = {Robotics {{Research}}},
  author = {Scaramuzza, Davide and Kaufmann, Elia},
  editor = {Billard, Aude and Asfour, Tamim and Khatib, Oussama},
  year = {2023},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {11--18},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-25555-7_2},
  abstract = {We present our latest research in learning deep sensorimotor policies for agile, vision-based quadrotor flight. We show methodologies for the successful transfer of such policies from simulation to the real world. In addition, we discuss the open research questions that still need to be answered to improve the agility and robustness of autonomous drones toward human-pilot performance.},
  isbn = {978-3-031-25555-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PN7E4LKJ/Scaramuzza and Kaufmann - 2023 - Learning Agile, Vision-Based Drone Flight From Si.pdf}
}

@article{scarselli_graph_2009,
  title = {The {{Graph Neural Network Model}}},
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  year = {2009},
  month = jan,
  journal = {IEEE Transactions on Neural Networks},
  volume = {20},
  number = {1},
  pages = {61--80},
  issn = {1941-0093},
  doi = {10.1109/TNN.2008.2005605},
  url = {https://ieeexplore.ieee.org/document/4700287/?arnumber=4700287},
  urldate = {2025-01-03},
  abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
  keywords = {Biological system modeling,Biology,Chemistry,Computer vision,Data engineering,Data mining,graph neural networks (GNNs),graph processing,Graphical domains,Neural networks,Parameter estimation,Pattern recognition,recursive neural networks,Supervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/TADYJ6HH/Scarselli et al. - 2009 - The Graph Neural Network Model.pdf;/Users/kshitijgoel/Zotero/storage/LVYTZ8FH/4700287.html}
}

@article{schaub_probabilistic_2022,
  title = {Probabilistic {{Fusion}} of {{Depth Maps With}} a {{Reliable Estimation}} of the {{Local Reconstruction Quality}}},
  author = {Schaub, H. and Sch{\"o}ttl, A. and Hoh, M.},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {11982--11989},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3208371},
  url = {https://ieeexplore.ieee.org/document/9896932},
  urldate = {2024-06-06},
  abstract = {Depth sensors in general, but especially consumer level sensors, have noise characteristics that are difficult to generalize due to external factors such as material specific properties or varying lighting conditions. The quality of the reconstructed surface from fused depth data may therefore vary and some surface segments may be more accurately reconstructed than others. High average accuracy is important but it must be supported by an estimation of the local quality if subsequent algorithms, such as robotic grasping, use the surface reconstruction. We propose a novel approach which models sensor noise depending on local object properties and incrementally refines surface estimations using Bayesian updates. Experiments demonstrate that our algorithm reconstructs challenging scenes of the ROBI dataset (Yang et al., 2021) with comparatively high accuracy and significantly fewer outliers. We additionally provide a reliable, local estimation of the surface uncertainty.},
  keywords = {grasping,Image reconstruction,Measurement uncertainty,Noise measurement,Probabilistic logic,probability and statistical methods,RGB-D perception,sensor fusion,Sensor phenomena and characterization,Surface reconstruction,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/F8ZNE2S4/Schaub et al. - 2022 - Probabilistic Fusion of Depth Maps With a Reliable Estimation of the Local Reconstruction Quality.pdf;/Users/kshitijgoel/Zotero/storage/JPC2U5M8/9896932.html}
}

@article{schaub_probabilistic_2024,
  title = {Probabilistic {{Closed-Loop Active Grasping}}},
  author = {Schaub, Henry and Wolff, Christian and Hoh, Maximilian and Sch{\"o}ttl, Alfred},
  year = {2024},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {4},
  pages = {3964--3971},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3371328},
  url = {https://ieeexplore.ieee.org/document/10452789},
  urldate = {2024-06-06},
  abstract = {Picking a specific object is an essential task of assistive robotics. While the majority of grasp detection approaches focus on grasp synthesis from a single depth image or point cloud, this approach is often not viable in an unstructured, uncontrolled environment. Due to occlusion, heavy influence of noise or simply because no collision-free grasp is visible from some perspectives, it is beneficial to collect additional information from other views before opting for grasp execution. We present a closed-loop approach that selects and navigates towards the next-best-view by minimizing the entropy of the volume under consideration. We use a local measure of estimation uncertainty of the surface reconstruction, to sample grasps and estimate their success probabilities in an online fashion. Our experiments show that our algorithm achieves better grasp success rates than comparable approaches, when presented with challenging household objects.},
  keywords = {Assistive robots,Entropy,Estimation,Grasping,manipulators,Noise measurement,Probabilistic logic,robot motion,robot sensing systems,Robot sensing systems,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/CL5ZV8C6/Schaub et al. - 2024 - Probabilistic Closed-Loop Active Grasping.pdf;/Users/kshitijgoel/Zotero/storage/WLK5EF4X/10452789.html}
}

@inproceedings{scheiber_midair_2021,
  title = {Mid-{{Air Range-Visual-Inertial Estimator Initialization}} for {{Micro Air Vehicles}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Scheiber, Martin and Delaune, Jeff and Weiss, Stephan and Brockers, Roland},
  year = {2021},
  month = may,
  pages = {7613--7619},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9560913},
  abstract = {Monocular Visual-Inertial Odometry (VIO) has become ubiquitous for navigation of autonomous Micro Air Vehicles (MAVs). Yet, state-of-the-art VIO is still very failure-prone, which can have dramatic consequences. To prevent this, VIO must be able to re-initialize in mid-air, either during a free fall or on a constant velocity trajectory after attitude control has been re-established. However, for both of these trajectories, the visual scale cannot be observed with VIO batch initializers because of the absence of acceleration change. We propose to use a small and lightweight laser-range finder (LRF) and a scene facet model to initialize vision-based navigation at the right scale under any motion condition and over any scene structure. This new range constraint is integrated into a visual-inertial bundle-adjustment initializer. We evaluate our approach in simulation, including robustness to various parameters, and demonstrate on real data how this approach can address midair state estimation failure in real-time.},
  keywords = {Monte Carlo methods,Navigation,Real-time systems,Robot sensing systems,Robustness,Unmanned aerial vehicles,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/CURBIHEL/Scheiber et al. - 2021 - Mid-Air Range-Visual-Inertial Estimator Initializa.pdf}
}

@article{scherer_resilient_2022,
  title = {Resilient and {{Modular Subterranean Exploration}} with a {{Team}} of {{Roving}} and {{Flying Robots}}},
  author = {Scherer, Sebastian},
  year = {2022},
  journal = {Field Robotics},
  url = {https://fieldrobotics.net/Field_Robotics/SI_DARPA_SubT_files/Vol2_23.pdf},
  abstract = {Subterranean robot exploration is difficult, with many mobility, communications, and navigation challenges that require an approach with a diverse set of systems, and reliable autonomy. While prior work has demonstrated partial successes in addressing the problem, here we convey a comprehensive approach to address the problem of subterranean exploration in a wide range of tunnel, urban, and cave environments. Our approach is driven by the themes of resiliency and modularity, and we show examples of how these themes influence the design of the different modules. In particular, we detail our approach to artifact detection, pose estimation, coordination, planning, control, and autonomy, and we discuss our performance in the tunnel, urban, and self-organized cave circuits of the DARPA Subterranean Challenge. Our approach led to a winning result in the tunnel circuit, and placing second in the urban circuit event. We convey lessons learned in designing and testing a resilient system for subterranean exploration that can generalize to a large range of operating conditions, and potential improvements for the future.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ENI7TXWY/Scherer - 2022 - Resilient and Modular Subterranean Exploration wit.pdf}
}

@inproceedings{scheuermann_feature_2011,
  title = {Feature {{Quarrels}}: {{The Dempster-Shafer Evidence Theory}} for {{Image Segmentation Using}} a {{Variational Framework}}},
  shorttitle = {Feature {{Quarrels}}},
  booktitle = {Computer {{Vision}} -- {{ACCV}} 2010},
  author = {Scheuermann, Bj{\"o}rn and Rosenhahn, Bodo},
  editor = {Kimmel, Ron and Klette, Reinhard and Sugimoto, Akihiro},
  year = {2011},
  pages = {426--439},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19309-5_33},
  abstract = {Image segmentation is the process of partitioning an image into at least two regions. Usually, active contours or level set based image segmentation methods combine different feature channels, arising from the color distribution, texture or scale information, in an energy minimization approach. In this paper, we integrate the Dempster-Shafer evidence theory in level set based image segmentation to fuse the information (and resolve conflicts) arising from different feature channels. They are further combined with a smoothing term and applied to the signed distance function of an evolving contour. In several experiments we demonstrate the properties and advantages of using the Dempster-Shafer evidence theory in level set based image segmentation.},
  isbn = {978-3-642-19309-5},
  langid = {english},
  keywords = {Active Contour,Bayesian Model,Belief Function,Feature Channel,Image Segmentation},
  file = {/Users/kshitijgoel/Zotero/storage/CTHTUMTG/Scheuermann and Rosenhahn - 2011 - Feature Quarrels The Dempster-Shafer Evidence Theory for Image Segmentation Using a Variational Fra.pdf}
}

@article{schlotfeldt_anytime_2018,
  title = {Anytime {{Planning}} for {{Decentralized Multirobot Active Information Gathering}}},
  author = {Schlotfeldt, Brent and Thakur, Dinesh and Atanasov, Nikolay and Kumar, Vijay and Pappas, George J.},
  year = {2018},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {2},
  pages = {1025--1032},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2794608},
  url = {https://ieeexplore.ieee.org/document/8260881},
  urldate = {2024-11-15},
  abstract = {This letter considers the problem of reducing uncertainty about a physical process of interest by designing sensing trajectories for a team of robots. This active information gathering problem has applications in environmental monitoring, search and rescue, and security and surveillance. Our previous work developed a search-based planning method for information gathering which prunes uninformative trajectories from the search space while providing suboptimality guarantees and decentralizes the planning across multiple robots via coordinate descent. The novelty of this letter is to demonstrate the practical feasibility of these algorithms in a target tracking scenario featuring three collaborating UAVs and five mobile targets. To achieve this, we relax the previous requirement of having centralized estimation by performing distributed information filtering. We then develop an anytime planning algorithm that progressively reduces the suboptimality of the information gathering plans while respecting real-time constraints. These contributions enable robust and scalable information gathering using a team of agile robots that adapt their cooperation to timing constraints and ad hoc communication without the need for external or centralized computation.},
  keywords = {Estimation,motion and path planning,multi-robot systems,Planning,Reactive and sensor-based planning,Robot kinematics,Robot sensing systems,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/789ZYJLP/Schlotfeldt et al. - 2018 - Anytime Planning for Decentralized Multirobot Active Information Gathering.pdf;/Users/kshitijgoel/Zotero/storage/K5NR57MR/8260881.html}
}

@article{schmid_efficient_2020,
  title = {An {{Efficient Sampling-Based Method}} for {{Online Informative Path Planning}} in {{Unknown Environments}}},
  author = {Schmid, Lukas and Pantic, Michael and Khanna, Raghav and Ott, Lionel and Siegwart, Roland and Nieto, Juan},
  year = {2020},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {1500--1507},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.2969191},
  abstract = {The ability to plan informative paths online is essential to robot autonomy. In particular, sampling-based approaches are often used as they are capable of using arbitrary information gain formulations. However, they are prone to local minima, resulting in sub-optimal trajectories, and sometimes do not reach global coverage. In this letter, we present a new RRT*-inspired online informative path planning algorithm. Our method continuously expands a single tree of candidate trajectories and rewires nodes to maintain the tree and refine intermediate paths. This allows the algorithm to achieve global coverage and maximize the utility of a path in a global context, using a single objective function. We demonstrate the algorithm's capabilities in the applications of autonomous indoor exploration as well as accurate Truncated Signed Distance Field (TSDF)-based 3D reconstruction on-board a Micro Aerial Vehicle (MAV). We study the impact of commonly used information gain and cost formulations in these scenarios and propose a novel TSDF-based 3D reconstruction gain and cost-utility formulation. Detailed evaluation in realistic simulation environments show that our approach outperforms sampling-based state of the art methods in these tasks. Experiments on a real MAV demonstrate the ability of our method to robustly plan in real-time, exploring an indoor environment with on-board sensing and computation. We make our framework available for future research.},
  keywords = {aerial systems,Linear programming,Motion and path planning,perception and autonomy,Planning,reactive and sensor-based planning,Robots,Surface reconstruction,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/BPWAHAXH/Schmid et al. - 2020 - An Efficient Sampling-Based Method for Online Info.pdf;/Users/kshitijgoel/Zotero/storage/MTZN4EZ5/8968434.html}
}

@inproceedings{schmid_khronos_2024,
  title = {Khronos: {{A Unified Approach}} for {{Spatio-Temporal Metric-Semantic SLAM}} in {{Dynamic Environments}}},
  shorttitle = {Khronos},
  booktitle = {Robotics: {{Science}} and {{Systems XX}}},
  author = {Schmid, Lukas and Abate, Marcus and Chang, Yun and Carlone, Luca},
  year = {2024},
  month = jul,
  volume = {20},
  url = {https://www.roboticsproceedings.org/rss20/p081.html},
  urldate = {2024-10-14},
  isbn = {979-8-9902848-0-7},
  file = {/Users/kshitijgoel/Zotero/storage/EX36MMCJ/Schmid et al. - 2024 - Khronos A Unified Approach for Spatio-Temporal Metric-Semantic SLAM in Dynamic Environments.pdf}
}

@inproceedings{schmid_panoptic_2022,
  title = {Panoptic {{Multi-TSDFs}}: A {{Flexible Representation}} for {{Online Multi-resolution Volumetric Mapping}} and {{Long-term Dynamic Scene Consistency}}},
  shorttitle = {Panoptic {{Multi-TSDFs}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Schmid, Lukas and Delmerico, Jeffrey and Sch{\"o}nberger, Johannes L. and Nieto, Juan and Pollefeys, Marc and Siegwart, Roland and Cadena, Cesar},
  year = {2022},
  month = may,
  pages = {8018--8024},
  doi = {10.1109/ICRA46639.2022.9811877},
  abstract = {For robotic interaction in environments shared with other agents, access to volumetric and semantic maps of the scene is crucial. However, such environments are inevitably subject to long-term changes, which the map needs to account for. We thus propose panoptic multi-TSDFs as a novel representation for multi-resolution volumetric mapping in changing environments. By leveraging high-level information for 3D reconstruction, our proposed system allocates high resolution only where needed. Through reasoning on the object level, semantic consistency over time is achieved. This enables our method to maintain up-to-date reconstructions with high accuracy while improving coverage by incorporating previous data. We show in thorough experimental evaluation that our map can be efficiently constructed, maintained, and queried during online operation, and that the presented approach can operate robustly on real depth sensors using non-optimized panoptic segmentation as input.},
  keywords = {Automation,Cognition,Hardware,Robots,Semantics,Sensors,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/YHY6T65E/Schmid et al. - 2022 - Panoptic Multi-TSDFs a Flexible Representation fo.pdf;/Users/kshitijgoel/Zotero/storage/L6RR83GM/9811877.html}
}

@phdthesis{schmid_robust_2022,
  type = {Doctoral {{Thesis}}},
  title = {Robust {{Active Perception}} and {{Volumetric Mapping}} in {{Unknown Changing Environments}}},
  author = {Schmid, Lukas},
  year = {2022},
  doi = {10.3929/ethz-b-000583169},
  url = {https://www.research-collection.ethz.ch/handle/20.500.11850/583169},
  urldate = {2023-03-16},
  abstract = {Autonomous mobile robots have the potential to profoundly impact and transform numerous applications, ranging from search and rescue, to autonomous inspection, industrial and warehouse robotics, augmented and virtual reality applications, as well as personal and service robotics. For all these applications, the ability to perceive and model one's environment in a map is a crucial component in order to meaningfully interact with it. Maps for interaction enable capabilities such as collision avoidance, navigation, manipulation, or planning, which are fundamental building blocks of robot autonomy. Furthermore, since robots are embodied agents, they can actively move to perceive and incrementally map their surroundings, enabling autonomous robot application in previously unknown scenes.  However, reliable modeling of complex real world environments on an autonomous robot is a challenging problem for several reasons. First, there is noise in the sensor measurements and pose tracking. Second, the robot state estimate can drift over time, leading to spatial inconsistency in the map. Furthermore, real environments that are shared with other agents oftentimes change over time, leading to temporal inconsistencies. Lastly, the robot needs to be able to efficiently and safely navigate in unknown environments in order to map them.  This additionally puts a constraint on both mapping and planning, requiring operation in real time on computationally constrained mobile hardware.  The research question addressed in this thesis is thus twofold. First, we investigate what optimal representations for the map are, that can tackle the problems mentioned above. Second, we investigate how to autonomously map unknown and complex environments efficiently and safely.  Motivated by the human capabilities to deal with these problems, the central approach of this thesis is to explore how scene understanding in different forms can facilitate both mapping and planning.  We first explore scene understanding as classical geometry, and develop a general framework for view-based informative path planning in unknown environments.  The proposed system continuously adapts its path to maximize any given information gain against a given cost within global context, using a parameter-free optimization formulation. We then use the map update rule to derive a novel information gain significantly improving the accuracy of the obtained 3D reconstruction.  We further present a submap-based multi-layer mapping approach for active perception with drifting state estimates. Our approach uses locally consistent submaps to be able to account for past pose corrections and augments this global map with both a spatially and a temporally local mapping layer for effective planning. Based on this, we develop a planning approach for safe and efficient constant-time local view planning, and for guaranteeing complete global coverage, both with a changing global map.  The second part explores scene understanding as the recognition of prior beliefs, that can be learned from data. Here, we first address the challenge of high computational requirements in sampling-based view planning by proposing a method to learn the underlying informed distribution of high utility views from the robot map. This approach significantly speeds up computation and achieves strong exploration performance, as only few candidates need to be evaluated to reliably identify good view points.  We then tackle the challenge of representing complex geometry amid noisy measurements and propose a novel volumetric mapping approach based on neural implicit representations that can leverage the spatial context within the large voxels represented by a single neural code together with deep learnt shape priors to reliably fuse noisy measurements. Even in the presence of sensing errors and notable pose tracking inaccuracy, this system can well capture and represent the underlying geometry, also of thin objects that are not well captured in traditional methods.  Lastly, we explore the capabilities of explicit semantic scene understanding. We address a major limitation when exploring unknown scenes, being that the robot has to operate on the limited information available at each time step, and propose an approach that leverages semantic scene completion to predict what the unknown environment might look like. This additional information can reasonably fill in holes in the reconstruction, significantly speeding up coverage of a scene with only minimal decrease in map accuracy. In addition, it can also be used to guide the robot to choose more informative paths, notably speeding up the measurement of the environment with the sensors of the robot.  Eventually, we tackle the challenge of temporal consistency in volumetric maps by developing an object-centric map representation modeling the world as a set of temporally and semantically consistent object submaps. This allows efficient reasoning about scene persistence or changes on this abstract level, guaranteeing semantic and temporal consistency of the map, and enables direct spatio-temporal map queries for interaction planning.  In summary, we identify and tackle major challenges in robust volumetric mapping and active perception in complex unknown environments. Our contributions include the development of the first approach for volumetric exploration subject to state estimation drift, the first approach for incremental robotic volumetric mapping directly on neural implicit representations, and the first online volumetric mapping method with long-term temporal consistency. We further present a new approach for general view-based informative path planning in unknown environments, and propose novel ways to safely combine learning with exploration planning, by proposing to learn the components of sampling-based exploration and integrating semantic scene completion into the exploration pipeline. Our contributions together constitute the components of a complete pipeline for autonomous perception and mapping in complex environments, addressing the challenges pointed out and bringing such systems closer to reliable autonomous application in the challenging conditions outside the research lab. We show that scene understanding in various forms can be a key component in addressing these challenges, and that these approaches can successfully be deployed on different aerial and ground robots using solely mobile hardware.},
  copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
  langid = {english},
  school = {ETH Zurich},
  annotation = {Accepted: 2022-11-28T07:20:27Z},
  file = {/Users/kshitijgoel/Documents/downloaded_papers/thesis/lukas_schmid_phd.pdf;/Users/kshitijgoel/Zotero/storage/29TA8CKM/Schmid - 2022 - Robust Active Perception and Volumetric Mapping in.pdf}
}

@article{schmid_unified_2021,
  title = {A {{Unified Approach}} for {{Autonomous Volumetric Exploration}} of {{Large Scale Environments Under Severe Odometry Drift}}},
  author = {Schmid, Lukas and Reijgwart, Victor and Ott, Lionel and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
  year = {2021},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4504--4511},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3068954},
  abstract = {Exploration is a fundamental problem in robot autonomy. A major limitation, however, is that during exploration robots oftentimes have to rely on on-board systems alone for state estimation, accumulating significant drift over time in large environments. Drift can be detrimental to robot safety and exploration performance. In this work, a submap-based, multi-layer approach for both mapping and planning is proposed to enable safe and efficient volumetric exploration of large scale environments despite odometry drift. The central idea of our approach combines local (temporally and spatially) and global mapping to guarantee safety and efficiency. Similarly, our planning approach leverages the presented map to compute global volumetric frontiers in a changing global map and utilizes the nature of exploration dealing with partial information for efficient local and global planning. The presented system is thoroughly evaluated and shown to outperform state of the art methods even under drift-free conditions. Our system, termed GLocal, is made available open source.},
  keywords = {Aerial systems,motion and path planning,Optimization,perception and autonomy,Planning,reactive and sensor-based planning,Safety,Search problems,Simultaneous localization and mapping,Task analysis,Two dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/T7DCIXIN/Schmid et al. - 2021 - A Unified Approach for Autonomous Volumetric Explo.pdf}
}

@article{schneider_maplab_2018,
  title = {Maplab: {{An Open Framework}} for {{Research}} in {{Visual-Inertial Mapping}} and {{Localization}}},
  shorttitle = {Maplab},
  author = {Schneider, Thomas and Dymczyk, Marcin and Fehr, Marius and Egger, Kevin and Lynen, Simon and Gilitschenski, Igor and Siegwart, Roland},
  year = {2018},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {3},
  pages = {1418--1425},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2800113},
  abstract = {Robust and accurate visual-inertial estimation is crucial to many of today's challenges in robotics. Being able to localize against a prior map and obtain accurate and drift-free pose estimates can push the applicability of such systems even further. Most of the currently available solutions, however, either focus on a single session use case, lack localization capabilities, or do not provide an end-to-end pipeline. We believe that only a complete system, combining state-of-the-art algorithms, scalable multisession mapping tools, and a flexible user interface, can become an efficient research platform. We, therefore, present maplab, an open, research-oriented visual-inertial mapping framework for processing and manipulating multisession maps, written in C++. On the one hand, maplab can be seen as a ready-to-use visual-inertial mapping and localization system. On the other hand, maplab provides the research community with a collection of multisession mapping tools that include map merging, visual-inertial batch optimization, and loop closure. Furthermore, it includes an online frontend that can create visual-inertial maps and also track a global drift-free pose within a localization map. In this letter, we present the system architecture, five use cases, and evaluations of the system on public datasets. The source code of maplab is freely available for the benefit of the robotics research community.},
  keywords = {localization,Mapping,Merging,Optimization,Simultaneous localization and mapping,Three-dimensional displays,Tools,visual-based navigation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/GV4EABJK/Schneider et al. - 2018 - Maplab An Open Framework for Research in Visual-I.pdf;/Users/kshitijgoel/Zotero/storage/6VVYTCHP/stamp.html}
}

@article{schneider_medical_2016,
  title = {Medical and Logistical Challenges of Trauma Care in a 12-Day Cave Rescue: {{A}} Case Report},
  author = {Schneider, Thomas-Michael and Bregani, Rino and Krammer, Jacob and G{\"o}ksu, Martin and M{\"u}ller, Natalie and Petermeyer, Michael and Schiffer, Johannes and Strapazzon, Giacomo and others},
  year = {2016},
  journal = {Injury},
  volume = {47},
  number = {1},
  pages = {280--283},
  publisher = {Elsevier}
}

@inproceedings{schonberger_structurefrommotion_2016,
  title = {Structure-from-{{Motion Revisited}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Sch{\"o}nberger, Johannes L. and Frahm, Jan-Michael},
  year = {2016},
  month = jun,
  pages = {4104--4113},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.445},
  abstract = {Incremental Structure-from-Motion is a prevalent strategy for 3D reconstruction from unordered image collections. While incremental reconstruction systems have tremendously advanced in all regards, robustness, accuracy, completeness, and scalability remain the key problems towards building a truly general-purpose pipeline. We propose a new SfM technique that improves upon the state of the art to make a further step towards this ultimate goal. The full reconstruction pipeline is released to the public as an open-source implementation.},
  keywords = {Cameras,Image reconstruction,Image registration,Internet,Pipelines,Robustness,Transmission line matrix methods},
  file = {/Users/kshitijgoel/Zotero/storage/M5M3M3Y2/Schönberger and Frahm - 2016 - Structure-from-Motion Revisited.pdf}
}

@article{schrum_when_2020,
  title = {When {{Your Robot Breaks}}: {{Active Learning During Plant Failure}}},
  shorttitle = {When {{Your Robot Breaks}}},
  author = {Schrum, Mariah L. and Gombolay, Matthew C.},
  year = {2020},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {438--445},
  issn = {2377-3766},
  doi = {10.1109/LRA.2019.2961598},
  url = {https://ieeexplore.ieee.org/document/8938725/?arnumber=8938725},
  urldate = {2025-02-14},
  abstract = {Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.},
  keywords = {Aerial systems: mechanics and control,autonomous agents,Autonomous agents,Deep learning,deep learning in robotics and automation,Mathematical model,Predictive control,Robots,Unmanned aerial vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/9D4BAJJ8/Schrum and Gombolay - 2020 - When Your Robot Breaks Active Learning During Plant Failure.pdf;/Users/kshitijgoel/Zotero/storage/PBFK9HTM/8938725.html}
}

@article{schubert_qosbased_2006,
  title = {{{QoS-Based Resource Allocation}} and {{Transceiver Optimization}}},
  author = {Schubert, Martin and Boche, Holger},
  year = {2006},
  month = jul,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {2},
  number = {6},
  pages = {383--529},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000010},
  url = {https://www.nowpublishers.com/article/Details/CIT-010},
  urldate = {2024-04-29},
  abstract = {QoS-Based Resource Allocation and Transceiver Optimization},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/6LXQ933Y/Schubert and Boche - 2006 - QoS-Based Resource Allocation and Transceiver Opti.pdf}
}

@misc{schulman_proximal_2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  number = {arXiv:1707.06347},
  eprint = {1707.06347},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1707.06347},
  url = {http://arxiv.org/abs/1707.06347},
  urldate = {2024-12-10},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/T896ZKFJ/Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf;/Users/kshitijgoel/Zotero/storage/E5DYZ44T/1707.html}
}

@inproceedings{schulman_trust_2015,
  title = {Trust {{Region Policy Optimization}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  year = {2015},
  month = jun,
  pages = {1889--1897},
  publisher = {PMLR},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v37/schulman15.html},
  urldate = {2024-12-13},
  abstract = {In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BF6RMVBU/Schulman et al. - 2015 - Trust Region Policy Optimization.pdf}
}

@inproceedings{schulz_efficient_2018,
  title = {Efficient {{Map Representations}} for {{Multi-Dimensional Normal Distributions Transforms}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Schulz, Cornelia and Hanten, Richard and Zell, Andreas},
  year = {2018},
  month = oct,
  pages = {2679--2686},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8593602},
  abstract = {Efficient 2D and 3D map representations of both static and dynamic, indoor and outdoor environments are crucial for navigation of driving and flying robots. In this paper, we propose a fast and accurate approach for 2D and 3D Normal Distributions Transform (NDT) mapping based on indexed kd-trees. Similar to other approaches, we also model free space, which allows us to obtain occupancy probabilities. Additionally, we provide optional visibility based updates to enhance map consistency in case of noisy data, e.g. from stereo cameras. Unlike other available implementations, our approach is natively applicable to large-scale environments and in real-time, because our maps are able to grow dynamically. This also offers applicability to exploration tasks. To evaluate our approach, we present experimental results on publicly available datasets and discuss the mapping efficiency in terms of accuracy, runtime and memory management. As an exemplary use case, we apply our maps to Monte Carlo Localization on a well-known large-scale dataset.},
  keywords = {Gaussian distribution,Robot sensing systems,Task analysis,Three-dimensional displays,Transforms,Two dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/MFVL7A4L/Schulz et al. - 2018 - Efficient Map Representations for Multi-Dimensiona.pdf;/Users/kshitijgoel/Zotero/storage/IIMZVDKQ/8593602.html}
}

@article{schussler_path_2022,
  title = {Path {{Guiding}} with {{Vertex Triplet Distributions}}},
  author = {Sch{\"u}{\ss}ler, Vincent and Hanika, Johannes and Jung, Alisa and Dachsbacher, Carsten},
  year = {2022},
  journal = {Computer Graphics Forum},
  volume = {41},
  number = {4},
  pages = {1--15},
  issn = {1467-8659},
  doi = {10.1111/cgf.14582},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14582},
  urldate = {2023-03-17},
  abstract = {Good importance sampling strategies are decisive for the quality and robustness of photorealistic image synthesis with Monte Carlo integration. Path guiding approaches use transport paths sampled by an existing base sampler to build and refine a guiding distribution. This distribution then guides subsequent paths in regions that are otherwise hard to sample. We observe that all terms in the measurement contribution function sampled during path construction depend on at most three consecutive path vertices. We thus propose to build a 9D guiding distribution over vertex triplets that adapts to the full measurement contribution with a 9D Gaussian mixture model (GMM). For incremental path sampling, we query the model for the last two vertices of a path prefix, resulting in a 3D conditional distribution with which we sample the next vertex along the path. To make this approach scalable, we partition the scene with an octree and learn a local GMM for each leaf separately. In a learning phase, we sample paths using the current guiding distribution and collect triplets of path vertices. We resample these triplets online and keep only a fixed-size subset in reservoirs. After each progression, we obtain new GMMs from triplet samples by an initial hard clustering followed by expectation maximization. Since we model 3D vertex positions, our guiding distribution naturally extends to participating media. In addition, the symmetry in the GMM allows us to query it for paths constructed by a light tracer. Therefore our method can guide both a path tracer and light tracer from a jointly learned guiding distribution.},
  langid = {english},
  keywords = {CCS Concepts,Computing methodologies  Ray tracing},
  file = {/Users/kshitijgoel/Zotero/storage/WAVDA26I/Schüßler et al. - 2022 - Path Guiding with Vertex Triplet Distributions.pdf}
}

@phdthesis{schwander_informationgeometric_2013,
  type = {These de Doctorat},
  title = {Information-Geometric Methods for Mixture Models},
  author = {Schwander, Olivier},
  year = {2013},
  month = jan,
  url = {https://www.theses.fr/2013EPXX0046},
  urldate = {2024-01-28},
  abstract = {Cette th{\`e}se pr{\'e}sente de nouvelles m{\'e}thodes pour l'apprentissage de mod{\`e}les de m{\'e}langes bas{\'e}es sur la g{\'e}om{\'e}trie de l'information. Les mod{\`e}les de m{\'e}langes consid{\'e}r{\'e}s ici sont des m{\'e}langes de familles exponentielles, permettant ainsi d'englober une large part des mod{\`e}les de m{\'e}langes utilis{\'e}s en pratique. Gr{\^a}ce {\`a} la g{\'e}om{\'e}trie de l'information, les probl{\`e}mes statistiques peuvent {\^e}tre trait{\'e}s avec des outils g{\'e}om{\'e}triques. Ce cadre offre de nouvelles perspectives permettant de mettre au point des algorithmes {\`a} la fois rapides et g{\'e}n{\'e}riques. Deux contributions principales sont propos{\'e}es ici. La premi{\`e}re est une m{\'e}thode de simplification d'estimateurs par noyaux. Cette simplification est effectu{\'e}e {\`a} l'aide un algorithme de partitionnement, d'abord avec la divergence de Bregman puis, pour des raisons de rapidit{\'e}, avec la distance de Fisher-Rao et des barycentres mod{\`e}les. La seconde contribution est une g{\'e}n{\'e}ralisation de l'algorithme k-MLE permettant de traiter des m{\'e}langes o{\`u} toutes les composantes ne font pas partie de la m{\^e}me famille: cette m{\'e}thode est appliqu{\'e}e au cas des m{\'e}langes de Gaussiennes g{\'e}n{\'e}ralis{\'e}es et des m{\'e}langes de lois Gamma et est plus rapide que les m{\'e}thodes existantes. La description de ces deux m{\'e}thodes est accompagn{\'e}e d'une impl{\'e}mentation logicielle compl{\`e}te et leur efficacit{\'e} est {\'e}valu{\'e}e gr{\^a}ce {\`a} des applications en bio-informatique et en classification de textures.},
  collaborator = {Nielsen, Frank},
  copyright = {Licence Etalab},
  school = {Palaiseau, Ecole polytechnique},
  keywords = {Famille exponentielle,Gaussienne generalisee,Geometrie de l'information,Loi Gamma,Modeles de melange},
  file = {/Users/kshitijgoel/Zotero/storage/SHINBFRG/document.pdf}
}

@article{schwarz_estimating_1978,
  title = {Estimating the {{Dimension}} of a {{Model}}},
  author = {Schwarz, Gideon},
  year = {1978},
  journal = {The Annals of Statistics},
  volume = {6},
  number = {2},
  eprint = {2958889},
  eprinttype = {jstor},
  pages = {461--464},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2958889},
  urldate = {2022-06-27},
  abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
  file = {/Users/kshitijgoel/Zotero/storage/VUMNF224/Schwarz - 1978 - Estimating the Dimension of a Model.pdf}
}

@article{schwenk_explanes_2010,
  title = {{{ExPlanes}}: {{Exploring Planes}} in {{Triplet Data}}},
  shorttitle = {{{ExPlanes}}},
  author = {Schwenk, Bruno and Selbig, Joachim and {Ben-Zion}, Yehuda and Holschneider, Matthias},
  year = {2010},
  month = dec,
  journal = {Journal of Integrative Bioinformatics},
  volume = {7},
  number = {3},
  pages = {231--253},
  publisher = {De Gruyter},
  issn = {1613-4516},
  doi = {10.1515/jib-2010-132},
  url = {https://www.degruyter.com/document/doi/10.1515/jib-2010-132/html},
  urldate = {2024-07-23},
  abstract = {Many methods for the analysis of gene expression-, protein- or metabolite-data focus on the investigation of binary relationships, while the underlying biological processes creating this data may generate relations of higher than bivariate complexity. We give a novel method ExPlanes that helps to explore certain types of ternary relationships in a statistically robust, Bayesian framework. To arrive at an characterization of the data structure contained in triplet data we investigate 2-dimensional planes being the only linear structures that cannot be inferred from projections of the data. The key part of our methodology is the definition of a robust, Bayesian plane posterior under the assumption of an invariant prior and a Gaussian error model. A numerical representation of the plane posterior can be explored interactively. Beyond this purely Bayesian approach we can use the plane posterior to construct a family of posterior-based test statistics that allow testing the data for different plane related hypotheses. To demonstrate practicability we queried triplets of metabolic data from a plant crossing experiment for the presence of plane-, line- and point-structures by using posterior-based test statistics and were able to show their distinctiveness.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/89MVB4UC/Schwenk et al. - 2010 - ExPlanes Exploring Planes in Triplet Data.pdf}
}

@article{scott_kernels_2001,
  title = {From {{Kernels}} to {{Mixtures}}},
  author = {Scott, David W. and Szewczyk, William F.},
  year = {2001},
  journal = {Technometrics},
  volume = {43},
  number = {3},
  eprint = {1271220},
  eprinttype = {jstor},
  pages = {323--335},
  publisher = {[Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
  issn = {0040-1706},
  url = {https://www.jstor.org/stable/1271220},
  urldate = {2023-06-15},
  abstract = {Mixture models, which include kernel estimators, are used widely to model complex densities; however, one is faced with the challenge of determining an appropriate number of components. This task often involves identifying those components that are close enough to be combined. This article introduces a new easily calculated measure of similarity between pairs of densities and illustrates its use in recursively collapsing components. This similarity measure leads naturally to a new algorithm (IPRA) for fitting mixture models sequentially. The algorithm is used to test for bumps in galaxy star velocity data and to examine MRI data.},
  file = {/Users/kshitijgoel/Zotero/storage/QSBQKDFI/Scott and Szewczyk - 2001 - From Kernels to Mixtures.pdf}
}

@book{scott_multivariate_1992,
  title = {Multivariate Density Estimation: Theory, Practice, and Visualization},
  shorttitle = {Multivariate Density Estimation},
  author = {Scott, David W.},
  year = {1992},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  address = {New York},
  isbn = {978-0-471-54770-9},
  langid = {english},
  lccn = {QA276.8 .S28 1992},
  keywords = {Estimation theory,Multivariate analysis},
  file = {/Users/kshitijgoel/Zotero/storage/ASYFGUV8/Scott - 1992 - Multivariate density estimation theory, practice, and visualization.pdf}
}

@book{scott_statistics_2020,
  title = {Statistics: {{A Concise Mathematical Introduction}} for {{Students}}, {{Scientists}}, and {{Engineers}}},
  shorttitle = {Statistics},
  author = {Scott, David W.},
  year = {2020},
  month = aug,
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/9781119675860},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119675860},
  urldate = {2024-05-09},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  isbn = {978-1-119-67584-6 978-1-119-67586-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9RNQY5EE/Scott - 2020 - Statistics A Concise Mathematical Introduction for Students, Scientists, and Engineers.pdf}
}

@article{sebastian_physicsinformed_2025,
  title = {Physics-{{Informed Multiagent Reinforcement Learning}} for {{Distributed Multirobot Problems}}},
  author = {Sebasti{\'a}n, Eduardo and Duong, Thai and Atanasov, Nikolay and Montijano, Eduardo and Sag{\"u}{\'e}s, Carlos},
  year = {2025},
  journal = {IEEE Transactions on Robotics},
  volume = {41},
  pages = {4499--4517},
  issn = {1941-0468},
  doi = {10.1109/TRO.2025.3582836},
  url = {https://ieeexplore.ieee.org/document/11049031/},
  urldate = {2025-08-09},
  abstract = {The networked nature of multirobot systems presents challenges in the context of multiagent reinforcement learning. Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots, exhibiting poor performance in cooperative-competitive tasks. In this work, we propose a physics-informed reinforcement learning approach able to learn distributed multirobot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions. Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor--critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multirobot scenarios demonstrate the success of the proposed approach, surpassing previous multirobot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to {\textbackslash}times {\textbackslash}text2 greater than the state-of-the-art with robot teams {\textbackslash}times {\textbackslash}text6 larger than the number of robots at training time). We also validate our approach on multiple real robots in the Georgia Tech Robotarium under imperfect communication, demonstrating zero-shot sim-to-real transfer and scalability across number of robots.},
  keywords = {Collision avoidance,Cooperative control,distributed systems,Legged locomotion,Multi-robot systems,multirobot systems,Navigation,Neural networks,physics-informed neural networks,reinforcement learning,Reinforcement learning,Robot kinematics,Robots,Scalability,Training},
  file = {/Users/kshitijgoel/Zotero/storage/GJ32PILC/Sebastián et al. - 2025 - Physics-Informed Multiagent Reinforcement Learning for Distributed Multirobot Problems.pdf}
}

@inproceedings{segal_generalizedicp_2009,
  title = {Generalized-{{ICP}}},
  booktitle = {Robotics: {{Science}} and {{Systems V}}},
  author = {Segal, A. and Haehnel, D. and Thrun, S.},
  year = {2009},
  month = jun,
  volume = {05},
  url = {http://www.roboticsproceedings.org/rss05/p21.html},
  urldate = {2022-07-24},
  isbn = {978-0-262-51463-7},
  file = {/Users/kshitijgoel/Zotero/storage/UQBBJBMX/Segal et al. - 2009 - Generalized-ICP.pdf;/Users/kshitijgoel/Zotero/storage/RZPIZMN9/p21.html}
}

@inproceedings{seichter_efficient_2022,
  title = {Efficient and {{Robust Semantic Mapping}} for {{Indoor Environments}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Seichter, Daniel and Langer, Patrick and Wengefeld, Tim and Lewandowski, Benjamin and H{\"o}chemer, Dominik and Gross, Horst-Michael},
  year = {2022},
  month = may,
  pages = {9221--9227},
  doi = {10.1109/ICRA46639.2022.9812205},
  abstract = {A key proficiency an autonomous mobile robot must have to perform high-level tasks is a strong understanding of its environment. This involves information about what types of objects are present, where they are, what their spatial extend is, and how they can be reached, i.e., information about free space is also crucial. Semantic maps are a powerful instrument providing such information. However, applying semantic segmentation and building 3D maps with high spatial resolution is challenging given limited resources on mobile robots. In this paper, we incorporate semantic information into efficient occupancy normal distribution transform (NDT) maps to enable real-time semantic mapping on mobile robots. On the publicly available dataset Hypersim, we show that, due to their sub-voxel accuracy, semantic NDT maps are superior to other approaches. We compare them to the recent state-of-the-art approach based on voxels and semantic Bayesian spatial kernel inference (S-BKI) and to an optimized version of it derived in this paper. The proposed semantic NDT maps can represent semantics to the same level of detail, while mapping is 2.7 to 17.5 times faster. For the same grid resolution, they perform significantly better, while mapping is up to more than 5 times faster. Finally, we prove the real-world applicability of semantic NDT maps with qualitative results in a domestic application.},
  keywords = {Indoor environment,Instruments,Mobile robots,Real-time systems,Semantics,Three-dimensional displays,Transforms},
  file = {/Users/kshitijgoel/Zotero/storage/BDGPAYPG/Seichter et al. - 2022 - Efficient and Robust Semantic Mapping for Indoor E.pdf;/Users/kshitijgoel/Zotero/storage/9LPBINIP/9812205.html}
}

@book{seidenberg_lectures_2012,
  title = {Lectures in {{Projective Geometry}}},
  author = {Seidenberg, A.},
  year = {2012},
  month = jun,
  publisher = {Courier Corporation},
  abstract = {An ideal text for undergraduate courses in projective geometry, this volume begins on familiar ground. It starts by employing the leading methods of projective geometry as an extension of high school-level studies of geometry and algebra, and proceeds to more advanced topics with an axiomatic approach.An introductory chapter leads to discussions of projective geometry\&\#39;s axiomatic foundations: establishing coordinates in a plane; relations between the basic theorems; higher-dimensional space; and conics. Additional topics include coordinate systems and linear transformations; an abstract consideration of coordinate systems; an analytical treatment of conic sections; coordinates on a conic; pairs of conics; quadric surfaces; and the Jordan canonical form. Numerous figures illuminate the text.},
  googlebooks = {byfZdJ\_z1hcC},
  isbn = {978-0-486-15473-2},
  langid = {english},
  keywords = {Mathematics / Geometry / General},
  file = {/Users/kshitijgoel/Zotero/storage/XU3JJGAE/2015.147716.Lectures-In-Projective-Geometry.pdf}
}

@article{selig_active_2006,
  title = {Active versus Passive Transformations in Robotics},
  author = {Selig, J.M.},
  year = {2006},
  month = mar,
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {13},
  number = {1},
  pages = {79--84},
  issn = {1558-223X},
  doi = {10.1109/MRA.2006.1598057},
  url = {https://ieeexplore.ieee.org/document/1598057/?arnumber=1598057},
  urldate = {2025-02-28},
  abstract = {This paper suggests that the active approach is preferrabe to the passive approach when it comes to teaching and learning robotics. Unlike the passive approach, the active approach puts more emphasis on the bodies and their motion and, consequently, less emphasis on coordinate frames and changes of coordinates. While the active view is straightforward to teach and learn, it is mathematically equivalent to the standard passive approach. Ultimately, the choice between the two approaches is a matter of personal preference and depends on familiarity and personal taste.},
  keywords = {Geometry,Robot kinematics,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/NHMHV3D7/Selig - 2006 - Active versus passive transformations in robotics.pdf;/Users/kshitijgoel/Zotero/storage/HAEUFRL5/1598057.html}
}

@misc{senanayake_role_2024,
  title = {The {{Role}} of {{Predictive Uncertainty}} and {{Diversity}} in {{Embodied AI}} and {{Robot Learning}}},
  author = {Senanayake, Ransalu},
  year = {2024},
  month = may,
  number = {arXiv:2405.03164},
  eprint = {2405.03164},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2405.03164},
  urldate = {2024-05-28},
  abstract = {Uncertainty has long been a critical area of study in robotics, particularly when robots are equipped with analytical models. As we move towards the widespread use of deep neural networks in robots, which have demonstrated remarkable performance in research settings, understanding the nuances of uncertainty becomes crucial for their real-world deployment. This guide offers an overview of the importance of uncertainty and provides methods to quantify and evaluate it from an applications perspective.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/JTPNI7AV/Senanayake - 2024 - The Role of Predictive Uncertainty and Diversity in Embodied AI and Robot Learning.pdf}
}

@article{senbaslar_dream_2025,
  title = {{{DREAM}}: {{Decentralized Real-Time Asynchronous Probabilistic Trajectory Planning}} for {{Collision-Free Multirobot Navigation}} in {{Cluttered Environments}}},
  shorttitle = {{{DREAM}}},
  author = {{\c S}enba{\c s}lar, Bask{\i}n and Sukhatme, Gaurav S.},
  year = {2025},
  journal = {IEEE Transactions on Robotics},
  volume = {41},
  pages = {573--592},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3509015},
  url = {https://ieeexplore.ieee.org/document/10771711/},
  urldate = {2025-08-12},
  abstract = {Collision-free navigation in cluttered environments with static and dynamic obstacles is essential for many multirobot tasks. Dynamic obstacles may also be interactive, i.e., their behavior varies based on the behavior of other entities. We propose a novel representation for interactive behavior of dynamic obstacles and a decentralized real-time multirobot trajectory planning algorithm allowing interrobot collision avoidance as well as static and dynamic obstacle avoidance. Our planner simulates the behavior of dynamic obstacles, accounting for interactivity. We account for the perception inaccuracy of static and prediction inaccuracy of dynamic obstacles. We handle asynchronous planning between teammates and message delays, drops, and reorderings. We evaluate our algorithm in simulations using 25400 random cases and compare it against three state-of-the-art baselines using 2100 random cases. Our algorithm achieves up to 1.68{\texttimes} success rate using as low as 0.28{\texttimes} time in single-robot, and up to 2.15{\texttimes} success rate using as low as 0.36{\texttimes} time in multirobot cases compared to the best baseline. We implement our planner on real quadrotors to show its real-world applicability.},
  keywords = {Collision avoidance,Decision making,Heuristic algorithms,motion and path planning,multi-robot systems,Navigation,Planning,probabilistic trajectory planning,Robot sensing systems,Robots,Trajectory,Uncertainty,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/TXVF59Z6/Şenbaşlar and Sukhatme - 2025 - DREAM Decentralized Real-Time Asynchronous Probabilistic Trajectory Planning for Collision-Free Mul.pdf}
}

@article{sethian_fast_1996,
  title = {A Fast Marching Level Set Method for Monotonically Advancing Fronts.},
  author = {Sethian, J A},
  year = {1996},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {93},
  number = {4},
  pages = {1591--1595},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC39986/},
  urldate = {2022-04-06},
  abstract = {A fast marching level set method is presented for monotonically advancing fronts, which leads to an extremely fast scheme for solving the Eikonal equation. Level set methods are numerical techniques for computing the position of propagating fronts. They rely on an initial value partial differential equation for a propagating level set function and use techniques borrowed from hyperbolic conservation laws. Topological changes, corner and cusp development, and accurate determination of geometric properties such as curvature and normal direction are naturally obtained in this setting. This paper describes a particular case of such methods for interfaces whose speed depends only on local position. The technique works by coupling work on entropy conditions for interface motion, the theory of viscosity solutions for Hamilton-Jacobi equations, and fast adaptive narrow band level set methods. The technique is applicable to a variety of problems, including shape-from-shading problems, lithographic development calculations in microchip manufacturing, and arrival time problems in control theory.},
  pmcid = {PMC39986},
  pmid = {11607632},
  file = {/Users/kshitijgoel/Zotero/storage/B3ZRP2BU/Sethian - 1996 - A fast marching level set method for monotonically.pdf}
}

@book{settles_active_2012,
  title = {Active {{Learning}}},
  author = {Settles, Burr},
  year = {2012},
  series = {Synthesis {{Lectures}} on {{Artificial Intelligence}} and {{Machine Learning}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-01560-1},
  url = {https://link.springer.com/10.1007/978-3-031-01560-1},
  urldate = {2025-01-03},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-031-00432-2 978-3-031-01560-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/MYTRFYVN/Settles - 2012 - Active Learning.pdf}
}

@inproceedings{sfikas_majorizationminimization_2011,
  title = {Majorization-Minimization Mixture Model Determination in Image Segmentation},
  booktitle = {{{CVPR}} 2011},
  author = {Sfikas, Giorgos and Nikou, Christophoros and Galatsanos, Nikolaos and Heinrich, Christian},
  year = {2011},
  month = jun,
  pages = {2169--2176},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2011.5995349},
  url = {https://ieeexplore.ieee.org/document/5995349},
  urldate = {2024-06-07},
  abstract = {A new Bayesian model for image segmentation based on a Gaussian mixture model is proposed. The model structure allows the automatic determination of the number of segments while ensuring spatial smoothness of the final output. This is achieved by defining two separate mixture weight sets: the first set of weights is spatially variant and incorporates an MRF edge-preserving smoothing prior; the second set of weights is governed by a Dirichlet prior in order to prune unnecessary mixture components. The model is trained using variational inference and the Majorization-Minimization (MM) algorithm, resulting in closed-form parameter updates. The algorithm was successfully evaluated in terms of various segmentation indices using the Berkeley image data base.},
  keywords = {Bayesian methods,Computational modeling,Estimation,Image segmentation,Kernel,Mathematical model,Training},
  file = {/Users/kshitijgoel/Zotero/storage/G9JC376N/Sfikas et al. - 2011 - Majorization-minimization mixture model determination in image segmentation.pdf;/Users/kshitijgoel/Zotero/storage/I6743A3A/5995349.html}
}

@inproceedings{shafieezadeh-abadeh_wasserstein_2018,
  title = {Wasserstein Distributionally Robust Kalman Filtering},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {{Shafieezadeh-Abadeh}, Soroosh and Nguyen, Viet Anh and Kuhn, Daniel and Esfahani, Peyman Mohajerin},
  year = {2018},
  month = dec,
  series = {{{NIPS}}'18},
  pages = {8483--8492},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2023-09-27},
  abstract = {We study a distributionally robust mean square error estimation problem over a nonconvex Wasserstein ambiguity set containing only normal distributions. We show that the optimal estimator and the least favorable distribution form a Nash equilibrium. Despite the non-convex nature of the ambiguity set, we prove that the estimation problem is equivalent to a tractable convex program. We further devise a Frank-Wolfe algorithm for this convex program whose direction-searching subproblem can be solved in a quasi-closed form. Using these ingredients, we introduce a distributionally robust Kalman filter that hedges against model risk.},
  file = {/Users/kshitijgoel/Zotero/storage/RI4FFBFX/Shafieezadeh-Abadeh et al. - 2018 - Wasserstein distributionally robust kalman filteri.pdf}
}

@article{shah_robust_2017,
  title = {Robust Continuous Clustering},
  author = {Shah, Sohil Atul and Koltun, Vladlen},
  year = {2017},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {37},
  pages = {9814--9819},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1700770114},
  url = {https://www.pnas.org/doi/10.1073/pnas.1700770114},
  urldate = {2024-10-12},
  abstract = {Clustering is a fundamental procedure in the analysis of scientific data. It is used ubiquitously across the sciences. Despite decades of research, existing clustering algorithms have limited effectiveness in high dimensions and often require tuning parameters for different domains and datasets. We present a clustering algorithm that achieves high accuracy across multiple domains and scales efficiently to high dimensions and large datasets. The presented algorithm optimizes a smooth continuous objective, which is based on robust statistics and allows heavily mixed clusters to be untangled. The continuous nature of the objective also allows clustering to be integrated as a module in end-to-end feature learning pipelines. We demonstrate this by extending the algorithm to perform joint clustering and dimensionality reduction by efficiently optimizing a continuous global objective. The presented approach is evaluated on large datasets of faces, hand-written digits, objects, newswire articles, sensor readings from the Space Shuttle, and protein expression levels. Our method achieves high accuracy across all datasets, outperforming the best prior algorithm by a factor of 3 in average rank.},
  file = {/Users/kshitijgoel/Zotero/storage/QAEJUMKK/Shah and Koltun - 2017 - Robust continuous clustering.pdf}
}

@book{shakhnarovich_nearestneighbor_2005,
  title = {Nearest-Neighbor Methods in Learning and Vision: Theory and Practice},
  shorttitle = {Nearest-Neighbor Methods in Learning and Vision},
  editor = {Shakhnarovich, Gregory},
  year = {2005},
  series = {Neural Information Processing Series},
  publisher = {MIT Press},
  address = {Cambridge, Mass.},
  isbn = {978-0-262-19547-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/WTYGRK4D/Shakhnarovich - 2005 - Nearest-neighbor methods in learning and vision theory and practice.pdf}
}

@inproceedings{shankar_mrfmap_2020,
  title = {{{MRFMap}}: {{Online Probabilistic 3D Mapping}} Using {{Forward Ray Sensor Models}}},
  shorttitle = {{{MRFMap}}},
  booktitle = {Robotics: {{Science}} and {{Systems XVI}}},
  author = {Shankar, Kumar Shaurya and Michael, Nathan},
  year = {2020},
  month = jul,
  volume = {16},
  url = {http://www.roboticsproceedings.org/rss16/p060.html},
  urldate = {2022-05-27},
  isbn = {978-0-9923747-6-1},
  file = {/Users/kshitijgoel/Zotero/storage/KR32H4VT/Shankar and Michael - 2020 - MRFMap Online Probabilistic 3D Mapping using Forw.pdf;/Users/kshitijgoel/Zotero/storage/RFGKYJ8E/p060.html}
}

@phdthesis{shankar_online_2020,
  title = {Online {{Inference}} of {{Joint Occupancy}} Using {{Forward Sensor Models}} and {{Trajectory Posteriors}} for {{Deliberate Robot Navigation}}},
  author = {Shankar, Kumar Shaurya},
  year = {2020},
  month = aug,
  address = {Pittsburgh, PA, USA},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/QZAUQ9YX/Shankar - Online Inference of Joint Occupancy using Forward .pdf}
}

@article{shannon_mathematical_1948,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, C. E.},
  year = {1948},
  month = jul,
  journal = {The Bell System Technical Journal},
  volume = {27},
  number = {3},
  pages = {379--423},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1948.tb01338.x},
  url = {https://ieeexplore.ieee.org/abstract/document/6773024},
  urldate = {2024-04-18},
  abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
  file = {/Users/kshitijgoel/Zotero/storage/CNC9HC46/Shannon - 1948 - A mathematical theory of communication.pdf}
}

@misc{shaoul_multirobot_2024,
  title = {Multi-{{Robot Motion Planning}} with {{Diffusion Models}}},
  author = {Shaoul, Yorai and Mishani, Itamar and Vats, Shivam and Li, Jiaoyang and Likhachev, Maxim},
  year = {2024},
  month = oct,
  number = {arXiv:2410.03072},
  eprint = {2410.03072},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.03072},
  url = {http://arxiv.org/abs/2410.03072},
  urldate = {2024-11-27},
  abstract = {Diffusion models have recently been successfully applied to a wide range of robotics applications for learning complex multi-modal behaviors from data. However, prior works have mostly been confined to single-robot and small-scale environments due to the high sample complexity of learning multi-robot diffusion models. In this paper, we propose a method for generating collision-free multi-robot trajectories that conform to underlying data distributions while using only single-robot data. Our algorithm, Multi-robot Multi-model planning Diffusion (MMD), does so by combining learned diffusion models with classical search-based techniques -- generating data-driven motions under collision constraints. Scaling further, we show how to compose multiple diffusion models to plan in large environments where a single diffusion model fails to generalize well. We demonstrate the effectiveness of our approach in planning for dozens of robots in a variety of simulated scenarios motivated by logistics environments. View video demonstrations in our supplementary material, and our code at: https://github.com/yoraish/mmd.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/TA5WAPAX/Shaoul et al. - 2024 - Multi-Robot Motion Planning with Diffusion Models.pdf;/Users/kshitijgoel/Zotero/storage/5C2BNED2/2410.html}
}

@phdthesis{sharma_lowpower_2023,
  title = {Low-{{Power}} and {{Miniaturized Medical Electronics}} for {{In-Vivo Localization}} and {{Tracking}}},
  author = {Sharma, Saransh},
  year = {2023},
  address = {United States -- California},
  doi = {10.7907/xrw0-k789},
  url = {https://www.proquest.com/docview/2866353730/abstract/667411746B6A449CPQ/1},
  urldate = {2024-11-08},
  abstract = {Medical electronic devices are an integral part of the healthcare system today. Significant advances have been made over the past few decades to yield highly miniaturized and low-power medical devices that are suitable for implantable, ingestible, or wearable applications. A key feature of medical devices that is central to their use in many applications is the capability to locate them precisely inside the body, and quite a lot of research effort has been expended in this direction. Location sensing is crucial for several applications: tracking pills in the GI tract, navigation during precision surgeries, endovascular procedures, robotic and minimally invasive surgery, and targeted therapy. The current gold-standard solutions for these procedures include invasive techniques such as endoscopy, or procedures that require repeated use of potentially harmful X-ray radiation such as CT scans. These techniques also require repeated evaluation in a hospital setting and are not conducive for non-clinical environments. While there are several alternative non-ionizing methods for imaging and localization based on electromagnetic tracking, radio-frequency, ultrasound, and optical tracking, none of them are able to simultaneously achieve a high field-of-view of tracking, high spatiotemporal resolution, fully wireless operation and miniaturization of the sensing devices, and system scalability with the number of devices. In this dissertation, we present a radiation-free system for high-precision localization and tracking of miniaturized wireless devices in vivo, using harmless magnetic field gradients. First, we demonstrate our system for precision surgery applications. We designed highly miniaturized, wireless and battery-less microdevices, capable of measuring and transmitting their local magnetic field. One such device can be attached to an implant inside the body and another to a surgical tool, such that both can simultaneously measure and communicate the magnetic field at their respective locations to an external receiver. The relative location of the two devices on a real-time display can enable precise surgical navigation without using X-ray fluoroscopy. The prototype device consists of a micro-chip fabricated in 65nm CMOS technology, a 3D magnetic sensor and an inductor-coil. The chip performs wireless power management, wireless bi-directional data-telemetry, and I2C communication with the sensor. Planar electromagnetic coils are designed for creating monotonically varying magnetic fields in the X, Y, and Z directions, resulting in field gradients that encode each spatial point with a unique magnetic field value. The concept of gradient-based spatial encoding is inspired by MRI. The system is tested in vitroto demonstrate a localization accuracy of {$<$}100{\textmu}m in 3D, the highest reported to the best of our knowledge. Second, we demonstrate our system for localization and tracking of ingestible microdevices in the GI tract, which is valuable for the diagnosis and treatment of GI disorders. We designed highly miniaturized, low-power, and wireless ingestible devices to sense and transmit their local magnetic field as they travel through the GI tract. These devices consist of a 3D magnetic sensor, a Bluetooth microprocessor and a 2.4GHz Bluetooth antenna for wireless communication, all packaged into a 000- size capsule. The magnetic field sensed by the devices is created by using high-efficiency planar electromagnetic coils that encode each spatial point with a distinct magnetic field magnitude, allowing us to track the location of the devices unambiguously.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798380267595},
  langid = {english},
  school = {California Institute of Technology},
  keywords = {Barium,Bone surgery,Catheters,Chronic illnesses,CMOS,Colon,Communication,Design,Design specifications,Electrical engineering,Electromagnetics,Electromagnetism,Feces,Integrated circuits,Magnetic fields,Medical equipment,Medical research,Medicine,Physics,Plastics,Polyethylene,Polymer chemistry,Radiation,Real time,Receivers & amplifiers,Semiconductors,Sensors,Surgery,Surgical apparatus & instruments,Toilet facilities,Transplants & implants},
  file = {/Users/kshitijgoel/Zotero/storage/7PZKA732/Sharma - 2023 - Low-Power and Miniaturized Medical Electronics for In-Vivo Localization and Tracking.pdf}
}

@article{sharp_vector_2019,
  title = {The {{Vector Heat Method}}},
  author = {Sharp, Nicholas and Soliman, Yousuf and Crane, Keenan},
  year = {2019},
  month = jun,
  journal = {ACM Transactions on Graphics},
  volume = {38},
  number = {3},
  pages = {24:1--24:19},
  issn = {0730-0301},
  doi = {10.1145/3243651},
  url = {https://dl.acm.org/doi/10.1145/3243651},
  urldate = {2023-09-27},
  abstract = {This article describes a method for efficiently computing parallel transport of tangent vectors on curved surfaces, or more generally, any vector-valued data on a curved manifold. More precisely, it extends a vector field defined over any region to the rest of the domain via parallel transport along shortest geodesics. This basic operation enables fast, robust algorithms for extrapolating level set velocities, inverting the exponential map, computing geometric medians and Karcher/Fr{\'e}chet means of arbitrary distributions, constructing centroidal Voronoi diagrams, and finding consistently ordered landmarks. Rather than evaluate parallel transport by explicitly tracing geodesics, we show that it can be computed via a short-time heat flow involving the connection Laplacian. As a result, transport can be achieved by solving three prefactored linear systems, each akin to a standard Poisson problem. To implement the method, we need only a discrete connection Laplacian, which we describe for a variety of geometric data structures (point clouds, polygon meshes, etc.). We also study the numerical behavior of our method, showing empirically that it converges under refinement, and augment the construction of intrinsic Delaunay triangulations so that they can be used in the context of tangent vector field processing.},
  keywords = {Discrete differential geometry,exponential map,geometric median,Karcher mean,logarithmic map,parallel transport,velocity extrapolation},
  file = {/Users/kshitijgoel/Zotero/storage/X896RCRI/Sharp et al. - 2019 - The Vector Heat Method.pdf}
}

@inproceedings{sheikh_modeseeking_2007,
  title = {Mode-Seeking by {{Medoidshifts}}},
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  author = {Sheikh, Yaser Ajmal and Khan, Erum Arif and Kanade, Takeo},
  year = {2007},
  month = oct,
  pages = {1--8},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2007.4408978},
  url = {https://ieeexplore.ieee.org/document/4408978/},
  urldate = {2025-07-31},
  abstract = {We present a nonparametric mode-seeking algorithm, called medoidshift, based on approximating the local gradient using a weighted estimate of medoids. Like meanshift, medoidshift clustering automatically computes the number of clusters and the data does not have to be linearly separable. Unlike meanshift, the proposed algorithm does not require the definition of a mean. This property allows medoidshift to find modes even when only a distance measure between samples is defined. In this sense, the relationship between the medoidshift algorithm and the meanshift algorithm is similar to the relationship between the k-medoids and the k-means algorithms. We show that medoidshifts can also be used for incremental clustering of growing datasets by recycling previous computations. We present experimental results using medoidshift for image segmentation, incremental clustering for shot segmentation and clustering on nonlinearly separable data.},
  keywords = {Application software,Clustering algorithms,Computer science,Computer vision,Image segmentation,Lakes,Partitioning algorithms,Recycling,Robotics and automation,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/4MBLHXZP/Sheikh et al. - 2007 - Mode-seeking by Medoidshifts.pdf}
}

@inproceedings{shell_decision_2023,
  title = {Decision Diagrams as Plans: {{Answering}} Observation-Grounded Queries},
  shorttitle = {Decision Diagrams as Plans},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Shell, Dylan A. and O'Kane, Jason M.},
  year = {2023},
  month = may,
  pages = {1659--1665},
  doi = {10.1109/ICRA48891.2023.10161530},
  abstract = {We consider a robot that answers questions about its environment by traveling to appropriate places and then sensing. Questions are posed as structured queries and may involve conditional or contingent relationships between observable properties. After formulating this problem, and empha-sizing the advantages of exploiting deducible information, we describe how non-trivial knowledge of the world and queries can be given a convenient, concise, unified representation via reduced ordered binary decision diagrams (BDDs). To use these data structures directly for inference and planning, we introduce a new product operation, and generalize the classic dynamic variable reordering techniques to solve planning problems. Also, finally, we evaluate optimizations that exploit locality.},
  keywords = {Automation,Boolean functions,Data structures,Optimization,Planning,Robot sensing systems,Sensors},
  file = {/Users/kshitijgoel/Zotero/storage/47RXZDHK/Shell and O'Kane - 2023 - Decision diagrams as plans Answering observation-.pdf;/Users/kshitijgoel/Zotero/storage/VBHQVAKQ/10161530.html}
}

@incollection{shen_state_2013,
  title = {State {{Estimation}} for {{Indoor}} and {{Outdoor Operation}} with a {{Micro-Aerial Vehicle}}},
  booktitle = {Experimental {{Robotics}}: {{The}} 13th {{International Symposium}} on {{Experimental Robotics}}},
  author = {Shen, Shaojie and Michael, Nathan},
  editor = {Desai, Jaydev P. and Dudek, Gregory and Khatib, Oussama and Kumar, Vijay},
  year = {2013},
  pages = {273--288},
  publisher = {Springer International Publishing},
  address = {Heidelberg},
  doi = {10.1007/978-3-319-00065-7_20},
  url = {https://doi.org/10.1007/978-3-319-00065-7_20},
  urldate = {2025-03-24},
  abstract = {In this work, we detail a methodology for estimating the state of a microaerial vehicle (MAV) as it transitions between different operating environments with varying applicable sensors. We ensure that the estimate is smooth and continuous throughout and provide an associated quality measure of the state estimate. We address the challenge of maintaining consistency between local and global measurements and propose a strategy to recursively estimate the transform between different coordinate frames. We close with experiments that validate the approach and the resulting performance as a MAV navigates between mixed indoor and outdoor environments.},
  isbn = {978-3-319-00065-7},
  langid = {english},
  keywords = {Global Frame,Local Frame,Outdoor Environment,Position Estimate,State Estimation},
  file = {/Users/kshitijgoel/Zotero/storage/GFXRGJIU/Shen and Michael - 2013 - State Estimation for Indoor and Outdoor Operation with a Micro-Aerial Vehicle.pdf}
}

@article{shen_stochastic_2012,
  title = {Stochastic Differential Equation-Based Exploration Algorithm for Autonomous Indoor {{3D}} Exploration with a Micro-Aerial Vehicle},
  author = {Shen, Shaojie and Michael, Nathan and Kumar, Vijay},
  year = {2012},
  month = oct,
  journal = {The International Journal of Robotics Research},
  volume = {31},
  number = {12},
  pages = {1431--1444},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364912461676},
  url = {https://doi.org/10.1177/0278364912461676},
  urldate = {2023-09-29},
  abstract = {In this paper, we propose a stochastic differential equation-based exploration algorithm to enable exploration in three-dimensional indoor environments with a payload-constrained micro-aerial vehicle (MAV). We are able to address computation, memory, and sensor limitations by using a map representation which is dense for the known occupied space but sparse for the free space. We determine regions for further exploration based on the evolution of a stochastic differential equation that simulates the expansion of a system of particles with Newtonian dynamics. The regions of most significant particle expansion correlate to unexplored space. After identifying and processing these regions, the autonomous MAV navigates to these locations to enable fully autonomous exploration. The performance of the approach is demonstrated through numerical simulations and experimental results in single- and multi-floor indoor experiments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XIJ4BVGU/Shen et al. - 2012 - Stochastic differential equation-based exploration.pdf}
}

@inproceedings{shental_computing_2003,
  title = {Computing {{Gaussian Mixture Models}} with {{EM Using Equivalence Constraints}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shental, Noam and {Bar-hillel}, Aharon and Hertz, Tomer and Weinshall, Daphna},
  year = {2003},
  volume = {16},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper_files/paper/2003/hash/831caa1b600f852b7844499430ecac17-Abstract.html},
  urldate = {2023-12-07},
  abstract = {Density estimation with Gaussian Mixture Models is a popular gener- ative technique used also for clustering. We develop a framework to incorporate side information in the form of equivalence constraints into the model estimation procedure. Equivalence constraints are defined on pairs of data points, indicating whether the points arise from the same source (positive constraints) or from different sources (negative con- straints). Such constraints can be gathered automatically in some learn- ing problems, and are a natural form of supervision in others. For the estimation of model parameters we present a closed form EM procedure which handles positive constraints, and a Generalized EM procedure us- ing a Markov net which handles negative constraints. Using publicly available data sets we demonstrate that such side information can lead to considerable improvement in clustering tasks, and that our algorithm is preferable to two other suggested methods using the same type of side information.},
  file = {/Users/kshitijgoel/Zotero/storage/P77E28UT/Shental et al. - 2003 - Computing Gaussian Mixture Models with EM Using Eq.pdf}
}

@article{shi_accurate_2023,
  title = {Accurate {{Implicit Neural Mapping With More Compact Representation}} in {{Large-Scale Scenes Using Ranging Data}}},
  author = {Shi, Chenhui and Tang, Fulin and Wu, Yihong and Jin, Xin and Ma, Gang},
  year = {2023},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {10},
  pages = {6683--6690},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3311355},
  url = {https://ieeexplore.ieee.org/document/10238795/},
  urldate = {2024-01-24},
  abstract = {Large-scale 3D mapping nowadays is a research hotspot in robotics. A greatly concerning issue is reconstructing high-accuracy maps in a hardware environment with limited memory. To address this problem, we propose a novel implicit neural mapping approach with higher accuracy and less memory. It first adopts an improved hierarchical hash encoder, independent of geometric bounding (e.g., bounding box or sphere), for a more compact map representation, and then leverages a spatial hash grid to restrict the encoding space to the proximity of geometric surfaces, preventing hash collisions between encoding in free space and near geometric surfaces. The hash grid indexes the scene point cloud produced by ranging data. Through a tiny MLP, features encoded from sampled points in the hash grid can be converted to truncated signed distance values. To further improve mapping accuracy, a new method is developed to instantly obtain more accurate signed distance labels from ranging data by computing the closest distances from sampled points to the point cloud indexed by the constructed hash grid, not just the distances from sampled points to geometric surfaces along rays, and then use these labels to supervise the learning of our hash encoder. Experimental evaluations performed on large-scale indoor and outdoor datasets demonstrate that our approach achieves state-of-the-art mapping performance with less than half of the memory consumption compared with previous advanced 3D mapping methods using ranging data.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9PB9SBWK/Shi et al. - 2023 - Accurate Implicit Neural Mapping With More Compact.pdf}
}

@misc{shi_crisp_2024,
  title = {{{CRISP}}: {{Object Pose}} and {{Shape Estimation}} with {{Test-Time Adaptation}}},
  shorttitle = {{{CRISP}}},
  author = {Shi, Jingnan and Talak, Rajat and Zhang, Harry and Jin, David and Carlone, Luca},
  year = {2024},
  month = dec,
  number = {arXiv:2412.01052},
  eprint = {2412.01052},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.01052},
  url = {http://arxiv.org/abs/2412.01052},
  urldate = {2024-12-19},
  abstract = {We consider the problem of estimating object pose and shape from an RGB-D image. Our first contribution is to introduce CRISP, a category-agnostic object pose and shape estimation pipeline. The pipeline implements an encoder-decoder model for shape estimation. It uses FiLM-conditioning for implicit shape reconstruction and a DPT-based network for estimating pose-normalized points for pose estimation. As a second contribution, we propose an optimization-based pose and shape corrector that can correct estimation errors caused by a domain gap. Observing that the shape decoder is well behaved in the convex hull of known shapes, we approximate the shape decoder with an active shape model, and show that this reduces the shape correction problem to a constrained linear least squares problem, which can be solved efficiently by an interior point algorithm. Third, we introduce a self-training pipeline to perform self-supervised domain adaptation of CRISP. The self-training is based on a correct-and-certify approach, which leverages the corrector to generate pseudo-labels at test time, and uses them to self-train CRISP. We demonstrate CRISP (and the self-training) on YCBV, SPE3R, and NOCS datasets. CRISP shows high performance on all the datasets. Moreover, our self-training is capable of bridging a large domain gap. Finally, CRISP also shows an ability to generalize to unseen objects. Code and pre-trained models will be available on https://web.mit.edu/sparklab/research/crisp\_object\_pose\_shape/.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/A9C9UIFW/Shi et al. - 2024 - CRISP Object Pose and Shape Estimation with Test-Time Adaptation.pdf;/Users/kshitijgoel/Zotero/storage/CEFD4EE7/2412.html}
}

@inproceedings{shi_good_1994,
  title = {Good Features to Track},
  booktitle = {1994 {{Proceedings}} of {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Shi, Jianbo and {Tomasi}},
  year = {1994},
  month = jun,
  pages = {593--600},
  issn = {1063-6919},
  doi = {10.1109/CVPR.1994.323794},
  abstract = {No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.{$<>$}},
  keywords = {Feature extraction,Machine vision,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/H3GVBWGB/Shi and Tomasi - 1994 - Good features to track.pdf;/Users/kshitijgoel/Zotero/storage/DEP7P9V9/323794.html}
}

@inproceedings{shi_realtime_2024,
  title = {Real-Time {{Bandwidth-efficient Occupancy Grid Map Synchronization}} for {{Multi-Robot Systems}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Shi, Liuyu and Yin, Longji and Kong, Fanze and Ren, Yunfan and Zhu, Fangcheng and Tang, Benxu and Zhang, Fu},
  year = {2024},
  month = oct,
  pages = {8489--8496},
  issn = {2153-0866},
  doi = {10.1109/IROS58592.2024.10802281},
  url = {https://ieeexplore.ieee.org/document/10802281/?arnumber=10802281},
  urldate = {2024-12-31},
  abstract = {Robot swarms are increasingly being applied in various domains. However, due to the inherent limitation imposed by low real-time communication bandwidth, the synchronization of environmental information among multiple robots remains a persistent and challenging problem in practical applications. In response to this challenge, we introduce a comprehensive framework for synchronizing occupancy grid maps (OGMs) in practical multi-robot systems that operate under communication bandwidth constraints. In our research, we elaborately design the data structure of transmitted local OGMs and employ the Hilbert space-filling curve for voxel sorting. By adopting this approach, data redundancy is effectively increased, resulting in lower information entropy for compression and significantly reducing the volume of communication data. Finally, our framework outperforms the benchmark method by reducing the average and maximum bandwidth usage by more than 10 times in high-resolution scenarios. Moreover, our method has been successfully applied in the multi-UAV autonomous navigation application, demonstrating its real-time and bandwidth-efficient nature, as well as its practical value.},
  keywords = {Bandwidth,Data structures,Information entropy,Intelligent robots,Multi-robot systems,Probability distribution,Real-time systems,Sorting,Synchronization,Termination of employment},
  file = {/Users/kshitijgoel/Zotero/storage/QEGFHZAG/Shi et al. - 2024 - Real-time Bandwidth-efficient Occupancy Grid Map Synchronization for Multi-Robot Systems.pdf;/Users/kshitijgoel/Zotero/storage/XMWD2BJR/10802281.html}
}

@techreport{shlens_tutorial_2003,
  title = {A {{Tutorial}} on {{Principal Component Analysis}}},
  author = {Shlens, Jon},
  year = {2003},
  month = mar,
  url = {https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Q4CR8GFR/Shlens - A TUTORIAL ON PRINCIPAL COMPONENT ANALYSIS.pdf}
}

@phdthesis{shun_sharedmemory_2017,
  title = {Shared-{{Memory Parallelism Can Be Simple}}, {{Fast}}, and {{Scalable}}},
  author = {Shun, Julian},
  year = {2017},
  month = jun,
  address = {Pittsburgh, PA, USA},
  doi = {10.1145/3018787},
  url = {https://dl.acm.org/doi/book/10.1145/3018787},
  urldate = {2024-03-27},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/RVP96RXG/Shun - 2017 - Shared-Memory Parallelism Can Be Simple, Fast, and.pdf}
}

@article{sibley_sliding_2010,
  title = {Sliding Window Filter with Application to Planetary Landing},
  author = {Sibley, Gabe and Matthies, Larry and Sukhatme, Gaurav},
  year = {2010},
  journal = {Journal of Field Robotics},
  volume = {27},
  number = {5},
  pages = {587--608},
  issn = {1556-4967},
  doi = {10.1002/rob.20360},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.20360},
  urldate = {2025-03-24},
  abstract = {We are concerned with improving the range resolution of stereo vision for entry, descent, and landing (EDL) missions to Mars and other planetary bodies. The goal is to create accurate and precise three-dimensional planetary surface-structure estimates by filtering sequences of stereo images taken from an autonomous landing vehicle. We describe a sliding window filter (SWF) approach based on delayed state marginalization. The SWF can run in constant time, yet still achieve experimental results close to those of the bundle adjustment solution. This technique can scale from the offline batch least-squares solution to fast online incremental solutions. For instance, if the window encompasses all time, the solution is equivalent to full bundle adjustment; if only one time step is maintained, the solution matches the extended Kalman filter; if poses and landmarks are slowly marginalized out over time such that the state vector ceases to grow, then the filter becomes constant time, like visual odometry. Within the constant time regime, the sliding window approach demonstrates convergence properties that are close to those of the full batch solution and strictly superior to visual odometry. Experiments with real data show that ground structure estimates follow the expected convergence pattern that is predicted by theory. These experiments indicate the effectiveness of filtering long-range stereo for EDL. {\copyright} 2010 Wiley Periodicals, Inc.},
  copyright = {Copyright {\copyright} 2010 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3QYIGVTF/Sibley et al. - 2010 - Sliding window filter with application to planetary landing.pdf}
}

@misc{sifferman_review_2022,
  title = {A {{Review}} of {{Scene Representations}} for {{Robot Manipulators}}},
  author = {Sifferman, Carter},
  year = {2022},
  month = dec,
  number = {arXiv:2301.11275},
  eprint = {2301.11275},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2301.11275},
  urldate = {2023-07-25},
  abstract = {For a robot to act intelligently, it needs to sense the world around it. Increasingly, robots build an internal representation of the world from sensor readings. This representation can then be used to inform downstream tasks, such as manipulation, collision avoidance, or human interaction. In practice, scene representations vary widely depending on the type of robot, the sensing modality, and the task that the robot is designed to do. This review provides an overview of the scene representations used for robot manipulators (robot arms). We focus primarily on representations which are built from real world sensing and are used to inform some downstream robotics task.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/6ATS4BTF/Sifferman - 2022 - A Review of Scene Representations for Robot Manipu.pdf;/Users/kshitijgoel/Zotero/storage/D6DC3HQM/2301.html}
}

@book{sigg_gpubased_2006,
  title = {{{GPU-Based Ray-Casting}} of {{Quadratic Surfaces}}},
  author = {Sigg, Christian and Weyrich, Tim and Botsch, Mario and Gross, Markus},
  year = {2006},
  publisher = {The Eurographics Association},
  issn = {1811-7813},
  url = {https://doi.org/10.2312/SPBG/SPBG06/059-065},
  urldate = {2025-01-14},
  abstract = {Quadratic surfaces are frequently used primitives in geometric modeling and scientific visualization, such as rendering of tensor fields, particles, and molecular structures. While high visual quality can be achieved using sophisticated ray tracing techniques, interactive applications typically use either coarsely tessellated polygonal approximations or pre-rendered depth sprites, thereby trading off visual quality and perspective correctness for higher rendering performance. In contrast, we propose an efficient rendering technique for quadric primitives based on GPU-accelerated splatting. While providing similar performance as point-sprites, our methods provides perspective correctness and superior visual quality using per-pixel ray-casting.},
  isbn = {978-3-905673-32-6},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/U6ZGRZ5N/Sigg et al. - 2006 - GPU-Based Ray-Casting of Quadratic Surfaces.pdf}
}

@article{simon_behavioral_1955,
  title = {A {{Behavioral Model}} of {{Rational Choice}}},
  author = {Simon, Herbert A.},
  year = {1955},
  journal = {The Quarterly Journal of Economics},
  volume = {69},
  number = {1},
  eprint = {1884852},
  eprinttype = {jstor},
  pages = {99--118},
  publisher = {Oxford University Press},
  issn = {0033-5533},
  doi = {10.2307/1884852},
  url = {https://www.jstor.org/stable/1884852},
  urldate = {2025-02-14},
  abstract = {Introduction, 99.--I. Some general features of rational choice, 100.--II. The essential simplifications, 103.--III. Existence and uniqueness of solutions, 111.--IV. Further comments on dynamics, 113.--V. Conclusion, 114.--Appendix, 115.},
  file = {/Users/kshitijgoel/Zotero/storage/HM7R7KI8/Simon - 1955 - A Behavioral Model of Rational Choice.pdf}
}

@misc{simon_mononav_2023,
  title = {{{MonoNav}}: {{MAV Navigation}} via {{Monocular Depth Estimation}} and {{Reconstruction}}},
  shorttitle = {{{MonoNav}}},
  author = {Simon, Nathaniel and Majumdar, Anirudha},
  year = {2023},
  month = nov,
  number = {arXiv:2311.14100},
  eprint = {2311.14100},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.14100},
  url = {http://arxiv.org/abs/2311.14100},
  urldate = {2024-12-10},
  abstract = {A major challenge in deploying the smallest of Micro Aerial Vehicle (MAV) platforms ({$<$} 100 g) is their inability to carry sensors that provide high-resolution metric depth information (e.g., LiDAR or stereo cameras). Current systems rely on end-to-end learning or heuristic approaches that directly map images to control inputs, and struggle to fly fast in unknown environments. In this work, we ask the following question: using only a monocular camera, optical odometry, and offboard computation, can we create metrically accurate maps to leverage the powerful path planning and navigation approaches employed by larger state-of-the-art robotic systems to achieve robust autonomy in unknown environments? We present MonoNav: a fast 3D reconstruction and navigation stack for MAVs that leverages recent advances in depth prediction neural networks to enable metrically accurate 3D scene reconstruction from a stream of monocular images and poses. MonoNav uses off-the-shelf pre-trained monocular depth estimation and fusion techniques to construct a map, then searches over motion primitives to plan a collision-free trajectory to the goal. In extensive hardware experiments, we demonstrate how MonoNav enables the Crazyflie (a 37 g MAV) to navigate fast (0.5 m/s) in cluttered indoor environments. We evaluate MonoNav against a state-of-the-art end-to-end approach, and find that the collision rate in navigation is significantly reduced (by a factor of 4). This increased safety comes at the cost of conservatism in terms of a 22\% reduction in goal completion.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/UGXAPULC/Simon and Majumdar - 2023 - MonoNav MAV Navigation via Monocular Depth Estimation and Reconstruction.pdf;/Users/kshitijgoel/Zotero/storage/GY8BAYTH/2311.html}
}

@article{singh_adaptive_2009,
  title = {Adaptive {{Hausdorff}} Estimation of Density Level Sets},
  author = {Singh, Aarti and Scott, Clayton and Nowak, Robert},
  year = {2009},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {37},
  number = {5B},
  pages = {2760--2782},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/08-AOS661},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-37/issue-5B/Adaptive-Hausdorff-estimation-of-density-level-sets/10.1214/08-AOS661.full},
  urldate = {2024-05-29},
  abstract = {Consider the problem of estimating the {$\gamma$}-level set G{$\gamma$}*=\{x: f(x){$\geq\gamma$}\} of an unknown d-dimensional density function f based on n independent observations X1, {\dots}, Xn from the density. This problem has been addressed under global error criteria related to the symmetric set difference. However, in certain applications a spatially uniform mode of convergence is desirable to ensure that the estimated set is close to the target set everywhere. The Hausdorff error criterion provides this degree of uniformity and, hence, is more appropriate in such situations. It is known that the minimax optimal rate of error convergence for the Hausdorff metric is (n/log n)-1/(d+2{$\alpha$}) for level sets with boundaries that have a Lipschitz functional form, where the parameter {$\alpha$} characterizes the regularity of the density around the level of interest. However, the estimators proposed in previous work are nonadaptive to the density regularity and require knowledge of the parameter {$\alpha$}. Furthermore, previously developed estimators achieve the minimax optimal rate for rather restricted classes of sets (e.g., the boundary fragment and star-shaped sets) that effectively reduce the set estimation problem to a function estimation problem. This characterization precludes level sets with multiple connected components, which are fundamental to many applications. This paper presents a fully data-driven procedure that is adaptive to unknown regularity conditions and achieves near minimax optimal Hausdorff error control for a class of density level sets with very general shapes and multiple connected components.},
  keywords = {62G05,62G20,Adaptivity,Density level set,Hausdorff error,rates of convergence},
  file = {/Users/kshitijgoel/Zotero/storage/NNJF6WF2/Singh et al. - 2009 - Adaptive Hausdorff estimation of density level sets.pdf}
}

@phdthesis{singh_minimal_2023,
  title = {Minimal {{Perception}}: {{Enabling Autonomy}} on {{Resource-Constrained Robots}}},
  shorttitle = {Minimal {{Perception}}},
  author = {Singh, Chahat Deep},
  year = {2023},
  eprint = {1903/30819},
  eprinttype = {hdl},
  url = {http://hdl.handle.net/1903/30819},
  urldate = {2023-11-21},
  abstract = {Mobile robots are widely used and crucial in diverse fields due to their autonomous task performance. They enhance efficiency, and safety, and enable novel applications like precision agriculture, environmental monitoring, disaster management, and inspection. Perception plays a vital role in their autonomous behavior for environmental understanding and interaction. Perception in robots refers to their ability to gather, process, and interpret environmental data, enabling autonomous interactions. It facilitates navigation, object identification, and real-time reactions. By integrating perception, robots achieve onboard autonomy, operating without constant human intervention, even in remote or hazardous areas. This enhances adaptability and scalability. This thesis explores the challenge of developing autonomous systems for smaller robots used in precise tasks like confined space inspections and robot pollination. These robots face limitations in real-time perception due to computing, power, and sensing constraints. To address this, we draw inspiration from small organisms such as insects and hummingbirds, known for their sophisticated perception, navigation, and survival abilities despite their minimalistic sensory and neural systems. This research aims to provide insights into designing compact, efficient, and minimal perception systems for tiny autonomous robots. Embracing this minimalism is paramount in unlocking the full potential of tiny robots and enhancing their perception systems. By streamlining and simplifying their design and functionality, these compact robots can maximize efficiency and overcome limitations imposed by size constraints. In this work, a Minimal Perception framework is proposed that enables onboard autonomy in resource-constrained robots at scales (as small as a credit card) that were not possible before. Minimal perception refers to a simplified, efficient, and selective approach from both hardware and software perspectives to gather and process sensory information. Adopting a task-centric perspective allows for further refinement of the minimalist perception framework for tiny robots. For instance, certain animals like jumping spiders, measuring just 1/2 inch in length, demonstrate minimal perception capabilities through sparse vision facilitated by multiple eyes, enabling them to efficiently perceive their surroundings and capture prey with remarkable agility. This thesis introduces a cutting-edge exploration of the minimal perception framework, pushing the boundaries of robot autonomy to new heights. The contributions of this work can be summarized as follows:1. Utilizing minimal quantities such as uncertainty in optical flow and its untapped potential to enable autonomous navigation, static and dynamic obstacle avoidance, and the ability to fly through unknown gaps. 2. By utilizing the principles of interactive perception, the framework proposes novel object segmentation in cluttered environments eliminating the reliance on neural network training for object recognition. 3. Introducing a generative simulator called WorldGen that has the power to generate countless cities and petabytes of high-quality annotated data, designed to minimize the demanding need for laborious 3D modeling and annotations, thus unlocking unprecedented possibilities for perception and autonomy tasks. 4. Proposed a method to predict metric dense depth maps in never-seen or out-of-domain environments by fusing information from a traditional RGB camera and a sparse 64-pixel depth sensor. 5. The autonomous capabilities of the tiny robots are demonstrated on both aerial and ground robots: (a) autonomous car with a size smaller than a credit card (70mm), and (b) bee drone with a length of 120mm, showcasing navigation abilities, depth perception in all four main directions, and effective avoidance of both static and dynamic obstacles. In conclusion, the integration of the minimal perception framework in tiny mobile robots heralds a new era of possibilities, signaling a paradigm shift in unlocking their perception and autonomy potential. This thesis would serve as a transformative milestone that will reshape the landscape of mobile robot autonomy, ushering in a future where tiny robots operate synergistically in swarms, revolutionizing fields such as exploration, disaster response, and distributed sensing.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UP6TQQIG/Singh - 2023 - Minimal Perception Enabling Autonomy on Resource-.pdf}
}

@misc{sivaprakasam_salon_2024,
  title = {{{SALON}}: {{Self-supervised Adaptive Learning}} for {{Off-road Navigation}}},
  shorttitle = {{{SALON}}},
  author = {Sivaprakasam, Matthew and Triest, Samuel and Ho, Cherie and Aich, Shubhra and Lew, Jeric and Adu, Isaiah and Wang, Wenshan and Scherer, Sebastian},
  year = {2024},
  month = dec,
  number = {arXiv:2412.07826},
  eprint = {2412.07826},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.07826},
  url = {http://arxiv.org/abs/2412.07826},
  urldate = {2024-12-13},
  abstract = {Autonomous robot navigation in off-road environments presents a number of challenges due to its lack of structure, making it difficult to handcraft robust heuristics for diverse scenarios. While learned methods using hand labels or self-supervised data improve generalizability, they often require a tremendous amount of data and can be vulnerable to domain shifts. To improve generalization in novel environments, recent works have incorporated adaptation and self-supervision to develop autonomous systems that can learn from their own experiences online. However, current works often rely on significant prior data, for example minutes of human teleoperation data for each terrain type, which is difficult to scale with more environments and robots. To address these limitations, we propose SALON, a perception-action framework for fast adaptation of traversability estimates with minimal human input. SALON rapidly learns online from experience while avoiding out of distribution terrains to produce adaptive and risk-aware cost and speed maps. Within seconds of collected experience, our results demonstrate comparable navigation performance over kilometer-scale courses in diverse off-road terrain as methods trained on 100-1000x more data. We additionally show promising results on significantly different robots in different environments. Our code is available at https://theairlab.org/SALON.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/V9A2LW7W/Sivaprakasam et al. - 2024 - SALON Self-supervised Adaptive Learning for Off-road Navigation.pdf;/Users/kshitijgoel/Zotero/storage/U7JEVZLP/2412.html}
}

@article{smith_adaptive_2011,
  title = {Adaptive Compression for {{3D}} Laser Data},
  author = {Smith, Mike and Posner, Ingmar and Newman, Paul},
  year = {2011},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {30},
  number = {7},
  pages = {914--935},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364911403019},
  url = {https://doi.org/10.1177/0278364911403019},
  urldate = {2024-11-29},
  abstract = {This paper concerns the creation of efficient surface representations from laser point clouds created by a push broom laser system. We produce a continuous, implicit, non-parametric and non-stationary representation with an update time that is constant. This allows us to form predictions of the underlying workspace surfaces at arbitrary locations and densities. The algorithm places no restriction on the complexity of the surfaces and automatically prunes redundant data via an information theoretic criterion. This criterion makes the use of Gaussian Process Regression a natural choice. We adopt a formulation which handles the typical non-functional relation between XY location and elevation allowing us to map arbitrary environments. Results are presented that use real and synthetic data to analyse the trade-off between compression rate and reconstruction error. We attain decimation factors in excess of two orders of magnitude without significant degradation in fidelity.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VASX36FN/Smith et al. - 2011 - Adaptive compression for 3D laser data.pdf}
}

@inproceedings{snelson_sparse_2005,
  title = {Sparse {{Gaussian Processes}} Using {{Pseudo-inputs}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Snelson, Edward and Ghahramani, Zoubin},
  year = {2005},
  volume = {18},
  publisher = {MIT Press},
  url = {https://papers.nips.cc/paper_files/paper/2005/hash/4491777b1aa8b5b32c2e8666dbe1a495-Abstract.html},
  urldate = {2023-10-11},
  abstract = {We present a new Gaussian process (GP) regression model whose covariance is parameterized by the the locations of M pseudo-input points, which we learn by a gradient based optimization. We take M N, where N is the number of real data points, and hence obtain a sparse regression method which has O(M 2 N ) training cost and O(M 2 ) prediction cost per test case. We also find hyperparameters of the covariance function in the same joint optimization. The method can be viewed as a Bayesian regression model with particular input dependent noise. The method turns out to be closely related to several other sparse GP approaches, and we discuss the relation in detail. We finally demonstrate its performance on some large data sets, and make a direct comparison to other sparse GP methods. We show that our method can match full GP performance with small M , i.e. very sparse solutions, and it significantly outperforms other approaches in this regime.},
  file = {/Users/kshitijgoel/Zotero/storage/KJ9AC9CJ/Snelson and Ghahramani - 2005 - Sparse Gaussian Processes using Pseudo-inputs.pdf}
}

@inproceedings{so_convergence_2022,
  title = {Convergence of Online K-Means},
  booktitle = {Proceedings of {{The}} 25th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {So, Geelon and Mahajan, Gaurav and Dasgupta, Sanjoy},
  year = {2022},
  month = may,
  pages = {8534--8569},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v151/so22a.html},
  urldate = {2023-02-18},
  abstract = {We prove asymptotic convergence for a general class of k-means algorithms performed over streaming data from a distribution--the centers asymptotically converge to the set of stationary points of the k-means objective function. To do so, we show that online k-means over a distribution can be interpreted as stochastic gradient descent with a stochastic learning rate schedule. Then, we prove convergence by extending techniques used in optimization literature to handle settings where center-specific learning rates may depend on the past trajectory of the centers.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DD9GAGAL/So et al. - 2022 - Convergence of online k-means.pdf}
}

@misc{sola_quaternion_2017,
  title = {Quaternion Kinematics for the Error-State {{Kalman}} Filter},
  author = {Sol{\`a}, Joan},
  year = {2017},
  month = nov,
  number = {arXiv:1711.02508},
  eprint = {1711.02508},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1711.02508},
  url = {http://arxiv.org/abs/1711.02508},
  urldate = {2025-04-05},
  abstract = {This article is an exhaustive revision of concepts and formulas related to quaternions and rotations in 3D space, and their proper use in estimation engines such as the error-state Kalman filter. The paper includes an in-depth study of the rotation group and its Lie structure, with formulations using both quaternions and rotation matrices. It makes special attention in the definition of rotation perturbations, derivatives and integrals. It provides numerous intuitions and geometrical interpretations to help the reader grasp the inner mechanisms of 3D rotation. The whole material is used to devise precise formulations for error-state Kalman filters suited for real applications using integration of signals from an inertial measurement unit (IMU).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/RIHI7KTW/Solà - 2017 - Quaternion kinematics for the error-state Kalman filter.pdf;/Users/kshitijgoel/Zotero/storage/FYG98TI3/1711.html}
}

@inproceedings{solak_derivative_2002,
  title = {Derivative {{Observations}} in {{Gaussian Process Models}} of {{Dynamic Systems}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Solak, E. and {Murray-smith}, R. and Leithead, W. and Leith, D. and Rasmussen, Carl},
  year = {2002},
  volume = {15},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper_files/paper/2002/hash/5b8e4fd39d9786228649a8a8bec4e008-Abstract.html},
  urldate = {2023-09-22},
  abstract = {Gaussian processes provide an approach to nonparametric modelling which allows a straightforward combination of function and derivative observations in an empirical model. This is of particular importance in identification of nonlinear dynamic systems from experimental data. 1) It allows us to combine derivative information, and associated uncertainty with normal function observations into the learning and inference pro- cess. This derivative information can be in the form of priors specified by an expert or identified from perturbation data close to equilibrium. 2) It allows a seamless fusion of multiple local linear models in a consis- tent manner, inferring consistent models and ensuring that integrability constraints are met. 3) It improves dramatically the computational ef- ficiency of Gaussian process models for dynamic system identification, by summarising large quantities of near-equilibrium data by a handful of linearisations, reducing the training set size -- traditionally a problem for Gaussian process models.},
  file = {/Users/kshitijgoel/Zotero/storage/RPM83DP5/Solak et al. - 2002 - Derivative Observations in Gaussian Process Models.pdf}
}

@misc{solomon_general_2014,
  title = {A {{General Framework}} for {{Bilateral}} and {{Mean Shift Filtering}}},
  author = {Solomon, Justin and Crane, Keenan and Butscher, Adrian and Wojtan, Chris},
  year = {2014},
  month = apr,
  number = {arXiv:1405.4734},
  eprint = {1405.4734},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1405.4734},
  urldate = {2024-07-27},
  abstract = {We present a generalization of the bilateral filter that can be applied to feature-preserving smoothing of signals on images, meshes, and other domains within a single unified framework. Our discretization is competitive with state-of-the-art smoothing techniques in terms of both accuracy and speed, is easy to implement, and has parameters that are straightforward to understand. Unlike previous bilateral filters developed for meshes and other irregular domains, our construction reduces exactly to the image bilateral on rectangular domains and comes with a rigorous foundation in both the smooth and discrete settings. These guarantees allow us to construct unconditionally convergent mean-shift schemes that handle a variety of extremely noisy signals. We also apply our framework to geometric edge-preserving effects like feature enhancement and show how it is related to local histogram techniques.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/XUC6CEJQ/Solomon et al. - 2014 - A General Framework for Bilateral and Mean Shift Filtering.pdf}
}

@article{soltanolkotabi_robust_2014,
  title = {Robust {{Subspace Clustering}}},
  author = {Soltanolkotabi, Mahdi and Elhamifar, Ehsan and Cand{\`e}s, Emmanuel J.},
  year = {2014},
  journal = {The Annals of Statistics},
  volume = {42},
  number = {2},
  eprint = {43556300},
  eprinttype = {jstor},
  pages = {669--699},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/43556300},
  urldate = {2024-04-26},
  abstract = {Subspace clustering refers to the task of finding a multi-subspace representation that best fits a collection of points taken from a high-dimensional space. This paper introduces an algorithm inspired by sparse subspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern Recognition, CVPR (2009) 2790-2797] to cluster noisy data, and develops some novel theory demonstrating its correctness. In particular, the theory uses ideas from geometric functional analysis to show that the algorithm can accurately recover the underlying subspaces under minimal requirements on their orientation, and on the number of samples per subspace. Synthetic as well as real data experiments complement our theoretical study, illustrating our approach and demonstrating its effectiveness.},
  file = {/Users/kshitijgoel/Zotero/storage/W2ARQFK5/Soltanolkotabi et al. - 2014 - Robust Subspace Clustering.pdf}
}

@article{son_when_2025,
  title = {When {{Meta-Learning Meets Online}} and {{Continual Learning}}: {{A Survey}}},
  shorttitle = {When {{Meta-Learning Meets Online}} and {{Continual Learning}}},
  author = {Son, Jaehyeon and Lee, Soochan and Kim, Gunhee},
  year = {2025},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {47},
  number = {1},
  pages = {413--432},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2024.3463709},
  url = {https://ieeexplore.ieee.org/document/10684017/},
  urldate = {2025-05-24},
  abstract = {Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as ``learning to learn,'' meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.},
  keywords = {Continual learning,Continuing education,Data models,meta-learning,Metalearning,online learning,Streams,Surveys,Taxonomy,Training},
  file = {/Users/kshitijgoel/Zotero/storage/UJCDG353/Son et al. - 2025 - When Meta-Learning Meets Online and Continual Learning A Survey.pdf}
}

@article{song_dynavins_2022,
  title = {{{DynaVINS}}: A {{Visual-Inertial SLAM}} for {{Dynamic Environments}}},
  shorttitle = {{{DynaVINS}}},
  author = {Song, Seungwon and Lim, Hyungtae and Lee, Alex Junho and Myung, Hyun},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3203231},
  abstract = {Visual inertial odometry and SLAM algorithms are widely used in various fields, such as service robots, drones, and autonomous vehicles. Most of the SLAM algorithms are based on assumption that landmarks are static. However, in the real-world, various dynamic objects exist, and they degrade the pose estimation accuracy. In addition, temporarily static objects, which are static during observation but move when they are out of sight, trigger false positive loop closings. To overcome these problems, we propose a novel visual-inertial SLAM framework, called DynaVINS, which is robust against both dynamic objects and temporarily static objects. In our framework, we first present a robust bundle adjustment that could reject the features from dynamic objects by leveraging pose priors estimated by the IMU preintegration. Then, a keyframe grouping and a multi-hypothesis-based constraints grouping methods are proposed to reduce the effect of temporarily static objects in the loop closing. Subsequently, we evaluated our method in a public dataset that contains numerous dynamic objects. Finally, the experimental results corroborate that our DynaVINS has promising performance compared with other state-of-the-art methods by successfully rejecting the effect of dynamic and temporarily static objects. Our code is available: https://github.com/url-kaist/dynaVINS},
  keywords = {Cameras,Dynamics,Heuristic algorithms,Optimization,Simultaneous localization and mapping,SLAM,Vehicle dynamics,Visual Tracking,Visual-Inertial SLAM,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/W3MIHDCC/Song et al. - 2022 - DynaVINS a Visual-Inertial SLAM for Dynamic Envir.pdf;/Users/kshitijgoel/Zotero/storage/49RAUSN5/9870851.html}
}

@inproceedings{song_multiuav_2022,
  title = {Multi-{{UAV Disaster Environment Coverage Planning}} with {{Limited-Endurance}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Song, Hongyu and Yu, Jincheng and Qiu, Jiantao and Sun, Zhixiao and Lang, Kuijun and Luo, Qing and Shen, Yuan and Wang, Yu},
  year = {2022},
  month = may,
  pages = {10760--10766},
  doi = {10.1109/ICRA46639.2022.9812201},
  abstract = {Disaster areas involving floods and earthquakes are commonly large, with the rescue time being quite tight, suggesting multi-Unmanned Aerial Vehicles (UAV) exploration rather than employing a single UAV. For such scenarios, current UAV exploration is modeled as a Coverage Path Planning (CPP) problem to achieve full area coverage in the presence of obstacles. However, the UAV's endurance capability is limited, and the rescue time is constrained, prohibiting even multiple UAVs from completing disaster area coverage on time. Therefore, this paper defines a multi-Agent Endurance-limited CPP (MAEl-CPP) problem that is based on an a priori known heatmap of the disaster area, which affords to explore the most valuable areas under UAV limited energy constraints. Furthermore, we propose a path planning algorithm for the MAEl-CPP problem by ranking the possible disaster areas according to their importance through satellite or remote sensing aerial images and completing path planning according to this ranking. Experimental results demonstrate that the search efficiency of the proposed algorithm is 4.2 times that of the existing algorithm.},
  keywords = {Automation,Autonomous aerial vehicles,Earthquakes,Heating systems,Path planning,Planning,Satellites},
  file = {/Users/kshitijgoel/Zotero/storage/EKLVCBYR/Song et al. - 2022 - Multi-UAV Disaster Environment Coverage Planning w.pdf}
}

@article{song_online_2020,
  title = {Online Coverage and Inspection Planning for {{3D}} Modeling},
  author = {Song, Soohwan and Kim, Daekyum and Jo, Sungho},
  year = {2020},
  month = nov,
  journal = {Autonomous Robots},
  volume = {44},
  number = {8},
  pages = {1431--1450},
  issn = {1573-7527},
  doi = {10.1007/s10514-020-09936-7},
  url = {https://doi.org/10.1007/s10514-020-09936-7},
  urldate = {2025-01-08},
  abstract = {In this study, we address an exploration problem when constructing complete 3D models in an unknown environment using a Micro-Aerial Vehicle. Most previous exploration methods were based on the Next-Best-View (NBV) approaches, which iteratively determine the most informative view, that exposes the greatest unknown area from the current partial model. However, these approaches sometimes miss minor unreconstructed regions like holes or sparse surfaces (while these can be important features). Furthermore, because the NBV methods iterate the next-best path from a current partial view, they sometimes produce unnecessarily long trajectories by revisiting known regions. To address these problems, we propose a novel exploration algorithm that integrates coverage and inspection strategies. The suggested algorithm first computes a global plan to cover unexplored regions to complete the target model sequentially. It then plans local inspection paths that comprehensively scans local frontiers. This approach reduces the total exploration time and improves the completeness of the reconstructed models. We evaluate the proposed algorithm in comparison with other state-of-the-art approaches through simulated and real-world experiments. The results show that our algorithm outperforms the other approaches and in particular improves the completeness of surface coverage.},
  langid = {english},
  keywords = {Active sensing,Artificial Intelligence,Autonomous inspection,Exploration planning,Motion planning,Next-best-view},
  file = {/Users/kshitijgoel/Zotero/storage/NRRXR5DI/Song et al. - 2020 - Online coverage and inspection planning for 3D modeling.pdf}
}

@inproceedings{song_surfacebased_2018,
  title = {Surface-{{Based Exploration}} for {{Autonomous 3D Modeling}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Song, Soohwan and Jo, Sungho},
  year = {2018},
  month = may,
  pages = {4319--4326},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8460862},
  url = {https://ieeexplore.ieee.org/document/8460862},
  urldate = {2025-01-08},
  abstract = {In this study, we addressed a path planning problem of a mobile robot to construct highly accurate 3D models of an unknown environment. Most studies have focused on exploration approaches, which find the most informative viewpoint or trajectories by analyzing a volumetric map. However, the completion of a volumetric map does not necessarily describe the completion of a 3D model. A highly complicated structure sometimes cannot be represented as a volumetric model. We propose a novel exploration algorithm that considers not only a volumetric map but also reconstructed surfaces. Unlike previous approaches, we evaluate the model completeness according to the quality of the reconstructed surfaces and extract low-confidence surfaces. The surface information is used to guide the computation of the exploration path. Experimental results showed that the proposed algorithm performed better than other state-of-the-art exploration methods and especially improved the completeness and confidence of the 3D models.},
  keywords = {Computational modeling,Inspection,Mobile robots,Robot sensing systems,Solid modeling,Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/SPS7ZCVG/Song and Jo - 2018 - Surface-Based Exploration for Autonomous 3D Modeling.pdf;/Users/kshitijgoel/Zotero/storage/MCA2DWD3/8460862.html}
}

@article{song_view_2022,
  title = {View {{Path Planning}} via {{Online Multiview Stereo}} for 3-{{D Modeling}} of {{Large-Scale Structures}}},
  author = {Song, Soohwan and Kim, Daekyum and Choi, Sunghee},
  year = {2022},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {1},
  pages = {372--390},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3083197},
  abstract = {This study addresses a view-path-planning problem during 3-D scanning of a large-scale structure based on multiview stereo (MVS) for unmanned aerial platforms. Recently, most studies have adopted an explore-then-exploit strategy for 3-D scanning. The strategy first generates a coarse model from a simple overhead scanning and then plans an inspection path to cover the entire surface of the coarse model. However, even though the inspection path may be optimal, it is difficult to guarantee a complete and accurate reconstruction result due to defective factors of MVS such as occlusions, textureless surfaces, and insufficient parallaxes. Furthermore, the entire procedure of this strategy is inefficiently slow because of path redundancies and long MVS processing time. Therefore, we propose a novel view-path-planning method for 3-D scanning based on an online MVS reconstruction algorithm. The suggested method incrementally reconstructs the target model online and iteratively plans view paths by analyzing the current partial reconstructions. The method continuously analyzes the quality of the model and detects inaccurately reconstructed surfaces. It then plans an inspection path that provides a complete coverage of the detected surfaces while maximizing the performance of MVS. This method can construct a complete 3-D model in a single scanning trial without the need for rescanning. Extensive experiments show that our method outperforms the other state-of-the-art methods, especially in terms of the model completeness of complex structures.},
  keywords = {3-D reconstruction,active sensing,Computational modeling,Image reconstruction,Inspection,multiview stereo,Planning,Solid modeling,Surface reconstruction,Three-dimensional displays,unmanned aerial vehicles,view path planning},
  file = {/Users/kshitijgoel/Zotero/storage/9HNIUIX9/Song et al. - 2022 - View Path Planning via Online Multiview Stereo for.pdf}
}

@phdthesis{spitzer_dynamical_2021,
  title = {Dynamical {{Model Learning}} and {{Inversion}} for {{Aggressive Quadrotor Flight}}},
  author = {Spitzer, Alexander E},
  year = {2021},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JFCGVKBE/Spitzer - Dynamical Model Learning and Inversion for Aggress.pdf}
}

@inproceedings{spitzer_fast_2020,
  title = {Fast and {{Agile Vision-Based Flight}} with {{Teleoperation}} and {{Collision Avoidance}} on a {{Multirotor}}},
  booktitle = {Proceedings of the 2018 {{International Symposium}} on {{Experimental Robotics}}},
  author = {Spitzer, Alex and Yang, Xuning and Yao, John and Dhawale, Aditya and Goel, Kshitij and Dabhi, Mosam and Collins, Matt and Boirum, Curtis and Michael, Nathan},
  editor = {Xiao, Jing and Kr{\"o}ger, Torsten and Khatib, Oussama},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {524--535},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-33950-0_45},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-33950-0_45},
  copyright = {All rights reserved},
  isbn = {978-3-030-33950-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LVL2DY6U/Spitzer et al. - 2020 - Fast and Agile Vision-Based Flight with Teleoperat.pdf}
}

@book{springer_algebra_1979,
  title = {The Algebra of Random Variables},
  author = {Springer, Melvin D. and Springer, Melvin Dale},
  year = {1979},
  series = {Wiley Series in Probability and Mathematical Statistics},
  publisher = {Wiley},
  address = {New York},
  isbn = {978-0-471-01406-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DN25PVIV/springer_algebra_1979.pdf}
}

@article{sra_short_2012,
  title = {A Short Note on Parameter Approximation for von {{Mises-Fisher}} Distributions: And a Fast Implementation of {{Is}}(x)},
  shorttitle = {A Short Note on Parameter Approximation for von {{Mises-Fisher}} Distributions},
  author = {Sra, Suvrit},
  year = {2012},
  month = mar,
  journal = {Computational Statistics},
  volume = {27},
  number = {1},
  pages = {177--190},
  issn = {1613-9658},
  doi = {10.1007/s00180-011-0232-x},
  url = {https://doi.org/10.1007/s00180-011-0232-x},
  urldate = {2024-07-15},
  abstract = {In high-dimensional directional statistics one of the most basic probability distributions is the von Mises-Fisher (vMF) distribution. Maximum likelihood estimation for the vMF distribution turns out to be surprisingly hard because of a difficult transcendental equation that needs to be solved for computing the concentration parameter {$\kappa$}. This paper is a followup to the recent paper of Tanabe et~al. (Comput Stat 22(1):145--157, 2007), who exploited inequalities about Bessel function ratios to obtain an interval in which the parameter estimate for {$\kappa$} should lie; their observation lends theoretical validity to the heuristic approximation of Banerjee et~al. (JMLR 6:1345--1382, 2005). Tanabe et~al. (Comput Stat 22(1):145--157, 2007) also presented a fixed-point algorithm for computing improved approximations for {$\kappa$}. However, their approximations require (potentially significant) additional computation, and in this short paper we show that given the same amount of computation as their method, one can achieve more accurate approximations using a truncated Newton method. A more interesting contribution of this paper is a simple algorithm for computing Is(x): the modified Bessel function of the first kind. Surprisingly, our na{\"i}ve implementation turns out to be several orders of magnitude faster for large arguments common to high-dimensional data, than the standard implementations in well-established software such as Mathematica{\copyright}, Maple{\copyright}, and Gp/Pari.},
  langid = {english},
  keywords = {Bessel ratio,Maximum-likelihood,Modified Bessel function,Numerical approximation,von Mises-Fisher distribution},
  file = {/Users/kshitijgoel/Zotero/storage/IJCSQHML/Sra - 2012 - A short note on parameter approximation for von Mises-Fisher distributions and a fast implementatio.pdf}
}

@article{srisuchinnawong_growable_2025,
  title = {Growable and Interpretable Neural Control with Online Continual Learning for Autonomous Lifelong Locomotion Learning Machines},
  author = {Srisuchinnawong, Arthicha and Manoonpong, Poramate},
  year = {2025},
  month = may,
  journal = {The International Journal of Robotics Research},
  pages = {02783649251336385},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649251336385},
  url = {https://doi.org/10.1177/02783649251336385},
  urldate = {2025-05-22},
  abstract = {Continual locomotion learning faces four challenges: incomprehensibility, sample inefficiency, lack of knowledge exploitation, and catastrophic forgetting. Thus, this work introduces growable online locomotion learning under multicondition (GOLLUM), which exploits the interpretability feature to address the aforementioned challenges. GOLLUM has two dimensions of interpretability: layer-wise interpretability for neural control function encoding and column-wise interpretability for robot skill encoding. With this interpretable control structure, GOLLUM utilizes neurogenesis to unsupervisely increment columns (ring-like networks); each column is trained separately to encode and maintain a specific primary robot skill. GOLLUM also transfers the parameters to new skills and supplements the learned combination of acquired skills through another neural mapping layer added (layer-wise) with online supplementary learning. On a physical hexapod robot, GOLLUM successfully acquired multiple locomotion skills (e.g., walking, slope climbing, and bouncing) autonomously and continuously within an hour using a simple reward function. Furthermore, it demonstrated the capability of combining previous learned skills to facilitate the learning process of new skills while preventing catastrophic forgetting. Compared to state-of-the-art locomotion learning approaches, GOLLUM is the only approach that addresses the four challenges above mentioned without human intervention. It also emphasizes the potential exploitation of interpretability to achieve autonomous lifelong learning machines.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZU57JWUL/Srisuchinnawong and Manoonpong - 2025 - Growable and interpretable neural control with online continual learning for autonomous lifelong loc.pdf}
}

@article{srivastava_efficient_2019,
  title = {Efficient, {{Multifidelity Perceptual Representations}} via {{Hierarchical Gaussian Mixture Models}}},
  author = {Srivastava, Shobhit and Michael, Nathan},
  year = {2019},
  month = feb,
  journal = {IEEE Transactions on Robotics},
  volume = {35},
  number = {1},
  pages = {248--260},
  issn = {1941-0468},
  doi = {10.1109/TRO.2018.2878363},
  url = {https://ieeexplore.ieee.org/document/8534383},
  urldate = {2024-01-27},
  abstract = {This paper presents a probabilistic environment representation that allows efficient high-fidelity modeling and inference toward enabling informed planning (active perception) on a computationally constrained mobile autonomous system. The proposed approach exploits the fact that real-world environments inherently possess structure that introduces dependencies between spatially distinct locations. Gaussian mixture models are employed to capture these structural dependencies and learn a semiparametric, arbitrary resolution spatial representation. A hierarchy of spatial models is proposed to enable a multifidelity representation with the variation in fidelity quantified via information-theoretic measures. Crucially for active perception, the proposed modeling approach enables a distribution over occupancy with an associated measure of uncertainty via incorporation of free space information. Evaluation of the proposed technique via a real-time graphics processing unit based implementation is presented on real-world data sets in diverse environments. The proposed approach is shown to perform favorably as compared to state-of-the-art occupancy mapping techniques in terms of memory footprint, prediction accuracy, and generalizability to structurally diverse environments.},
  keywords = {Active perception,Computational modeling,Gaussian distribution,Gaussian mixture model,large-scale mapping,machine perception,multi-fidelity representation,Robot sensing systems,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/KBC7SZE5/Srivastava and Michael - 2019 - Efficient, Multifidelity Perceptual Representation.pdf;/Users/kshitijgoel/Zotero/storage/9H6SG4PI/8534383.html}
}

@inproceedings{srivastava_riemannian_2007,
  title = {Riemannian {{Analysis}} of {{Probability Density Functions}} with {{Applications}} in {{Vision}}},
  booktitle = {2007 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Srivastava, Anuj and Jermyn, Ian and Joshi, Shantanu},
  year = {2007},
  month = jun,
  pages = {1--8},
  publisher = {IEEE},
  address = {Minneapolis, MN, USA},
  doi = {10.1109/CVPR.2007.383188},
  url = {http://ieeexplore.ieee.org/document/4270213/},
  urldate = {2024-02-28},
  abstract = {Applications in computer vision involve statistically analyzing an important class of constrained, nonnegative functions, including probability density functions (in texture analysis), dynamic time-warping functions (in activity analysis), and re-parametrization or non-rigid registration functions (in shape analysis of curves). For this one needs to impose a Riemannian structure on the spaces formed by these functions. We propose a ``spherical'' version of the Fisher-Rao metric that provides closed-form expressions for geodesics and distances, and allows fast computation of sample statistics. To demonstrate this approach, we present an application in planar shape classification.},
  isbn = {978-1-4244-1179-5 978-1-4244-1180-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YZYDE2P9/Srivastava et al. - 2007 - Riemannian Analysis of Probability Density Functio.pdf}
}

@book{st.laurent_understanding_2004,
  title = {Understanding Open Source and Free Software Licensing},
  author = {St. Laurent, Andrew M.},
  year = {2004},
  edition = {1st ed},
  publisher = {O'Reilly},
  address = {Beijing ; Sebastopol, CA},
  isbn = {978-0-596-00581-8},
  lccn = {K1443.C6 S7 2004},
  keywords = {Computer programs,Computer software industry,Copyright,Free computer software,Law and legislation,Licenses,Open source software},
  annotation = {OCLC: ocm56643828},
  file = {/Users/kshitijgoel/Zotero/storage/GQSNT6ZY/St. Laurent - 2004 - Understanding open source and free software licens.pdf}
}

@inproceedings{stachniss_information_2005,
  title = {Information {{Gain-based Exploration Using Rao-Blackwellized Particle Filters}}},
  booktitle = {Robotics: {{Science}} and {{Systems I}}},
  author = {Stachniss, Cyrill and Grisetti, Giorgio and Burgard, Wolfram},
  year = {2005},
  month = jun,
  volume = {01},
  url = {https://www.roboticsproceedings.org/rss01/p09.html},
  urldate = {2023-10-28},
  isbn = {978-0-262-70114-3},
  file = {/Users/kshitijgoel/Zotero/storage/8AL4SGIM/Stachniss et al. - 2005 - Information Gain-based Exploration Using Rao-Black.pdf}
}

@inproceedings{stachniss_mapping_2003,
  title = {Mapping and Exploration with Mobile Robots Using Coverage Maps},
  booktitle = {Proceedings 2003 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}} 2003) ({{Cat}}. {{No}}.{{03CH37453}})},
  author = {Stachniss, C. and Burgard, W.},
  year = {2003},
  volume = {1},
  pages = {467--472},
  publisher = {IEEE},
  address = {Las Vegas, Nevada, USA},
  doi = {10.1109/IROS.2003.1250673},
  url = {http://ieeexplore.ieee.org/document/1250673/},
  urldate = {2023-10-28},
  isbn = {978-0-7803-7860-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/B7M75V8S/Stachniss and Burgard - 2003 - Mapping and exploration with mobile robots using c.pdf}
}

@article{stamenkovic_next_2019,
  title = {The next Frontier for Planetary and Human Exploration},
  author = {Stamenkovi{\'c}, V. and Beegle, L. W. and Zacny, K. and Arumugam, D. D. and Baglioni, P. and Barba, N. and Baross, J. and Bell, M. S. and Bhartia, R. and Blank, J. G. and Boston, P. J. and Breuer, D. and Brinckerhoff, W. and Burgin, M. S. and Cooper, I. and Cormarkovic, V. and Davila, A. and Davis, R. M. and Edwards, C. and Etiope, G. and Fischer, W. W. and Glavin, D. P. and Grimm, R. E. and Inagaki, F. and Kirschvink, J. L. and Kobayashi, A. and Komarek, T. and Malaska, M. and Michalski, J. and M{\'e}nez, B. and Mischna, M. and Moser, D. and Mustard, J. and Onstott, T. C. and Orphan, V. J. and Osburn, M. R. and Plaut, J. and Plesa, A.-C. and Putzig, N. and Rogers, K. L. and Rothschild, L. and Russell, M. and Sapers, H. and Lollar, B. Sherwood and Spohn, T. and Tarnas, J. D. and Tuite, M. and Viola, D. and Ward, L. M. and Wilcox, B. and Woolley, R.},
  year = {2019},
  month = feb,
  journal = {Nature Astronomy},
  volume = {3},
  number = {2},
  pages = {116--120},
  publisher = {Nature Publishing Group},
  issn = {2397-3366},
  doi = {10.1038/s41550-018-0676-9},
  url = {https://www.nature.com/articles/s41550-018-0676-9},
  urldate = {2023-01-24},
  abstract = {The surface of Mars has been well mapped and characterized, yet the subsurface --- the most likely place to find signs of extant or extinct life and a repository of useful resources for human exploration --- remains unexplored. In the near future this is set to change.},
  copyright = {2019 Springer Nature Limited},
  langid = {english},
  keywords = {Astrobiology,Astronomical instrumentation,Funding,Inner planets}
}

@article{stanford_finding_2000,
  title = {Finding Curvilinear Features in Spatial Point Patterns: Principal Curve Clustering with Noise},
  shorttitle = {Finding Curvilinear Features in Spatial Point Patterns},
  author = {Stanford, D.C. and Raftery, A.E.},
  year = {2000},
  month = jun,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {22},
  number = {6},
  pages = {601--609},
  issn = {01628828},
  doi = {10.1109/34.862198},
  url = {http://ieeexplore.ieee.org/document/862198/},
  urldate = {2024-04-29},
  abstract = {{\DH}Clustering about principal curves combines parametric modeling of noise with nonparametric modeling of feature shape. This is useful for detecting curvilinear features in spatial point patterns, with or without background noise. Applications include the detection of curvilinear minefields from reconnaissance images, some of the points in which represent false detections, and the detection of seismic faults from earthquake catalogs. Our algorithm for principal curve clustering is in two steps: The first is hierarchical and agglomerative (HPCC) and the second consists of iterative relocation based on the Classification EM algorithm (CEM-PCC). HPCC is used to combine potential feature clusters, while CEM-PCC refines the results and deals with background noise. It is important to have a good starting point for the algorithm: This can be found manually or automatically using, for example, nearest neighbor clutter removal or model-based clustering. We choose the number of features and the amount of smoothing simultaneously, using approximate Bayes factors.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/UYMKDS2K/Stanford and Raftery - 2000 - Finding curvilinear features in spatial point patt.pdf}
}

@inproceedings{stauffer_adaptive_1999,
  title = {Adaptive Background Mixture Models for Real-Time Tracking},
  booktitle = {Proceedings. 1999 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{Cat}}. {{No PR00149}})},
  author = {Stauffer, C. and Grimson, W.E.L.},
  year = {1999},
  month = jun,
  volume = {2},
  pages = {246-252 Vol. 2},
  issn = {1063-6919},
  doi = {10.1109/CVPR.1999.784637},
  abstract = {A common method for real-time segmentation of moving regions in image sequences involves "background subtraction", or thresholding the error between an estimate of the image without moving objects and the current image. The numerous approaches to this problem differ in the type of background model used and the procedure used to update the model. This paper discusses modeling each pixel as a mixture of Gaussians and using an on-line approximation to update the model. The Gaussian, distributions of the adaptive mixture model are then evaluated to determine which are most likely to result from a background process. Each pixel is classified based on whether the Gaussian distribution which represents it most effectively is considered part of the background model. This results in a stable, real-time outdoor tracker which reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. This system has been run almost continuously for 16 months, 24 hours a day, through rain and snow.},
  keywords = {Adaptive systems,Artificial intelligence,Gaussian distribution,Image segmentation,Image sequences,Laboratories,Layout,Robustness,Tracking,Vehicle detection},
  file = {/Users/kshitijgoel/Zotero/storage/I2G945LQ/Stauffer and Grimson - 1999 - Adaptive background mixture models for real-time t.pdf;/Users/kshitijgoel/Zotero/storage/MCR9L93P/784637.html}
}

@inproceedings{steinbrucker_largescale_2013,
  title = {Large-{{Scale Multi-resolution Surface Reconstruction}} from {{RGB-D Sequences}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Steinbrucker, Frank and Kerl, Christian and Cremers, Daniel},
  year = {2013},
  pages = {3264--3271},
  url = {https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Steinbrucker_Large-Scale_Multi-resolution_Surface_2013_ICCV_paper.html},
  urldate = {2024-06-10},
  file = {/Users/kshitijgoel/Zotero/storage/T8NFBNMU/Steinbrucker et al. - 2013 - Large-Scale Multi-resolution Surface Reconstruction from RGB-D Sequences.pdf}
}

@phdthesis{steinruecken_lossless_2014,
  title = {Lossless {{Data Compression}}},
  author = {Steinruecken, Christian},
  year = {2014},
  month = aug,
  address = {King's College},
  abstract = {This thesis makes several contributions to the field of data compression. Lossless data compression algorithms shorten the description of input objects, such as sequences of text, in a way that allows perfect recovery of the original object. Such algorithms exploit the fact that input objects are not uniformly distributed: by allocating shorter descriptions to more probable objects and longer descriptions to less probable objects, the expected length of the compressed output can be made shorter than the object's original description. Compression algorithms can be designed to match almost any given probability distribution over input objects.},
  langid = {english},
  school = {University of Cambridge},
  file = {/Users/kshitijgoel/Zotero/storage/C4F4WC6A/Steinruecken - Lossless Data Compression.pdf}
}

@article{stella-watts_epidemiology_2012,
  title = {The Epidemiology of Caving Injuries in the {{United States}}},
  author = {{Stella-Watts}, Alejandro C and Holstege, Christopher P and Lee, Jae K and Charlton, Nathan P},
  year = {2012},
  journal = {Wilderness \& environmental medicine},
  volume = {23},
  number = {3},
  pages = {215--222},
  publisher = {Elsevier}
}

@article{stepanas_ohm_2022,
  title = {{{OHM}}: {{GPU Based Occupancy Map Generation}}},
  shorttitle = {{{OHM}}},
  author = {Stepanas, Kazys and Williams, Jason and Hern{\'a}ndez, Emili and Ruetz, Fabio and Hines, Thomas},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {11078--11085},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3196145},
  abstract = {Occupancy grid maps (OGMs) are fundamental to most systems for autonomous robotic navigation. However, CPU-based implementations struggle to keep up with data rates from modern 3D lidar sensors, and provide little capacity for modern extensions which maintain richer voxel representations. This article presents Occupancy Homogenous Mapping (OHM), our open source, GPU-based OGM framework. We show how the algorithms can be mapped to GPU resources, resolving difficulties with contention to obtain a successful implementation. The implementation supports many modern OGM algorithms including Normal Distributions Transform-Occupancy Maps (NDT-OM), Normal Distributions Transform-Traversability Maps (NDT-TM), decay-rate and Truncated Sign Distance Function (TSDF). A thorough performance evaluation is presented based on tracked and quadruped Uncrewed Ground Vehicle (UGV) platforms and UAVs, and data sets from both outdoor and subterranean environments. The results demonstrate excellent performance improvements both offline, and for online processing in embedded platforms. Finally, we describe how OHM was a key enabler for the UGV navigation solution for our entry in the Defense Advanced Research Projects Agency (DARPA) Subterranean Challenge, which placed second at the Final Event.},
  keywords = {Autonomous vehicle navigation,Graphics processing units,Laser radar,Navigation,Robot sensing systems,Robots,sensor fusion,Sensors,software tools for robot programming,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/FE5JNJGN/Stepanas et al. - 2022 - OHM GPU Based Occupancy Map Generation.pdf;/Users/kshitijgoel/Zotero/storage/VG4NDR4J/9849048.html}
}

@article{stephan_precise_2020,
  title = {Precise {{Tracking}} of {{Extended Three-Dimensional Dubins Paths}} for {{Fixed-Wing Aircraft}}},
  author = {Stephan, Johannes and Pfeifle, Ole and Notter, Stefan and Pinchetti, Federico and Fichter, Walter},
  year = {2020},
  journal = {Journal of Guidance, Control, and Dynamics},
  volume = {43},
  number = {12},
  pages = {2399--2405},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0731-5090},
  doi = {10.2514/1.G005240},
  url = {https://doi.org/10.2514/1.G005240},
  urldate = {2023-02-13},
  file = {/Users/kshitijgoel/Zotero/storage/2233VDAJ/Stephan et al. - 2020 - Precise Tracking of Extended Three-Dimensional Dub.pdf;/Users/kshitijgoel/Zotero/storage/7EF2I5DN/1.html}
}

@techreport{stephens_techniques_1969,
  type = {Technical {{Report}}},
  title = {Techniques for {{Directional Data}}},
  author = {Stephens, M. A.},
  year = {1969},
  number = {SOL\_ONR\_150},
  address = {Stanford, CA},
  institution = {Stanford University},
  url = {https://purl.stanford.edu/rw590rq7988},
  urldate = {2024-06-27},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/K9AAUPQ2/rw590rq7988.html}
}

@article{stern_multiagent_2019,
  title = {Multi-{{Agent Pathfinding}}: {{Definitions}}, {{Variants}}, and {{Benchmarks}}},
  shorttitle = {Multi-{{Agent Pathfinding}}},
  author = {Stern, Roni and Sturtevant, Nathan and Felner, Ariel and Koenig, Sven and Ma, Hang and Walker, Thayne and Li, Jiaoyang and Atzmon, Dor and Cohen, Liron and Kumar, T. K. and Bart{\'a}k, Roman and Boyarski, Eli},
  year = {2019},
  journal = {Proceedings of the International Symposium on Combinatorial Search},
  volume = {10},
  number = {1},
  pages = {151--158},
  issn = {2832-9163},
  doi = {10.1609/socs.v10i1.18510},
  url = {https://ojs.aaai.org/index.php/SOCS/article/view/18510},
  urldate = {2024-03-01},
  abstract = {The multi-agent pathfinding problem (MAPF) is the fundamental problem of planning paths for multiple agents, where the key constraint is that the agents will be able to follow these paths concurrently without colliding with each other. Applications of MAPF include automated warehouses, autonomous vehicles, and robotics. Research on MAPF has been flourishing in the past couple of years. Different MAPF research papers assume different sets of assumptions, e.g., whether agents can traverse the same road at the same time, and have different objective functions, e.g., minimize makespan or sum of agents' actions costs. These assumptions and objectives are sometimes implicitly assumed or described informally. This makes it difficult for establishing appropriate baselines for comparison in research papers, as well as making it difficult for practitioners to find the papers relevant to their concrete application. This paper aims to fill this gap and facilitate future research and practitioners by providing a unifying terminology for describing the common MAPF assumptions and objectives. In addition, we also provide pointers to two MAPF benchmarks. In particular, we introduce a new grid-based benchmark for MAPF, and demonstrate experimentally that it poses a challenge to contemporary MAPF algorithms.},
  copyright = {Copyright (c) 2021 Proceedings of the International Symposium on Combinatorial Search},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SXSL7NVF/Stern et al. - 2019 - Multi-Agent Pathfinding Definitions, Variants, an.pdf}
}

@article{stewart_efficient_1980,
  title = {The {{Efficient Generation}} of {{Random Orthogonal Matrices}} with an {{Application}} to {{Condition Estimators}}},
  author = {Stewart, G. W.},
  year = {1980},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {17},
  number = {3},
  eprint = {2156882},
  eprinttype = {jstor},
  pages = {403--409},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1429},
  url = {https://www.jstor.org/stable/2156882},
  urldate = {2024-04-15},
  abstract = {This paper presents a method for generating pseudo-random orthogonal matrices from the Haar distribution for the group of orthogonal matrices. The random matrices are expressed as products of n - 1 Householder transformations, which can be computed in O(n\textsuperscript{2}) time. The technique is used in an empirical study of two methods for estimating the condition number of a matrix.},
  file = {/Users/kshitijgoel/Zotero/storage/VSH6IEUW/Stewart - 1980 - The Efficient Generation of Random Orthogonal Matr.pdf}
}

@misc{stoica_specifications_2024,
  title = {Specifications: {{The}} Missing Link to Making the Development of {{LLM}} Systems an Engineering Discipline},
  shorttitle = {Specifications},
  author = {Stoica, Ion and Zaharia, Matei and Gonzalez, Joseph and Goldberg, Ken and Sen, Koushik and Zhang, Hao and Angelopoulos, Anastasios and Patil, Shishir G. and Chen, Lingjiao and Chiang, Wei-Lin and Davis, Jared Q.},
  year = {2024},
  month = dec,
  number = {arXiv:2412.05299},
  eprint = {2412.05299},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.05299},
  url = {http://arxiv.org/abs/2412.05299},
  urldate = {2024-12-24},
  abstract = {Despite the significant strides made by generative AI in just a few short years, its future progress is constrained by the challenge of building modular and robust systems. This capability has been a cornerstone of past technological revolutions, which relied on combining components to create increasingly sophisticated and reliable systems. Cars, airplanes, computers, and software consist of components-such as engines, wheels, CPUs, and libraries-that can be assembled, debugged, and replaced. A key tool for building such reliable and modular systems is specification: the precise description of the expected behavior, inputs, and outputs of each component. However, the generality of LLMs and the inherent ambiguity of natural language make defining specifications for LLM-based components (e.g., agents) both a challenging and urgent problem. In this paper, we discuss the progress the field has made so far-through advances like structured outputs, process supervision, and test-time compute-and outline several future directions for research to enable the development of modular and reliable LLM-based systems through improved specifications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Software Engineering},
  file = {/Users/kshitijgoel/Zotero/storage/USKQ3D8G/Stoica et al. - 2024 - Specifications The missing link to making the development of LLM systems an engineering discipline.pdf;/Users/kshitijgoel/Zotero/storage/XLTDGIS8/2412.html}
}

@inproceedings{stoyanov_normal_2013,
  title = {Normal {{Distributions Transform Occupancy Map}} Fusion: {{Simultaneous}} Mapping and Tracking in Large Scale Dynamic Environments},
  shorttitle = {Normal {{Distributions Transform Occupancy Map}} Fusion},
  booktitle = {2013 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Stoyanov, Todor and Saarinen, Jari and Andreasson, Henrik and Lilienthal, Achim J.},
  year = {2013},
  month = nov,
  pages = {4702--4708},
  issn = {2153-0866},
  doi = {10.1109/IROS.2013.6697033},
  url = {https://ieeexplore.ieee.org/document/6697033},
  urldate = {2024-11-15},
  abstract = {Autonomous vehicles operating in real-world industrial environments have to overcome numerous challenges, chief among which are the creation of consistent 3D world models and the simultaneous tracking of the vehicle pose with respect to the created maps. In this paper we integrate two recently proposed algorithms in an online, near-realtime mapping and tracking system. Using the Normal Distributions Transform (NDT), a sparse Gaussian Mixture Model, for representation of 3D range scan data, we propose a frame-to-model registration and data fusion algorithm - NDT Fusion. The proposed approach uses a submap indexing system to achieve operation in arbitrarily-sized environments. The approach is evaluated on a publicly available city-block sized data set, achieving accuracy and runtime performance significantly better than current state of the art. In addition, the system is evaluated on a data set covering ten hours of operation and a trajectory of 7.2km in a real-world industrial environment, achieving centimeter accuracy at update rates of 5-10 Hz.},
  keywords = {Accuracy,Gaussian distribution,Runtime,Simultaneous localization and mapping,Three-dimensional displays,Trajectory,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/ZRJ6733P/Stoyanov et al. - 2013 - Normal Distributions Transform Occupancy Map fusion Simultaneous mapping and tracking in large scal.pdf;/Users/kshitijgoel/Zotero/storage/PLJ2JZS4/6697033.html}
}

@inproceedings{stoyanov_path_2010,
  title = {Path Planning in {{3D}} Environments Using the {{Normal Distributions Transform}}},
  booktitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Stoyanov, Todor and Magnusson, Martin and Andreasson, Henrik and Lilienthal, Achim J.},
  year = {2010},
  month = oct,
  pages = {3263--3268},
  issn = {2153-0866},
  doi = {10.1109/IROS.2010.5650789},
  abstract = {Planning feasible paths in fully three-dimensional environments is a challenging problem. Application of existing algorithms typically requires the use of limited 3D representations that discard potentially useful information. This article proposes a novel approach to path planning that utilizes a full 3D representation directly: the Three-Dimensional Normal Distributions Transform (3D-NDT). The well known wavefront planner is modified to use 3D-NDT as a basis for map representation and evaluated using both indoor and outdoor data sets. The use of 3D-NDT for path planning is thus demonstrated to be a viable choice with good expressive capabilities.},
  keywords = {Collision avoidance,Gaussian distribution,Path planning,Planning,Robots,Three dimensional displays,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/GA7QEISJ/Stoyanov et al. - 2010 - Path planning in 3D environments using the Normal .pdf;/Users/kshitijgoel/Zotero/storage/ILWK5TI3/5650789.html}
}

@article{strapazzon_caves_2014,
  title = {{{CAVES}} as an Environment for Astronaut Training},
  author = {Strapazzon, Giacomo and Pilo, Luca and Bessone, Loredana and Barratt, Michael R},
  year = {2014},
  journal = {Wilderness \& environmental medicine},
  volume = {25},
  number = {2},
  pages = {244--245},
  publisher = {Elsevier}
}

@inproceedings{straub_dirichlet_2015,
  title = {A {{Dirichlet Process Mixture Model}} for {{Spherical Data}}},
  booktitle = {Proceedings of the {{Eighteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Straub, Julian and Chang, Jason and Freifeld, Oren and Iii, John Fisher},
  year = {2015},
  month = feb,
  pages = {930--938},
  publisher = {PMLR},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v38/straub15.html},
  urldate = {2024-07-15},
  abstract = {Directional data, naturally represented as points on the unit sphere, appear in many applications.  However, unlike the case of Euclidean data, flexible mixture models on the sphere that can capture correlations, handle an unknown number of components and extend readily to high-dimensional data have yet to be suggested.  For this purpose we propose a Dirichlet process mixture model of Gaussian distributions in distinct tangent spaces (DP-TGMM) to the sphere.  Importantly, the formulation of the proposed model allows the extension of recent advances in efficient inference for Bayesian nonparametric models to the spherical domain.  Experiments on synthetic data as well as real-world 3D surface normal and 20-dimensional semantic word vector data confirm the expressiveness and applicability of the DP-TGMM.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7W7882VR/Straub et al. - 2015 - A Dirichlet Process Mixture Model for Spherical Data.pdf}
}

@phdthesis{straub_nonparametric_2017,
  type = {Thesis},
  title = {Nonparametric Directional Perception},
  author = {Straub, Julian},
  year = {2017},
  url = {https://dspace.mit.edu/handle/1721.1/112029},
  urldate = {2024-03-04},
  abstract = {Artificial perception systems, like autonomous cars and augmented reality headsets, rely on dense 3D sensing technology such as RGB-D cameras and LiDAR. scanners. Due to the structural simplicity of man-made environments, understanding and leveraging not only the 3D data but also the local orientations of the constituent surfaces, has huge potential. From an indoor scene to large-scale urban environments, a large fraction of the surfaces can be described by just a few planes with even fewer different normal directions. This sparsity is evident in the surface normal distributions, which exhibit a small number of concentrated clusters. In this work, I draw a rigorous connection between surface normal distributions and 3D structure, and explore this connection in light of different environmental assumptions to further 3D perception. Specifically, I propose the concepts of the Manhattan Frame and the unconstrained directional segmentation. These capture, in the space of surface normals, scenes composed of multiple Manhattan Worlds and more general Stata Center Worlds, in which the orthogonality assumption of the Manhattan World is not applicable. This exploration is theoretically founded in Bayesian nonparametric models, which capture two key properties of the 3D sensing process of an artificial perception system: (1) the inherent sequential nature of data acquisition and (2) that the required model complexity grows with the amount of observed data. Herein, I derive inference algorithms for directional clustering and segmentation which inherently exploit and respect these properties. The fundamental insights gleaned from the connection between surface normal distributions and 3D structure lead to practical advances in scene segmentation, drift-free rotation estimation, global point cloud registration and real-time direction-aware 3D reconstruction to aid artificial perception systems.},
  copyright = {MIT theses are protected by copyright. They may be viewed, downloaded, or printed from this source but further reproduction or distribution in any format is prohibited without written permission.},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2017-10-30T15:28:23Z},
  file = {/Users/kshitijgoel/Zotero/storage/2UHZVA4N/Straub - 2017 - Nonparametric directional perception.pdf}
}

@inproceedings{straub_smallvariance_2015,
  title = {Small-{{Variance Nonparametric Clustering}} on the {{Hypersphere}}},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Straub, Julian and Campbell, Trevor and How, Jonathan P. and Fisher, John W.},
  year = {2015},
  pages = {334--342},
  url = {https://openaccess.thecvf.com/content_cvpr_2015/html/Straub_Small-Variance_Nonparametric_Clustering_2015_CVPR_paper.html},
  urldate = {2024-07-15},
  file = {/Users/kshitijgoel/Zotero/storage/6X6CUZH9/Straub et al. - 2015 - Small-Variance Nonparametric Clustering on the Hypersphere.pdf}
}

@misc{stroobants_neuromorphic_2024,
  title = {Neuromorphic {{Attitude Estimation}} and {{Control}}},
  author = {Stroobants, Stein and de Wagter, Christophe and Croon, Guido C. H. E. De},
  year = {2024},
  month = nov,
  number = {arXiv:2411.13945},
  eprint = {2411.13945},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.13945},
  url = {http://arxiv.org/abs/2411.13945},
  urldate = {2025-02-04},
  abstract = {The real-world application of small drones is mostly hampered by energy limitations. Neuromorphic computing promises extremely energy-efficient AI for autonomous flight, but is still challenging to train and deploy on real robots. In order to reap the maximal benefits from neuromorphic computing, it is desired to perform all autonomy functions end-to-end on a single neuromorphic chip, from low-level attitude control to high-level navigation. This research presents the first neuromorphic control system using a spiking neural network (SNN) to effectively map a drone's raw sensory input directly to motor commands. We apply this method to low-level attitude estimation and control for a quadrotor, deploying the SNN on a tiny Crazyflie. We propose a modular SNN, separately training and then merging estimation and control sub-networks. The SNN is trained with imitation learning, using a flight dataset of sensory-motor pairs. Post-training, the network is deployed on the Crazyflie, issuing control commands from sensor inputs at \$500\$Hz. Furthermore, for the training procedure we augmented training data by flying a controller with additional excitation and time-shifting the target data to enhance the predictive capabilities of the SNN. On the real drone the perception-to-control SNN tracks attitude commands with an average error of \$3\$ degrees, compared to \$2.5\$ degrees for the regular flight stack. We also show the benefits of the proposed learning modifications for reducing the average tracking error and reducing oscillations. Our work shows the feasibility of performing neuromorphic end-to-end control, laying the basis for highly energy-efficient and low-latency neuromorphic autopilots.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/TIYALMCI/Stroobants et al. - 2024 - Neuromorphic Attitude Estimation and Control.pdf;/Users/kshitijgoel/Zotero/storage/69ILTN5D/2411.html}
}

@phdthesis{strub_leveraging_2021,
  type = {Thesis},
  title = {Leveraging Multiple Sources of Information to Search Continuous Spaces},
  author = {Strub, Marlin P.},
  year = {2021},
  url = {https://robotic-esp.com/papers/strub_dphil21},
  urldate = {2024-06-13},
  abstract = {Path planning algorithms can solve the problem of finding paths through continuous spaces. This problem appears in a wide range of applications, from navigating autonomous robots to automating assessments of surgical tolerances. The performance requirements on these algorithms tend to become more demanding as the problems they are applied to become more sophisticated. This simultaneous increase in performance requirements and application complexity calls for new approaches to the path planning problem and makes it an active area of research in robotics and beyond. This thesis demonstrates how different types of information can be leveraged to solve the path planning problem more effectively. Optimization-specific information can guide the search towards high-quality solutions, environment-specific information can exploit incremental information about the surroundings, and intent-specific information can directly align the search of a problem with its priorities. These three types of information are leveraged in this thesis by integrating advanced graph-search techniques in sampling-based path planning algorithms. The resulting planners, Advanced BIT* (ABIT*), Adaptively Informed Trees (AIT*), and Effort Informed Trees (EIT*), are theoretically shown to be almost-surely asymptotically optimal and experimentally demonstrated to outperform existing planners on diverse problems in abstract, robotic, and biomedical domains.},
  langid = {english},
  school = {University of Oxford},
  file = {/Users/kshitijgoel/Zotero/storage/QSXQIDSZ/Strub - 2021 - Leveraging multiple sources of information to search continuous spaces.pdf}
}

@inproceedings{subbarao_nonlinear_2006,
  title = {Nonlinear {{Mean Shift}} for {{Clustering}} over {{Analytic Manifolds}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'06)},
  author = {Subbarao, R. and Meer, P.},
  year = {2006},
  month = jun,
  volume = {1},
  pages = {1168--1175},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2006.210},
  url = {https://ieeexplore.ieee.org/document/1640882},
  urldate = {2024-06-27},
  abstract = {The mean shift algorithm is widely applied for nonparametric clustering in Euclidean spaces. Recently, mean shift was generalized for clustering on matrix Lie groups. We further extend the algorithm to a more general class of nonlinear spaces, the set of analytic manifolds. As examples, two specific classes of frequently occurring parameter spaces, Grassmann manifolds and Lie groups, are considered. When the algorithm proposed here is restricted to matrix Lie groups the previously proposed method is obtained. The algorithm is applied to a variety of robust motion segmentation problems and multibody factorization. The motion segmentation method is robust to outliers, does not require any prior specification of the number of independent motions and simultaneously estimates all the motions present.},
  keywords = {Algorithm design and analysis,Cameras,Clustering algorithms,Clustering methods,Computer vision,Image segmentation,Manifolds,Motion estimation,Motion segmentation,Robustness},
  file = {/Users/kshitijgoel/Zotero/storage/ZTW4XB7E/Subbarao and Meer - 2006 - Nonlinear Mean Shift for Clustering over Analytic Manifolds.pdf;/Users/kshitijgoel/Zotero/storage/FBWJFECL/1640882.html}
}

@article{subbarao_nonlinear_2009,
  title = {Nonlinear {{Mean Shift}} over {{Riemannian Manifolds}}},
  author = {Subbarao, Raghav and Meer, Peter},
  year = {2009},
  month = aug,
  journal = {International Journal of Computer Vision},
  volume = {84},
  number = {1},
  pages = {1--20},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-008-0195-8},
  url = {http://link.springer.com/10.1007/s11263-008-0195-8},
  urldate = {2024-02-28},
  abstract = {The original mean shift algorithm is widely applied for nonparametric clustering in vector spaces. In this paper we generalize it to data points lying on Riemannian manifolds. This allows us to extend mean shift based clustering and filtering techniques to a large class of frequently occurring non-vector spaces in vision. We present an exact algorithm and prove its convergence properties as opposed to previous work which approximates the mean shift vector. The computational details of our algorithm are presented for frequently occurring classes of manifolds such as matrix Lie groups, Grassmann manifolds, essential matrices and symmetric positive definite matrices. Applications of the mean shift over these manifolds are shown.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HZGN5EXU/Subbarao and Meer - 2009 - Nonlinear Mean Shift over Riemannian Manifolds.pdf}
}

@inproceedings{sucar_imap_2021,
  title = {{{iMAP}}: {{Implicit Mapping}} and {{Positioning}} in {{Real-Time}}},
  shorttitle = {{{iMAP}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Sucar, Edgar and Liu, Shikun and Ortiz, Joseph and Davison, Andrew J.},
  year = {2021},
  pages = {6229--6238},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Sucar_iMAP_Implicit_Mapping_and_Positioning_in_Real-Time_ICCV_2021_paper.html},
  urldate = {2023-09-14},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M9TEFIVD/Sucar et al. - 2021 - iMAP Implicit Mapping and Positioning in Real-Tim.pdf}
}

@inproceedings{sudhakar_uncertainty_2022,
  title = {Uncertainty from {{Motion}} for {{DNN Monocular Depth Estimation}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Sudhakar, Soumya and Sze, Vivienne and Karaman, Sertac},
  year = {2022},
  month = may,
  pages = {8673--8679},
  doi = {10.1109/ICRA46639.2022.9812222},
  url = {https://ieeexplore.ieee.org/document/9812222},
  urldate = {2025-02-20},
  abstract = {Deployment of deep neural networks (DNNs) for monocular depth estimation in safety-critical scenarios on resource-constrained platforms requires well-calibrated and efficient uncertainty estimates. However, many popular uncertainty estimation techniques, including state-of-the-art ensembles and popular sampling-based methods, require multiple inferences per input, making them difficult to deploy in latency-constrained or energy-constrained scenarios. We propose a new algorithm, called Uncertainty from Motion (UfM), that requires only one inference per input. UfM exploits the temporal redundancy in video inputs by merging incrementally the per-pixel depth prediction and per-pixel aleatoric uncertainty prediction of points that are seen in multiple views in the video sequence. When UfM is applied to ensembles, we show that UfM can retain the uncertainty quality of ensembles at a fraction of the energy by running only a single ensemble member at each frame and fusing the uncertainty over the sequence of frames. In a set of representative experiments using FCDenseNet and eight indistribution and out-of-distribution video sequences, UfM offers comparable uncertainty quality to an ensemble of size 10 while consuming only 11.3\% of the ensemble's energy and running 6.4{\texttimes} faster on a single Nvidia RTX 2080 Ti GPU, enabling near ensemble uncertainty quality for resource-constrained, real-time scenarios.},
  keywords = {Estimation,Graphics processing units,Merging,Neural networks,Redundancy,Uncertainty,Video sequences},
  file = {/Users/kshitijgoel/Zotero/storage/BBZ6PT8E/Sudhakar et al. - 2022 - Uncertainty from Motion for DNN Monocular Depth Estimation.pdf;/Users/kshitijgoel/Zotero/storage/35HIMYQG/9812222.html}
}

@article{sugar_finding_2003,
  title = {Finding the {{Number}} of {{Clusters}} in a {{Dataset}}: {{An Information-Theoretic Approach}}},
  shorttitle = {Finding the {{Number}} of {{Clusters}} in a {{Dataset}}},
  author = {Sugar, Catherine A. and James, Gareth M.},
  year = {2003},
  journal = {Journal of the American Statistical Association},
  volume = {98},
  number = {463},
  eprint = {30045303},
  eprinttype = {jstor},
  pages = {750--763},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  url = {https://www.jstor.org/stable/30045303},
  urldate = {2022-05-30},
  abstract = {One of the most difficult problems in cluster analysis is identifying the number of groups in a dataset. Most previously suggested approaches to this problem are either somewhat ad hoc or require parametric assumptions and complicated calculations. In this article we develop a simple, yet powerful nonparametric method for choosing the number of clusters based on distortion, a quantity that measures the average distance, per dimension, between each observation and its closest cluster center. Our technique is computationally efficient and straightforward to implement. We demonstrate empirically its effectiveness, not only for choosing the number of clusters, but also for identifying underlying structure, on a wide range of simulated and real world datasets. In addition, we give a rigorous theoretical justification for the method based on information-theoretic ideas. Specifically, results from the subfield of electrical engineering known as rate distortion theory allow us to describe the behavior of the distortion in both the presence and absence of clustering. Finally, we note that these ideas potentially can be extended to a wide range of other statistical model selection problems.},
  file = {/Users/kshitijgoel/Zotero/storage/LHQS6GJ9/Sugar and James - 2003 - Finding the Number of Clusters in a Dataset An In.pdf}
}

@book{sullivant_algebraic_2018,
  title = {Algebraic {{Statistics}}},
  author = {Sullivant, Seth},
  year = {2018},
  month = nov,
  series = {Graduate {{Studies}} in {{Mathematics}}},
  volume = {194},
  publisher = {American Mathematical                     Society},
  address = {Providence, Rhode                     Island},
  doi = {10.1090/gsm/194},
  url = {http://www.ams.org/gsm/194},
  urldate = {2024-07-11},
  isbn = {978-1-4704-3517-2 978-1-4704-4980-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KER4QP47/Sullivant - 2018 - Algebraic Statistics.pdf}
}

@inproceedings{sun_dense_2018,
  title = {Dense 3-{{D Mapping}} with {{Spatial Correlation}} via {{Gaussian Filtering}}},
  booktitle = {2018 {{Annual American Control Conference}} ({{ACC}})},
  author = {Sun, Ke and Saulnier, Kelsey and Atanasov, Nikolay and Pappas, George J. and Kumar, Vijay},
  year = {2018},
  month = jun,
  pages = {4267--4274},
  issn = {2378-5861},
  doi = {10.23919/ACC.2018.8431777},
  url = {https://ieeexplore.ieee.org/abstract/document/8431777},
  urldate = {2024-06-06},
  abstract = {Constructing an occupancy representation of the environment is a fundamental problem for robot autonomy. Many accurate and efficient methods exist that address this problem but most assume that the occupancy states of different elements in the map representation are statistically independent. The focus of this paper is to provide a model that captures correlation of the occupancy of map elements. Correlation is important not only for improved accuracy but also for quantifying uncertainty in the map and for planning autonomous mapping trajectories based on the correlation among known and unknown areas. Recent work proposes Gaussian Process (GP) regression to capture covariance information and enable resolution-free occupancy estimation. The drawback of techniques based on GP regression (or classification) is that the computation complexity scales cubically with the length of the measurement history. Our main contribution is a new approach for occupancy mapping that models the binary nature of occupancy measurements precisely, via a Bernoulli distribution, and provides an efficient approximation of GP classification with complexity that does not scale with time. We prove that the error between the estimates provided by our method and those provided by GP classification is negligible. The proposed method is evaluated using both simulated data and real data collected using a Velodyne Puck 3-D range sensor.},
  keywords = {Computational complexity,Correlation,Kernel,Robot sensing systems,Time measurement,Training},
  file = {/Users/kshitijgoel/Zotero/storage/LEDCHA8Q/Sun et al. - 2018 - Dense 3-D Mapping with Spatial Correlation via Gaussian Filtering.pdf;/Users/kshitijgoel/Zotero/storage/HBIZJXNI/8431777.html}
}

@article{sun_directionalityaware_2024,
  title = {Directionality-{{Aware Mixture Model Parallel Sampling}} for {{Efficient Linear Parameter Varying Dynamical System Learning}}},
  author = {Sun, Sunan and Gao, Haihui and Li, Tianyu and Figueroa, Nadia},
  year = {2024},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {7},
  pages = {6248--6255},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3401128},
  url = {https://ieeexplore.ieee.org/document/10530930/?arnumber=10530930},
  urldate = {2025-02-18},
  abstract = {The Linear Parameter Varying Dynamical System (LPV-DS) is an effective approach that learns stable, time-invariant motion policies using statistical modeling and semi-definite optimization to encode complex motions for reactive robot control. Despite its strengths, the LPV-DS learning approach faces challenges in achieving high model accuracy without compromising computational efficiency. To address this, we introduce the Directionality-Aware Mixture Model (DAMM), a novel statistical model that applies the Riemannian metric on the n-sphere to efficiently blend non-Euclidean directional data with Euclidean states. Additionally, we develop a hybrid Markov chain Monte Carlo technique that combines Gibbs Sampling with Split/Merge Proposal, allowing for parallel computation to speed up inference. Extensive empirical tests demonstrate that LPV-DS integrated with DAMM achieves higher reproduction accuracy, better computational efficiency, and near real-time/online learning compared to standard estimation methods on various datasets. Lastly, we demonstrate its suitability for incrementally learning multi-behavior policies in real-world robot experiments.},
  keywords = {Computational modeling,Dynamical systems,imitation learning,Learning from demonstration,machine learning for robot control,Manifolds,Measurement,Mixture models,Trajectory,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/5LG46N4H/Sun et al. - 2024 - Directionality-Aware Mixture Model Parallel Sampling for Efficient Linear Parameter Varying Dynamica.pdf;/Users/kshitijgoel/Zotero/storage/3RPKQLND/10530930.html}
}

@article{sun_frontiernet_2025,
  title = {{{FrontierNet}}: {{Learning Visual Cues}} to {{Explore}}},
  shorttitle = {{{FrontierNet}}},
  author = {Sun, Boyang and Chen, Hanzhi and Leutenegger, Stefan and Cadena, Cesar and Pollefeys, Marc and Blum, Hermann},
  year = {2025},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {7},
  pages = {6576--6583},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3569122},
  url = {https://ieeexplore.ieee.org/document/10999073/},
  urldate = {2025-07-16},
  abstract = {Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for different tasks, such as mapping, object discovery, and environmental assessment. Existing solutions, such as frontier-based exploration approaches, rely heavily on 3D map operations, which are limited by map quality and, more critically, often overlook valuable context from visual cues. This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map. We propose a visual-only frontier-based exploration system, with FrontierNet as its core component. FrontierNet is a learning-based model that (i) proposes frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors. Our approach provides an alternative to existing 3D-dependent goal-extraction approaches, achieving a 15\% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments.},
  keywords = {Cameras,deep learning,Electronic mail,motion and path planning,Perception and autonomy,Predictive models,Proposals,Robots,Semantics,Solid modeling,Three-dimensional displays,Training,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/XZE9MQCX/Sun et al. - 2025 - FrontierNet Learning Visual Cues to Explore.pdf}
}

@misc{sun_highfidelity_2024,
  title = {High-{{Fidelity SLAM Using Gaussian Splatting}} with {{Rendering-Guided Densification}} and {{Regularized Optimization}}},
  author = {Sun, Shuo and Mielle, Malcolm and Lilienthal, Achim J. and Magnusson, Martin},
  year = {2024},
  month = oct,
  number = {arXiv:2403.12535},
  eprint = {2403.12535},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.12535},
  urldate = {2024-11-10},
  abstract = {We propose a dense RGBD SLAM system based on 3D Gaussian Splatting that provides metrically accurate pose tracking and visually realistic reconstruction. To this end, we first propose a Gaussian densification strategy based on the rendering loss to map unobserved areas and refine reobserved areas. Second, we introduce extra regularization parameters to alleviate the forgetting problem in the continuous mapping problem, where parameters tend to overfit the latest frame and result in decreasing rendering quality for previous frames. Both mapping and tracking are performed with Gaussian parameters by minimizing re-rendering loss in a differentiable way. Compared to recent neural and concurrently developed gaussian splatting RGBD SLAM baselines, our method achieves state-of-the-art results on the synthetic dataset Replica and competitive results on the real-world dataset TUM.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/56U2AEZ2/Sun et al. - 2024 - High-Fidelity SLAM Using Gaussian Splatting with Rendering-Guided Densification and Regularized Opti.pdf;/Users/kshitijgoel/Zotero/storage/GDJCJMN7/2403.html}
}

@inproceedings{sun_neural_2022,
  title = {Neural {{3D Reconstruction}} in the {{Wild}}},
  booktitle = {Special {{Interest Group}} on {{Computer Graphics}} and {{Interactive Techniques Conference Proceedings}}},
  author = {Sun, Jiaming and Chen, Xi and Wang, Qianqian and Li, Zhengqi and {Averbuch-Elor}, Hadar and Zhou, Xiaowei and Snavely, Noah},
  year = {2022},
  month = aug,
  pages = {1--9},
  publisher = {ACM},
  address = {Vancouver BC Canada},
  doi = {10.1145/3528233.3530718},
  url = {https://dl.acm.org/doi/10.1145/3528233.3530718},
  urldate = {2023-04-11},
  isbn = {978-1-4503-9337-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SACHD6G5/Sun et al. - 2022 - Neural 3D Reconstruction in the Wild.pdf}
}

@article{sun_novel_2022,
  title = {A {{Novel Coding Scheme}} for {{Large-Scale Point Cloud Sequences Based}} on {{Clustering}} and {{Registration}}},
  author = {Sun, Xuebin and Sun, Yuxiang and Zuo, Weixun and Cheng, Shing Shin and Liu, Ming},
  year = {2022},
  month = jul,
  journal = {IEEE Transactions on Automation Science and Engineering},
  volume = {19},
  number = {3},
  pages = {2384--2396},
  issn = {1558-3783},
  doi = {10.1109/TASE.2021.3082196},
  abstract = {Due to the huge volume of point cloud data, storing and transmitting it is currently difficult and expensive in autonomous driving. Learning from the high-efficiency video coding (HEVC) framework, we propose a novel compression scheme for large-scale point cloud sequences, in which several techniques have been developed to remove the spatial and temporal redundancy. The proposed strategy consists mainly of three parts: intracoding, intercoding, and residual data coding. For intracoding, inspired by the depth modeling modes (DMMs), in 3-D HEVC (3-D-HEVC), a cluster-based prediction method is proposed to remove the spatial redundancy. For intercoding, a point cloud registration algorithm is utilized to transform two adjacent point clouds into the same coordinate system. By calculating the residual map of their corresponding depth image, the temporal redundancy can be removed. Finally, the residual data are compressed either by lossless or lossy methods. Our approach can deal with multiple types of point cloud data, from simple to more complex. The lossless method can compress the point cloud data to 3.63\% of its original size by intracoding and 2.99\% by intercoding without distance distortion. Experiments on the KITTI dataset also demonstrate that our method yields better performance compared with recent well-known methods. Note to Practitioners---This article deals with the problem of efficient compression of point cloud sequences that come from light detection and ranging (LiDARs) mounted on autonomous mobile robots. The vast amount of point cloud data could be an important bottleneck for transmission and storage. Inspired by the HEVC algorithm, we develop a novel coding architecture for the point cloud sequence. The scans are divided into intraframe and interframe, which are encoded separately using different techniques. Our method can be used for the compression of LiDAR point cloud sequences or dense LiDAR point cloud map and will significantly reduce the transmission bandwidth and storage spaces. We have to admit that although our method is less effective for real-time solutions, it can be highly efficient for off-line applications. Future studies will concentrate on further optimizing the coding algorithm to reduce the computational complexity and trying to find a balance between them.},
  keywords = {Cluster-based prediction,compression,depth modeling mode (DMM),Encoding,Image coding,Laser radar,point cloud sequence,Prediction algorithms,Redundancy,registration,Three-dimensional displays,Video coding},
  file = {/Users/kshitijgoel/Zotero/storage/4RCHKXG5/Sun et al. - 2022 - A Novel Coding Scheme for Large-Scale Point Cloud .pdf}
}

@article{sun_rateconstrained_2014,
  title = {Rate-{{Constrained 3D Surface Estimation From Noise-Corrupted Multiview Depth Videos}}},
  author = {Sun, Wenxiu and Cheung, Gene and Chou, Philip A. and Florencio, Dinei and Zhang, Cha and Au, Oscar C.},
  year = {2014},
  month = jul,
  journal = {IEEE Transactions on Image Processing},
  volume = {23},
  number = {7},
  pages = {3138--3151},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2014.2326413},
  url = {http://ieeexplore.ieee.org/document/6819840/},
  urldate = {2024-04-05},
  abstract = {Transmitting compactly represented geometry of a dynamic 3D scene from a sender can enable a multitude of imaging functionalities at a receiver, such as synthesis of virtual images at freely chosen viewpoints via depth-image-based rendering. While depth maps---projections of 3D geometry onto 2D image planes at chosen camera viewpoints---can nowadays be readily captured by inexpensive depth sensors, they are often corrupted by non-negligible acquisition noise. Given depth maps need to be denoised and compressed at the encoder for efficient network transmission to the decoder, in this paper, we consider the denoising and compression problems jointly, arguing that doing so will result in a better overall performance than the alternative of solving the two problems separately in two stages. Specifically, we formulate a rate-constrained estimation problem, where given a set of observed noise-corrupted depth maps, the most probable (maximum a posteriori (MAP)) 3D surface is sought within a search space of surfaces with representation size no larger than a prespecified rate constraint. Our rate-constrained MAP solution reduces to the conventional unconstrained MAP 3D surface reconstruction solution if the rate constraint is loose. To solve our posed rate-constrained estimation problem, we propose an iterative algorithm, where in each iteration the structure (object boundaries) and the texture (surfaces within the object boundaries) of the depth maps are optimized alternately. Using the MVC codec for compression of multiview depth video and MPEG free viewpoint video sequences as input, experimental results show that rate-constrained estimated 3D surfaces computed by our algorithm can reduce coding rate of depth maps by up to 32\% compared with unconstrained estimated surfaces for the same quality of synthesized virtual views at the decoder.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/EIBUAMCY/Sun et al. - 2014 - Rate-Constrained 3D Surface Estimation From Noise-.pdf}
}

@article{sun_selforganization_2023,
  title = {Self-{{Organization Preserved Graph Structure Learning}} with {{Principle}} of {{Relevant Information}}},
  author = {Sun, Qingyun and Li, Jianxin and Yang, Beining and Fu, Xingcheng and Peng, Hao and Yu, Philip S.},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {4643--4651},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i4.25587},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/25587},
  urldate = {2024-12-19},
  abstract = {Most Graph Neural Networks follow the message-passing paradigm, assuming the observed structure depicts the ground-truth node relationships. However, this fundamental assumption cannot always be satisfied, as real-world graphs are always incomplete, noisy, or redundant. How to reveal the inherent graph structure in a unified way remains under-explored.  We proposed PRI-GSL, a Graph Structure Learning framework guided by the Principle of Relevant Information, providing a simple and unified framework for identifying the self-organization and revealing the hidden structure. PRI-GSL learns a structure that contains the most relevant yet least redundant information quantified by von Neumann entropy and Quantum Jensen Shannon divergence. PRI-GSL incorporates the evolution of quantum continuous walk with graph wavelets to encode node structural roles, showing in which way the nodes interplay and self-organize with the graph structure. Extensive experiments demonstrate the superior effectiveness and robustness of PRI-GSL.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {DMKM: Graph Mining,Social Network Analysis & Community Mining},
  file = {/Users/kshitijgoel/Zotero/storage/JCSUML76/Sun et al. - 2023 - Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information.pdf}
}

@phdthesis{sung_gaussian_2004,
  title = {Gaussian {{Mixture Regression}} and {{Classification}}},
  author = {Sung, Hsi Guang},
  year = {2004},
  month = may,
  address = {Houston, Texas},
  url = {https://www.stat.rice.edu/~hgsung/thesis.pdf},
  langid = {english},
  school = {Rice University},
  file = {/Users/kshitijgoel/Zotero/storage/C5FCPTQ7/Sung - Gaussian Mixture Regression and Classiﬁcation.pdf}
}

@inproceedings{suresh_shapemap_2022,
  title = {{{ShapeMap}} 3-{{D}}: {{Efficient}} Shape Mapping through Dense Touch and Vision},
  shorttitle = {{{ShapeMap}} 3-{{D}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Suresh, Sudharshan and Si, Zilin and Mangelson, Joshua G. and Yuan, Wenzhen and Kaess, Michael},
  year = {2022},
  month = may,
  pages = {7073--7080},
  doi = {10.1109/ICRA46639.2022.9812040},
  abstract = {Knowledge of 3-D object shape is of great importance to robot manipulation tasks, but may not be readily available in unstructured environments. While vision is often occluded during robot-object interaction, high-resolution tactile sensors can give a dense local perspective of the object. However, tactile sensors have limited sensing area and the shape representation must faithfully approximate non-contact areas. In addition, a key challenge is efficiently incorporating these dense tactile measurements into a 3-D mapping framework. In this work, we propose an incremental shape mapping method using a GelSight tactile sensor and a depth camera. Local shape is recovered from tactile images via a learned model trained in simulation. Through efficient inference on a spatial factor graph informed by a Gaussian process, we build an implicit surface representation of the object. We demonstrate visuo-tactile mapping in both simulated and real-world experiments, to incrementally build 3-D reconstructions of household objects.},
  keywords = {Gaussian processes,Sensors,Shape,Surface reconstruction,Tactile sensors,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/9AMSID5K/Suresh et al. - 2022 - ShapeMap 3-D Efficient shape mapping through dens.pdf;/Users/kshitijgoel/Zotero/storage/DFCC8D9I/9812040.html}
}

@book{szeliski_computer_2022,
  title = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Computer {{Vision}}},
  author = {Szeliski, Richard},
  year = {2022},
  series = {Texts in {{Computer Science}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-34372-9},
  url = {https://link.springer.com/10.1007/978-3-030-34372-9},
  urldate = {2023-03-21},
  isbn = {978-3-030-34371-2 978-3-030-34372-9},
  langid = {english},
  keywords = {3D Reconstruction,Computational Photography,Computer Vision,Deep Learning,Feature Detection and Matching,Image Processing,Image Segmentation,Image Stitching,Image-Based Rendering,Motion Estimation,Scene Recognition,Structure from Motion},
  file = {/Users/kshitijgoel/Zotero/storage/FGE82PAK/Szeliski - 2022 - Computer Vision Algorithms and Applications.pdf}
}

@article{szilagyi_slag_2025,
  title = {{{SLAG}}: {{Scalable Language-Augmented Gaussian Splatting}}},
  shorttitle = {{{SLAG}}},
  author = {Szilagyi, Laszlo and Engelmann, Francis and Bohg, Jeannette},
  year = {2025},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {7},
  pages = {6991--6998},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3573203},
  url = {https://ieeexplore.ieee.org/document/11014241/},
  urldate = {2025-06-09},
  abstract = {Language-augmented scene representations hold great promise for large-scale robotics applications such as search-and-rescue, smart cities, and mining. Many of these scenarios are time-sensitive, requiring rapid scene encoding while also being data-intensive, necessitating scalable solutions. Deploying these representations on robots with limited computational resources further adds to the challenge. To address this, we introduce SLAG, a multi-GPU framework for language-augmented Gaussian splatting that enhances the speed and scalability of embedding large scenes. Our method integrates 2D visual-language model features into 3D scenes using SAM (Kirillov et al., 2023) and CLIP (Radford et al., 2021). Unlike prior approaches, SLAG eliminates the need for a loss function to compute per-Gaussian language embeddings. Instead, it derives embeddings from 3D Gaussian scene parameters via a normalized weighted average, enabling highly parallelized scene encoding. Additionally, we introduce a vector database for efficient embedding storage and retrieval. Our experiments show that SLAG achieves an 18{\texttimes} speedup in embedding computation on a 16-GPU setup compared to OpenGaussian (Wu et al., 2024), while preserving embedding quality on the ScanNet (Dai et al., 2017) and LERF (Kerr et al., 2023) datasets.},
  keywords = {big data in robotics and automation,Cameras,deep learning for visual perception,Graphics processing units,Image reconstruction,Neural radiance field,Robots,Scalability,Semantic scene understanding,Semantics,Slag,software architecture for robotics and automation,Three-dimensional displays,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/68ZKAMGQ/Szilagyi et al. - 2025 - SLAG Scalable Language-Augmented Gaussian Splatting.pdf}
}

@phdthesis{tabib_approximate_2019,
  title = {Approximate {{Continuous Belief Distributions}} for {{Exploration}}},
  author = {Tabib, Wennie},
  year = {2019},
  address = {Pittsburgh, PA, USA},
  url = {http://reports-archive.adm.cs.cmu.edu/anon/2019/CMU-CS-19-108.pdf},
  langid = {english},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/D8WIFNZ3/Tabib - Approximate Continuous Belief Distributions for Ex.pdf}
}

@article{tabib_autonomous_2022,
  title = {Autonomous {{Cave Surveying With}} an {{Aerial Robot}}},
  author = {Tabib, Wennie and Goel, Kshitij and Yao, John and Boirum, Curtis and Michael, Nathan},
  year = {2022},
  month = apr,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {2},
  pages = {1016--1032},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3104459},
  url = {https://ieeexplore.ieee.org/document/9536757},
  urldate = {2024-08-16},
  abstract = {This article presents a method for cave surveying in total darkness using an autonomous aerial vehicle equipped with a depth camera for mapping, downward-facing camera for state estimation, and forward and downward lights. Traditional methods of cave surveying are labor-intensive and dangerous due to the risk of injury when operating in darkness, and the potential structural instability of the subterranean environment. Although these dangers can be mitigated by deploying robots to map dangerous passages and voids, real-time feedback is often needed to operate robots safely and efficiently. Few state-of-the-art, high-resolution perceptual modeling techniques attempt to reduce their high bandwidth requirements to work well with low bandwidth communication channels. To bridge this gap in the state-of- the-art, this work compactly represents sensor observations as Gaussian mixture models and maintains a local occupancy grid map for a motion planner that greedily maximizes an information-theoretic objective function. The approach accommodates both limited field of view (FoV) depth cameras and larger FoV LiDAR sensors and is extensively evaluated in long duration simulations on an embedded PC. An aerial system is leveraged to demonstrate the repeatability of the approach in a flight arena as well as the effects of communication dropouts. Finally, the system is deployed in Laurel Caverns, a commercially owned and operated cave in southwestern Pennsylvania, USA, and a wild cave in West Virginia, USA. Videos of the simulation and hardware results are available at https://youtu.be/iwi3p7IENjE and https://youtu.be/H8MdtJ5VhyU.},
  keywords = {Aerial system,autonomy,Cameras,exploration,Laser radar,perceptual modeling,Planning,Real-time systems,Robot sensing systems,Robot vision systems,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/6MQKCGEN/Tabib et al. - 2022 - Autonomous Cave Surveying With an Aerial Robot.pdf;/Users/kshitijgoel/Zotero/storage/EPI295AS/9536757.html}
}

@inproceedings{tabib_efficient_2016,
  title = {Efficient Multi-Sensor Exploration Using Dependent Observations and Conditional Mutual Information},
  booktitle = {2016 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Tabib, Wennie and Whittaker, Red and Michael, Nathan},
  year = {2016},
  month = oct,
  pages = {42--47},
  doi = {10.1109/SSRR.2016.7784275},
  url = {https://ieeexplore.ieee.org/abstract/document/7784275},
  urldate = {2024-02-10},
  abstract = {In search and rescue scenarios, it is important to find survivors and map their locations quickly and efficiently. This paper presents a multimodal exploration and mapping approach that extends an occupancy grid map formulation to incorporate conditionally dependent sensor observations from multiple sensors and enables reasoning about uncertainty to select maximally informative actions. Temperature from a simulated thermal camera and range from a simulated time-of-flight camera provide updates to spatial and thermal dense voxel maps. The information gain is computed as the sum of the Mutual Information between the depth sensor and spatial map and Conditional Mutual Information between the multimodal sensor and map. Formulating multimodal exploration and mapping in this way results in selecting actions that drive the robot to collect thermal observations of occupied regions and reduce the uncertainty of both the occupancy state and temperature state of the environment. The performance of the proposed methodology is evaluated through simulations with an aerial robot exploring an office room and compared to state-of-art information-theoretic exploration techniques.},
  keywords = {Cameras,Mathematical model,Mutual information,Robot sensing systems,Temperature measurement,Temperature sensors},
  file = {/Users/kshitijgoel/Zotero/storage/E9ALM2LG/Tabib et al. - 2016 - Efficient multi-sensor exploration using dependent.pdf;/Users/kshitijgoel/Zotero/storage/J9TS5KFK/7784275.html}
}

@article{tabib_onmanifold_2018,
  title = {On-{{Manifold GMM Registration}}},
  author = {Tabib, Wennie and O'Meadhra, Cormac and Michael, Nathan},
  year = {2018},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {4},
  pages = {3805--3812},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2856279},
  url = {https://ieeexplore.ieee.org/document/8411140},
  urldate = {2024-11-15},
  abstract = {This letter presents a robust Gaussian mixture model registration technique to enable mapping and navigation in dark, complex, unstructured domains such as caves and mines. Subterranean environments are often unmapped and challenged by low-lighting conditions and communication constraints. Prior works that leverage direct and image-based techniques with active illumination fail when taking tight turns due to sensor washout, dense methods are sensitive to initialization, and state-of-the-art registration methods that leverage probabilistic models are neither real-time viable nor thoroughly evaluated with real-world data. The proposed approach minimizes the squared L2 norm between two distributions through an on-manifold parameterization of the objective function. The contribution of this letter is a robust, real-time viable distribution-to-distribution registration methodology that considers all possible correspondences between mixture components. The approach is evaluated in a feature-scarce mine, unstructured cave, and on open-source data of an office environment with both light detection and ranging (LIDAR) and depth sensors. The results demonstrate superior performance as compared to the state of the art. Beyond cave and mine environments, the method readily extends to solving the problem of registration in cluttered domains.},
  keywords = {Correlation,Cost function,Localization,mining robotics,Probabilistic logic,range sensing,Real-time systems,Robot sensing systems,Robustness},
  file = {/Users/kshitijgoel/Zotero/storage/G8C4KZ6T/Tabib et al. - 2018 - On-Manifold GMM Registration.pdf;/Users/kshitijgoel/Zotero/storage/5UFEZ9U3/8411140.html}
}

@inproceedings{tabib_realtime_2019,
  title = {Real-{{Time Information-Theoretic Exploration}} with {{Gaussian Mixture Model Maps}}},
  booktitle = {Robotics: {{Science}} and {{Systems XV}}},
  author = {Tabib, Wennie and Goel, Kshitij and Yao, John and Dabhi, Mosam and Boirum, Curtis and Michael, Nathan},
  year = {2019},
  month = jun,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2019.XV.061},
  url = {http://www.roboticsproceedings.org/rss15/p61.pdf},
  urldate = {2021-09-22},
  copyright = {All rights reserved},
  isbn = {978-0-9923747-5-4},
  file = {/Users/kshitijgoel/Zotero/storage/Q75UNJ4U/Tabib et al. - 2019 - Real-Time Information-Theoretic Exploration with G.pdf}
}

@inproceedings{tabib_simultaneous_2021,
  title = {Simultaneous {{Localization}} and {{Mapping}} of {{Subterranean Voids}} with {{Gaussian Mixture Models}}},
  booktitle = {Field and {{Service Robotics}}},
  author = {Tabib, Wennie and Michael, Nathan},
  editor = {Ishigami, Genya and Yoshida, Kazuya},
  year = {2021},
  pages = {173--187},
  publisher = {Springer},
  address = {Singapore},
  doi = {10.1007/978-981-15-9460-1_13},
  url = {https://link.springer.com/chapter/10.1007/978-981-15-9460-1_13},
  abstract = {This paper presents a real-time viable method for Simultaneous Localization and Mapping (SLAM) using Gaussian mixture models (GMMs) for compute-constrained systems that operate in subterranean environments. The two contributions of this work are (1) a SLAM formulation that uses a GMM-based map representation for pose estimation, mapping and loop closure, and (2) an Expectation Maximization (EM) formulation that significantly reduces the time to learn a GMM from a sensor observation by exploiting the insight that although Gaussian distributions have infinite support, a substantial amount of the support is contained within a finite region. An on-manifold distribution-to-distribution registration approach is used to estimate the pose between consecutive GMMs, and the Cauchy--Schwarz divergence is employed to calculate the difference between the distributions to identify loop closures. The method is evaluated in mine and unstructured cave environments. The results demonstrate superior performance in leveraging the compact representation of the GMM as compared to traditional pose graph SLAM techniques that rely on point cloud-based methods. Further, exploiting the sparsity of the compact support significantly reduces training time toward enabling real-time viability.},
  isbn = {978-981-15-9460-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DLC5IXBA/Tabib and Michael - 2021 - Simultaneous Localization and Mapping of Subterranean Voids with Gaussian Mixture Models.pdf}
}

@inproceedings{tagliabue_lion_2021,
  title = {{{LION}}: {{Lidar-Inertial Observability-Aware Navigator}} for {{Vision-Denied Environments}}},
  shorttitle = {{{LION}}},
  booktitle = {Experimental {{Robotics}}},
  author = {Tagliabue, Andrea and Tordesillas, Jesus and Cai, Xiaoyi and {Santamaria-Navarro}, Angel and How, Jonathan P. and Carlone, Luca and {Agha-mohammadi}, Ali-akbar},
  editor = {Siciliano, Bruno and Laschi, Cecilia and Khatib, Oussama},
  year = {2021},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {380--390},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-71151-1_34},
  abstract = {State estimation for robots navigating in GPS-denied and perceptually-degraded environments, such as underground tunnels, mines and planetary sub-surface voids~[1], remains challenging in robotics. Towards this goal, we present LION (Lidar-Inertial Observability-Aware Navigator), which is part of the state estimation framework developed by the team CoSTAR [2] for the DARPA Subterranean Challenge [3], where the team achieved second and first places in the Tunnel and Urban circuits in August 2019 and February 2020, respectively. LION provides high-rate odometry estimates by fusing high-frequency inertial data from an IMU and low-rate relative pose estimates from a lidar via a fixed-lag sliding window smoother. LION does not require knowledge of relative positioning between lidar and IMU, as the extrinsic calibration is estimated online. In addition, LION is able to self-assess its performance using an observability metric that evaluates whether the pose estimate is geometrically ill-constrained. Odometry and confidence estimates are used by HeRO [4], a supervisory algorithm that provides robust estimates by switching between different odometry sources. In this paper we benchmark the performance of LION in perceptually-degraded subterranean environments, demonstrating its high technology readiness level for deployment in the field.},
  isbn = {978-3-030-71151-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Z3JLSHDY/Tagliabue et al. - 2021 - LION Lidar-Inertial Observability-Aware Navigator.pdf}
}

@misc{tagliasacchi_volume_2022,
  title = {Volume {{Rendering Digest}} (for {{NeRF}})},
  author = {Tagliasacchi, Andrea and Mildenhall, Ben},
  year = {2022},
  month = aug,
  number = {arXiv:2209.02417},
  eprint = {2209.02417},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.02417},
  url = {http://arxiv.org/abs/2209.02417},
  urldate = {2025-02-04},
  abstract = {Neural Radiance Fields employ simple volume rendering as a way to overcome the challenges of differentiating through ray-triangle intersections by leveraging a probabilistic notion of visibility. This is achieved by assuming the scene is composed by a cloud of light-emitting particles whose density changes in space. This technical report summarizes the derivations for differentiable volume rendering. It is a condensed version of previous reports, but rewritten in the context of NeRF, and adopting its commonly used notation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/VYAAL7FV/Tagliasacchi and Mildenhall - 2022 - Volume Rendering Digest (for NeRF).pdf;/Users/kshitijgoel/Zotero/storage/JD9HZVCY/2209.html}
}

@article{takatsu_wasserstein_2011,
  title = {Wasserstein Geometry of {{Gaussian}} Measures},
  author = {Takatsu, Asuka},
  year = {2011},
  month = dec,
  journal = {Osaka Journal of Mathematics},
  volume = {48},
  number = {4},
  pages = {1005--1026},
  publisher = {{Osaka University and Osaka Metropolitan University, Departments of Mathematics}},
  issn = {0030-6126},
  url = {https://projecteuclid.org/journals/osaka-journal-of-mathematics/volume-48/issue-4/Wasserstein-geometry-of-Gaussian-measures/ojm/1326291215.full},
  urldate = {2023-09-28},
  abstract = {This paper concerns the Riemannian/Alexandrov geometry of Gaussian measures, from the view point of the \$L{\textasciicircum}\{2\}\$-Wasserstein geometry. The space of Gaussian measures is of finite dimension, which allows to write down the explicit Riemannian metric which in turn induces the \$L{\textasciicircum}\{2\}\$-Wasserstein distance. Moreover, its completion as a metric space provides a complete picture of the singular behavior of the \$L{\textasciicircum}\{2\}\$-Wasserstein geometry. In particular, the singular set is stratified according to the dimension of the support of the Gaussian measures, providing an explicit nontrivial example of Alexandrov space with extremal sets.},
  keywords = {53C23,60D05},
  file = {/Users/kshitijgoel/Zotero/storage/UYJYS3TI/Takatsu - 2011 - Wasserstein geometry of Gaussian measures.pdf}
}

@article{takeda_kernel_2007,
  title = {Kernel {{Regression}} for {{Image Processing}} and {{Reconstruction}}},
  author = {Takeda, Hiroyuki and Farsiu, Sina and Milanfar, Peyman},
  year = {2007},
  month = feb,
  journal = {IEEE Transactions on Image Processing},
  volume = {16},
  number = {2},
  pages = {349--366},
  issn = {1941-0042},
  doi = {10.1109/TIP.2006.888330},
  abstract = {In this paper, we make contact with the field of nonparametric statistics and present a development and generalization of tools and results for use in image processing and reconstruction. In particular, we adapt and expand kernel regression ideas for use in image denoising, upscaling, interpolation, fusion, and more. Furthermore, we establish key relationships with some popular existing methods and show how several of these algorithms, including the recently popularized bilateral filter, are special cases of the proposed framework. The resulting algorithms and analyses are amply illustrated with practical examples},
  keywords = {Bilateral filter,Charge coupled devices,Costs,denoising,Digital images,Filters,fusion,Image processing,Image reconstruction,interpolation,Interpolation,irregularly sampled data,Kernel,kernel function,kernel regression,local polynomial,Noise reduction,nonlinear filter,nonparametric,scaling,Spatial resolution,spatially adaptive,super-resolution},
  file = {/Users/kshitijgoel/Zotero/storage/79K3NQFI/Takeda et al. - 2007 - Kernel Regression for Image Processing and Reconst.pdf;/Users/kshitijgoel/Zotero/storage/9IWQTKJJ/stamp.html}
}

@inproceedings{takikawa_variable_2022,
  title = {Variable {{Bitrate Neural Fields}}},
  booktitle = {Special {{Interest Group}} on {{Computer Graphics}} and {{Interactive Techniques Conference Proceedings}}},
  author = {Takikawa, Towaki and Evans, Alex and Tremblay, Jonathan and M{\"u}ller, Thomas and McGuire, Morgan and Jacobson, Alec and Fidler, Sanja},
  year = {2022},
  month = aug,
  pages = {1--9},
  publisher = {ACM},
  address = {Vancouver BC Canada},
  doi = {10.1145/3528233.3530727},
  url = {https://dl.acm.org/doi/10.1145/3528233.3530727},
  urldate = {2023-04-11},
  isbn = {978-1-4503-9337-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/NNTI7SY5/Takikawa et al. - 2022 - Variable Bitrate Neural Fields.pdf}
}

@article{tal_aerobatic_2023,
  title = {Aerobatic {{Trajectory Generation}} for a {{VTOL Fixed-Wing Aircraft Using Differential Flatness}}},
  author = {Tal, Ezra and Ryou, Gilhyun and Karaman, Sertac},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--15},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3301312},
  abstract = {This article proposes a novel algorithm for aerobatic trajectory generation for a vertical take-off and landing (VTOL) tailsitter flying wing aircraft. The algorithm differs from existing approaches for fixed-wing trajectory generation, as it considers a realistic six-degree-of-freedom (6-DOF) flight dynamics model, including aerodynamic equations. Using a global dynamics model enables the generation of aerobatics trajectories that exploit the entire flight envelope, allowing agile maneuvering through the stall regime, sideways uncoordinated flight, inverted flight, etc. The method uses the differential flatness property of the global tailsitter flying wing dynamics, which is derived in this work. By performing snap minimization in the differentially flat output space, a computationally efficient algorithm, suitable for online motion planning, is obtained. The algorithm is demonstrated in extensive flight experiments encompassing six aerobatic maneuvers, a time-optimal drone racing trajectory, and an airshowlike aerobatic sequence for three tailsitter aircraft.},
  keywords = {Aerial systems,Aerodynamics,Aircraft,autonomous vehicle navigation,Force,Heuristic algorithms,Mathematical models,mechanics and control,motion and path planning,Trajectory,trajectory optimization,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/66N5YLYB/Tal et al. - 2023 - Aerobatic Trajectory Generation for a VTOL Fixed-W.pdf;/Users/kshitijgoel/Zotero/storage/3VTRCCBD/10224280.html}
}

@phdthesis{tal_algorithms_2022,
  type = {Thesis},
  title = {Algorithms for {{Generation}} and {{Tracking}} of {{Fast}} and {{Agile Flight Trajectories}}},
  author = {Tal, Ezra},
  year = {2022},
  month = feb,
  url = {https://dspace.mit.edu/handle/1721.1/143268},
  urldate = {2022-12-22},
  abstract = {High-speed flight through cluttered environments is essential to many time-sensitive robotics applications. It requires motion planning and flight control algorithms that enable highly accurate maneuvering at the edge of the vehicle's capability. These algorithms must overcome challenges particular to fast and agile flight, such as complex dynamics effects including significant unsteady aerodynamics and challenging conditions like post-stall and uncoordinated flight. We propose trajectory generation and tracking algorithms that address these challenges for a quadcopter aircraft and for a fixed-wing transitioning aircraft that combines vertical take-off and landing (VTOL) with efficient forward flight.    This thesis contains several contributions. First, we show that robust control based on incremental nonlinear dynamic inversion (INDI) enables fast and agile flight without depending on an accurate dynamics model. Based on the INDI technique, we design a comprehensive quadcopter flight control algorithm that achieves accurate trajectory tracking without relying on any vehicle aerodynamics model. Second, we show differential flatness of a global nonlinear six-degree-of-freedom (6DOF) flight dynamics model for a tailsitter flying wing transitioning aircraft. We leverage the flat transform to design an INDI flight control algorithm capable of tracking agile aerobatics maneuvers that exploit the entire flight envelope, including post-stall and sideways knife-edge flight. Third, we present a trajectory generation algorithm that aims to identify the actual dynamic feasibility boundary by efficiently combining analytical, numerical, and experimental evaluations in trajectory optimization. Finally, we demonstrate our contributions in fast and agile flight through elaborate experiments.},
  copyright = {In Copyright - Educational Use Permitted},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2022-06-15T13:08:31Z},
  file = {/Users/kshitijgoel/Zotero/storage/5ZHCW7SK/Tal - 2022 - Algorithms for Generation and Tracking of Fast and.pdf}
}

@article{tal_global_2022,
  title = {Global {{Incremental Flight Control}} for {{Agile Maneuvering}} of a {{Tailsitter Flying Wing}}},
  author = {Tal, Ezra and Karaman, Sertac},
  year = {2022},
  month = dec,
  journal = {Journal of Guidance, Control, and Dynamics},
  volume = {45},
  number = {12},
  pages = {2332--2349},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0731-5090},
  doi = {10.2514/1.G006645},
  url = {https://arc.aiaa.org/doi/10.2514/1.G006645},
  urldate = {2023-09-07},
  abstract = {This paper proposes a novel control law for accurate tracking of agile trajectories using a tailsitter flying wing unmanned aerial vehicle that transitions between vertical takeoff and landing and forward flight. The global control formulation enables maneuvering throughout the flight envelope, including uncoordinated flight with sideslip. Differential flatness of the nonlinear tailsitter dynamics with a simplified aerodynamics model is shown. Using the flatness transform, the proposed controller incorporates tracking of the position reference along with its derivatives velocity, acceleration, and jerk, as well as the yaw reference and yaw rate. The inclusion of jerk and yaw rate references through an angular velocity feedforward term improves tracking of trajectories with fast-changing accelerations. The controller does not depend on extensive aerodynamic modeling but instead uses incremental nonlinear dynamic inversion to compute control updates based on only a local input--output relation, resulting in robustness against discrepancies in the simplified aerodynamics equations. Exact inversion of the nonlinear input--output relation is achieved through the derived flatness transform. The resulting control algorithm is extensively evaluated in flight tests, where it demonstrates accurate trajectory tracking and challenging agile maneuvers, such as sideways flight and aggressive transitions while turning.},
  keywords = {Closed Loop,Control Surfaces,Flight Control,Flight Test,Nonlinear Dynamic Inversion,Sideslip Angle,Unmanned Aircraft},
  file = {/Users/kshitijgoel/Zotero/storage/5ZNGR9Q8/Tal and Karaman - 2022 - Global Incremental Flight Control for Agile Maneuv.pdf}
}

@misc{talak_outlierrobust_2024,
  title = {Outlier-{{Robust Training}} of {{Machine Learning Models}}},
  author = {Talak, Rajat and Georgiou, Charis and Shi, Jingnan and Carlone, Luca},
  year = {2024},
  month = dec,
  number = {arXiv:2501.00265},
  eprint = {2501.00265},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.00265},
  url = {http://arxiv.org/abs/2501.00265},
  urldate = {2025-01-16},
  abstract = {Robust training of machine learning models in the presence of outliers has garnered attention across various domains. The use of robust losses is a popular approach and is known to mitigate the impact of outliers. We bring to light two literatures that have diverged in their ways of designing robust losses: one using M-estimation, which is popular in robotics and computer vision, and another using a risk-minimization framework, which is popular in deep learning. We first show that a simple modification of the Black-Rangarajan duality provides a unifying view. The modified duality brings out a definition of a robust loss kernel \${\textbackslash}sigma\$ that is satisfied by robust losses in both the literatures. Secondly, using the modified duality, we propose an Adaptive Alternation Algorithm (AAA) for training machine learning models with outliers. The algorithm iteratively trains the model by using a weighted version of the non-robust loss, while updating the weights at each iteration. The algorithm is augmented with a novel parameter update rule by interpreting the weights as inlier probabilities, and obviates the need for complex parameter tuning. Thirdly, we investigate convergence of the adaptive alternation algorithm to outlier-free optima. Considering arbitrary outliers (i.e., with no distributional assumption on the outliers), we show that the use of robust loss kernels \{{\textbackslash}sigma\} increases the region of convergence. We experimentally show the efficacy of our algorithm on regression, classification, and neural scene reconstruction problems. We release our implementation code: https://github.com/MIT-SPARK/ORT.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/TPZKU8ZS/Talak et al. - 2024 - Outlier-Robust Training of Machine Learning Models.pdf;/Users/kshitijgoel/Zotero/storage/JNZ2ASZQ/2501.html}
}

@article{tang_information_2019,
  title = {Information {{Geometric Approach}} to {{Multisensor Estimation Fusion}}},
  author = {Tang, Mengjiao and Rong, Yao and Zhou, Jie and Li, X. Rong},
  year = {2019},
  month = jan,
  journal = {IEEE Transactions on Signal Processing},
  volume = {67},
  number = {2},
  pages = {279--292},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2018.2879035},
  url = {https://ieeexplore.ieee.org/document/8519318/},
  urldate = {2024-03-13},
  abstract = {Distributed estimation fusion is concerned with the combination of local estimates from multiple distributed sensors to produce a fused result. In this paper, we characterize local estimates as posterior probability densities, and assume that they all belong to a parametric family. Our starting point is to consider this family as a Riemannian manifold by introducing the Fisher information metric. From the perspective of information geometry, the fused density is formulated as an informative barycenter in the space of probability densities and sought by minimizing the sum of its squared geodesic distances from the local posterior densities. Under Gaussian assumptions, a geodesic projection (GP) method and a Siegel distance (SD) method in the information-geometric framework are proposed to tackle the problem. The GP method gives a fusion result in accord with the covariance intersection estimate but under an information-geometric criterion, while the SD method appears to achieve a better approximation of the informative barycenter. Numerical examples are provided to demonstrate the performance of the proposed estimation fusion algorithms.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7NVFB4AA/Tang et al. - 2019 - Information Geometric Approach to Multisensor Esti.pdf}
}

@inproceedings{tang_rgbonly_2023,
  title = {{{RGB-Only Reconstruction}} of {{Tabletop Scenes}} for {{Collision-Free Manipulator Control}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Tang, Zhenggang and Sundaralingam, Balakumar and Tremblay, Jonathan and Wen, Bowen and Yuan, Ye and Tyree, Stephen and Loop, Charles and Schwing, Alexander and Birchfield, Stan},
  year = {2023},
  month = may,
  pages = {1778--1785},
  doi = {10.1109/ICRA48891.2023.10160247},
  abstract = {We present a system for collision-free control of a robot manipulator that uses only RGB views of the world. Perceptual input of a tabletop scene is provided by multiple images of an RGB camera (without depth) that is either handheld or mounted on the robot end effector. A NeRF-like process is used to reconstruct the 3D geometry of the scene, from which the Euclidean full signed distance function (ESDF) is computed. A model predictive control algorithm is then used to control the manipulator to reach a desired pose while avoiding obstacles in the ESDF. We show results on a real dataset collected and annotated in our lab. Our results are also available at https://ngp-mpc.github.io/.},
  keywords = {Cameras,Control systems,End effectors,Geometry,Prediction algorithms,Robot vision systems,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/DFQSTRXL/Tang et al. - 2023 - RGB-Only Reconstruction of Tabletop Scenes for Col.pdf}
}

@article{tanner_largescale_2022,
  title = {Large-Scale Outdoor Scene Reconstruction and Correction with Vision},
  author = {Tanner, Michael and Pini{\'e}s, Pedro and Paz, Lina Mar{\'i}a and S{\u a}ftescu, {\c S}tefan and Bewley, Alex and Jonasson, Emil and Newman, Paul},
  year = {2022},
  month = may,
  journal = {The International Journal of Robotics Research},
  volume = {41},
  number = {6},
  pages = {637--663},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364920937052},
  url = {https://doi.org/10.1177/0278364920937052},
  urldate = {2023-06-12},
  abstract = {We provide the theory and the system needed to create large-scale dense reconstructions for mobile-robotics applications: this stands in contrast to the object-centric reconstructions dominant in the literature. Our BOR2G system fuses data from multiple sensor modalities (cameras, lidars, or both) and regularizes the resulting 3D model. We use a compressed 3D data structure, which allows us to operate over a large scale. In addition, because of the paucity of surface observations by the camera and lidar sensors, we regularize over both two (camera depth maps) and three dimensions (voxel grid) to provide a local contextual prior for the reconstruction. Our regularizer reduces the median error between 27\% and 36\% in 7.3 km of dense reconstructions with a median accuracy between 4 and 8 cm. Our pipeline does not end with regularization. We take the unusual step to apply a learned correction mechanism that takes the global context of the reconstruction and adjusts the constructed mesh, addressing errors that are pathological to the first-pass camera-derived reconstruction. We evaluate our system using the Stanford Burghers of Calais, Imperial College ICL-NUIM, Oxford Broad Street (released with this paper), and the KITTI datasets. These latter datasets see us operating at a combined scale and accuracy not seen in the literature. We provide statistics for the metric errors in all surfaces created compared with those measured with 3D lidar as ground truth. We demonstrate our system in practice by reconstructing the inside of the EUROfusion Joint European Torus (JET) fusion reactor, located at the Culham Centre for Fusion Energy (UK Atomic Energy Authority) in Oxfordshire.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Y5HEYCJN/Tanner et al. - 2022 - Large-scale outdoor scene reconstruction and corre.pdf}
}

@article{tao_3d_2024,
  title = {{{3D Active Metric-Semantic SLAM}}},
  author = {Tao, Yuezhan and Liu, Xu and Spasojevic, Igor and Agarwal, Saurav and Kumar, Vijay},
  year = {2024},
  month = mar,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {3},
  pages = {2989--2996},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3363542},
  url = {https://ieeexplore.ieee.org/abstract/document/10423804},
  urldate = {2024-03-04},
  abstract = {In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots. Most previous work in exploration assumes that robot localization is solved. However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself. Furthermore, actions that reduce localization errors may be at direct odds with the exploration task. We develop a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent. In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots. Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments. From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90\% in translation and approximately 75\% in yaw, and the uncertainties in pose estimates and semantic maps by over 70\% and 65\%, respectively. Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available.},
  keywords = {Aerial systems: Perception and autonomy,Autonomous aerial vehicles,mapping,perception-action coupling,Planning,Real-time systems,Semantics,Simultaneous localization and mapping,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/2DPDE752/Tao et al. - 2024 - 3D Active Metric-Semantic SLAM.pdf;/Users/kshitijgoel/Zotero/storage/2MKMH2D6/10423804.html}
}

@phdthesis{tao_martian_2022,
  title = {On {{Martian Surface Exploration}}: {{Development}} of {{Automated 3D Reconstruction}} and {{Super-Resolution Restoration Techniques}} for {{Mars Orbital Images}}},
  author = {Tao, Yu},
  year = {2022},
  abstract = {Very high spatial resolution imaging and topographic (3D) data play an important role in modern Mars science research and engineering applications. This work describes a set of image processing and machine learning methods to produce the ``best possible'' high-resolution and high-quality 3D and imaging products from existing Mars orbital imaging datasets. The research work is described in nine chapters of which seven are based on separate published journal papers. These include a) a hybrid photogrammetric processing chain that combines the advantages of different stereo matching algorithms to compute stereo disparity with optimal completeness, fine-scale details, and minimised matching artefacts; b) image and 3D co-registration methods that correct a target image and/or 3D data to a reference image and/or 3D data to achieve robust cross-instrument multi-resolution 3D and image coalignment; c) a deep learning network and processing chain to estimate pixel-scale surface topography from single-view imagery that outperforms traditional photogrammetric methods in terms of product quality and processing speed; d) a deep learning-based single-image super-resolution restoration (SRR) method to enhance the quality and effective resolution of Mars orbital imagery; e) a subpixelscale 3D processing system using a combination of photogrammetric 3D reconstruction, SRR, and photoclinometric 3D refinement; and f) an optimised subpixel-scale 3D processing system using coupled deep learning based single-view SRR and deep learning based 3D estimation to derive the best possible (in terms of visual quality, effective resolution, and accuracy) 3D products out of present epoch Mars orbital images. The resultant 3D imaging products from the above listed new developments are qualitatively and quantitatively evaluated either in comparison with products from the official NASA planetary data system (PDS) and/or ESA planetary science archive (PSA) releases, and/or in comparison with products generated with different open-source systems. Examples of the scientific application of these novel 3D imaging products are discussed.},
  langid = {english},
  school = {University College London},
  file = {/Users/kshitijgoel/Zotero/storage/CTJJ25U4/Tao - On Martian Surface Exploration Development of Automated 3D Reconstruction and Super-Resolution Rest.pdf}
}

@misc{tao_rtguide_2025,
  title = {{{RT-GuIDE}}: {{Real-Time Gaussian}} Splatting for {{Information-Driven Exploration}}},
  shorttitle = {{{RT-GuIDE}}},
  author = {Tao, Yuezhan and Ong, Dexter and Murali, Varun and Spasojevic, Igor and Chaudhari, Pratik and Kumar, Vijay},
  year = {2025},
  month = jun,
  number = {arXiv:2409.18122},
  eprint = {2409.18122},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.18122},
  url = {http://arxiv.org/abs/2409.18122},
  urldate = {2025-07-19},
  abstract = {We propose a framework for active mapping and exploration that leverages Gaussian splatting for constructing dense maps. Further, we develop a GPU-accelerated motion planning algorithm that can exploit the Gaussian map for real-time navigation. The Gaussian map constructed onboard the robot is optimized for both photometric and geometric quality while enabling real-time situational awareness for autonomy. We show through simulation experiments that our method yields comparable Peak Signal-to-Noise Ratio (PSNR) and similar reconstruction error to state-of-the-art approaches, while being orders of magnitude faster to compute. In real-world experiments, our algorithm achieves better map quality (at least 0.8dB higher PSNR and more than 16\% higher geometric reconstruction accuracy) than maps constructed by a state-of-the-art method, enabling semantic segmentation using off-the-shelf open-set models. Experiment videos and more details can be found on our project page: https://tyuezhan.github.io/RT\_GuIDE/},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/LS9GMT9X/Tao et al. - 2025 - RT-GuIDE Real-Time Gaussian splatting for Information-Driven Exploration.pdf;/Users/kshitijgoel/Zotero/storage/JADR5TE4/2409.html}
}

@misc{taylor_introduction_2024,
  title = {An Introduction to Graphical Tensor Notation for Mechanistic Interpretability},
  author = {Taylor, Jordan K.},
  year = {2024},
  month = feb,
  number = {arXiv:2402.01790},
  eprint = {2402.01790},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.01790},
  url = {http://arxiv.org/abs/2402.01790},
  urldate = {2025-02-28},
  abstract = {Graphical tensor notation is a simple way of denoting linear operations on tensors, originating from physics. Modern deep learning consists almost entirely of operations on or between tensors, so easily understanding tensor operations is quite important for understanding these systems. This is especially true when attempting to reverse-engineer the algorithms learned by a neural network in order to understand its behavior: a field known as mechanistic interpretability. It's often easy to get confused about which operations are happening between tensors and lose sight of the overall structure, but graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences. The first half of this document introduces the notation and applies it to some decompositions (SVD, CP, Tucker, and tensor network decompositions), while the second half applies it to some existing some foundational approaches for mechanistically understanding language models, loosely following ``A Mathematical Framework for Transformer Circuits'', then constructing an example ``induction head'' circuit in graphical tensor notation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/4PDYQZHL/Taylor - 2024 - An introduction to graphical tensor notation for mechanistic interpretability.pdf;/Users/kshitijgoel/Zotero/storage/6K7AKQJV/2402.html}
}

@inproceedings{teixeira_realtime_2017,
  title = {Real-Time Local {{3D}} Reconstruction for Aerial Inspection Using Superpixel Expansion},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Teixeira, Lucas and Chli, Margarita},
  year = {2017},
  month = may,
  pages = {4560--4567},
  doi = {10.1109/ICRA.2017.7989530},
  url = {https://ieeexplore.ieee.org/document/7989530/?arnumber=7989530},
  urldate = {2025-01-09},
  abstract = {On the quest of automating the navigation of challenging and promising Robotics platforms such as small Unmanned Aerial Vehicles (UAVs), the community has been increasingly active in developing perception capabilities able to run onboard such platforms in real-time. Despite that vision-based techniques have been at the heart of recent advancements, the realistic employment onboard UAVs is still in its infancy. Inspired by some of the most recent breakthroughs in online dense scene estimation and borrowing fundamental concepts from Computer Vision, in this work we propose a new pipeline for real-time, local scene reconstruction using a single camera for aerial navigation. Aiming for denser scene estimation than traditional feature-based maps with the ability to run onboard a small UAV in real-time, the proposed approach is demonstrated to achieve unprecedented performance producing rich maps of the camera's workspace, timely enough to serve in obstacle avoidance and real-time interaction of a robot with its direct surroundings. Evaluation on benchmarking datasets and on challenging aerial footage captured with a UAV featuring a conventional camera, reveals dramatic speed-ups, as well as denser and more accurate local reconstructions with respect to the state of the art.},
  keywords = {Cameras,Estimation,Image reconstruction,Pipelines,Real-time systems,Simultaneous localization and mapping},
  file = {/Users/kshitijgoel/Zotero/storage/BD92FUZV/Teixeira and Chli - 2017 - Real-time local 3D reconstruction for aerial inspection using superpixel expansion.pdf;/Users/kshitijgoel/Zotero/storage/SB4X5845/7989530.html}
}

@techreport{telgarsky_deep_,
  title = {Deep Learning Theory Lecture Notes},
  author = {Telgarsky, Matus},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5FA3H79L/Deep learning theory lecture notes.pdf}
}

@misc{teo_unveiling_2024,
  title = {Unveiling the {{Hidden Structure}} of {{Self-Attention}} via {{Kernel Principal Component Analysis}}},
  author = {Teo, Rachel S. Y. and Nguyen, Tan M.},
  year = {2024},
  month = oct,
  number = {arXiv:2406.13762},
  eprint = {2406.13762},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.13762},
  urldate = {2024-11-04},
  abstract = {The remarkable success of transformers in sequence modeling tasks, spanning various applications in natural language processing and computer vision, is attributed to the critical role of self-attention. Similar to the development of most deep learning models, the construction of these attention mechanisms relies on heuristics and experience. In our work, we derive self-attention from kernel principal component analysis (kernel PCA) and show that self-attention projects its query vectors onto the principal component axes of its key matrix in a feature space. We then formulate the exact formula for the value matrix in self-attention, theoretically and empirically demonstrating that this value matrix captures the eigenvectors of the Gram matrix of the key vectors in self-attention. Leveraging our kernel PCA framework, we propose Attention with Robust Principal Components (RPC-Attention), a novel class of robust attention that is resilient to data contamination. We empirically demonstrate the advantages of RPC-Attention over softmax attention on the ImageNet-1K object classification, WikiText-103 language modeling, and ADE20K image segmentation task.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/YXQU547X/Teo and Nguyen - 2024 - Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis.pdf;/Users/kshitijgoel/Zotero/storage/22IZ5YKM/2406.html}
}

@article{terrell_variable_1992,
  title = {Variable {{Kernel Density Estimation}}},
  author = {Terrell, George R. and Scott, David W.},
  year = {1992},
  journal = {The Annals of Statistics},
  volume = {20},
  number = {3},
  eprint = {2242011},
  eprinttype = {jstor},
  pages = {1236--1265},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2242011},
  urldate = {2024-05-09},
  abstract = {We investigate some of the possibilities for improvement of univariate and multivariate kernel density estimates by varying the window over the domain of estimation, pointwise and globally. Two general approaches are to vary the window width by the point of estimation and by point of the sample observation. The first possibility is shown to be of little efficacy in one variable. In particular, nearest-neighbor estimators in all versions perform poorly in one and two dimensions, but begin to be useful in three or more variables. The second possibility is more promising. We give some general properties and then focus on the popular Abramson estimator. We show that in many practical situations, such as normal data, a nonlocality phenomenon limits the commonly applied version of the Abramson estimator to bias of O([ h / log h]2) instead of the hoped for O(h4).},
  file = {/Users/kshitijgoel/Zotero/storage/QW2S9IHS/Terrell and Scott - 1992 - Variable Kernel Density Estimation.pdf}
}

@article{thiesson_accelerating_2001,
  title = {Accelerating {{EM}} for {{Large Databases}}},
  author = {Thiesson, Bo and Meek, Christopher and Heckerman, David},
  year = {2001},
  month = dec,
  journal = {Machine Learning},
  volume = {45},
  number = {3},
  pages = {279--299},
  issn = {1573-0565},
  doi = {10.1023/A:1017986506241},
  url = {https://doi.org/10.1023/A:1017986506241},
  urldate = {2024-06-13},
  abstract = {The EM algorithm is a popular method for parameter estimation in a variety of problems involving missing data. However, the EM algorithm often requires significant computational resources and has been dismissed as impractical for large databases. We present two approaches that significantly reduce the computational cost of applying the EM algorithm to databases with a large number of cases, including databases with large dimensionality. Both approaches are based on partial E-steps for which we can use the results of Neal and Hinton (In Jordan, M. (Ed.), Learning in Graphical Models, pp. 355--371. The Netherlands: Kluwer Academic Publishers) to obtain the standard convergence guarantees of EM. The first approach is a version of the incremental EM algorithm, described in Neal and Hinton (1998), which cycles through data cases in blocks. The number of cases in each block dramatically effects the efficiency of the algorithm. We provide amethod for selecting a near optimal block size. The second approach, which we call lazy EM, will, at scheduled iterations, evaluate the significance of each data case and then proceed for several iterations actively using only the significant cases. We demonstrate that both methods can significantly reduce computational costs through their application to high-dimensional real-world and synthetic mixture modeling problems for large databases.},
  langid = {english},
  keywords = {clustering,data blocking,Expectation Maximization algorithm,incremental EM,lazy EM,mixture models,online EM},
  file = {/Users/kshitijgoel/Zotero/storage/3PBJ4R7W/Thiesson et al. - 2001 - Accelerating EM for Large Databases.pdf}
}

@article{thomas_exact_2022,
  title = {Exact and {{Bounded Collision Probability}} for {{Motion Planning Under Gaussian Uncertainty}}},
  author = {Thomas, Antony and Mastrogiovanni, Fulvio and Baglietto, Marco},
  year = {2022},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {1},
  pages = {167--174},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2021.3121073},
  url = {https://ieeexplore.ieee.org/document/9580644/},
  urldate = {2023-11-07},
  abstract = {Computing collision-free trajectories is of prime importance for safe navigation. We present an approach for computing the collision probability under Gaussian distributed motion and sensing uncertainty with the robot and static obstacle shapes approximated as ellipsoids. The collision condition is formulated as the distance between ellipsoids and unlike previous approaches we provide a method for computing the exact collision probability. Furthermore, we provide a tight upper bound that can be computed much faster during online planning. Comparison to other state-of-the-art methods is also provided. The proposed method is evaluated in simulation under varying configuration and number of obstacles.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FFY8NLFS/Thomas et al. - 2022 - Exact and Bounded Collision Probability for Motion.pdf}
}

@article{thomas_integrated_2021,
  title = {An {{Integrated Localization}}, {{Motion Planning}} and {{Obstacle Avoidance Algorithm}} in {{Belief Space}}},
  author = {Thomas, Antony and Mastrogiovanni, Fulvio and Baglietto, Marco},
  year = {2021},
  month = apr,
  journal = {Intelligent Service Robotics},
  volume = {14},
  number = {2},
  pages = {235--250},
  issn = {1861-2784},
  doi = {10.1007/s11370-021-00359-6},
  url = {https://doi.org/10.1007/s11370-021-00359-6},
  urldate = {2023-11-07},
  abstract = {As robots are being increasingly used in close proximity to humans and objects, it is imperative that robots operate safely and efficiently under real-world conditions. Yet, the environment is seldom known perfectly. Noisy sensors and actuation errors compound to the errors introduced while estimating features of the environment. We present a novel approach (1) to incorporate these uncertainties for robot state estimation and (2) to compute the probability of collision pertaining to the estimated robot configurations. The expression for collision probability is obtained as an infinite series, and we prove its convergence. An upper bound for the truncation error is also derived, and the number of terms required is demonstrated by analyzing the convergence for different robot and obstacle configurations. We evaluate our approach using two simulation domains which use a roadmap-based strategy to synthesize trajectories that satisfy collision probability bounds.},
  langid = {english},
  keywords = {Belief space planning,Collision probability,Motion planning},
  file = {/Users/kshitijgoel/Zotero/storage/EFM2EY93/Thomas et al. - 2021 - An Integrated Localization, Motion Planning and Ob.pdf}
}

@inproceedings{thomas_probabilistic_2022,
  title = {Probabilistic {{Collision Constraint}} for {{Motion Planning}} in {{Dynamic Environments}}},
  booktitle = {Intelligent {{Autonomous Systems}} 16},
  author = {Thomas, Antony and Mastrogiovanni, Fulvio and Baglietto, Marco},
  editor = {Ang Jr, Marcelo H. and Asama, Hajime and Lin, Wei and Foong, Shaohui},
  year = {2022},
  series = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
  pages = {141--154},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-95892-3_11},
  abstract = {Online generation of collision free trajectories is of prime importance for autonomous navigation. Dynamic environments, robot motion and sensing uncertainties adds further challenges to collision avoidance systems. This paper presents an approach for collision avoidance in dynamic environments, incorporating robot and obstacle state uncertainties. We derive a tight upper bound for collision probability between robot and obstacle and formulate it as a motion planning constraint which is solvable in real time. The proposed approach is tested in simulation considering mobile robots as well as quadrotors to demonstrate that successful collision avoidance is achieved in real time application. We also provide a comparison of our approach with several state-of-the-art methods.},
  isbn = {978-3-030-95892-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZJ69Y9S5/Thomas et al. - 2022 - Probabilistic Collision Constraint for Motion Plan.pdf}
}

@inproceedings{thomas_taskmotion_2022,
  title = {Task-{{Motion Planning}} for~{{Navigation}} in~{{Belief Space}}},
  booktitle = {Robotics {{Research}}},
  author = {Thomas, Antony and Mastrogiovanni, Fulvio and Baglietto, Marco},
  editor = {Asfour, Tamim and Yoshida, Eiichi and Park, Jaeheung and Christensen, Henrik and Khatib, Oussama},
  year = {2022},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {542--558},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-95459-8_33},
  abstract = {We present an integrated Task-Motion Planning (TMP) framework for navigation in large-scale environment. Autonomous robots operating in real world complex scenarios require planning in the discrete (task) space and the continuous (motion) space. In knowledge intensive domains, on the one hand, a robot has to reason at the highest-level, for example the regions to navigate to; on the other hand, the feasibility of the respective navigation tasks have to be checked at the execution level. This presents a need for motion-planning-aware task planners. We discuss a probabilistically complete approach that leverages this task-motion interaction for navigating in indoor domains, returning a plan that is optimal at the task-level. Furthermore, our framework is intended for motion planning under motion and sensing uncertainty, which is formally known as belief space planning. The underlying methodology is validated with a simulated office environment in Gazebo. In addition, we discuss the limitations and provide suggestions for improvements and future work.},
  isbn = {978-3-030-95459-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/YILXREQN/Thomas et al. - 2022 - Task-Motion Planning for Navigation in Belief Spac.pdf}
}

@article{thrun_graph_2006,
  title = {The {{Graph SLAM Algorithm}} with {{Applications}} to {{Large-Scale Mapping}} of {{Urban Structures}}},
  author = {Thrun, Sebastian and Montemerlo, Michael},
  year = {2006},
  month = may,
  journal = {The International Journal of Robotics Research},
  volume = {25},
  number = {5-6},
  pages = {403--429},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364906065387},
  url = {https://doi.org/10.1177/0278364906065387},
  urldate = {2023-03-14},
  abstract = {This article presents GraphSLAM, a unifying algorithm for the offline SLAM problem. GraphSLAM is closely related to a recent sequence of research papers on applying optimization techniques to SLAM problems. It transforms the SLAM posterior into a graphical network, representing the log-likelihood of the data. It then reduces this graph using variable elimination techniques, arriving at a lower-dimensional problems that is then solved using conventional optimization techniques. As a result, GraphSLAM can generate maps with 108 or more features. The paper discusses a greedy algorithm for data association, and presents results for SLAM in urban environments with occasional GPS measurements.},
  file = {/Users/kshitijgoel/Zotero/storage/PCXVATZY/Thrun and Montemerlo - 2006 - The Graph SLAM Algorithm with Applications to Larg.pdf}
}

@article{thrun_probabilistic_2002,
  title = {Probabilistic Robotics},
  author = {Thrun, Sebastian},
  year = {2002},
  month = mar,
  journal = {Communications of the ACM},
  volume = {45},
  number = {3},
  pages = {52--57},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/504729.504754},
  url = {https://dl.acm.org/doi/10.1145/504729.504754},
  urldate = {2022-03-19},
  abstract = {Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.},
  langid = {english}
}

@phdthesis{tian_algorithms_2023,
  type = {Thesis},
  title = {Algorithms and {{Systems}} for {{Scalable Multi-Agent Geometric Estimation}}},
  author = {Tian, Yulun},
  year = {2023},
  month = sep,
  url = {https://dspace.mit.edu/handle/1721.1/152675},
  urldate = {2025-05-29},
  abstract = {Collaborative geometric estimation, which enables multiple agents to construct globally consistent geometric models of the environment (e.g., maps and robot poses) from noisy local measurements, is a crucial capability for multi-agent systems. However, achieving scalable collaborative estimation in the real world is challenging. On one hand, solving the underlying geometric optimization problems is hard due to the coupling among agents and poor numerical conditioning. On the other hand, realworld communication networks impose operational constraints (e.g., in the form of available bandwidth) that need to be accounted for during deployment. This thesis develops algorithms and systems toward enabling scalable collaborative geometric estimation, with a focus on tackling the aforementioned technical challenges. The first part of this thesis considers geometric estimation under a fully distributed communication architecture, in which agents directly communicate with each other without relying on a central server. To this end, this thesis presents distributed pose graph optimization algorithms with the goals of achieving certifiable global optimality and convergence under asynchronous communication. Leveraging the developed algorithms, this thesis then develops a complete system for distributed simultaneous localization and mapping (SLAM), and demonstrates the proposed system in large-scale urban environments where up to 8 ground robots traverse a total distance close to 8 km. The second part of this thesis tackles geometric estimation under a server-client architecture, where a server coordinates communication during collaborative optimization. To this end, this thesis presents a communication-efficient solver that enables large-scale collaborative mapping with significantly reduced communication. Furthermore, specialized solvers for collaborative rotation averaging and translation estimation are developed, which exploit spectral graph theoretic methods to achieve fast convergence. These algorithmic contributions, together with opensource code and datasets, facilitate the development of scalable multi-agent perception systems in complex environments.},
  copyright = {In Copyright - Educational Use Permitted},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2023-11-02T20:07:39Z},
  file = {/Users/kshitijgoel/Zotero/storage/7DUQAXF9/Tian - 2023 - Algorithms and Systems for Scalable Multi-Agent Geometric Estimation.pdf}
}

@article{tian_kimeramulti_2022,
  title = {Kimera-{{Multi}}: {{Robust}}, {{Distributed}}, {{Dense Metric-Semantic SLAM}} for {{Multi-Robot Systems}}},
  shorttitle = {Kimera-{{Multi}}},
  author = {Tian, Yulun and Chang, Yun and Herrera Arias, Fernando and {Nieto-Granda}, Carlos and How, Jonathan P. and Carlone, Luca},
  year = {2022},
  month = aug,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {4},
  pages = {2022--2038},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3137751},
  abstract = {Multi-robot simultaneous localization and mapping (SLAM) is a crucial capability to obtain timely situational awareness over large areas. Real-world applications demand multi-robot SLAM systems to be robust to perceptual aliasing and to operate under limited communication bandwidth; moreover, it is desirable for these systems to capture semantic information to enable high-level decision-making and spatial artificial intelligence. This article presents \$ {\textbackslash}mathsfKimera-Multi \$, a multi-robot system that: 1) is robust and capable of identifying and rejecting incorrect inter- and intrarobot loop closures resulting from perceptual aliasing; 2) is fully distributed and only relies on local (peer-to-peer) communication to achieve distributed localization and mapping; and 3) builds a globally consistent metric-semantic 3-D mesh model of the environment in real time, where faces of the mesh are annotated with semantic labels. \$ {\textbackslash}mathsfKimera-Multi \$ is implemented by a team of robots equipped with visual-inertial sensors. Each robot builds a local trajectory estimate and a local mesh using \$ {\textbackslash}mathsfKimera \$. When communication is available, robots initiate a distributed place recognition and robust pose graph optimization protocol based on a distributed graduated nonconvexity algorithm. The proposed protocol allows the robots to improve their local trajectory estimates by leveraging inter-robot loop closures while being robust to outliers. Finally, each robot uses its improved trajectory estimate to correct the local mesh using mesh deformation techniques. We demonstrate \$ {\textbackslash}mathsfKimera-Multi \$ in photo-realistic simulations, SLAM benchmarking datasets, and challenging outdoor datasets collected using ground robots. Both real and simulated experiments involve long trajectories (e.g., up to 800 m per robot). The experiments show that \$ {\textbackslash}mathsfKimera-Multi \$: 1) outperforms the state of the art in terms of robustness and accuracy; 2) achieves estimation errors comparable to a centralized SLAM system while being fully distributed; 3) is parsimonious in terms of communication bandwidth; 4) produces accurate metric-semantic 3-D meshes; and 5) is modular and can also be used for standard 3-D reconstruction (i.e., without semantic labels) or for trajectory estimation (i.e., without reconstructing a 3-D mesh).},
  keywords = {Collaboration,Estimation,Multi-robot systems,Robot kinematics,robot vision systems,Semantics,simultaneous localization and mapping,Simultaneous localization and mapping,Solid modeling,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/W2HE6UTI/Tian et al. - 2022 - Kimera-Multi Robust, Distributed, Dense Metric-Se.pdf;/Users/kshitijgoel/Zotero/storage/343LS4Z9/9686955.html}
}

@article{tian_spectral_2024,
  title = {Spectral {{Sparsification}} for {{Communication-Efficient Collaborative Rotation}} and {{Translation Estimation}}},
  author = {Tian, Yulun and How, Jonathan P.},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {257--276},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3327635},
  url = {https://ieeexplore.ieee.org/document/10296053/},
  urldate = {2024-04-04},
  abstract = {We propose fast and communication-efficient optimization algorithms for multirobot rotation averaging and translation estimation problems that arise from collaborative simultaneous localization and mapping (SLAM), structure-from-motion (SfM), and camera network localization applications. Our methods are based on theoretical relations between the Hessians of the underlying Riemannian optimization problems and the Laplacians of suitably weighted graphs. We leverage these results to design a collaborative solver in which robots coordinate with a central server to perform approximate second-order optimization, by solving a Laplacian system at each iteration. Crucially, our algorithms permit robots to employ spectral sparsification to sparsify intermediate dense matrices before communication, and hence provide a mechanism to tradeoff accuracy with communication efficiency with provable guarantees. We perform rigorous theoretical analysis of our methods and prove that they enjoy (local) linear rate of convergence. Furthermore, we show that our methods can be combined with graduated nonconvexity to achieve outlier-robust estimation. Extensive experiments on real-world SLAM and SfM scenarios demonstrate the superior convergence rate and communication efficiency of our methods.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/U5IP7534/Tian and How - 2024 - Spectral Sparsification for Communication-Efficien.pdf}
}

@misc{tishby_information_2000,
  title = {The Information Bottleneck Method},
  author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
  year = {2000},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.PHYSICS/0004057},
  url = {https://arxiv.org/abs/physics/0004057},
  urldate = {2023-02-18},
  abstract = {We define the relevant information in a signal \$x{\textbackslash}in X\$ as being the information that this signal provides about another signal \$y{\textbackslash}in {\textbackslash}Y\$. Examples include the information that face images provide about the names of the people portrayed, or the information that speech sounds provide about the words spoken. Understanding the signal \$x\$ requires more than just predicting \$y\$, it also requires specifying which features of \${\textbackslash}X\$ play a role in the prediction. We formalize this problem as that of finding a short code for \${\textbackslash}X\$ that preserves the maximum information about \${\textbackslash}Y\$. That is, we squeeze the information that \${\textbackslash}X\$ provides about \${\textbackslash}Y\$ through a `bottleneck' formed by a limited set of codewords \${\textbackslash}tX\$. This constrained optimization problem can be seen as a generalization of rate distortion theory in which the distortion measure \$d(x,{\textbackslash}x)\$ emerges from the joint statistics of \${\textbackslash}X\$ and \${\textbackslash}Y\$. This approach yields an exact set of self consistent equations for the coding rules \$X {\textbackslash}to {\textbackslash}tX\$ and \${\textbackslash}tX {\textbackslash}to {\textbackslash}Y\$. Solutions to these equations can be found by a convergent re-estimation method that generalizes the Blahut-Arimoto algorithm. Our variational principle provides a surprisingly rich framework for discussing a variety of problems in signal processing and learning, as will be described in detail elsewhere.},
  copyright = {Assumed arXiv.org perpetual, non-exclusive license to distribute this article for submissions made before January 2004},
  keywords = {Adaptation and Self-Organizing Systems (nlin.AO),Data Analysis Statistics and Probability (physics.data-an),Disordered Systems and Neural Networks (cond-mat.dis-nn),FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG)},
  file = {/Users/kshitijgoel/Zotero/storage/64YME9LN/Tishby et al. - 2000 - The information bottleneck method.pdf}
}

@book{tong_multivariate_1990,
  title = {The {{Multivariate Normal Distribution}}},
  author = {Tong, Y. L.},
  year = {1990},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4613-9655-0},
  url = {http://link.springer.com/10.1007/978-1-4613-9655-0},
  urldate = {2024-07-23},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4613-9657-4 978-1-4613-9655-0},
  keywords = {correlation,normal distribution,probability,regression,statistical computing,statistics},
  file = {/Users/kshitijgoel/Zotero/storage/7LNE5NV8/Tong - 1990 - The Multivariate Normal Distribution.pdf}
}

@article{tordesillas_deeppanther_2023,
  title = {Deep-{{PANTHER}}: {{Learning-Based Perception-Aware Trajectory Planner}} in {{Dynamic Environments}}},
  shorttitle = {Deep-{{PANTHER}}},
  author = {Tordesillas, Jesus and How, Jonathan P.},
  year = {2023},
  month = mar,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {3},
  pages = {1399--1406},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3235678},
  url = {https://ieeexplore.ieee.org/abstract/document/10012552},
  urldate = {2024-02-08},
  abstract = {This letter presents Deep-PANTHER, a learning-based perception-aware trajectory planner for unmanned aerial vehicles (UAVs) in dynamic environments. Given the current state of the UAV, and the predicted trajectory and size of the obstacle, Deep-PANTHER generates multiple trajectories to avoid a dynamic obstacle while simultaneously maximizing its presence in the field of view (FOV) of the onboard camera. To obtain a computationally tractable real-time solution, imitation learning is leveraged to train a Deep-PANTHER policy using demonstrations provided by a multimodal optimization-based expert. Extensive simulations show replanning times that are two orders of magnitude faster than the optimization-based expert, while achieving a similar cost. By ensuring that each expert trajectory is assigned to one distinct student trajectory in the loss function, Deep-PANTHER can also capture the multimodality of the problem and achieve a mean squared error (MSE) loss with respect to the expert that is up to 18 times smaller than state-of-the-art (Relaxed) Winner-Takes-All approaches. Deep-PANTHER is also shown to generalize well to obstacle trajectories that differ from the ones used in training.},
  keywords = {Costs,Imitation learning,optimization,Optimization,perception-aware trajectory planning,Splines (mathematics),Training,Trajectory,Trajectory planning,UAV,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/GYHLXTFR/Tordesillas and How - 2023 - Deep-PANTHER Learning-Based Perception-Aware Traj.pdf;/Users/kshitijgoel/Zotero/storage/35MHWRVU/10012552.html}
}

@article{tordesillas_faster_2022,
  title = {{{FASTER}}: {{Fast}} and {{Safe Trajectory Planner}} for {{Navigation}} in {{Unknown Environments}}},
  shorttitle = {{{FASTER}}},
  author = {Tordesillas, Jesus and Lopez, Brett T. and Everett, Michael and How, Jonathan P.},
  year = {2022},
  month = apr,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {2},
  pages = {922--938},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2021.3100142},
  url = {https://ieeexplore.ieee.org/document/9592663/},
  urldate = {2024-01-27},
  abstract = {Planning high-speed trajectories for UAVs in unknown environments requires algorithmic techniques that enable fast reaction times to guarantee safety as more information about the environment becomes available. The standard approaches that ensure safety by enforcing a ``stop'' condition in the free-known space can severely limit the speed of the vehicle, especially in situations where much of the world is unknown. Moreover, the ad-hoc time and interval allocation scheme usually imposed on the trajectory also leads to conservative and slower trajectories. This work proposes FASTER (Fast and Safe Trajectory Planner) to ensure safety without sacrificing speed. FASTER obtains highspeed trajectories by enabling the local planner to optimize in both the free-known and unknown spaces. Safety is ensured by always having a safe back-up trajectory in the free-known space. The MIQP formulation proposed also allows the solver to choose the trajectory interval allocation. FASTER is tested extensively in simulation and in real hardware, showing flights in unknown cluttered environments with velocities up to 7.8 m/s, and experiments at the maximum speed of a skid-steer ground robot (2 m/s).},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/G92TIQU4/Tordesillas et al. - 2022 - FASTER Fast and Safe Trajectory Planner for Navig.pdf}
}

@phdthesis{tordesillastorres_trajectory_2022,
  type = {Thesis},
  title = {Trajectory {{Planning}} for {{Flights}} in {{Multiagent}} and {{Dynamic Environments}}},
  author = {Tordesillas Torres, Jesus},
  year = {2022},
  month = sep,
  url = {https://dspace.mit.edu/handle/1721.1/147446},
  urldate = {2023-11-20},
  abstract = {While efficient and fast trajectory planners in static worlds have been extensively proposed for UAVs (Unmanned Aerial Vehicles), a 3D real-time planner for environments with static obstacles, dynamic obstacles, and other planning agents still remains an open problem. The dynamic nature of these environments demands high replanning rates, making this problem especially hard on computationally limited platforms. Existing state-of-the-art planners reduce the computational complexity at the expense of more conservative results by relying on three main simplifications or assumptions: First, the collision avoidance constraints are imposed using the Bernstein and B-Spline polynomial bases, which do not tightly enclose a given interval of a polynomial trajectory. Second, multiagent planners usually make centralized and/or synchronized computation assumptions, which lead to poor scalability with the number of agents or can degrade the overall performance. Finally, position and yaw are decoupled when optimizing perception-aware trajectories, which produces highly conservative results.      This thesis addresses the aforementioned limitations with the following contributions: First, it presents the MINVO basis, a polynomial basis that generates the simplex with minimum volume enclosing a polynomial curve, therefore reducing the conservativeness in the obstacle avoidance constraints. Leveraging the MINVO basis, this thesis then proposes a tractable way to avoid dynamic obstacles by imposing linear separability constraints between the polyhedral enclosures of the intervals of the trajectories. This is then extended to multiagent scenarios, and a decentralized and asynchronous obstacle avoidance algorithm among many replanning agents is presented. Real-time perception-aware planning is achieved by implicitly imposing the underactuated dynamics of the UAV through the Hopf fibration while jointly optimizing the full pose. Finally, a reduction of two orders of magnitude in the computation time is obtained by learning a policy that imitates the optimization-based planner. These proposed contributions are extensively evaluated in simulation, showing up to 32 agents planning in real time, and in real-world experiments, showcasing flights up to 5.8 m/s in unknown dynamic environments with only onboard computation.},
  copyright = {In Copyright - Educational Use Permitted},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2023-01-19T19:50:58Z},
  file = {/Users/kshitijgoel/Zotero/storage/8TI8ZECE/Tordesillas Torres - 2022 - Trajectory Planning for Flights in Multiagent and .pdf}
}

@misc{tosi_how_2024,
  title = {How {{NeRFs}} and {{3D Gaussian Splatting}} Are {{Reshaping SLAM}}: A {{Survey}}},
  shorttitle = {How {{NeRFs}} and {{3D Gaussian Splatting}} Are {{Reshaping SLAM}}},
  author = {Tosi, Fabio and Zhang, Youmin and Gong, Ziren and Sandstr{\"o}m, Erik and Mattoccia, Stefano and Oswald, Martin R. and Poggi, Matteo},
  year = {2024},
  month = apr,
  number = {arXiv:2402.13255},
  eprint = {2402.13255},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2402.13255},
  urldate = {2024-05-28},
  abstract = {Over the past two decades, research in the field of Simultaneous Localization and Mapping (SLAM) has undergone a significant evolution, highlighting its critical role in enabling autonomous exploration of unknown environments. This evolution ranges from hand-crafted methods, through the era of deep learning, to more recent developments focused on Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (3DGS) representations. Recognizing the growing body of research and the absence of a comprehensive survey on the topic, this paper aims to provide the first comprehensive overview of SLAM progress through the lens of the latest advancements in radiance fields. It sheds light on the background, evolutionary path, inherent strengths and limitations, and serves as a fundamental reference to highlight the dynamic progress and specific challenges.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/5H8IWAHJ/Tosi et al. - 2024 - How NeRFs and 3D Gaussian Splatting are Reshaping SLAM a Survey.pdf}
}

@article{toumieh_highspeed_2024,
  title = {High-{{Speed Motion Planning}} for {{Aerial Swarms}} in {{Unknown}} and {{Cluttered Environments}}},
  author = {Toumieh, Charbel and Floreano, Dario},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {3642--3656},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3429193},
  url = {https://ieeexplore.ieee.org/document/10599811/?arnumber=10599811},
  urldate = {2024-11-14},
  abstract = {Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the State-of-the-Art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100\% success in reaching the target location), flight speed (97\% faster), and flight time (50\% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.},
  keywords = {Aerial swarms,Delays,Drones,high-speed navigation,motion planning,obstacle avoidance,Planning,Point cloud compression,Safety,Sensors,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/NE65XGVS/Toumieh and Floreano - 2024 - High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered Environments.pdf;/Users/kshitijgoel/Zotero/storage/G8DRXKZ3/10599811.html}
}

@phdthesis{townsend_lossless_2021,
  title = {Lossless {{Compression}} with {{Latent Variable Models}}},
  author = {Townsend, James},
  year = {2021},
  month = apr,
  eprint = {2104.10544},
  url = {http://arxiv.org/abs/2104.10544},
  urldate = {2024-10-17},
  abstract = {We develop a simple and elegant method for lossless compression using latent variable models, which we call 'bits back with asymmetric numeral systems' (BB-ANS). The method involves interleaving encode and decode steps, and achieves an optimal rate when compressing batches of data. We demonstrate it firstly on the MNIST test set, showing that state-of-the-art lossless compression is possible using a small variational autoencoder (VAE) model. We then make use of a novel empirical insight, that fully convolutional generative models, trained on small images, are able to generalize to images of arbitrary size, and extend BB-ANS to hierarchical latent variable models, enabling state-of-the-art lossless compression of full-size colour images from the ImageNet dataset. We describe 'Craystack', a modular software framework which we have developed for rapid prototyping of compression using deep generative models.},
  archiveprefix = {arXiv},
  school = {University College London},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Information Theory,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/JSJCVAAA/Townsend - 2021 - Lossless Compression with Latent Variable Models.pdf;/Users/kshitijgoel/Zotero/storage/E4CAD3XS/2104.html}
}

@inproceedings{tracy_differentiable_2023,
  title = {Differentiable {{Collision Detection}} for a {{Set}} of {{Convex Primitives}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Tracy, Kevin and Howell, Taylor A. and Manchester, Zachary},
  year = {2023},
  month = may,
  pages = {3663--3670},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160716},
  url = {https://ieeexplore.ieee.org/document/10160716/},
  urldate = {2023-11-26},
  abstract = {Collision detection between objects is critical for simulation, control, and learning for robotic systems. However, existing collision detection routines are inherently nondifferentiable, limiting their applications in gradient-based optimization tools. In this work, we propose DCOL: a fast and fully differentiable collision-detection framework that reasons about collisions between a set of composable and highly expressive convex primitive shapes. This is achieved by formulating the collision detection problem as a convex optimization problem that solves for the minimum uniform scaling applied to each primitive before they intersect. The optimization problem is fully differentiable with respect to the configurations of each primitive and is able to return a collision detection metric and contact points on each object, agnostic of interpenetration. We demonstrate the capabilities of DCOL on a range of robotics problems from trajectory optimization and contact physics, and have made an open-source implementation available.},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HJNH3XL5/Tracy et al. - 2023 - Differentiable Collision Detection for a Set of Co.pdf}
}

@misc{tramer_position_2024,
  title = {Position: {{Considerations}} for {{Differentially Private Learning}} with {{Large-Scale Public Pretraining}}},
  shorttitle = {Position},
  author = {Tram{\`e}r, Florian and Kamath, Gautam and Carlini, Nicholas},
  year = {2024},
  month = jul,
  number = {arXiv:2212.06470},
  eprint = {2212.06470},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2212.06470},
  urldate = {2024-07-23},
  abstract = {The performance of differentially private machine learning can be boosted significantly by leveraging the transfer learning capabilities of non-private models pretrained on large public datasets. We critically review this approach.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/7ZZRVNWA/Tramèr et al. - 2024 - Position Considerations for Differentially Private Learning with Large-Scale Public Pretraining.pdf}
}

@inproceedings{tran_gaussian_2014,
  title = {Gaussian {{Mixture Model Based}} on {{Hidden Markov Random Field}} for {{Color Image Segmentation}}},
  booktitle = {Ubiquitous {{Information Technologies}} and {{Applications}}},
  author = {Tran, Khoa Anh and Vo, Nhat Quang and Nguyen, Tam Thi and Lee, Gueesang},
  editor = {Jeong, Young-Sik and Park, Young-Ho and Hsu, Ching-Hsien (Robert) and Park, James J. (Jong Hyuk)},
  year = {2014},
  series = {Lecture {{Notes}} in {{Electrical Engineering}}},
  pages = {189--197},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-41671-2_25},
  abstract = {Gaussian Mixture Model (GMM) has been widely applied in image segmentation. However, the pixels themselves are considered independent of each other, making the segmentation result sensitive to noise. To overcome this problem for the segmentation process we propose a mixture model useing Markov Random Filed (MRF) that aims to incorporate spatial relationship among neighborhood pixels into the GMM. The proposed model has a simplified structure that allows the Expectation Maximization (EM) algorithm to be directly applied to the log-likelihood function to compute the optimum parameters of the mixture model. The experimental results show that our method has more advantage in image segmentation than other methods in terms of accuracy and quality of segmented image, and simple performance.},
  isbn = {978-3-642-41671-2},
  langid = {english},
  keywords = {Expectation Maximization,Gaussian mixture models,Hidden Markov random field,Image segmentation,Log-likelihood},
  file = {/Users/kshitijgoel/Zotero/storage/8BSHLJFH/Tran et al. - 2014 - Gaussian Mixture Model Based on Hidden Markov Rand.pdf}
}

@article{tranzatto_cerberus_2022,
  title = {{{CERBERUS}}: {{Autonomous Legged}} and {{Aerial Robotic Exploration}} in the {{Tunnel}} and {{Urban Circuits}} of the {{DARPA Subterranean Challenge}}},
  shorttitle = {{{CERBERUS}}},
  author = {Tranzatto, Marco and Mascarich, Frank and Bernreiter, Lukas and Godinho, Carolina and Camurri, Marco and Khattak, Shehryar and Dang, Tung and Reijgwart, Victor and L{\"o}je, Johannes and Wisth, David and Zimmermann, Samuel and Nguyen, Huan and Fehr, Marius and Solanka, Lukas and Buchanan, Russell and Bjelonic, Marko and Khedekar, Nikhil and Valceschini, Mathieu and Jenelten, Fabian and Dharmadhikari, Mihir and Homberger, Timon and De Petris, Paolo and Wellhausen, Lorenz and Kulkarni, Mihir and Miki, Takahiro and Hirsch, Satchel and Montenegro, Markus and Papachristos, Christos and Tresoldi, Fabian and Carius, Jan and Valsecchi, Giorgio and Lee, Joonho and Meyer, Konrad and Wu, Xiangyu and Nieto, Juan and Smith, Andy and Hutter, Marco and Siegwart, Roland and Mueller, Mark and Fallon, Maurice and Alexis, Kostas},
  year = {2022},
  month = mar,
  journal = {Field Robotics},
  volume = {2},
  number = {1},
  pages = {274--324},
  issn = {27713989},
  doi = {10.55417/fr.2022011},
  url = {https://fieldrobotics.net/Field_Robotics/Volume_2_files/Vol2_11.pdf},
  urldate = {2023-01-26},
  abstract = {Autonomous exploration of subterranean environments constitutes a major frontier for robotic systems, as underground settings present key challenges that can render robot autonomy hard to achieve. This problem has motivated the DARPA Subterranean Challenge, where teams of robots search for objects of interest in various underground environments. In response, we present the CERBERUS system-of-systems, as a unified strategy for subterranean exploration using legged and flying robots. Our proposed approach relies on ANYmal quadraped as primary robots, exploiting their endurance and ability to traverse challenging terrain. For aerial robots, we use both conventional and collision-tolerant multirotors to explore spaces too narrow or otherwise unreachable by ground systems. Anticipating degraded sensing conditions, we developed a complementary multimodal sensor-fusion approach, utilizing camera, LiDAR, and inertial data for resilient robot pose estimation. Individual robot pose estimates are refined by a centralized multi-robot map-optimization approach to improve the reported location accuracy of detected objects of interest in the DARPA-defined coordinate frame. Furthermore, a unified exploration path-planning policy is presented to facilitate the autonomous operation of both legged and aerial robots in complex underground networks. Finally, to enable communication among team agents and the base station, CERBERUS utilizes a ground rover with a high-gain antenna and an optical fiber connection to the base station and wireless ``breadcrumb'' nodes deployed by the legged robots. We report results from the CERBERUS system-of-systems deployment at the DARPA Subterranean Challenge's Tunnel and Urban Circuit events, along with the current limitations and the lessons learned for the benefit of the community.},
  file = {/Users/kshitijgoel/Zotero/storage/6MIX8X8R/Tranzatto et al. - 2022 - CERBERUS Autonomous Legged and Aerial Robotic Exp.pdf}
}

@article{tu_configuration_2023,
  title = {Configuration {{Identification}} for a {{Freeform Modular Self-Reconfigurable Robot}} - {{FreeSN}}},
  author = {Tu, Yuxiao and Lam, Tin Lun},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--17},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3303848},
  abstract = {Modular self-reconfigurable robotic systems are potentially more robust and adaptive than conventional systems. This article proposes a novel freeform and truss-structured modular self-reconfigurable robot called FreeSN, containing node and strut modules. A node module contains a low-carbon steel spherical shell. A strut module contains two magnetic-based freeform connectors, which can connect to any position of the node module and provide spherical motions. Accurate configuration identification is essential for the automation of modular robot systems. This article presents a novel configuration identification system for FreeSN, including connection point magnetic localization, module identification, module orientation fusion, and system configuration fusion. A magnetic sensor array is integrated into the node module. A graph convolutional network-based magnetic localization algorithm is proposed, which can efficiently locate a variable number of magnet arrays under ferromagnetic material distortion. The module relative orientation is then estimated by fusing the magnetic localization result with the inertia moment unit and wheel odometry. Finally, the system configuration can be estimated, including the connection topology graph and the poses of modules. The configuration identification system is validated by a series of accuracy evaluation experiments and two library-based automation demonstrations based on closed-loop control.},
  keywords = {Cellular and modular robots,Connectors,graph convolutional network (GCN),Location awareness,Magnetic levitation,magnetic localization,Robot sensing systems,Robots,self-reconfigurable,sensor fusion,Steel,Wheels},
  file = {/Users/kshitijgoel/Zotero/storage/7KLRINIB/Tu and Lam - 2023 - Configuration Identification for a Freeform Modula.pdf;/Users/kshitijgoel/Zotero/storage/8V6HTVBH/10232916.html}
}

@article{tulino_random_2004,
  title = {Random {{Matrix Theory}} and {{Wireless Communications}}},
  author = {Tulino, Antonia M. and Verd{\'u}, Sergio},
  year = {2004},
  month = jun,
  journal = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume = {1},
  number = {1},
  pages = {1--182},
  publisher = {Now Publishers, Inc.},
  issn = {1567-2190, 1567-2328},
  doi = {10.1561/0100000001},
  url = {https://www.nowpublishers.com/article/Details/CIT-001},
  urldate = {2024-04-29},
  abstract = {Random Matrix Theory and Wireless Communications},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/984MISMI/Tulino and Verdú - 2004 - Random Matrix Theory and Wireless Communications.pdf}
}

@misc{turkulainen_dnsplatter_2024,
  title = {{{DN-Splatter}}: {{Depth}} and {{Normal Priors}} for {{Gaussian Splatting}} and {{Meshing}}},
  shorttitle = {{{DN-Splatter}}},
  author = {Turkulainen, Matias and Ren, Xuqian and Melekhov, Iaroslav and Seiskari, Otto and Rahtu, Esa and Kannala, Juho},
  year = {2024},
  month = nov,
  number = {arXiv:2403.17822},
  eprint = {2403.17822},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.17822},
  urldate = {2024-11-10},
  abstract = {High-fidelity 3D reconstruction of common indoor scenes is crucial for VR and AR applications. 3D Gaussian splatting, a novel differentiable rendering technique, has achieved state-of-the-art novel view synthesis results with high rendering speeds and relatively low training times. However, its performance on scenes commonly seen in indoor datasets is poor due to the lack of geometric constraints during optimization. In this work, we explore the use of readily accessible geometric cues to enhance Gaussian splatting optimization in challenging, ill-posed, and textureless scenes. We extend 3D Gaussian splatting with depth and normal cues to tackle challenging indoor datasets and showcase techniques for efficient mesh extraction. Specifically, we regularize the optimization procedure with depth information, enforce local smoothness of nearby Gaussians, and use off-the-shelf monocular networks to achieve better alignment with the true scene geometry. We propose an adaptive depth loss based on the gradient of color images, improving depth estimation and novel view synthesis results over various baselines. Our simple yet effective regularization technique enables direct mesh extraction from the Gaussian representation, yielding more physically accurate reconstructions of indoor scenes.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/SBP8FARU/Turkulainen et al. - 2024 - DN-Splatter Depth and Normal Priors for Gaussian Splatting and Meshing.pdf;/Users/kshitijgoel/Zotero/storage/LBXVWFI3/2403.html}
}

@inproceedings{tuzel_simultaneous_2005,
  title = {Simultaneous Multiple {{3D}} Motion Estimation via Mode Finding on {{Lie}} Groups},
  booktitle = {Tenth {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}}'05) {{Volume}} 1},
  author = {Tuzel, O. and Subbarao, R. and Meer, P.},
  year = {2005},
  month = oct,
  volume = {1},
  pages = {18-25 Vol. 1},
  issn = {2380-7504},
  doi = {10.1109/ICCV.2005.226},
  url = {https://ieeexplore.ieee.org/document/1541234},
  urldate = {2024-06-27},
  abstract = {We propose a new method to estimate multiple rigid motions from noisy 3D point correspondences in the presence of outliers. The method does not require prior specification of number of motion groups and estimates all the motion parameters simultaneously. We start with generating samples from the rigid motion distribution. The motion parameters are then estimated via mode finding operations on the sampled distribution. Since rigid motions do not lie on a vector space, classical statistical methods can not be used for mode finding. We develop a mean shift algorithm which estimates modes of the sampled distribution using the Lie group structure of the rigid motions. We also show that proposed mean shift algorithm is general and can be applied to any distribution having a matrix Lie group structure. Experimental results on synthetic and real image data demonstrate the superior performance of the algorithm.},
  keywords = {Computer vision,Iterative algorithms,Iterative methods,Least squares approximation,Motion detection,Motion estimation,Parameter estimation,Singular value decomposition,Statistical analysis,Stereo vision},
  file = {/Users/kshitijgoel/Zotero/storage/83TB8UK9/Tuzel et al. - 2005 - Simultaneous multiple 3D motion estimation via mode finding on Lie groups.pdf}
}

@inproceedings{tzes_graph_2023,
  title = {Graph {{Neural Networks}} for {{Multi-Robot Active Information Acquisition}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Tzes, Mariliza and Bousias, Nikolaos and Chatzipantazis, Evangelos and Pappas, George J.},
  year = {2023},
  month = may,
  pages = {3497--3503},
  doi = {10.1109/ICRA48891.2023.10160723},
  url = {https://ieeexplore.ieee.org/abstract/document/10160723},
  urldate = {2024-02-10},
  abstract = {This paper addresses the Multi-Robot Active In-formation Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph represen-tation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot configurations. Numerical simulations on significantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efficacy in the application of localization and tracking of dynamic targets.},
  keywords = {Decision making,Location awareness,Numerical simulation,Scalability,Simultaneous localization and mapping,Target tracking,Training},
  file = {/Users/kshitijgoel/Zotero/storage/6ZXFNXMT/Tzes et al. - 2023 - Graph Neural Networks for Multi-Robot Active Infor.pdf;/Users/kshitijgoel/Zotero/storage/GUB3ZVAJ/10160723.html}
}

@inproceedings{ubellacker_robust_2023,
  title = {Robust {{Locomotion}} on {{Legged Robots}} through {{Planning}} on {{Motion Primitive Graphs}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Ubellacker, Wyatt and Ames, Aaron D.},
  year = {2023},
  month = may,
  pages = {12142--12148},
  doi = {10.1109/ICRA48891.2023.10160672},
  url = {https://ieeexplore.ieee.org/abstract/document/10160672},
  urldate = {2024-02-10},
  abstract = {The functional demands of robotic systems often require completing various tasks or behaviors under the effect of disturbances or uncertain environments. Of increasing interest is the autonomy for dynamic robots, such as multirotors, motor vehicles, and legged platforms. Here, disturbances and environmental conditions can have significant impact on the successful performance of the individual dynamic behaviors, referred to as ``motion primitives''. Despite this, robustness can be achieved by switching to and transitioning through suitable motion primitives. This paper contributes such a method by presenting an abstraction of the motion primitive dynamics and a corresponding''motion primitive transfer function''. From this, a mixed discrete and continuous ``motion primitive graph'' is constructed, and an algorithm capable of online search of this graph is detailed. The result is a framework capable of realizing holistic robustness on dynamic systems. This is experimentally demonstrated for a set of motion primitives on a quadrupedal robot, subject to various environmental and intentional disturbances.},
  keywords = {Behavioral sciences,Dynamics,Heuristic algorithms,Legged locomotion,Probabilistic logic,Robustness,Transfer functions},
  file = {/Users/kshitijgoel/Zotero/storage/RTL839VD/Ubellacker and Ames - 2023 - Robust Locomotion on Legged Robots through Plannin.pdf;/Users/kshitijgoel/Zotero/storage/2LSLTT6U/10160672.html}
}

@inproceedings{underwood_explicit_2013,
  title = {Explicit {{3D}} Change Detection Using Ray-Tracing in Spherical Coordinates},
  booktitle = {2013 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Underwood, J. P. and Gillsj{\"o}, D. and Bailey, T. and Vlaskine, V.},
  year = {2013},
  month = may,
  pages = {4735--4741},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2013.6631251},
  abstract = {Change detection is important for autonomous perception systems that operate in dynamic environments. Mapping and tracking components commonly handle two ends of the dynamic spectrum: stationarity and rapid motion. This paper presents a fast algorithm for 3D change detection from LIDAR or equivalent optical range sensors, that can operate from arbitrary viewpoints and can detect fast and slow dynamics. Distinct from prior work, the method explicitly detects changes in the world, and suppresses apparent changes in the data due to exploration at frontiers or behind occlusions. Comprehensive experimentation is performed to assess the performance in several application domains. Sample data and source code are provided.},
  keywords = {Data models,Laser radar,Measurement by laser beam,Noise,Sensors,Three-dimensional displays,Tracking},
  file = {/Users/kshitijgoel/Zotero/storage/QIUL7V2B/Underwood et al. - 2013 - Explicit 3D change detection using ray-tracing in .pdf;/Users/kshitijgoel/Zotero/storage/5FW5M6E5/6631251.html}
}

@inproceedings{upadhyay_less_2024,
  title = {Less Is {{More}} -- {{Towards}} Parsimonious Multi-Task Models Using Structured Sparsity},
  booktitle = {Conference on {{Parsimony}} and {{Learning}}},
  author = {Upadhyay, Richa and Phlypo, Ronald and Saini, Rajkumar and Liwicki, Marcus},
  year = {2024},
  month = jan,
  pages = {590--601},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v234/upadhyay24a.html},
  urldate = {2024-12-19},
  abstract = {Model sparsification in deep learning promotes simpler, more interpretable models with fewer parameters.  This not only reduces the model's memory footprint and computational needs but also shortens inference time. This work focuses on creating sparse models optimized for multiple tasks with fewer parameters.  These parsimonious models also possess the potential to match or outperform dense models in terms of performance. In this work, we introduce channel-wise \$l\_1/l\_2\$ group sparsity in the shared convolutional layers parameters (or weights) of the multi-task learning model. This approach facilitates the removal of extraneous groups i.e., channels (due to \$l\_1\$ regularization) and also imposes a penalty on the weights, further enhancing the learning efficiency for all tasks (due to \$l\_2\$ regularization). We analyzed the results of group sparsity in both single-task and multi-task settings on two widely-used multi-task learning datasets: NYU-v2 and CelebAMask-HQ. On both datasets, which consist of three different computer vision tasks each, multi-task models with approximately 70\% sparsity outperform their dense equivalents. We also investigate how changing the degree of sparsification influences the model's performance, the overall sparsity percentage, the patterns of sparsity, and the inference time.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HR9PCVDY/Upadhyay et al. - 2024 - Less is More – Towards parsimonious multi-task models using structured sparsity.pdf}
}

@inproceedings{valencia_active_2012,
  title = {Active {{Pose SLAM}}},
  booktitle = {2012 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Valencia, Rafael and Valls Mir{\'o}, Jaime and Dissanayake, Gamini and {Andrade-Cetto}, Juan},
  year = {2012},
  month = oct,
  pages = {1885--1891},
  issn = {2153-0866},
  doi = {10.1109/IROS.2012.6385637},
  url = {https://ieeexplore.ieee.org/document/6385637},
  urldate = {2023-10-23},
  abstract = {We present an active exploration strategy that complements Pose SLAM [1] and optimal navigation in Pose SLAM [2]. The method evaluates the utility of exploratory and place revisiting sequences and chooses the one that minimizes overall map and path entropies. The technique considers trajectories of similar path length taking marginal pose uncertainties into account. An advantage of the proposed strategy with respect to competing approaches is that to evaluate information gain over the map, only a very coarse prior map estimate needs to be computed. Its coarseness is independent and does not jeopardize the Pose SLAM estimate. Moreover, a replanning scheme is devised to detect significant localization improvement during path execution. The approach is tested in simulations in a common publicly available dataset comparing favorably against frontier based exploration.},
  file = {/Users/kshitijgoel/Zotero/storage/425ZDW3T/Valencia et al. - 2012 - Active Pose SLAM.pdf}
}

@article{vandenberg_efficient_2021,
  title = {Efficient {{Approximate Value Iteration}} for {{Continuous Gaussian POMDPs}}},
  author = {Van Den Berg, Jur and Patil, Sachin and Alterovitz, Ron},
  year = {2021},
  month = sep,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {26},
  number = {1},
  pages = {1832--1838},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v26i1.8371},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/8371},
  urldate = {2023-10-24},
  abstract = {We introduce a highly efficient method for solving continuous partially-observable Markov decision processes (POMDPs) in which beliefs can be modeled using Gaussian distributions over the state space. Our method enables fast solutions to sequential decision making under uncertainty for a variety of problems involving noisy or incomplete observations and stochastic actions. We present an efficient approach to compute locally-valid approximations to the value function over continuous spaces in time polynomial (O[n4]) in the dimension n of the state space. To directly tackle the intractability of solving general POMDPs, we leverage the assumption that beliefs are Gaussian distributions over the state space, approximate the belief update using an extended Kalman filter (EKF), and represent the value function by a function that is quadratic in the mean and linear in the variance of the belief. Our approach iterates towards a linear control policy over the state space that is locally-optimal with respect to a user defined cost function, and is approximately valid in the vicinity of a nominal trajectory through belief space. We demonstrate the scalability and potential of our approach on problems inspired by robot navigation under uncertainty for state spaces of up to 128 dimensions.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/I8U7NVQT/Van Den Berg et al. - 2021 - Efficient Approximate Value Iteration for Continuo.pdf}
}

@inproceedings{vandenboomgaard_equivalence_2002,
  title = {On the Equivalence of Local-Mode Finding, Robust Estimation and Mean-Shift Analysis as Used in Early Vision Tasks},
  booktitle = {2002 {{International Conference}} on {{Pattern Recognition}}},
  author = {{van den Boomgaard}, R. and {van de Weijer}, J.},
  year = {2002},
  month = aug,
  volume = {3},
  pages = {927-930 vol.3},
  issn = {1051-4651},
  doi = {10.1109/ICPR.2002.1048187},
  url = {https://ieeexplore.ieee.org/document/1048187},
  urldate = {2024-07-08},
  abstract = {In this paper we show the equivalence of three techniques used in image processing: local-mode finding, robust-estimation and mean-shift analysis. The computational common element in all these image operators is the spatial-tonal normalized convolution, an image operator that generalizes the bilateral filter.},
  keywords = {Convolution,Filtering,Histograms,Image analysis,Information analysis,Intelligent systems,Kernel,Low pass filters,Nonlinear filters,Robustness},
  file = {/Users/kshitijgoel/Zotero/storage/DNJXWQQ5/van den Boomgaard and van de Weijer - 2002 - On the equivalence of local-mode finding, robust estimation and mean-shift analysis as used in early.pdf;/Users/kshitijgoel/Zotero/storage/RBVMDPEM/1048187.html}
}

@phdthesis{vandermerwe_sigmapoint_2004,
  title = {Sigma-Point Kalman Filters for Probabilistic Inference in Dynamic State-Space Models},
  author = {{Van der Merwe}, Rudolph},
  year = {2004},
  month = apr,
  school = {Oregon Health and Science University},
  keywords = {bayesian statistical decision theory,estimation theory,kalman filtering,Machine Learning,probabilities},
  file = {/Users/kshitijgoel/Zotero/storage/7FM78ZD2/Van der Merwe - Sigma-point kalman filters for probabilistic inference in dynamic state-space models.pdf}
}

@incollection{vandermerwe_sigmapoint_2004a,
  title = {Sigma-{{Point Kalman Filters}} for {{Nonlinear Estimation}} and {{Sensor-Fusion}}: {{Applications}} to {{Integrated Navigation}}},
  shorttitle = {Sigma-{{Point Kalman Filters}} for {{Nonlinear Estimation}} and {{Sensor-Fusion}}},
  booktitle = {{{AIAA Guidance}}, {{Navigation}}, and {{Control Conference}} and {{Exhibit}}},
  author = {{van der Merwe}, Rudolph and Wan, Eric and Julier, Simon},
  year = {2004},
  month = aug,
  series = {Guidance, {{Navigation}}, and {{Control}} and {{Co-located Conferences}}},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2004-5120},
  url = {https://arc.aiaa.org/doi/10.2514/6.2004-5120},
  urldate = {2025-03-24},
  keywords = {Altimeter,GNC Systems,Helicopters,Inertial Measurement Unit,Quaternions,Sensor Fusion,State Dependent Riccati Equation,Unmanned Aerial Vehicle,Unscented Kalman Filter,Yaw},
  file = {/Users/kshitijgoel/Zotero/storage/EVM94TW3/Van Der Merwe et al. - 2004 - Sigma-Point Kalman Filters for Nonlinear Estimation and Sensor-Fusion Applications to Integrated Na.pdf}
}

@article{vaquero_eels_2024,
  title = {{{EELS}}: {{Autonomous}} Snake-like Robot with Task and Motion Planning Capabilities for Ice World Exploration},
  shorttitle = {{{EELS}}},
  author = {Vaquero, T. S. and Daddi, G. and Thakker, R. and Paton, M. and Jasour, A. and Strub, M. P. and Swan, R. M. and Royce, R. and Gildner, M. and Tosi, P. and Veismann, M. and Gavrilov, P. and Marteau, E. and Bowkett, J. and {de Mola Lemus}, D. Loret and Nakka, Y. and Hockman, B. and Orekhov, A. and Hasseler, T. D. and Leake, C. and Nuernberger, B. and Proen{\c c}a, P. and Reid, W. and Talbot, W. and Georgiev, N. and Pailevanian, T. and Archanian, A. and Ambrose, E. and Jasper, J. and Etheredge, R. and Roman, C. and Levine, D. and Otsu, K. and Yearicks, S. and Melikyan, H. and Rieber, R. R. and Carpenter, K. and Nash, J. and Jain, A. and Shiraishi, L. and Robinson, M. and Travers, M. and Choset, H. and Burdick, J. and Gardner, A. and Cable, M. and Ingham, M. and Ono, M.},
  year = {2024},
  month = mar,
  journal = {Science Robotics},
  volume = {9},
  number = {88},
  pages = {eadh8332},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.adh8332},
  url = {https://www.science.org/doi/10.1126/scirobotics.adh8332},
  urldate = {2024-03-14},
  abstract = {Ice worlds are at the forefront of astrobiological interest because of the evidence of subsurface oceans. Enceladus in particular is unique among the icy moons because there are known vent systems that are likely connected to a subsurface ocean, through which the ocean water is ejected to space. An existing study has shown that sending small robots into the vents and directly sampling the ocean water is likely possible. To enable such a mission, NASA's Jet Propulsion Laboratory is developing a snake-like robot called Exobiology Extant Life Surveyor (EELS) that can navigate Enceladus' extreme surface and descend an erupting vent to capture unaltered liquid samples and potentially reach the ocean. However, navigating to and through Enceladus' environment is challenging: Because of the limitations of existing orbital reconnaissance, there is substantial uncertainty with respect to its geometry and the physical properties of the surface/vents; communication is limited, which requires highly autonomous robots to execute the mission with limited human supervision. Here, we provide an overview of the EELS project and its development effort to create a risk-aware autonomous robot to navigate these extreme ice terrains/environments. We describe the robot's architecture and the technical challenges to navigate and sense the icy environment safely and effectively. We focus on the challenges related to surface mobility, task and motion planning under uncertainty, and risk quantification. We provide initial results on mobility and risk-aware task and motion planning from field tests and simulated scenarios.},
  file = {/Users/kshitijgoel/Zotero/storage/AZXQQLPN/Vaquero et al. - 2024 - EELS Autonomous snake-like robot with task and mo.pdf}
}

@inproceedings{vaswani_attention_2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  urldate = {2024-02-05},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {/Users/kshitijgoel/Zotero/storage/DHMX7XKP/Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@phdthesis{vats_plan_2024,
  title = {Plan to {{Learn}}: {{Active Robot Learning}} by {{Planning}}},
  shorttitle = {Plan to {{Learn}}},
  author = {Vats, Shivam},
  year = {2024},
  address = {United States -- Pennsylvania},
  url = {https://www.proquest.com/docview/3112753694/abstract/BABED774DB6F4ED5PQ/1},
  urldate = {2025-01-09},
  abstract = {Robots hold the promise of becoming an integral part of human life by helping us in our homes, out on farms and in our factories. However, current robots lack the motor skills necessary to perform everyday manipulation tasks, operate outside structured settings and interact with humans. This thesis advocates the principles of active, continual and collaborative learning to allow a robot to autonomously learn the skills necessary to master its domain. We propose a novel Plan to Learn (P2L) framework in which the robot solves a meta planning problem to decide which skills it should learn so that it can achieve its long-term objective while minimizing the cost of data collection. We formalize and study this idea from both a practical and a theoretical lens in two challenging scenarios. First, we explore how robots can plan to learn as part of a collaborative human-robot team. We develop an optimal mixed integer programming-based planner Act, Delegate, or Learn (ADL) to allocate tasks and decide which skills the robot should learn to reduce its teammate's workload. We also provide log(n)-approximation algorithms for ADL by showing that it is an instance of the well-known uncapacitated facility location problem. Next, we explore multi-step tasks, such as opening a door, which require several skills to be sequenced. Our first algorithm MetaReasoning for Skill Learning (MetaReSkill) estimates a probabilistic model of skill improvement to identify and prioritize skills that are both easy to learn and most relevant to the over- all task. Finally, we present a hierarchical reinforcement learning formulation to solve the P2L problem for recovery learning. RecoveryChaining learns both where and how to recover by leveraging a hybrid action space consisting of primitive robot actions and nominal options that transfer control to a model-based controller. We demonstrate the effectiveness of our P2L framework on a variety of practically motivated and challenging manipulation tasks both in simulation and in the real world. This thesis is only a first step towards the ambitious goal of building autonomously learning robots that plan to learn. We sincerely hope that the developed framework and its instantiations on these manipulation tasks will pave the way for further research.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798384469308},
  langid = {english},
  school = {Carnegie Mellon University},
  keywords = {Active learning,Artificial intelligence,Computer science,Human-robot collaboration,Manipulation,Planning,Robot learning,Robotics,Skill learning},
  file = {/Users/kshitijgoel/Zotero/storage/ERLFW8ES/Vats - 2024 - Plan to Learn Active Robot Learning by Planning.pdf}
}

@inproceedings{vats_synergistic_2022,
  title = {Synergistic {{Scheduling}} of {{Learning}} and {{Allocation}} of {{Tasks}} in {{Human-Robot Teams}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Vats, Shivam and Kroemer, Oliver and Likhachev, Maxim},
  year = {2022},
  month = may,
  pages = {2789--2795},
  doi = {10.1109/ICRA46639.2022.9812328},
  abstract = {We consider the problem of completing a set of \$n\$ tasks with a human-robot team using minimum effort. In many domains, teaching a robot to be fully autonomous can be counterproductive if there are finitely many tasks to be done. Rather, the optimal strategy is to weigh the cost of teaching a robot and its benefit- how many new tasks it allows the robot to solve autonomously. We formulate this as a planning problem where the goal is to decide what tasks the robot should do autonomously (act), what tasks should be delegated to a human (delegate) and what tasks the robot should be taught (learn) so as to complete all the given tasks with minimum effort. This planning problem results in a search tree that grows expo-nentially with \$n\$ - making standard graph search algorithms intractable. We address this by converting the problem into a mixed integer program that can be solved efficiently using off-the-shelf solvers with bounds on solution quality. To predict the benefit of learning, we use an approximate simulation model of the tasks to train a precondition model that is parameterized by the training task. Finally, we evaluate our approach on peg insertion and Lego stacking tasks- both in simulation and real-world, showing substantial savings in human effort.},
  keywords = {Planning,Prediction algorithms,Predictive models,Resource management,Search problems,Stacking,Training},
  file = {/Users/kshitijgoel/Zotero/storage/R5KYTZSG/Vats et al. - 2022 - Synergistic Scheduling of Learning and Allocation .pdf;/Users/kshitijgoel/Zotero/storage/KCFLK9XU/9812328.html}
}

@inproceedings{vedaldi_quick_2008,
  title = {Quick {{Shift}} and {{Kernel Methods}} for {{Mode Seeking}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2008},
  author = {Vedaldi, Andrea and Soatto, Stefano},
  editor = {Forsyth, David and Torr, Philip and Zisserman, Andrew},
  year = {2008},
  pages = {705--718},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-88693-8_52},
  abstract = {We show that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N2), with a small constant, if the underlying distance is Euclidean. This makes medoid shift considerably faster than mean shift, contrarily to what previously believed. We then exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances, with complexity bounded by the effective rank of the resulting kernel matrix, and with explicit regularization constraints. Finally, we show that, under certain conditions, medoid shift fails to cluster data points belonging to the same mode, resulting in over-fragmentation. We propose remedies for this problem, by introducing a novel, simple and extremely efficient clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation. Like medoid shift, quick shift operates in non-Euclidean spaces in a straightforward manner. We also show that the accelerated medoid shift can be used to initialize mean shift for increased efficiency. We illustrate our algorithms to clustering data on manifolds, image segmentation, and the automatic discovery of visual categories.},
  isbn = {978-3-540-88693-8},
  langid = {english},
  keywords = {Gaussian Window,Image Segmentation,Kernel Matrix,Kernel Method,Kernel Space},
  file = {/Users/kshitijgoel/Zotero/storage/UT6SHFWX/Vedaldi and Soatto - 2008 - Quick Shift and Kernel Methods for Mode Seeking.pdf}
}

@article{verbeek_accelerated_2006,
  title = {Accelerated {{EM-based}} Clustering of Large Data Sets},
  author = {Verbeek, Jakob J. and Nunnink, Jan R. J. and Vlassis, Nikos},
  year = {2006},
  month = nov,
  journal = {Data Mining and Knowledge Discovery},
  volume = {13},
  number = {3},
  pages = {291--307},
  issn = {1573-756X},
  doi = {10.1007/s10618-005-0033-3},
  url = {https://doi.org/10.1007/s10618-005-0033-3},
  urldate = {2023-03-17},
  abstract = {Motivated by the poor performance (linear complexity) of the EM algorithm in clustering large data sets, and inspired by the successful accelerated versions of related algorithms like k-means, we derive an accelerated variant of the EM algorithm for Gaussian mixtures that: (1) offers speedups that are at least linear in the number of data points, (2) ensures convergence by strictly increasing a lower bound on the data log-likelihood in each learning step, and (3) allows ample freedom in the design of other accelerated variants. We also derive a similar accelerated algorithm for greedy mixture learning, where very satisfactory results are obtained. The core idea is to define a lower bound on the data log-likelihood based on a grouping of data points. The bound is maximized by computing in turn (i) optimal assignments of groups of data points to the mixture components, and (ii) optimal re-estimation of the model parameters based on average sufficient statistics computed over groups of data points. The proposed method naturally generalizes to mixtures of other members of the exponential family. Experimental results show the potential of the proposed method over other state-of-the-art acceleration techniques.},
  langid = {english},
  keywords = {EM algorithm,Free energy,Gaussian mixtures,kd-trees,Large data sets},
  file = {/Users/kshitijgoel/Zotero/storage/YTTXS3PU/Verbeek et al. - 2006 - Accelerated EM-based clustering of large data sets.pdf}
}

@article{verbeek_efficient_2003,
  title = {Efficient Greedy Learning of Gaussian Mixture Models},
  author = {Verbeek, J. J. and Vlassis, N. and Kr{\"o}se, B.},
  year = {2003},
  month = feb,
  journal = {Neural Computation},
  volume = {15},
  number = {2},
  pages = {469--485},
  issn = {0899-7667},
  doi = {10.1162/089976603762553004},
  abstract = {This article concerns the greedy learning of gaussian mixtures. In the greedy approach, mixture components are inserted into the mixture one after the other. We propose a heuristic for searching for the optimal component to insert. In a randomized manner, a set of candidate new components is generated. For each of these candidates, we find the locally optimal new component and insert it into the existing mixture. The resulting algorithm resolves the sensitivity to initialization of state-of-the-art methods, like expectation maximization, and has running time linear in the number of data points and quadratic in the (final) number of mixture components. Due to its greedy nature, the algorithm can be particularly useful when the optimal number of mixture components is unknown. Experimental results comparing the proposed algorithm to other methods on density estimation and texture segmentation are provided.},
  langid = {english},
  pmid = {12590816},
  keywords = {Algorithms,Learning,Normal Distribution},
  file = {/Users/kshitijgoel/Zotero/storage/NUZQFZNL/Verbeek et al. - 2003 - Efficient greedy learning of gaussian mixture mode.pdf}
}

@article{verbeek_ksegments_2002,
  title = {A {\emph{K}}-Segments Algorithm for Finding Principal Curves},
  author = {Verbeek, J. J. and Vlassis, N. and Kr{\"o}se, B.},
  year = {2002},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {23},
  number = {8},
  pages = {1009--1017},
  issn = {0167-8655},
  doi = {10.1016/S0167-8655(02)00032-6},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865502000326},
  urldate = {2024-04-29},
  abstract = {We propose an incremental method to find principal curves. Line segments are fitted and connected to form polygonal lines (PLs). New segments are inserted until a performance criterion is met. Experimental results illustrate the performance of the method compared to other existing approaches.},
  keywords = {Dimension reduction,Feature extraction,Polygonal line,Principal curve,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/MQB35ZMT/Verbeek et al. - 2002 - A k-segments algorithm for finding principa.pdf;/Users/kshitijgoel/Zotero/storage/3NPZSB63/S0167865502000326.html}
}

@phdthesis{verbeek_mixture_2004,
  title = {Mixture Models for Clustering and Dimension Reduction},
  author = {Verbeek, Jakob},
  year = {2004},
  langid = {english},
  school = {ASCI graduate school ASCI},
  file = {/Users/kshitijgoel/Zotero/storage/GIPWBDZJ/document.pdf}
}

@article{verbeek_selforganizing_2005,
  title = {Self-Organizing Mixture Models},
  author = {Verbeek, J. J. and Vlassis, N. and Kr{\"o}se, B. J. A.},
  year = {2005},
  month = jan,
  journal = {Neurocomputing},
  series = {New {{Aspects}} in {{Neurocomputing}}: 11th {{European Symposium}} on {{Artificial Neural Networks}}},
  volume = {63},
  pages = {99--123},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2004.04.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0925231204003182},
  urldate = {2023-02-17},
  abstract = {We present an expectation-maximization (EM) algorithm that yields topology preserving maps of data based on probabilistic mixture models. Our approach is applicable to any mixture model for which we have a normal EM algorithm. Compared to other mixture model approaches to self-organizing maps (SOMs), the function our algorithm maximizes has a clear interpretation: it sums data log-likelihood and a penalty term that enforces self-organization. Our approach allows principled handling of missing data and learning of mixtures of SOMs. We present example applications illustrating our approach for continuous, discrete, and mixed discrete and continuous data.},
  langid = {english},
  keywords = {EM algorithm,Mixture models,Self-organizing maps},
  file = {/Users/kshitijgoel/Zotero/storage/EAF82HSI/Verbeek et al. - 2005 - Self-organizing mixture models.pdf;/Users/kshitijgoel/Zotero/storage/TUYNLL88/S0925231204003182.html}
}

@inproceedings{verde_comparing_2008,
  title = {Comparing {{Histogram Data Using}} a {{Mahalanobis}}--{{Wasserstein Distance}}},
  booktitle = {{{COMPSTAT}} 2008},
  author = {Verde, Rosanna and Irpino, Antonio},
  editor = {Brito, Paula},
  year = {2008},
  pages = {77--89},
  publisher = {Physica-Verlag HD},
  address = {Heidelberg},
  doi = {10.1007/978-3-7908-2084-3_7},
  abstract = {In this paper, we present a new distance for comparing data described by histograms. The distance is a generalization of the classical Mahalanobis distance for data described by correlated variables. We define a way to extend the classical concept of inertia and codeviance from a set of points to a set of data described by histograms. The same results are also presented for data described by continuous density functions (empiric or estimated). An application to real data is performed to illustrate the effects of the new distance using dynamic clustering.},
  isbn = {978-3-7908-2084-3},
  langid = {english},
  keywords = {dependence,dynamic clustering,histogram data,inertia,Mahalanobis distance,Wasserstein distance},
  file = {/Users/kshitijgoel/Zotero/storage/6M27XUU5/Verde and Irpino - 2008 - Comparing Histogram Data Using a Mahalanobis–Wasse.pdf}
}

@inproceedings{verma_asml_2024,
  title = {{{ASML}}: {{A Scalable}} and {{Efficient AutoML Solution}} for {{Data Streams}}},
  shorttitle = {{{ASML}}},
  booktitle = {Proceedings of the {{Third International Conference}} on {{Automated Machine Learning}}},
  author = {Verma, Nilesh and Bifet, Albert and Pfahringer, Bernhard and Bahri, Maroua},
  year = {2024},
  month = oct,
  pages = {11/1-26},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v256/verma24a.html},
  urldate = {2025-05-29},
  abstract = {Online learning poses a significant challenge to AutoML, as the best model and configuration may change depending on the data distribution. To address this challenge, we propose Automated Streaming Machine Learning (ASML), an online learning framework that automatically finds the best machine learning models and their configurations for changing data streams. It adapts to the online learning scenario by continuously exploring a large and diverse pipeline configuration space. It uses an adaptive optimisation technique that utilizes the current best design, adaptive random directed nearby search, and an ensemble of best performing pipelines. We experimented with real and synthetic drifting data streams and showed that ASML can build accurate and adaptive pipelines by constantly exploring and responding to changes. In several datasets, it outperforms existing online AutoML and state-of-the-art online learning algorithms.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/FBTE36VC/Verma et al. - 2024 - ASML A Scalable and Efficient AutoML Solution for Data Streams.pdf}
}

@article{verma_autonomous_2023,
  title = {Autonomous Robotics Is Driving {{Perseverance}} Rover's Progress on {{Mars}}},
  author = {Verma, Vandi and Maimone, Mark W. and Gaines, Daniel M. and Francis, Raymond and Estlin, Tara A. and Kuhn, Stephen R. and Rabideau, Gregg R. and Chien, Steve A. and McHenry, Michael M. and Graser, Evan J. and Rankin, Arturo L. and Thiel, Ellen R.},
  year = {2023},
  month = jul,
  journal = {Science Robotics},
  volume = {8},
  number = {80},
  pages = {eadi3099},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.adi3099},
  url = {https://www.science.org/doi/10.1126/scirobotics.adi3099},
  urldate = {2023-08-02},
  abstract = {NASA's Perseverance rover uses robotic autonomy to achieve its mission goals on Mars. Its self-driving autonomous navigation system (AutoNav) has been used to evaluate 88\% of the 17.7-kilometer distance traveled during its first Mars year of operation. Previously, the maximum total autonomous distance evaluated was 2.4 kilometers by the Opportunity rover during its 14-year lifetime. AutoNav has set multiple planetary rover records, including the greatest distance driven without human review (699.9 meters) and the greatest single-day drive distance (347.7 meters). The Autonomous Exploration for Gathering Increased Science (AEGIS) system analyzes wide-angle imagery onboard to autonomously select targets for observations by the SuperCam instrument, a multimode sensor suite capable of millimeter-scale geochemical and mineralogical analysis. AEGIS enables observations of scientifically interesting targets during or immediately after long drives without the need for ground communication. OnBoard Planner (OBP) is a scheduling capability planned for operational use in September 2023 that has the potential to reduce energy usage by up to 20\% and complete drive and arm-contact science campaigns in 25\% fewer days on Mars. This paper presents an overview of the AutoNav, AEGIS, and OBP capabilities used on Perseverance.},
  file = {/Users/kshitijgoel/Zotero/storage/FRJE4LI6/Verma et al. - 2023 - Autonomous robotics is driving Perseverance rover’.pdf}
}

@article{verwimp_continual_2023,
  title = {Continual {{Learning}}: {{Applications}} and the {{Road Forward}}},
  shorttitle = {Continual {{Learning}}},
  author = {Verwimp, Eli and Aljundi, Rahaf and {Ben-David}, Shai and Bethge, Matthias and Cossu, Andrea and Gepperth, Alexander and Hayes, Tyler L. and H{\"u}llermeier, Eyke and Kanan, Christopher and Kudithipudi, Dhireesha and Lampert, Christoph H. and Mundt, Martin and Pascanu, Razvan and Popescu, Adrian and Tolias, Andreas S. and van de Weijer, Joost and Liu, Bing and Lomonaco, Vincenzo and Tuytelaars, Tinne and van de Ven, Gido M.},
  year = {2023},
  month = nov,
  journal = {Transactions on Machine Learning Research},
  issn = {2835-8856},
  url = {https://openreview.net/forum?id=axBIMcGZn9},
  urldate = {2025-06-11},
  abstract = {Continual learning is a subfield of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: "Why should one care about continual learning in the first place?". We set the stage by examining recent continual learning papers published at four major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they might seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model editing, personalization and specialization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/X34KC563/Verwimp et al. - 2023 - Continual Learning Applications and the Road Forward.pdf}
}

@inproceedings{vespa_adaptiveresolution_2019,
  title = {Adaptive-{{Resolution Octree-Based Volumetric SLAM}}},
  booktitle = {2019 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Vespa, Emanuele and Funk, Nils and Kelly, Paul H. J. and Leutenegger, Stefan},
  year = {2019},
  month = sep,
  pages = {654--662},
  issn = {2475-7888},
  doi = {10.1109/3DV.2019.00077},
  abstract = {We introduce a novel volumetric SLAM pipeline for the integration and rendering of depth images at an adaptive level of detail. Our core contribution is a fusion algorithm which dynamically selects the appropriate integration scale based on the effective sensor resolution given the distance from the observed scene, addressing aliasing issues, reconstruction quality, and efficiency simultaneously. We implement our approach using an efficient octree structure which supports multi-resolution rendering allowing for online frame-to-model alignment. Our qualitative and quantitative experiments demonstrate significantly improved reconstruction quality and up to six-fold execution time speed-ups compared to single resolution grids.},
  keywords = {3D Reconstruction,Cameras,Indexes,Mapping,Octrees,Pipelines,Rendering (computer graphics),Simultaneous localization and mapping,SLAM,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/2536DQ79/Vespa et al. - 2019 - Adaptive-Resolution Octree-Based Volumetric SLAM.pdf;/Users/kshitijgoel/Zotero/storage/HMYTN2RD/8885452.html}
}

@article{vespa_efficient_2018,
  title = {Efficient {{Octree-Based Volumetric SLAM Supporting Signed-Distance}} and {{Occupancy Mapping}}},
  author = {Vespa, Emanuele and Nikolov, Nikolay and Grimm, Marius and Nardi, Luigi and Kelly, Paul H. J. and Leutenegger, Stefan},
  year = {2018},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {3},
  number = {2},
  pages = {1144--1151},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2792537},
  url = {https://ieeexplore.ieee.org/document/8255617},
  urldate = {2024-11-15},
  abstract = {We present a dense volumetric simultaneous localisation and mapping (SLAM) framework that uses an octree representation for efficient fusion and rendering of either a truncated signed distance field (TSDF) or an occupancy map. The primary aim of this letter is to use one single representation of the environment that can be used not only for robot pose tracking and high-resolution mapping, but seamlessly for planning. We show that our highly efficient octree representation of space fits SLAM and planning purposes in a real-time control loop. In a comprehensive evaluation, we demonstrate dense SLAM accuracy and runtime performance on-par with flat hashing approaches when using TSDF-based maps, and considerable speed-ups when using occupancy mapping compared to standard occupancy maps frameworks. Our SLAM system can run at 10--40 Hz on a modern quadcore CPU, without the need for massive parallelization on a GPU. We, furthermore, demonstrate a probabilistic occupancy mapping as an alternative to TSDF mapping in dense SLAM and show its direct applicability to online motion planning, using the example of informed rapidly-exploring random trees (RRT{\textasciicircum}*).},
  keywords = {Mapping,Octrees,Pipelines,Planning,Real-time systems,Resource management,simultaneous localisation and mapping (SLAM),Simultaneous localization and mapping,visual-based navigation},
  file = {/Users/kshitijgoel/Zotero/storage/VXLR4QCR/Vespa et al. - 2018 - Efficient Octree-Based Volumetric SLAM Supporting Signed-Distance and Occupancy Mapping.pdf}
}

@phdthesis{vespa_sparse_2019,
  title = {Sparse Octree Algorithms for Scalable Dense Volumetric Tracking and Mapping},
  author = {Vespa, Emanuele},
  year = {2019},
  month = aug,
  url = {http://spiral.imperial.ac.uk/handle/10044/1/79560},
  urldate = {2023-03-16},
  abstract = {This thesis is concerned with the problem of Simultaneous Localisation and Mapping (SLAM), the task of localising an agent within an unknown environment and at the same time building a representation of it. In particular, we tackle the fundamental scalability limitations of dense volumetric SLAM systems. We do so by proposing a highly efficient hierarchical data-structure based on octrees together with a set of algorithms to support the most compute-intensive operations in typical volumetric reconstruction pipelines.    We employ our hierarchical representation in a novel dense pipeline based on occupancy probabilities. Crucially, the complete space representation encoded by the octree enables to demonstrate a fully integrated system in which tracking, mapping and occupancy queries can be performed seamlessly on a single coherent representation. While achieving accuracy either at par or better than the current state-of-the-art, we demonstrate run-time performance of at least an order of magnitude better than currently available hierarchical data-structures.    Finally, we introduce a novel multi-scale reconstruction system that exploits our octree hierarchy. By adaptively selecting the appropriate scale to match the effective sensor resolution in both integration and rendering, we demonstrate better reconstruction results and tracking accuracy compared to single-resolution grids. Furthermore, we achieve much higher computational performance by propagating information up and down the tree in a lazy fashion, which allow us to reduce the computational load when updating distant surfaces.     We have released our software as an open-source library, named supereight, which is freely available for the benefit of the wider community. One of the main advantages of our library is its flexibility. By carefully providing a set of algorithmic abstractions, supereight enables SLAM practitioners to freely experiment with different map representations with no intervention on the back-end library code and crucially, preserving performance. Our work has been adopted by robotics researchers in both academia and industry.},
  copyright = {Creative Commons Attribution NonCommercial Licence},
  langid = {english},
  school = {Imperial College London},
  annotation = {Accepted: 2020-06-04T11:35:40Z},
  file = {/Users/kshitijgoel/Zotero/storage/A772FTF9/Vespa - 2019 - Sparse octree algorithms for scalable dense volume.pdf;/Users/kshitijgoel/Zotero/storage/T6UUWZ96/Vespa - 2019 - Sparse octree algorithms for scalable dense volume.pdf}
}

@book{vidal_generalized_2016,
  title = {Generalized {{Principal Component Analysis}}},
  author = {Vidal, Ren{\'e} and Ma, Yi and Sastry, S.S.},
  year = {2016},
  series = {Interdisciplinary {{Applied Mathematics}}},
  volume = {40},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-87811-9},
  url = {http://link.springer.com/10.1007/978-0-387-87811-9},
  urldate = {2024-04-03},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-0-387-87810-2 978-0-387-87811-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7T442C2J/Vidal et al. - 2016 - Generalized Principal Component Analysis.pdf}
}

@article{viejo_robust_2014,
  title = {A Robust and Fast Method for {{6DoF}} Motion Estimation from Generalized {{3D}} Data},
  author = {Viejo, Diego and Cazorla, Miguel},
  year = {2014},
  month = apr,
  journal = {Autonomous Robots},
  volume = {36},
  number = {4},
  pages = {295--308},
  issn = {1573-7527},
  doi = {10.1007/s10514-013-9354-z},
  url = {https://doi.org/10.1007/s10514-013-9354-z},
  urldate = {2023-01-05},
  abstract = {Nowadays, there is an increasing number of robotic applications that need to act in real three-dimensional (3D) scenarios. In this paper we present a new mobile robotics orientated 3D registration method that improves previous Iterative Closest Points based solutions both in speed and accuracy. As an initial step, we perform a low cost computational method to obtain descriptions for 3D scenes planar surfaces. Then, from these descriptions we apply a force system in order to compute accurately and efficiently a six degrees of freedom egomotion. We describe the basis of our approach and demonstrate its validity with several experiments using different kinds of 3D sensors and different 3D real environments.},
  langid = {english},
  keywords = {3D mapping,6DoF pose registration,Mobile robots,Scene modeling},
  file = {/Users/kshitijgoel/Zotero/storage/RP2ANIPF/Viejo and Cazorla - 2014 - A robust and fast method for 6DoF motion estimatio.pdf}
}

@article{vishwajeet_adaptive_2018,
  title = {Adaptive {{Split}}/{{Merge-Based Gaussian Mixture Model Approach}} for {{Uncertainty Propagation}}},
  author = {Vishwajeet, Kumar and Singla, Puneet},
  year = {2018},
  journal = {Journal of Guidance, Control, and Dynamics},
  volume = {41},
  number = {3},
  pages = {603--617},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  issn = {0731-5090},
  doi = {10.2514/1.G002801},
  url = {https://doi.org/10.2514/1.G002801},
  urldate = {2024-07-08},
  abstract = {This paper presents an adaptive splitting and merging scheme for dynamic selection of Gaussian kernels in a Gaussian mixture model. The Gaussian kernel in the Gaussian mixture model is split into multiple components if the Kolmogorov equation error exceeds a prescribed threshold. Two different splitting mechanisms are presented in this work. The first splitting mechanism corresponds to splitting one Gaussian kernel in all directions, whereas the second splitting mechanism corresponds to splitting in only the direction of maximum nonlinearity. The state transition matrix in conjunction with unscented transformation is used to compute the departure from linearity, and hence approximate the direction of maximum nonlinearity. The merging mechanism exploits the angle between eigenvectors corresponding to the maximum eigenvalue of covariance matrices corresponding to two different Gaussian kernels to find candidate components for merging. Finally, a sparse approximation problem is defined to provide a mechanism to trade off between the number of Gaussian kernels and the Kolmogorov equation error in a mixture model. The uncertainty propagation problem for a satellite motion in a low Earth orbit is considered to show the efficacy of the proposed ideas.},
  file = {/Users/kshitijgoel/Zotero/storage/L56MVNSG/Vishwajeet and Singla - 2018 - Adaptive SplitMerge-Based Gaussian Mixture Model Approach for Uncertainty Propagation.pdf}
}

@inproceedings{viswanathan_efficient_2020,
  title = {Efficient {{Trajectory Library Filtering}} for {{Quadrotor Flight}} in {{Unknown Environments}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Viswanathan, Vaibhav K. and Dexheimer, Eric and Li, Guanrui and Loianno, Giuseppe and Kaess, Michael and Scherer, Sebastian},
  year = {2020},
  month = oct,
  pages = {2510--2517},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341273},
  url = {https://ieeexplore.ieee.org/document/9341273},
  urldate = {2024-06-09},
  abstract = {Quadrotor flight in cluttered, unknown environments is challenging due to the limited range of perception sensors, challenging obstacles, and limited onboard computation. In this work, we directly address these challenges by proposing an efficient, reactive planning approach. We introduce the Bitwise Trajectory Elimination (BiTE) algorithm for efficiently filtering out in-collision trajectories from a trajectory library by using bitwise operations. Then, we outline a full receding-horizon planning approach for quadrotor flight in unknown environments demonstrated at up to 50 Hz on an onboard computer. This approach is evaluated extensively in simulation and shown to collision check up to 4896 trajectories in under 20{$\mu$}s, which is the fastest collision checking time for a MAV planner, to the best of the authors' knowledge. Finally, we validate our planner in over 120 minutes of flights in forest-like and urban subterranean environments.},
  keywords = {Filtering,Forestry,Intelligent robots,Libraries,Planning,Sensors,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/XET85FCY/Viswanathan et al. - 2020 - Efficient Trajectory Library Filtering for Quadrotor Flight in Unknown Environments.pdf;/Users/kshitijgoel/Zotero/storage/WWLVM4GA/9341273.html}
}

@phdthesis{vizzo_robot_2023,
  title = {{Robot Mapping with 3D LiDARs}},
  author = {Vizzo, Ignacio Martin},
  year = {2023},
  langid = {ngerman},
  school = {University of Bonn},
  file = {/Users/kshitijgoel/Zotero/storage/II23PZY6/Vizzo - Robot Mapping with 3D LiDARs.pdf}
}

@inproceedings{vodisch_codeps_2023,
  title = {{{CoDEPS}}: {{Online Continual Learning}} for {{Depth Estimation}} and {{Panoptic Segmentation}}},
  shorttitle = {{{CoDEPS}}},
  booktitle = {Robotics: {{Science}} and {{Systems XIX}}},
  author = {V{\"o}disch, Niclas and Petek, K{\"u}rsat and Burgard, Wolfram and Valada, Abhinav},
  year = {2023},
  month = jul,
  volume = {19},
  url = {https://www.roboticsproceedings.org/rss19/p073.html},
  urldate = {2025-02-20},
  isbn = {978-0-9923747-9-2},
  file = {/Users/kshitijgoel/Zotero/storage/R6B8LSPC/Vödisch et al. - 2023 - CoDEPS Online Continual Learning for Depth Estimation and Panoptic Segmentation.pdf}
}

@article{vonmises_uber_1918,
  title = {{\"U}ber Die ``{{Ganzzahligkeit}}" Der {{Atomgewichte}} Und Verwandete {{Fragen}}},
  author = {{von Mises}, Richard},
  year = {1918},
  journal = {Physikalische Zeitschrift},
  volume = {19},
  pages = {490--500},
  url = {https://cir.nii.ac.jp/crid/1370853567725059334},
  urldate = {2024-06-27},
  file = {/Users/kshitijgoel/Zotero/storage/X2LXDIE6/1370853567725059334.html}
}

@article{vorba_online_2014,
  title = {On-Line Learning of Parametric Mixture Models for Light Transport Simulation},
  author = {Vorba, Ji{\v r}{\'i} and Karl{\'i}k, Ond{\v r}ej and {\v S}ik, Martin and Ritschel, Tobias and K{\v r}iv{\'a}nek, Jaroslav},
  year = {2014},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {33},
  number = {4},
  pages = {101:1--101:11},
  issn = {0730-0301},
  doi = {10.1145/2601097.2601203},
  url = {https://dl.acm.org/doi/10.1145/2601097.2601203},
  urldate = {2023-03-17},
  abstract = {Monte Carlo techniques for light transport simulation rely on importance sampling when constructing light transport paths. Previous work has shown that suitable sampling distributions can be recovered from particles distributed in the scene prior to rendering. We propose to represent the distributions by a parametric mixture model trained in an on-line (i.e. progressive) manner from a potentially infinite stream of particles. This enables recovering good sampling distributions in scenes with complex lighting, where the necessary number of particles may exceed available memory. Using these distributions for sampling scattering directions and light emission significantly improves the performance of state-of-the-art light transport simulation algorithms when dealing with complex lighting.},
  keywords = {importance sampling,light transport simulation,on-line expectation maximization,parametric density estimation},
  file = {/Users/kshitijgoel/Zotero/storage/VK92J7MD/Vorba et al. - 2014 - On-line learning of parametric mixture models for .pdf}
}

@article{vutetakis_active_2025,
  title = {Active Perception Network for Non-Myopic Online Exploration and Visual Surface Coverage},
  author = {Vutetakis, David and Xiao, Jing},
  year = {2025},
  month = feb,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {2},
  pages = {247--272},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241264577},
  url = {https://doi.org/10.1177/02783649241264577},
  urldate = {2025-04-16},
  abstract = {This work addresses the problem of online exploration and visual sensor coverage of unknown environments. We introduce a novel perception roadmap we refer to as the Active Perception Network (APN) that serves as a hierarchical topological graph describing how to traverse and perceive an incrementally built spatial map of the environment. The APN state is incrementally updated to expand a connected configuration space that extends throughout as much of the known space as possible, using efficient difference-awareness techniques that track the discrete changes of the spatial map to inform the updates. A frontier-guided approach is presented for efficient evaluation of information gain and covisible information, which guides view sampling and refinement to ensure maximum coverage of the unmapped space is maintained within the APN. The updated roadmap is hierarchically decomposed into subgraph regions which we use to facilitate a non-myopic global view sequence planner. A comparative analysis to several state-of-the-art approaches was conducted, showing significant performance improvements in terms of total exploration time and surface coverage, and demonstrating high computational efficiency that is scalable to large and complex environments.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7M68UJJJ/Vutetakis and Xiao - 2025 - Active perception network for non-myopic online exploration and visual surface coverage.pdf}
}

@book{wackernagel_multivariate_2003,
  title = {Multivariate {{Geostatistics}}},
  author = {Wackernagel, Hans},
  year = {2003},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-05294-5},
  url = {http://link.springer.com/10.1007/978-3-662-05294-5},
  urldate = {2023-09-27},
  isbn = {978-3-642-07911-5 978-3-662-05294-5},
  langid = {english},
  keywords = {Analysis,digital elevation model,Kriging,linear optimization,linear regression,Measure,model,principal component analysis,Regression},
  file = {/Users/kshitijgoel/Zotero/storage/L42W3DBV/Wackernagel - 2003 - Multivariate Geostatistics.pdf}
}

@inproceedings{wakulicz_informative_2022,
  title = {Informative {{Planning}} for {{Worst-Case Error Minimisation}} in {{Sparse Gaussian Process Regression}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wakulicz, Jennifer and Brian Lee, Ki Myung and Yoo, Chanyeol and {Vidal-Calleja}, Teresa and Fitch, Robert},
  year = {2022},
  month = may,
  pages = {11066--11072},
  doi = {10.1109/ICRA46639.2022.9812375},
  abstract = {We present a planning framework for min-imising the deterministic worst-case error in sparse Gaus-sian process (GP) regression. We first derive a univer-sal worst-case error bound for sparse GP regression with bounded noise using interpolation theory on reproducing kernel Hilbert spaces (RKHSs). By exploiting the conditional inde-pendence (CI) assumption central to sparse GP regression, we show that the worst-case error minimisation can be achieved by solving a posterior entropy minimisation problem. In turn, the posterior entropy minimisation problem is solved using a Gaussian belief space planning algorithm. We corroborate the proposed worst-case error bound in a simple 1D example, and test the planning framework in simulation for a 2D vehicle in a complex flow field. Our results demonstrate that the proposed posterior entropy minimisation approach is effective in minimising deterministic error, and outperforms the conventional measurement entropy maximisation formulation when the inducing points are fixed.},
  keywords = {Automation,Entropy,Gaussian processes,Interpolation,Measurement uncertainty,Minimization,Upper bound},
  file = {/Users/kshitijgoel/Zotero/storage/3Y3B3E4N/Wakulicz et al. - 2022 - Informative Planning for Worst-Case Error Minimisa.pdf}
}

@incollection{waldron_kinematics_2008,
  title = {Kinematics},
  booktitle = {Springer {{Handbook}} of {{Robotics}}},
  author = {Waldron, Kenneth and Schmiedeler, James},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  year = {2008},
  pages = {9--33},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30301-5_2},
  url = {https://doi.org/10.1007/978-3-540-30301-5_2},
  urldate = {2025-02-28},
  abstract = {Kinematics pertains to the motion of bodies in a~robotic mechanism without regard to the forces/torques that cause the motion. Since robotic mechanisms are by their very essence designed for motion, kinematics is the most fundamental aspect of robot design, analysis, control, and simulation. The robotics community has focused on efficiently applying different representations of position and orientation and their derivatives with respect to time to solve foundational kinematics problems.},
  isbn = {978-3-540-30301-5},
  langid = {english},
  keywords = {Coordinate Frame,Euler Angle,Joint Model,Rolling Contact,Spherical Joint},
  file = {/Users/kshitijgoel/Zotero/storage/K9U7IJLJ/Waldron and Schmiedeler - 2008 - Kinematics.pdf}
}

@inproceedings{walter_slam_2008,
  title = {{{SLAM}} for Ship Hull Inspection Using Exactly Sparse Extended Information Filters},
  booktitle = {2008 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Walter, Matthew and Hover, Franz and Leonard, John},
  year = {2008},
  month = may,
  pages = {1463--1470},
  publisher = {IEEE},
  address = {Pasadena, CA, USA},
  doi = {10.1109/ROBOT.2008.4543408},
  url = {http://ieeexplore.ieee.org/document/4543408/},
  urldate = {2023-10-25},
  abstract = {Many important missions for autonomous underwater vehicles (AUVs), such as undersea inspection of ship hulls, require integrated navigation, control, and motion planning in complex, 3D environments. This paper describes a SLAM implementation using forward-looking sonar (FLS) data from a highly maneuverable, hovering AUV performing a ship hull inspection mission. The Exactly Sparse Extended Information Filter (ESEIF) algorithm is applied to perform SLAM based upon features manually selected within FLS images. The results demonstrate the ability to effectively map a ship hull in a challenging marine environment. This provides a foundation for future work in which real-time SLAM will be integrated with motion planning and control to achieve autonomous coverage of a complete ship hull.},
  isbn = {978-1-4244-1646-2},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DLQBEWXE/Walter et al. - 2008 - SLAM for ship hull inspection using exactly sparse.pdf}
}

@inproceedings{wang_architecture_2020,
  title = {An {{Architecture}} for {{Real-Time Reasoning}} and {{Learning}}},
  booktitle = {Artificial {{General Intelligence}}},
  author = {Wang, Pei and Hammer, Patrick and Wang, Hongzheng},
  editor = {Goertzel, Ben and Panov, Aleksandr I. and Potapov, Alexey and Yampolskiy, Roman},
  year = {2020},
  pages = {347--356},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-52152-3_37},
  abstract = {This paper compares the various conceptions of ``real-time'' in the context of AI, as different ways of taking the processing time into consideration when problems are solved. An architecture of real-time reasoning and learning is introduced, which is one aspect of the AGI system NARS. The basic idea is to form problem-solving processes flexibly and dynamically at run time by using inference rules as building blocks and incrementally self-organizing the system's beliefs and skills, under the restriction of time requirements of the tasks. NARS is designed under the Assumption of Insufficient Knowledge and Resources, which leads to an inherent ability to deal with varying situations in a timely manner.},
  isbn = {978-3-030-52152-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/C69DK8M4/Wang et al. - 2020 - An Architecture for Real-Time Reasoning and Learning.pdf}
}

@article{wang_comprehensive_2024,
  title = {A {{Comprehensive Survey}} of {{Continual Learning}}: {{Theory}}, {{Method}} and {{Application}}},
  shorttitle = {A {{Comprehensive Survey}} of {{Continual Learning}}},
  author = {Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  year = {2024},
  month = aug,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {46},
  number = {8},
  pages = {5362--5383},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2024.3367329},
  url = {https://ieeexplore.ieee.org/document/10444954/},
  urldate = {2025-06-02},
  abstract = {To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.},
  keywords = {catastrophic forgetting,Complexity theory,Continual learning,incremental learning,lifelong learning,Stability analysis,Surveys,Task analysis,Testing,Training,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/SHB3SHK3/Wang et al. - 2024 - A Comprehensive Survey of Continual Learning Theory, Method and Application.pdf}
}

@misc{wang_diffusion_2024,
  title = {Diffusion {{Models Learn Low-Dimensional Distributions}} via {{Subspace Clustering}}},
  author = {Wang, Peng and Zhang, Huijie and Zhang, Zekai and Chen, Siyi and Ma, Yi and Qu, Qing},
  year = {2024},
  month = sep,
  number = {arXiv:2409.02426},
  eprint = {2409.02426},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.02426},
  urldate = {2024-09-14},
  abstract = {Recent empirical studies have demonstrated that diffusion models can effectively learn the image distribution and generate new samples. Remarkably, these models can achieve this even with a small number of training samples despite a large image dimension, circumventing the curse of dimensionality. In this work, we provide theoretical insights into this phenomenon by leveraging key empirical observations: (i) the low intrinsic dimensionality of image data, (ii) a union of manifold structure of image data, and (iii) the low-rank property of the denoising autoencoder in trained diffusion models. These observations motivate us to assume the underlying data distribution of image data as a mixture of low-rank Gaussians and to parameterize the denoising autoencoder as a low-rank model according to the score function of the assumed distribution. With these setups, we rigorously show that optimizing the training loss of diffusion models is equivalent to solving the canonical subspace clustering problem over the training samples. Based on this equivalence, we further show that the minimal number of samples required to learn the underlying distribution scales linearly with the intrinsic dimensions under the above data and model assumptions. This insight sheds light on why diffusion models can break the curse of dimensionality and exhibit the phase transition in learning distributions. Moreover, we empirically establish a correspondence between the subspaces and the semantic representations of image data, facilitating image editing. We validate these results with corroborated experimental results on both simulated distributions and image datasets. The code is available at https://github.com/huijieZH/Diffusion-Model-Generalizability.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/K2UYRKVP/Wang et al. - 2024 - Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering.pdf}
}

@article{wang_directional_2013,
  title = {Directional Data Analysis under the General Projected Normal Distribution},
  author = {Wang, Fangpo and Gelfand, Alan E.},
  year = {2013},
  month = jul,
  journal = {Statistical methodology},
  volume = {10},
  number = {1},
  pages = {113--127},
  issn = {1572-3127},
  doi = {10.1016/j.stamet.2012.07.005},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3773532/},
  urldate = {2025-01-21},
  abstract = {The projected normal distribution is an under-utilized model for explaining directional data. In particular, the general version provides flexibility, e.g., asymmetry and possible bimodality along with convenient regression specification. Here, we clarify the properties of this general class. We also develop fully Bayesian hierarchical models for analyzing circular data using this class. We show how they can be fit using MCMC methods with suitable latent variables. We show how posterior inference for distributional features such as the angular mean direction and concentration can be implemented as well as how prediction within the regression setting can be handled. With regard to model comparison, we argue for an out-of-sample approach using both a predictive likelihood scoring loss criterion and a cumulative rank probability score criterion.},
  pmcid = {PMC3773532},
  pmid = {24046539},
  file = {/Users/kshitijgoel/Zotero/storage/D98N663H/Wang and Gelfand - 2013 - Directional data analysis under the general projected normal distribution.pdf}
}

@inproceedings{wang_dronemot_2024,
  title = {{{DroneMOT}}: {{Drone-based Multi-Object Tracking Considering Detection Difficulties}} and {{Simultaneous Moving}} of {{Drones}} and {{Objects}}},
  shorttitle = {{{DroneMOT}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wang, Peng and Wang, Yongcai and Li, Deying},
  year = {2024},
  month = may,
  pages = {7397--7404},
  doi = {10.1109/ICRA57147.2024.10610941},
  url = {https://ieeexplore.ieee.org/document/10610941/?arnumber=10610941},
  urldate = {2025-01-14},
  abstract = {Multi-object tracking (MOT) on static platforms, such as by surveillance cameras, has achieved significant progress, with various paradigms providing attractive performances. However, the effectiveness of traditional MOT methods is significantly reduced when it comes to dynamic platforms like drones. This decrease is attributed to the distinctive challenges in the MOT-on-drone scenario: (1) objects are generally small in the image plane, blurred, and frequently occluded, making them challenging to detect and recognize; (2) drones move and see objects from different angles, causing the unreliability of the predicted positions and feature embeddings of the objects. This paper proposes DroneMOT, which firstly proposes a Dual-domain Integrated Attention (DIA) module that considers the fast movements of drones to enhance the drone-based object detection and feature embedding for small-sized, blurred, and occluded objects. Then, an innovative Motion-Driven Association (MDA) scheme is introduced, considering the concurrent movements of both the drone and the objects. Within MDA, an Adaptive Feature Synchronization (AFS) technique is presented to update the object features seen from different angles. Additionally, a Dual Motion-based Prediction (DMP) method is employed to forecast the object positions. Finally, both the refined feature embeddings and the predicted positions are integrated to enhance the object association. Comprehensive evaluations on VisDrone2019-MOT and UAVDT datasets show that DroneMOT provides substantial performance improvements over the state-of-the-art in the domain of MOT on drones. The code will be available at https://github.com/PenK1nG/DroneMOT.},
  keywords = {Codes,Feature extraction,Heating systems,Image recognition,Object detection,Surveillance,Synchronization},
  file = {/Users/kshitijgoel/Zotero/storage/AE79Z3XT/Wang et al. - 2024 - DroneMOT Drone-based Multi-Object Tracking Considering Detection Difficulties and Simultaneous Movi.pdf;/Users/kshitijgoel/Zotero/storage/L57729LF/10610941.html}
}

@inproceedings{wang_exterior_2023,
  title = {Exterior {{Calculus}} in {{Graphics}}: {{Course Notes}} for a {{SIGGRAPH}} 2023 {{Course}}},
  shorttitle = {Exterior {{Calculus}} in {{Graphics}}},
  booktitle = {{{ACM SIGGRAPH}} 2023 {{Courses}}},
  author = {Wang, Stephanie and Nabizadeh, Mohammad Sina and Chern, Albert},
  year = {2023},
  month = jul,
  pages = {1--126},
  publisher = {ACM},
  address = {Los Angeles California},
  doi = {10.1145/3587423.3595525},
  url = {https://dl.acm.org/doi/10.1145/3587423.3595525},
  urldate = {2024-04-24},
  isbn = {979-8-4007-0145-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IZMANMYE/Wang et al. - 2023 - Exterior Calculus in Graphics Course Notes for a .pdf}
}

@inproceedings{wang_fast_2016,
  title = {Fast, Accurate Gaussian Process Occupancy Maps via Test-Data Octrees and Nested {{Bayesian}} Fusion},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wang, Jinkun and Englot, Brendan},
  year = {2016},
  month = may,
  pages = {1003--1010},
  doi = {10.1109/ICRA.2016.7487232},
  url = {https://ieeexplore.ieee.org/abstract/document/7487232},
  urldate = {2024-02-05},
  abstract = {We present a novel algorithm to produce descriptive online 3D occupancy maps using Gaussian processes (GPs). GP regression and classification have met with recent success in their application to robot mapping, as GPs are capable of expressing rich correlation among map cells and sensor data. However, the cubic computational complexity has limited its application to large-scale mapping and online use. In this paper we address this issue first by proposing test-data octrees, octrees within blocks of the map that prune away nodes of the same state, condensing the number of test data used in a regression, in addition to allowing fast data retrieval. We also propose a nested Bayesian committee machine which, after new sensor data is partitioned among several GP regressions, fuses the result and updates the map with greatly reduced complexity. Finally, by adjusting the range of influence of the training data and tuning a variance threshold implemented in our method's binary classification step, we are able to control the richness of inference achieved by GPs - and its tradeoff with classification accuracy. The performance of the proposed approach is evaluated with both simulated and real data, demonstrating that the method may serve both as an improved-accuracy classifier, and as a predictive tool to support autonomous navigation.},
  keywords = {Gaussian processes,Octrees,Robot sensing systems,Three-dimensional displays,Training data},
  file = {/Users/kshitijgoel/Zotero/storage/N3YPZZUU/Wang and Englot - 2016 - Fast, accurate gaussian process occupancy maps via.pdf;/Users/kshitijgoel/Zotero/storage/SK5ISB4Y/7487232.html}
}

@article{wang_geometrically_2022,
  title = {Geometrically {{Constrained Trajectory Optimization}} for {{Multicopters}}},
  author = {Wang, Zhepei and Zhou, Xin and Xu, Chao and Gao, Fei},
  year = {2022},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {5},
  pages = {3259--3278},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2022.3160022},
  url = {https://ieeexplore.ieee.org/document/9765821/},
  urldate = {2023-12-03},
  abstract = {In this article, we present an optimization-based framework for multicopter trajectory planning subject to geometrical configuration constraints and user-defined dynamic constraints. The basis of the framework is a novel trajectory representation built upon our novel optimality conditions for unconstrained control effort minimization. We design linear-complexity operations on this representation to conduct spatial--temporal deformation under various planning requirements. Smooth maps are utilized to exactly eliminate geometrical constraints in a lightweight fashion. A variety of state-input constraints are supported by the decoupling of dense constraint evaluation from sparse parameterization and the backward differentiation of flatness map. As a result, this framework transforms a generally constrained multicopter planning problem into an unconstrained optimization that can be solved reliably and efficiently. Our framework bridges the gaps among solution quality, planning efficiency, and constraint fidelity for a multicopter with limited resources and maneuvering capability. Its generality and robustness are both demonstrated by applications to different flight tasks. Extensive simulations and benchmarks are also conducted to show its capability of generating high-quality solutions while retaining the computation speed against other specialized methods by orders of magnitude.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PPP2SXWZ/Wang et al. - 2022 - Geometrically Constrained Trajectory Optimization .pdf}
}

@article{wang_gpateleoperation_2022,
  title = {{{GPA-Teleoperation}}: {{Gaze Enhanced Perception-Aware Safe Assistive Aerial Teleoperation}}},
  shorttitle = {{{GPA-Teleoperation}}},
  author = {Wang, Qianhao and He, Botao and Xun, Zhiren and Xu, Chao and Gao, Fei},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {5631--5638},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3153898},
  abstract = {Gaze isan intuitive and direct way to represent the intentions of an individual. However, when it comes to assistive aerial teleoperation which aims to perform operators' intention, rare attention has been paid to gaze. Existing methods obtain intention directly from the remote controller (RC) input, which is unfriendly to non-professional operators, as the experimental results show in Section VI-C. Further, most teleoperation works do not consider environment perception which is vital to guarantee safety. In this letter, we present GPA-Teleoperation, a gaze enhanced perception-aware assistive teleoperation framework, which addresses the above issues systematically. We capture the intention utilizing gaze information, and generate a topological path matching it. Then we refine the path into a safe and feasible trajectory which simultaneously enhances the perception awareness to the environment which the operator is interested in. Additionally, the proposed method is integrated into a customized quadrotor system. Extensive challenging indoor and outdoor real-world experiments and benchmark comparisons verify that the proposed system is reliable, robust and applicable to even unskilled users.},
  keywords = {Aerial systems,applications,Autonomous aerial vehicles,Drones,motion and path planning,Planning,Safety,telerobotics and teleoperation,Topology,Training,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/PLH2ZMZT/Wang et al. - 2022 - GPA-Teleoperation Gaze Enhanced Perception-Aware .pdf;/Users/kshitijgoel/Zotero/storage/5PGNJ4CF/stamp.html}
}

@article{wang_imagebased_2023,
  title = {Image-{{Based Visual Servoing}} of {{Quadrotors}} to {{Arbitrary Flight Targets}}},
  author = {Wang, Guojie and Qin, Jiahu and Liu, Qingchen and Ma, Qichao and Zhang, Cong},
  year = {2023},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {4},
  pages = {2022--2029},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3245416},
  url = {https://ieeexplore.ieee.org/document/10044962/},
  urldate = {2025-05-13},
  abstract = {Visual servoing of Unmanned Aerial Vehicles (UAVs) has achieved satisfactory performance in fixed and planar motion targets. Due to highly coupled system dynamics and the sensitivity of the target image to aircraft attitude, the problem for chasing free-flying targets remains challenging. In this paper, a vision-based algorithm is designed for controlling an UAV while tracking an intruder flying arbitrarily in 3D space. Image-based visual servoing is used to design controllers that depend directly on errors in image plane. Specifically, a virtual camera approach is adopted to decouple the UAV dynamics by compensating the pitch and yaw, and an improved image error term is proposed to reduce the impact of the UAV rotation on error signals in the process of tracking, thus a simplified control design is achieved, and the stability of the visual servo system is guaranteed. Comparison and ablation experiments in both simulated and real environments are provided to verify the effectiveness of the proposed method.},
  keywords = {Aerial systems,Autonomous aerial vehicles,Cameras,perception and autonomy,Quadrotors,Servomotors,Target tracking,Vehicle dynamics,visual servoing,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/KL5286JR/Wang et al. - 2023 - Image-Based Visual Servoing of Quadrotors to Arbitrary Flight Targets.pdf}
}

@article{wang_implicit_2024,
  title = {Implicit {{Swept Volume SDF}}: {{Enabling Continuous Collision-Free Trajectory Generation}} for {{Arbitrary Shapes}}},
  shorttitle = {Implicit {{Swept Volume SDF}}},
  author = {Wang, Jingping and Zhang, Tingrui and Zhang, Qixuan and Zeng, Chuxiao and Yu, Jingyi and Xu, Chao and Xu, Lan and Gao, Fei},
  year = {2024},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {43},
  number = {4},
  pages = {110:1--110:14},
  issn = {0730-0301},
  doi = {10.1145/3658181},
  url = {https://doi.org/10.1145/3658181},
  urldate = {2024-07-27},
  abstract = {In the field of trajectory generation for objects, ensuring continuous collision-free motion remains a huge challenge, especially for non-convex geometries and complex environments. Previous methods either oversimplify object shapes, which results in a sacrifice of feasible space or rely on discrete sampling, which suffers from the "tunnel effect". To address these limitations, we propose a novel hierarchical trajectory generation pipeline, which utilizes the Swept Volume Signed Distance Field (SVSDF) to guide trajectory optimization for Continuous Collision Avoidance (CCA). Our interdisciplinary approach, blending techniques from graphics and robotics, exhibits outstanding effectiveness in solving this problem. We formulate the computation of the SVSDF as a Generalized Semi-Infinite Programming model, and we solve for the numerical solutions at query points implicitly, thereby eliminating the need for explicit reconstruction of the surface. Our algorithm has been validated in a variety of complex scenarios and applies to robots of various dynamics, including both rigid and deformable shapes. It demonstrates exceptional universality and superior CCA performance compared to typical algorithms. The code will be released at https://github.com/ZJU-FAST-Lab/Implicit-SVSDF-Planner for the benefit of the community.},
  file = {/Users/kshitijgoel/Zotero/storage/SEL4H45R/Wang et al. - 2024 - Implicit Swept Volume SDF Enabling Continuous Collision-Free Trajectory Generation for Arbitrary Sh.pdf}
}

@inproceedings{wang_linear_2023,
  title = {A {{Linear}} and {{Exact Algorithm}} for {{Whole-Body Collision Evaluation}} via {{Scale Optimization}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wang, Qianhao and Wang, Zhepei and Pei, Liuao and Xu, Chao and Gao, Fei},
  year = {2023},
  month = may,
  pages = {3621--3627},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160516},
  url = {https://ieeexplore.ieee.org/document/10160516/},
  urldate = {2023-12-03},
  abstract = {Collision evaluation is of essential importance in various applications. However, existing methods are either cumbersome to calculate or not exact. Therefore, considering the cost of implementation, most whole-body planning works, which require evaluating collision between robots and environments, struggle to tradeoff between accuracy and computationally efficiency. In this paper, we propose a zero-gap whole-body collision evaluation that can be formulated as a low-dimensional linear programming. This evaluation can be solved analytically in linear complexity. Moreover, the method provides gradient efficiently, making it accessible to optimization-based applications. Additionally, this method provides support for obstacles represented by either points or hyperplanes. Experiments on the widely used aerial and car-like robots validate the versatility and practicality of our method.},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/KHT48CQF/Wang et al. - 2023 - A Linear and Exact Algorithm for Whole-Body Collis.pdf}
}

@phdthesis{wang_monocular_2024,
  title = {Monocular and {{Binocular Visual-Inertial System Initialization}} and {{Real-Time Dense 3D Mapping}}},
  author = {Wang, Weihan},
  year = {2024},
  address = {United States -- New Jersey},
  url = {https://www.proquest.com/docview/3149936491/abstract/DC8B37EE616F439BPQ/1},
  urldate = {2025-01-09},
  abstract = {Visual-Inertial Simultaneous Localization and Mapping (VI-SLAM) systems encounter considerable challenges in demanding environments, making advancements in this area crucial. Integrating a single camera with an Inertial Measurement Unit (IMU) in Visual-Inertial Navigation Systems (VINS) offers a cost-effective, low-power solution suitable for robot perception and AR/VR applications. The camera captures rich environmental details, while the IMU measures acceleration and angular velocity, enhancing system resilience in fast-motion or low-texture scenarios. This sensor fusion allows for complementary benefits, though achieving precise and dense 3D reconstruction in challenging conditions remains an unresolved issue. This dissertation introduces methods to enhance both accuracy and robustness through two different IMU initialization techniques. It also presents a real-time 3D reconstruction pipeline tailored for VI-SLAM systems on resource-limited devices and proposes a complete VI-SLAM system with dense reconstruction capabilities by leveraging 3D Gaussian Splatting. Key contributions include (1) A fast, precise, and robust monocular visual-inertial initialization method utilizing an Error-State Kalman Filter (ESKF) to improve accuracy in challenging environments. (2) An extended initialization method for stereo visual-inertial SLAM, significantly enhancing both accuracy and robustness. (3) A real-time 3D reconstruction pipeline optimized for resource-constrained Autonomous Underwater Vehicles (AUVs). (4) An online Visual-Inertial Gaussian Splatting SLAM system featuring dense reconstruction.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798346878735},
  langid = {english},
  school = {Stevens Institute of Technology},
  keywords = {Computer science,Inertial Measurement Unit,Robotics,Visual-Inertial Navigation System},
  file = {/Users/kshitijgoel/Zotero/storage/74I65YP5/Wang - 2024 - Monocular and Binocular Visual-Inertial System Initialization and Real-Time Dense 3D Mapping.pdf}
}

@article{wang_mvilfusion_2022,
  title = {{{mVIL-Fusion}}: {{Monocular Visual-Inertial-LiDAR Simultaneous Localization}} and {{Mapping}} in {{Challenging Environments}}},
  shorttitle = {{{mVIL-Fusion}}},
  author = {Wang, Yan and Ma, Hongwei},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3226074},
  abstract = {We propose mVIL-Fusion, a three-level multisensor fusion system that is able to achieve robust state estimation and globally consistent mapping in perceptually degraded environments. First, LiDAR depth-assisted visual-inertial odometry (VIO) with LiDAR odometry (LO) synchronous prediction and distortion correction functions is proposed as the frontend of our system. Second, a novel double-sliding-window-based optimization of midend joints of LiDAR scan-to-scan translation constraints (VIO status detection function) and scan-to-map rotation constraints (local mapping function) is used to enhance the accuracy and robustness of the state estimation. In the backend, loop closures of local-map-based keyframes are identified with altitude verification, and the global map is generated by incremental smoothing of a pose-only factor graph with altitude prior. The performance of our system is verified on both a public dataset and several self-collected sequences in challenging environments. To benefit the robotics community, our implementation is available at https://github.com/Stan994265/mVIL-Fusion.},
  keywords = {Cameras,Laser radar,Robustness,sensor fusion,Simultaneous localization and mapping,SLAM,Smoothing methods,State estimation,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/6JNSZEE6/Wang and Ma - 2022 - mVIL-Fusion Monocular Visual-Inertial-LiDAR Simul.pdf;/Users/kshitijgoel/Zotero/storage/3TMABVJM/9968060.html}
}

@article{wang_neither_2022,
  title = {Neither {{Fast}} nor {{Slow}}: {{How}} to {{Fly Through Narrow Tunnels}}},
  shorttitle = {Neither {{Fast}} nor {{Slow}}},
  author = {Wang, Luqi and Xu, Hao and Zhang, Yichen and Shen, Shaojie},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {5489--5496},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3154024},
  abstract = {Nowadays, multirotors are playing important roles in abundant types of missions. During these missions, entering confined and narrow tunnels that are barely accessible to humans is desirable yet extremely challenging for multirotors. The restricted space and significant ego airflow disturbances induce control issues at both fast and slow flight speeds, meanwhile bringing about problems in state estimation and perception. Thus, a smooth trajectory at the proper speed is necessary for safe tunnel flights. To address these challenges, in this letter, a complete autonomous aerial system that can achieve smooth flights through tunnels with dimensions as narrow as to 0.6 m is presented. The system contains a motion planner that generates smooth mini-jerk trajectories along the tunnel center lines, which are extracted according to the map and Euclidean distance field (EDF), and its practical speed range is obtained through computational fluid dynamics (CFD) and flight data analyses. Extensive flight experiments on the quadrotor are conducted inside multiple narrow tunnels to validate the planning framework as well as the robustness of the whole system.},
  keywords = {Aerial systems: Applications,autonomous vehicle navigation,Lighting,motion and path planning,Planning,Proximity effects,State estimation,Tracking,Trajectory,Vents},
  file = {/Users/kshitijgoel/Zotero/storage/U65ZMJBS/Wang et al. - 2022 - Neither Fast nor Slow How to Fly Through Narrow T.pdf;/Users/kshitijgoel/Zotero/storage/GS5INJKQ/9721002.html}
}

@article{wang_seamless_2021,
  title = {Seamless Integration of Above- and under-Canopy Unmanned Aerial Vehicle Laser Scanning for Forest Investigation},
  author = {Wang, Yunsheng and Kukko, Antero and Hyypp{\"a}, Eric and Hakala, Teemu and Py{\"o}r{\"a}l{\"a}, Jiri and Lehtom{\"a}ki, Matti and El Issaoui, Aimad and Yu, Xiaowei and Kaartinen, Harri and Liang, Xinlian and Hyypp{\"a}, Juha},
  year = {2021},
  month = feb,
  journal = {Forest Ecosystems},
  volume = {8},
  number = {1},
  pages = {10},
  issn = {2197-5620},
  doi = {10.1186/s40663-021-00290-3},
  url = {https://doi.org/10.1186/s40663-021-00290-3},
  urldate = {2025-06-01},
  abstract = {Current automated forest investigation is facing a dilemma over how to achieve high tree- and plot-level completeness while maintaining a high cost and labor efficiency. This study tackles the challenge by exploring a new concept that enables an efficient fusion of aerial and terrestrial perspectives for digitizing and characterizing individual trees in forests through an Unmanned Aerial Vehicle (UAV) that flies above and under canopies in a single operation. The advantage of such concept is that the aerial perspective from the above-canopy UAV and the terrestrial perspective from the under-canopy UAV can be seamlessly integrated in one flight, thus grants the access to simultaneous high completeness, high efficiency, and low cost.},
  keywords = {Above canopy,Close range remote sensing,Forest,In situ,Inventory,Laser scanning,Point cloud,Under canopy,Unmanned aerial vehicle},
  file = {/Users/kshitijgoel/Zotero/storage/LP464CQC/Wang et al. - 2021 - Seamless integration of above- and under-canopy unmanned aerial vehicle laser scanning for forest in.pdf;/Users/kshitijgoel/Zotero/storage/W5DLZUWR/s40663-021-00290-3.html}
}

@phdthesis{wang_space_2013,
  title = {Space and {{Space-Time Modeling}} of {{Directional Data}}},
  author = {Wang, Fangpo},
  year = {2013},
  langid = {english},
  school = {Duke University},
  file = {/Users/kshitijgoel/Zotero/storage/3VEXYBI9/Wang - 2013 - Space and Space-Time Modeling of Directional Data.pdf}
}

@article{wang_sparse_2022,
  title = {Sparse {{Tensor-Based Multiscale Representation}} for {{Point Cloud Geometry Compression}}},
  author = {Wang, Jianqiang and Ding, Dandan and Li, Zhu and Feng, Xiaoxing and Cao, Chuntong and Ma, Zhan},
  year = {2022},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  pages = {1--18},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2022.3225816},
  abstract = {This study develops a unified Point Cloud Geometry (PCG) compression method through the processing of multiscale sparse tensor-based voxelized PCG. We call this compression method SparsePCGC. The proposed SparsePCGC is a low complexity solution because it only performs the convolutions on sparsely-distributed Most-Probable Positively-Occupied Voxels (MP-POV). The multiscale representation also allows us to compress scale-wise MP-POVs by exploiting cross-scale and same-scale correlations extensively and flexibly. The overall compression efficiency highly depends on the accuracy of estimated occupancy probability for each MP-POV. Thus, we first design the Sparse Convolution-based Neural Network (SparseCNN) which stacks sparse convolutions and voxel sampling to best characterize and embed spatial correlations. We then develop the SparseCNN-based Occupancy Probability Approximation (SOPA) model to estimate the occupancy probability either in a single-stage manner only using the cross-scale correlation, or in a multi-stage manner by exploiting stage-wise correlation among same-scale neighbors. Besides, we also suggest the SparseCNN based Local Neighborhood Embedding (SLNE) to aggregate local variations as spatial priors in feature attribute to improve the SOPA. Our unified approach not only shows state-of-the-art performance in both lossless and lossy compression modes across a variety of datasets including the dense object PCGs (8iVFB, Owlii, MUVB) and sparse LiDAR PCGs (KITTI, Ford) when compared with standardized MPEG G-PCC and other prevalent learning-based schemes, but also has low complexity which is attractive to practical applications.},
  keywords = {Context modeling,Decoding,Encoding,Geometry,Multiscale representation,neighborhood embedding,occupancy probability approximation,Point cloud compression,point cloud geometry compression,sparse convolution,sparse tensor,Tensors,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/8GNTGQ6B/Wang et al. - 2022 - Sparse Tensor-Based Multiscale Representation for .pdf}
}

@article{wang_speed_2023,
  title = {Speed {{Adaptive Robot Trajectory Generation Based}} on {{Derivative Property}} of {{B-Spline Curve}}},
  author = {Wang, Lihui and Guo, Yilin},
  year = {2023},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {4},
  pages = {1905--1911},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3241812},
  abstract = {In order to improve the safety of autonomous flight of quadrotor in three-dimensional complex environments, this letter proposes a speed adaptive motion planning method by limiting the distance between two adjacent control points based on the derivative property of B-Spline curve. First the initial B-Spline curve control points and the speed constraints based on derivative property are efficiently obtained by the front-end search that is divided into the shortest safe path search and reasonable step targeted expansion satisfying dynamic constraints. Then the back-end optimization assigns the corresponding safe flight corridor to the local trajectories according to the stage of the initial control points and uses MINVO basis (Tordesillas and How, 2022) to limit the simplexes with minimum volume enclosing local trajectories. The trajectory generation is finally formulated as a Quadratically Constrained Quadratic Program (QCQP) which can be solved efficiently. Both simulations and real-world experiments validate the efficiency and performance of this method in generating safe, smooth, speed adaptive trajectories.},
  keywords = {aerial systems: applications,autonomous vehicle navigation,Motion and path planning,Optimization,Planning,Quadrotors,Safety,Splines (mathematics),Trajectory,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/XVKKFBXJ/Wang and Guo - 2023 - Speed Adaptive Robot Trajectory Generation Based o.pdf;/Users/kshitijgoel/Zotero/storage/XT5MFN7M/stamp.html}
}

@book{wasserman_all_2004,
  title = {All of {{Statistics}}: {{A Concise Course}} in {{Statistical Inference}}},
  shorttitle = {All of {{Statistics}}},
  author = {Wasserman, Larry},
  year = {2004},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-21736-9},
  url = {http://link.springer.com/10.1007/978-0-387-21736-9},
  urldate = {2024-04-25},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4419-2322-6 978-0-387-21736-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/7X52AAL7/Wasserman - 2004 - All of Statistics A Concise Course in Statistical.pdf}
}

@book{wasserman_all_2006,
  title = {All of Nonparametric Statistics},
  author = {Wasserman, Larry},
  year = {2006},
  series = {Springer Texts in Statistics},
  edition = {1st ed., 3rd print},
  publisher = {Springer},
  address = {New York, NY},
  isbn = {978-0-387-25145-5 978-1-4419-2044-7 978-0-387-30623-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/DWMIHGMT/Wasserman - 2006 - All of nonparametric statistics.pdf}
}

@article{wei_gsfusion_2024,
  title = {{{GSFusion}}: {{Online RGB-D Mapping Where Gaussian Splatting Meets TSDF Fusion}}},
  shorttitle = {{{GSFusion}}},
  author = {Wei, Jiaxin and Leutenegger, Stefan},
  year = {2024},
  month = dec,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {12},
  pages = {11865--11872},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3502065},
  url = {https://ieeexplore.ieee.org/document/10758260/},
  urldate = {2025-06-20},
  abstract = {Traditional volumetric fusion algorithms preserve the spatial structure of 3D scenes, which is beneficial for many tasks in computer vision and robotics. However, they often lack realism in terms of visualization. Emerging 3D Gaussian splatting bridges this gap, but existing Gaussian-based reconstruction methods often suffer from artifacts and inconsistencies with the underlying 3D structure, and struggle with real-time optimization, unable to provide users with immediate feedback in high quality. One of the bottlenecks arises from the massive amount of Gaussian parameters that need to be updated during optimization. Instead of using 3D Gaussian as a standalone map representation, we incorporate it into a volumetric mapping system to take advantage of geometric information and propose to use a quadtree data structure on images to drastically reduce the number of splats initialized. In this way, we simultaneously generate a compact 3D Gaussian map with fewer artifacts and a volumetric map on the fly. Our method, GSFusion, significantly enhances computational efficiency without sacrificing rendering quality, as demonstrated on both synthetic and real datasets.},
  keywords = {Image reconstruction,Mapping,Neural radiance field,Optimization,Real-time systems,Rendering (computer graphics),RGB-D perception,Simultaneous localization and mapping,Solid modeling,Three-dimensional displays,Training},
  file = {/Users/kshitijgoel/Zotero/storage/JAC6DX2Q/Wei and Leutenegger - 2024 - GSFusion Online RGB-D Mapping Where Gaussian Splatting Meets TSDF Fusion.pdf}
}

@article{wei_multiscale_2023,
  title = {Multiscale Principle of Relevant Information for Hyperspectral Image Classification},
  author = {Wei, Yantao and Yu, Shujian and Giraldo, Luis Sanchez and Pr{\'i}ncipe, Jos{\'e} C.},
  year = {2023},
  month = apr,
  journal = {Machine Learning},
  volume = {112},
  number = {4},
  pages = {1227--1252},
  issn = {1573-0565},
  doi = {10.1007/s10994-021-06011-9},
  url = {https://doi.org/10.1007/s10994-021-06011-9},
  urldate = {2023-06-29},
  abstract = {This paper proposes a novel architecture, termed multiscale principle of relevant information (MPRI), to learn discriminative spectral-spatial features for hyperspectral image classification. MPRI inherits the merits of the principle of relevant information (PRI) to effectively extract multiscale information embedded in the given data, and also takes advantage of the multilayer structure to learn representations in a coarse-to-fine manner. Specifically, MPRI performs spectral-spatial pixel characterization (using PRI) and feature dimensionality reduction (using regularized linear discriminant analysis) iteratively and successively. Extensive experiments on three benchmark data sets demonstrate that MPRI outperforms existing state-of-the-art methods (including deep learning based ones) qualitatively and quantitatively, especially in the scenario of limited training samples. Code of MPRI is available at http://bit.ly/MPRI\_HSI.},
  langid = {english},
  keywords = {Hyperspectral image classification,Principle of relevant information,Spectral-spatial pixel characterization},
  file = {/Users/kshitijgoel/Zotero/storage/7ICCKSH9/Wei et al. - 2023 - Multiscale principle of relevant information for h.pdf}
}

@inproceedings{weiler_hardwarebased_2002,
  title = {Hardware-Based View-Independent Cell Projection},
  booktitle = {Symposium on {{Volume Visualization}} and {{Graphics}}, 2002. {{Proceedings}}. {{IEEE}} / {{ACM SIGGRAPH}}},
  author = {Weiler, M. and Kraus, M. and Ertl, T.},
  year = {2002},
  month = oct,
  pages = {13--22},
  doi = {10.1109/SWG.2002.1226505},
  url = {https://ieeexplore.ieee.org/document/1226505},
  urldate = {2025-02-04},
  abstract = {We present the first, view-independent cell projection algorithm for off-the-shelf programmable graphics hardware. Our implementation performs all computations for the projection and scan conversion of a set of tetrahedra on the graphics hardware and is therefore compatible with many of the hardware-accelerated optimizations for polygonal graphics, e.g. OpenGL vertex arrays and display lists. Apart from our actual implementation, we discuss potential improvements on future, more flexible graphics hardware and applications to interactive volume visualization of unstructured meshes.},
  keywords = {Application software,Chromium,Computer displays,Computer graphics,Hardware,Image generation,Interactive systems,Projection algorithms,Rendering (computer graphics),Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/PA3QVHPN/Weiler et al. - 2002 - Hardware-based view-independent cell projection.pdf;/Users/kshitijgoel/Zotero/storage/HBCNIUFG/1226505.html}
}

@inproceedings{weng_cresceptron_1992,
  title = {Cresceptron: A Self-Organizing Neural Network Which Grows Adaptively},
  shorttitle = {Cresceptron},
  booktitle = {[{{Proceedings}} 1992] {{IJCNN International Joint Conference}} on {{Neural Networks}}},
  author = {Weng, J. and Ahuja, N. and Huang, T.S.},
  year = {1992},
  month = jun,
  volume = {1},
  pages = {576-581 vol.1},
  doi = {10.1109/IJCNN.1992.287150},
  abstract = {Cresceptron uses a hierarchical framework to grow neural networks automatically, adaptively, and incrementally through learning. At every level of the hierarchy, new concepts are detected automatically and the network grows by creating new neurons and synapses which memorize the new concepts and their context. The training samples are generalized to other perceptually equivalent items through hierarchical tolerance of deviation. The neural network recognizes the learned items and their variations by hierarchically associating the learned knowledge with the input. It segments the recognized items from the input through back training along the response paths.{$<>$}},
  keywords = {Backpropagation,Electric breakdown,Humans,Input variables,Learning systems,Neural networks,Neurons,Unsupervised learning},
  file = {/Users/kshitijgoel/Zotero/storage/DF5IH59I/Weng et al. - 1992 - Cresceptron a self-organizing neural network whic.pdf;/Users/kshitijgoel/Zotero/storage/B8HIMSU4/287150.html}
}

@article{wettergreen_exploring_1993,
  title = {Exploring {{Mount Erebus}} by Walking Robot},
  author = {Wettergreen, David and Thorpe, Chuck and Whittaker, Red},
  year = {1993},
  month = dec,
  journal = {Robotics and Autonomous Systems},
  volume = {11},
  number = {3},
  pages = {171--185},
  issn = {0921-8890},
  doi = {10.1016/0921-8890(93)90022-5},
  url = {https://www.sciencedirect.com/science/article/pii/0921889093900225},
  urldate = {2023-10-25},
  abstract = {Dante is a tethered walking robot capable of climbing steep slopes. In 1992 it was created at Carnegie Mellon University and deployed in Antarctica to explore an active volcano, Mount Erebus. The Dante project's robot science objectives were to demonstrate a real exploration mission, rough terrain locomotion, environmental survival, and self-sustained operation in the harsh Antarctic climate. The volcano science objective was to study the unique convecting magma lake inside Mount Erebus' inner crater. The expedition demonstrated the advancing state-of-art in mobile robotics and the future potential of robotic explorers. This paper details our objectives, describes the Dante robot, overviews what happened on the expedition and discusses what did and didn't work.},
  keywords = {Autonomous,Legged,Robot,Volcanoes,Walking},
  file = {/Users/kshitijgoel/Zotero/storage/Y9DWFMGX/Wettergreen et al. - 1993 - Exploring Mount Erebus by walking robot.pdf;/Users/kshitijgoel/Zotero/storage/4RRWD3CY/0921889093900225.html}
}

@article{weyrich_hardware_2007,
  title = {A Hardware Architecture for Surface Splatting},
  author = {Weyrich, Tim and Heinzle, Simon and Aila, Timo and Fasnacht, Daniel B. and Oetiker, Stephan and Botsch, Mario and Flaig, Cyril and Mall, Simon and Rohrer, Kaspar and Felber, Norbert and Kaeslin, Hubert and Gross, Markus},
  year = {2007},
  month = jul,
  journal = {ACM Trans. Graph.},
  volume = {26},
  number = {3},
  pages = {90--es},
  issn = {0730-0301},
  doi = {10.1145/1276377.1276490},
  url = {https://dl.acm.org/doi/10.1145/1276377.1276490},
  urldate = {2025-01-14},
  abstract = {We present a novel architecture for hardware-accelerated rendering of point primitives. Our pipeline implements a refined version of EWA splatting, a high quality method for antialiased rendering of point sampled representations. A central feature of our design is the seamless integration of the architecture into conventional, OpenGL-like graphics pipelines so as to complement triangle-based rendering. The specific properties of the EWA algorithm required a variety of novel design concepts including a ternary depth test and using an on-chip pipelined heap data structure for making the memory accesses of splat primitives more coherent. In addition, we developed a computationally stable evaluation scheme for perspectively corrected splats. We implemented our architecture both on reconfigurable FPGA boards and as an ASIC prototype, and we integrated it into an OpenGL-like software implementation. Our evaluation comprises a detailed performance analysis using scenes of varying complexity.},
  file = {/Users/kshitijgoel/Zotero/storage/KJCTV6NJ/Weyrich et al. - 2007 - A hardware architecture for surface splatting.pdf}
}

@inproceedings{whelan_elasticfusion_2015,
  title = {{{ElasticFusion}}: {{Dense SLAM Without A Pose Graph}}},
  shorttitle = {{{ElasticFusion}}},
  booktitle = {Robotics: {{Science}} and {{Systems XI}}},
  author = {Whelan, Thomas and Leutenegger, Stefan and Salas Moreno, Renato and Glocker, Ben and Davison, Andrew},
  year = {2015},
  month = jul,
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2015.XI.001},
  url = {http://www.roboticsproceedings.org/rss11/p01.pdf},
  urldate = {2022-02-06},
  isbn = {978-0-9923747-1-6},
  file = {/Users/kshitijgoel/Zotero/storage/BDVTK5A4/Whelan et al. - 2015 - ElasticFusion Dense SLAM Without A Pose Graph.pdf}
}

@article{whelan_realtime_2015,
  title = {Real-Time Large-Scale Dense {{RGB-D SLAM}} with Volumetric Fusion},
  author = {Whelan, Thomas and Kaess, Michael and Johannsson, Hordur and Fallon, Maurice and Leonard, John J. and McDonald, John},
  year = {2015},
  month = apr,
  journal = {The International Journal of Robotics Research},
  volume = {34},
  number = {4-5},
  pages = {598--626},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364914551008},
  url = {http://journals.sagepub.com/doi/10.1177/0278364914551008},
  urldate = {2022-02-06},
  abstract = {We present a new simultaneous localization and mapping (SLAM) system capable of producing high-quality globally consistent surface reconstructions over hundreds of meters in real time with only a low-cost commodity RGB-D sensor. By using a fused volumetric surface reconstruction we achieve a much higher quality map over what would be achieved using raw RGB-D point clouds. In this paper we highlight three key techniques associated with applying a volumetric fusion-based mapping system to the SLAM problem in real time. First, the use of a GPU-based 3D cyclical buffer trick to efficiently extend dense every-frame volumetric fusion of depth maps to function over an unbounded spatial region. Second, overcoming camera pose estimation limitations in a wide variety of environments by combining both dense geometric and photometric camera pose constraints. Third, efficiently updating the dense map according to place recognition and subsequent loop closure constraints by the use of an `as-rigid-as-possible' space deformation. We present results on a wide variety of aspects of the system and show through evaluation on de facto standard RGB-D benchmarks that our system performs strongly in terms of trajectory estimation, map quality and computational performance in comparison to other state-of-the-art systems.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/TW7RQJGR/Whelan et al. - 2015 - Real-time large-scale dense RGB-D SLAM with volume.pdf}
}

@book{whittle_probability_2000,
  title = {Probability via {{Expectation}}},
  author = {Whittle, Peter},
  year = {2000},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-0509-8},
  url = {http://link.springer.com/10.1007/978-1-4612-0509-8},
  urldate = {2023-10-20},
  isbn = {978-1-4612-6795-9 978-1-4612-0509-8},
  keywords = {Markov process,Martingale,optimization,probability measure,Probability Theory,Random variable},
  file = {/Users/kshitijgoel/Zotero/storage/2MU82P5H/Whittle - 2000 - Probability via Expectation.pdf}
}

@inproceedings{wiedemann_training_2023,
  title = {Training {{Efficient Controllers}} via {{Analytic Policy Gradient}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wiedemann, Nina and W{\"u}est, Valentin and Loquercio, Antonio and M{\"u}ller, Matthias and Floreano, Dario and Scaramuzza, Davide},
  year = {2023},
  month = may,
  pages = {1349--1356},
  doi = {10.1109/ICRA48891.2023.10160581},
  url = {https://ieeexplore.ieee.org/document/10160581/},
  urldate = {2025-08-12},
  abstract = {Control design for robotic systems is complex and often requires solving an optimization to follow a trajectory accurately. Online optimization approaches like Model Predictive Control (MPC) have been shown to achieve great tracking performance, but require high computing power. Conversely, learning-based offline optimization approaches, such as Reinforcement Learning (RL), allow fast and efficient execution on the robot but hardly match the accuracy of MPC in trajectory tracking tasks. In systems with limited compute, such as aerial vehicles, an accurate controller that is efficient at execution time is imperative. We propose an Analytic Policy Gradient (APG) method to tackle this problem. APG exploits the availability of differentiable simulators by training a controller offline with gradient descent on the tracking error. We address training instabilities that frequently occur with APG through curriculum learning and experiment on a widely used controls benchmark, the CartPole, and two common aerial robots, a quadrotor and a fixed-wing drone. Our proposed method outperforms both model-based and model-free RL methods in terms of tracking error. Concurrently, it achieves similar performance to MPC while requiring more than an order of magnitude less computation time. Our work provides insights into the potential of APG as a promising control method for robotics. To facilitate the exploration of APG, we open-source our code and make it available atgithub.com/lis-epfl/apg\_trajectory\_tracking.},
  keywords = {Computational modeling,Stability analysis,Task analysis,Training,Training data,Trajectory,Trajectory tracking},
  file = {/Users/kshitijgoel/Zotero/storage/4AVUAIJ8/Wiedemann et al. - 2023 - Training Efficient Controllers via Analytic Policy Gradient.pdf}
}

@article{wiesmann_locndf_2023,
  title = {{{LocNDF}}: {{Neural Distance Field Mapping}} for {{Robot Localization}}},
  shorttitle = {{{LocNDF}}},
  author = {Wiesmann, Louis and Guadagnino, Tiziano and Vizzo, Ignacio and Zimmerman, Nicky and Pan, Yue and Kuang, Haofei and Behley, Jens and Stachniss, Cyrill},
  year = {2023},
  month = aug,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {8},
  pages = {4999--5006},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3291274},
  url = {https://ieeexplore.ieee.org/document/10168941/},
  urldate = {2023-09-25},
  abstract = {Mapping an environment is essential for several robotic tasks, particularly for localization. In this letter, we address the problem of mapping the environment using LiDAR point clouds with the goal to obtain a map representation that is well suited for robot localization. To this end, we utilize a neural network to learn a discretization-free distance field of a given scene for localization. In contrast to prior approaches, we directly work on the sensor data and do not assume a perfect model of the environment or rely on normals. Inspired by the recently proposed NeRF representations, we supervise the network by points sampled along the measured beams, and our loss is designed to learn a valid distance field. Additionally, we show how to perform scan registration and global localization directly within the neural distance field. We illustrate the capabilities to globally localize within an indoor environment utilizing a particle filter as well as to perform scan registration by tracking the pose of a car based on matching LiDAR scans to the neural distance field.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/JPC2WWIP/Wiesmann et al. - 2023 - LocNDF Neural Distance Field Mapping for Robot Lo.pdf}
}

@inproceedings{wiesmann_retriever_2022,
  title = {Retriever: {{Point Cloud Retrieval}} in {{Compressed 3D Maps}}},
  shorttitle = {Retriever},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wiesmann, Louis and Marcuzzi, Rodrigo and Stachniss, Cyrill and Behley, Jens},
  year = {2022},
  month = may,
  pages = {10925--10932},
  doi = {10.1109/ICRA46639.2022.9811785},
  abstract = {Most autonomous driving and robotic applications require retrieving map data around the vehicle's current location. Those maps can cover large areas and are often stored in a compressed form to save memory and allow for efficient transmission. In this paper, we address the problem of place recognition in a compressed point cloud map. To this end, we propose a novel deep neural network architecture that directly operates on a compressed feature representation produced by a compression encoder. This enables us to bypass compute-heavy decompression of the map and exploits the compact as well as descriptive nature of the compressed features. Additionally, we propose an alternative to the commonly used NetVLAD layer to aggregate local descriptors. Here, we utilize an attention mechanism between local features and a latent code. Our experiments suggest that this produces a more descriptive feature representation of the point clouds for place recognition. We experimentally validate all architectural choices we made by our ablation studies and compare our performance to other state-of-the-art baselines on two commonly used datasets.},
  keywords = {Codes,Deep learning,Focusing,Memory management,Neural networks,Point cloud compression,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/YCAYGAKG/Wiesmann et al. - 2022 - Retriever Point Cloud Retrieval in Compressed 3D .pdf;/Users/kshitijgoel/Zotero/storage/QVCIGPCZ/9811785.html}
}

@misc{wilder-smith_radiance_2024,
  title = {Radiance {{Fields}} for {{Robotic Teleoperation}}},
  author = {{Wilder-Smith}, Maximum and Patil, Vaishakh and Hutter, Marco},
  year = {2024},
  month = jul,
  number = {arXiv:2407.20194},
  eprint = {2407.20194},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.20194},
  urldate = {2024-08-02},
  abstract = {Radiance field methods such as Neural Radiance Fields (NeRFs) or 3D Gaussian Splatting (3DGS), have revolutionized graphics and novel view synthesis. Their ability to synthesize new viewpoints with photo-realistic quality, as well as capture complex volumetric and specular scenes, makes them an ideal visualization for robotic teleoperation setups. Direct camera teleoperation provides high-fidelity operation at the cost of maneuverability, while reconstruction-based approaches offer controllable scenes with lower fidelity. With this in mind, we propose replacing the traditional reconstructionvisualization components of the robotic teleoperation pipeline with online Radiance Fields, offering highly maneuverable scenes with photorealistic quality. As such, there are three main contributions to state of the art: (1) online training of Radiance Fields using live data from multiple cameras, (2) support for a variety of radiance methods including NeRF and 3DGS, (3) visualization suite for these methods including a virtual reality scene. To enable seamless integration with existing setups, these components were tested with multiple robots in multiple configurations and were displayed using traditional tools as well as the VR headset. The results across methods and robots were compared quantitatively to a baseline of mesh reconstruction, and a user study was conducted to compare the different visualization methods. More code and additional samples are available at https://leggedrobotics.github.io/rffr.github.io/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/2NUYK9I8/Wilder-Smith et al. - 2024 - Radiance Fields for Robotic Teleoperation.pdf}
}

@inproceedings{williams_efficient_2005,
  title = {An Efficient and Robust Ray-Box Intersection Algorithm},
  booktitle = {{{ACM SIGGRAPH}} 2005 {{Courses}}},
  author = {Williams, Amy and Barrus, Steve and Morley, R. Keith and Shirley, Peter},
  year = {2005},
  month = jul,
  series = {{{SIGGRAPH}} '05},
  pages = {9--es},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1198555.1198748},
  url = {https://dl.acm.org/doi/10.1145/1198555.1198748},
  urldate = {2024-11-16},
  abstract = {The computational bottleneck in a ray tracer using bounding volume hierarchies is often the ray intersection routine with axis-aligned bounding boxes. We describe a version of this routine that uses IEEE numerical properties to ensure that those tests are both robust and efficient. Sample source code is available online.},
  isbn = {978-1-4503-7833-8},
  file = {/Users/kshitijgoel/Zotero/storage/QISUN9KV/Williams et al. - 2005 - An efficient and robust ray-box intersection algorithm.pdf}
}

@techreport{williams_gaussian_2007,
  title = {Gaussian {{Process Implicit Surfaces}}},
  author = {Williams, Oliver and Fitzgibbon, Andrew},
  year = {2007},
  institution = {Microsoft},
  url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2006/06/gpc.pdf},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LXBCN4GY/Williams and Fitzgibbon - Gaussian Process Implicit Surfaces.pdf}
}

@misc{wilson_modeling_2024,
  title = {Modeling {{Uncertainty}} in {{3D Gaussian Splatting}} through {{Continuous Semantic Splatting}}},
  author = {Wilson, Joey and Almeida, Marcelino and Sun, Min and Mahajan, Sachit and Ghaffari, Maani and Ewen, Parker and Ghasemalizadeh, Omid and Kuo, Cheng-Hao and Sen, Arnie},
  year = {2024},
  month = nov,
  number = {arXiv:2411.02547},
  eprint = {2411.02547},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2411.02547},
  urldate = {2024-11-09},
  abstract = {In this paper, we present a novel algorithm for probabilistically updating and rasterizing semantic maps within 3D Gaussian Splatting (3D-GS). Although previous methods have introduced algorithms which learn to rasterize features in 3D-GS for enhanced scene understanding, 3D-GS can fail without warning which presents a challenge for safety-critical robotic applications. To address this gap, we propose a method which advances the literature of continuous semantic mapping from voxels to ellipsoids, combining the precise structure of 3D-GS with the ability to quantify uncertainty of probabilistic robotic maps. Given a set of images, our algorithm performs a probabilistic semantic update directly on the 3D ellipsoids to obtain an expectation and variance through the use of conjugate priors. We also propose a probabilistic rasterization which returns per-pixel segmentation predictions with quantifiable uncertainty. We compare our method with similar probabilistic voxel-based methods to verify our extension to 3D ellipsoids, and perform ablation studies on uncertainty quantification and temporal smoothing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/LD8AVY6U/Wilson et al. - 2024 - Modeling Uncertainty in 3D Gaussian Splatting through Continuous Semantic Splatting.pdf;/Users/kshitijgoel/Zotero/storage/5M3B6847/2411.html}
}

@article{wilson_wassersteintype_2024,
  title = {A {{Wasserstein-Type Distance}} for {{Gaussian Mixtures}} on {{Vector Bundles}} with {{Applications}} to {{Shape Analysis}}},
  author = {Wilson, Michael and Needham, Tom and Park, Chiwoo and Kundu, Suparteek and Srivastava, Anuj},
  year = {2024},
  month = sep,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {17},
  number = {3},
  pages = {1433--1466},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/23M1620363},
  url = {https://epubs.siam.org/doi/10.1137/23M1620363},
  urldate = {2024-10-14},
  abstract = {In this paper we introduce a Wasserstein-type distance on the set of Gaussian mixture models. This distance is defined by restricting the set of possible coupling measures in the optimal transport problem to Gaussian mixture models. We derive a very simple discrete formulation for this distance, which makes it suitable for high dimensional problems. We also study the corresponding multi-marginal and barycenter formulations.  We show some properties of this Wasserstein-type distance, and we illustrate its practical use with some examples in image processing.},
  file = {/Users/kshitijgoel/Zotero/storage/GFMJW9GU/Wilson et al. - 2024 - A Wasserstein-Type Distance for Gaussian Mixtures on Vector Bundles with Applications to Shape Analy.pdf}
}

@inproceedings{wipf_new_2007,
  title = {A {{New View}} of {{Automatic Relevance Determination}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wipf, David and Nagarajan, Srikantan},
  year = {2007},
  volume = {20},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2007/hash/9c01802ddb981e6bcfbec0f0516b8e35-Abstract.html},
  urldate = {2024-09-20},
  abstract = {Automatic relevance determination (ARD), and the closely-related sparse Bayesian learning (SBL) framework, are effective tools for pruning large numbers of irrelevant features. However, popular update rules used for this process are either prohibitively slow in practice and/or heuristic in nature without proven convergence properties. This paper furnishes an alternative means of optimizing a general ARD cost function using an auxiliary function that can naturally be solved using a series of re-weighted L1 problems. The result is an efficient algorithm that can be implemented using standard convex programming toolboxes and is guaranteed to converge to a stationary point unlike existing methods. The analysis also leads to additional insights into the behavior of previous ARD updates as well as the ARD cost function. For example, the standard fixed-point updates of MacKay (1992) are shown to be iteratively solving a particular min-max problem, although they are not guaranteed to lead to a stationary point. The analysis also reveals that ARD is exactly equivalent to performing MAP estimation using a particular feature- and noise-dependent {\textbackslash}textit\{non-factorial\} weight prior with several desirable properties over conventional priors with respect to feature selection. In particular, it provides a tighter approximation to the L0 quasi-norm sparsity measure than the L1 norm. Overall these results suggests alternative cost functions and update procedures for selecting features and promoting sparse solutions.},
  file = {/Users/kshitijgoel/Zotero/storage/2ZWB6DME/Wipf and Nagarajan - 2007 - A New View of Automatic Relevance Determination.pdf}
}

@article{wisth_vilens_2022,
  title = {{{VILENS}}: {{Visual}}, {{Inertial}}, {{Lidar}}, and {{Leg Odometry}} for {{All-Terrain Legged Robots}}},
  shorttitle = {{{VILENS}}},
  author = {Wisth, David and Camurri, Marco and Fallon, Maurice},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--18},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3193788},
  abstract = {We present visual inertial lidar legged navigation system (VILENS), an odometry system for legged robots based on factor graphs. The key novelty is the tight fusion of four different sensor modalities to achieve reliable operation when the individual sensors would otherwise produce degenerate estimation. To minimize leg odometry drift, we extend the robot's state with a linear velocity bias term, which is estimated online. This bias is observable because of the tight fusion of this preintegrated velocity factor with vision, lidar, and inertial measurement unit (IMU) factors. Extensive experimental validation on different ANYmal quadruped robots is presented, for a total duration of 2 h and 1.8 km traveled. The experiments involved dynamic locomotion over loose rocks, slopes, and mud, which caused challenges such as slippage and terrain deformation. Perceptual challenges included dark and dusty underground caverns, and open and feature-deprived areas. We show an average improvement of 62\% translational and 51\% rotational errors compared to a state-of-the-art loosely coupled approach. To demonstrate its robustness, VILENS was also integrated with a perceptive controller and a local path planner.},
  keywords = {Cameras,Field robots,Foot,Kinematics,Laser radar,Legged locomotion,legged robots,localization,Robot sensing systems,Robots,sensor fusion},
  file = {/Users/kshitijgoel/Zotero/storage/DQ6CEBRF/Wisth et al. - 2022 - VILENS Visual, Inertial, Lidar, and Leg Odometry .pdf;/Users/kshitijgoel/Zotero/storage/C34YNGFL/9852710.html}
}

@inproceedings{witting_historyaware_2018,
  title = {History-{{Aware Autonomous Exploration}} in {{Confined Environments Using MAVs}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Witting, Christian and Fehr, Marius and B{\"a}hnemann, Rik and Oleynikova, Helen and Siegwart, Roland},
  year = {2018},
  month = oct,
  pages = {1--9},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8594502},
  abstract = {Many scenarios require a robot to be able to explore its 3D environment online without human supervision. This is especially relevant for inspection tasks and search and rescue missions. To solve this high-dimensional path planning problem, sampling-based exploration algorithms have proven successful. However, these do not necessarily scale well to larger environments or spaces with narrow openings. This paper presents a 3D exploration planner based on the principles of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle (MAV)equipped with a limited field-of-view depth sensor randomly samples its configuration space to find promising future viewpoints. In order to obtain high sampling efficiency, our planner maintains and uses a history of visited places, and locally optimizes the robot's orientation with respect to unobserved space. We evaluate our method in several simulated scenarios, and compare it against a state-of-the-art exploration algorithm. The experiments show substantial improvements in exploration time (2 ⨯ faster), computation time, and path length, and advantages in handling difficult situations such as escaping dead-ends (up to 20 ⨯ faster). Finally, we validate the on-line capability of our algorithm on a computational constrained real world MAV.},
  keywords = {History,Optimization,Planning,Robot sensing systems,Three-dimensional displays,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/YE493HCU/Witting et al. - 2018 - History-Aware Autonomous Exploration in Confined E.pdf;/Users/kshitijgoel/Zotero/storage/EDU9HS43/8594502.html}
}

@article{woodruff_sketching_2014,
  title = {Sketching as a {{Tool}} for {{Numerical Linear Algebra}}},
  author = {Woodruff, David P.},
  year = {2014},
  month = oct,
  journal = {Found. Trends Theor. Comput. Sci.},
  volume = {10},
  number = {1--2},
  pages = {1--157},
  issn = {1551-305X},
  doi = {10.1561/0400000060},
  url = {https://doi.org/10.1561/0400000060},
  urldate = {2024-12-01},
  abstract = {This survey highlights the recent advances in algorithms for numericallinear algebra that have come from the technique of linear sketching,whereby given a matrix, one first compresses it to a much smaller matrixby multiplying it by a (usually) random matrix with certain properties.Much of the expensive computation can then be performed onthe smaller matrix, thereby accelerating the solution for the originalproblem. In this survey we consider least squares as well as robust regressionproblems, low rank approximation, and graph sparsification.We also discuss a number of variants of these problems. Finally, wediscuss the limitations of sketching methods.},
  file = {/Users/kshitijgoel/Zotero/storage/D3PKZ7WY/Woodruff - 2014 - Sketching as a Tool for Numerical Linear Algebra.pdf}
}

@inproceedings{wright_classification_2007,
  title = {Classification via {{Minimum Incremental Coding Length}} ({{MICL}})},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wright, John and Tao, Yangyu and Lin, Zhouchen and Ma, Yi and Shum, Heung-yeung},
  year = {2007},
  volume = {20},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2007/hash/37693cfc748049e45d87b8c7d8b9aacd-Abstract.html},
  urldate = {2024-04-03},
  abstract = {We present a simple new criterion for classification, based on principles from lossy data compression. The criterion assigns a test sample to the class that uses the min- imum number of additional bits to code the test sample, subject to an allowable distortion. We prove asymptotic optimality of this criterion for Gaussian data and analyze its relationships to classical classifiers. Theoretical results provide new insights into relationships among popular classifiers such as MAP and RDA, as well as unsupervised clustering methods based on lossy compression [13]. Mini- mizing the lossy coding length induces a regularization effect which stabilizes the (implicit) density estimate in a small-sample setting. Compression also provides a uniform means of handling classes of varying dimension. This simple classi- fication criterion and its kernel and local versions perform competitively against existing classifiers on both synthetic examples and real imagery data such as hand- written digits and human faces, without requiring domain-specific information.},
  file = {/Users/kshitijgoel/Zotero/storage/IA7JMKEZ/Wright et al. - 2007 - Classification via Minimum Incremental Coding Leng.pdf}
}

@article{wright_coordinate_2015,
  title = {Coordinate Descent Algorithms},
  author = {Wright, Stephen J.},
  year = {2015},
  month = jun,
  journal = {Mathematical Programming},
  volume = {151},
  number = {1},
  pages = {3--34},
  issn = {1436-4646},
  doi = {10.1007/s10107-015-0892-3},
  url = {https://doi.org/10.1007/s10107-015-0892-3},
  urldate = {2024-06-24},
  abstract = {Coordinate descent algorithms solve optimization problems by successively performing approximate minimization along coordinate directions or coordinate hyperplanes. They have been used in applications for many years, and their popularity continues to grow because of their usefulness in data analysis, machine learning, and other areas of current interest. This paper describes the fundamentals of the coordinate descent approach, together with variants and extensions and their convergence properties, mostly with reference to convex objectives. We pay particular attention to a certain problem structure that arises frequently in machine learning applications, showing that efficient implementations of accelerated coordinate descent algorithms are possible for problems of this type. We also present some parallel variants and discuss their convergence properties under several models of parallel execution.},
  langid = {english},
  keywords = {49M20,90C25,Coordinate descent,Parallel numerical computing,Randomized algorithms},
  file = {/Users/kshitijgoel/Zotero/storage/ITJAPPW6/Wright - 2015 - Coordinate descent algorithms.pdf}
}

@misc{wu_3dgut_2024,
  title = {{{3DGUT}}: {{Enabling Distorted Cameras}} and {{Secondary Rays}} in {{Gaussian Splatting}}},
  shorttitle = {{{3DGUT}}},
  author = {Wu, Qi and Esturo, Janick Martinez and Mirzaei, Ashkan and {Moenne-Loccoz}, Nicolas and Gojcic, Zan},
  year = {2024},
  month = dec,
  number = {arXiv:2412.12507},
  eprint = {2412.12507},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.12507},
  url = {http://arxiv.org/abs/2412.12507},
  urldate = {2024-12-19},
  abstract = {3D Gaussian Splatting (3DGS) has shown great potential for efficient reconstruction and high-fidelity real-time rendering of complex scenes on consumer hardware. However, due to its rasterization-based formulation, 3DGS is constrained to ideal pinhole cameras and lacks support for secondary lighting effects. Recent methods address these limitations by tracing volumetric particles instead, however, this comes at the cost of significantly slower rendering speeds. In this work, we propose 3D Gaussian Unscented Transform (3DGUT), replacing the EWA splatting formulation in 3DGS with the Unscented Transform that approximates the particles through sigma points, which can be projected exactly under any nonlinear projection function. This modification enables trivial support of distorted cameras with time dependent effects such as rolling shutter, while retaining the efficiency of rasterization. Additionally, we align our rendering formulation with that of tracing-based methods, enabling secondary ray tracing required to represent phenomena such as reflections and refraction within the same 3D representation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/kshitijgoel/Zotero/storage/DLLYRNX5/Wu et al. - 2024 - 3DGUT Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting.pdf;/Users/kshitijgoel/Zotero/storage/2HLUP4W6/2412.html}
}

@article{wu_convergence_1983,
  title = {On the {{Convergence Properties}} of the {{EM Algorithm}}},
  author = {Wu, C. F. Jeff},
  year = {1983},
  journal = {The Annals of Statistics},
  volume = {11},
  number = {1},
  eprint = {2240463},
  eprinttype = {jstor},
  pages = {95--103},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  url = {https://www.jstor.org/stable/2240463},
  urldate = {2023-02-18},
  abstract = {Two convergence aspects of the EM algorithm are studied: (i) does the EM algorithm find a local maximum or a stationary value of the (incomplete-data) likelihood function? (ii) does the sequence of parameter estimates generated by EM converge? Several convergence results are obtained under conditions that are applicable to many practical situations. Two useful special cases are: (a) if the unobserved complete-data specification can be described by a curved exponential family with compact parameter space, all the limit points of any EM sequence are stationary points of the likelihood function; (b) if the likelihood function is unimodal and a certain differentiability condition is satisfied, then any EM sequence converges to the unique maximum likelihood estimate. A list of key properties of the algorithm is included.},
  file = {/Users/kshitijgoel/Zotero/storage/YYWEA3FK/Wu - 1983 - On the Convergence Properties of the EM Algorithm.pdf}
}

@article{wu_faithful_2021,
  title = {Faithful {{Euclidean Distance Field From Log-Gaussian Process Implicit Surfaces}}},
  author = {Wu, Lan and Lee, Ki Myung Brian and Liu, Liyang and {Vidal-Calleja}, Teresa},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {2461--2468},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3061356},
  url = {https://ieeexplore.ieee.org/abstract/document/9361242},
  urldate = {2023-09-24},
  abstract = {In this letter, we introduce the Log-Gaussian Process Implicit Surface (Log-GPIS), a novel continuous and probabilistic mapping representation suitable for surface reconstruction and local navigation. Our key contribution is the realisation that the regularised Eikonal equation can be simply solved by applying the logarithmic transformation to a GPIS formulation to recover the accurate Euclidean distance field (EDF) and, at the same time, the implicit surface. To derive the proposed representation, Varadhan's formula is exploited to approximate the non-linear Eikonal partial differential equation (PDE) of the EDF by the logarithm of a linear PDE. We show that members of the Mat{\'e}rn covariance family directly satisfy this linear PDE. The proposed approach does not require post-processing steps to recover the EDF. Moreover, unlike sampling-based methods, Log-GPIS does not use sample points inside and outside the surface as the derivative of the covariance allow direct estimation of the surface normals and distance gradients. We benchmarked the proposed method on simulated and real data against state-of-the-art mapping frameworks that also aim at recovering both the surface and a distance field. Our experiments show that Log-GPIS produces the most accurate results for the EDF and comparable results for surface reconstruction and its computation time still allows online operations.},
  file = {/Users/kshitijgoel/Zotero/storage/79WHSUVI/Wu et al. - 2021 - Faithful Euclidean Distance Field From Log-Gaussia.pdf;/Users/kshitijgoel/Zotero/storage/AB8LH572/9361242.html}
}

@article{wu_loggpismop_2023,
  title = {Log-{{GPIS-MOP}}: {{A Unified Representation}} for {{Mapping}}, {{Odometry}}, and {{Planning}}},
  shorttitle = {Log-{{GPIS-MOP}}},
  author = {Wu, Lan and Lee, Ki Myung Brian and Le Gentil, Cedric and {Vidal-Calleja}, Teresa},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {4078--4094},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3296982},
  url = {https://ieeexplore.ieee.org/document/10202666},
  urldate = {2024-01-27},
  abstract = {Whereas dedicated scene representations are required for each different task in conventional robotic systems, this article demonstrates that a unified representation can be used directly for multiple key tasks. We propose the log-Gaussian process implicit surface for mapping, odometry, and planning (Log-GPIS-MOP): a probabilistic framework for surface reconstruction, localization, and navigation based on a unified representation. Our framework applies a logarithmic transformation to a Gaussian process implicit surface (GPIS) formulation to recover a global representation that accurately captures the Euclidean distance field with gradients and, at the same time, the implicit surface. By directly estimating the distance field and its gradient through Log-GPIS inference, the proposed incremental odometry technique computes the optimal alignment of an incoming frame and fuses it globally to produce a map. Concurrently, an optimization-based planner computes a safe collision-free path using the same Log-GPIS surface representation. We validate the proposed framework on simulated and real datasets in 2-D and 3-D, and benchmark against the state-of-the-art approaches. Our experiments show that Log-GPIS-MOP produces competitive results in sequential odometry, surface mapping, and obstacle avoidance.},
  keywords = {Euclidean distance field (EDF),Gaussian process implicit surfaces (GPIS),localization,Location awareness,mapping,Odometry,planning,Planning,Robots,simultaneous localization and mapping (SLAM),Surface reconstruction,Surface treatment,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/7338D4NV/Wu et al. - 2023 - Log-GPIS-MOP A Unified Representation for Mapping.pdf;/Users/kshitijgoel/Zotero/storage/FMSW7CTT/10202666.html}
}

@inproceedings{wu_pseudo_2023,
  title = {Pseudo {{Inputs Optimisation}} for {{Efficient Gaussian Process Distance Fields}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Wu, Lan and Gentil, Cedric Le and {Vidal-Calleja}, Teresa},
  year = {2023},
  month = oct,
  pages = {7249--7255},
  issn = {2153-0866},
  doi = {10.1109/IROS55552.2023.10342483},
  url = {https://ieeexplore.ieee.org/document/10342483},
  urldate = {2024-01-27},
  abstract = {Robots reason about the environment through dedicated representations. Despite the fact that Gaussian Process (GP)-based representations are appealing due to their probabilistic and continuous nature, the cubic computational complexity is a concern. In this paper, we present a novel efficient GP-based representation that has the ability to produce accurate distance fields and is parameterised by the optimal locations of pseudo inputs. When applying the proposed method together with a kernel approximation approach, we show it outperforms well-established sparse GP frameworks in efficiency and accuracy. Moreover, we extend the proposed method to work in a dynamic setting, where a map is built iteratively and the scene dynamics are accounted for by adding or removing objects from the environment representation. In a nutshell, our method provides the ability to infer dynamic distance fields and achieve state-of-the-art reconstruction efficiently.},
  keywords = {Computational complexity,Computational efficiency,Euclidean Distance Fields,Gaussian Process,Gaussian processes,Kernel,Mapping,Optimization methods,Probabilistic logic,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/KAD62NGK/Wu et al. - 2023 - Pseudo Inputs Optimisation for Efficient Gaussian .pdf;/Users/kshitijgoel/Zotero/storage/S7ZIENF6/10342483.html}
}

@article{wu_skeletonbased_2020,
  title = {Skeleton-{{Based Conditionally Independent Gaussian Process Implicit Surfaces}} for {{Fusion}} in {{Sparse}} to {{Dense 3D Reconstruction}}},
  author = {Wu, Lan and Falque, Raphael and {Perez-Puchalt}, Victor and Liu, Liyang and Pietroni, Nico and {Vidal-Calleja}, Teresa},
  year = {2020},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {1532--1539},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.2969175},
  abstract = {3D object reconstructions obtained from 2D or 3D cameras are typically noisy. Probabilistic algorithms are suitable for information fusion and can deal with noise robustly. Consequently, these algorithms can be useful for accurate surface reconstruction. This paper presents an approach to estimate a probabilistic representation of the implicit surface of 3D objects. One of the contributions of the paper is the pipeline for generating an accurate reconstruction, given a set of sparse points that are close to the surface and a dense noisy point cloud. A novel submapping method following the topology of the object is proposed to generate conditional independent Gaussian Process Implicit Surfaces. This allows inference and fusion mechanisms to be performed in parallel followed by information propagation through the submaps. Large datasets can efficiently be processed by the proposed pipeline producing not only a surface but also the uncertainty information of the reconstruction. We evaluate the performance of our algorithm using simulated and real datasets.},
  keywords = {Bayesian fusion,conditionally independent maps,Gaussian process implicit surfaces,Gaussian processes,Image reconstruction,Kernel,Probabilistic logic,skeleton extraction,Surface reconstruction,Surface treatment,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/LYLFNT7T/Wu et al. - 2020 - Skeleton-Based Conditionally Independent Gaussian .pdf;/Users/kshitijgoel/Zotero/storage/KKK5ZVG8/8968326.html}
}

@inproceedings{wu_theoretical_2024,
  title = {Theoretical Insights for Diffusion Guidance: {{A}} Case Study for {{Gaussian}} Mixture Models},
  shorttitle = {Theoretical Insights for Diffusion Guidance},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Wu, Yuchen and Chen, Minshuo and Li, Zihao and Wang, Mengdi and Wei, Yuting},
  year = {2024},
  month = jul,
  pages = {53291--53327},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v235/wu24b.html},
  urldate = {2024-11-27},
  abstract = {Diffusion models benefit from instillation of task-specific information into the score function to steer the sample generation towards desired properties. Such information is coined as guidance. For example, in text-to-image synthesis, text input is encoded as guidance to generate semantically aligned images. Proper guidance inputs are closely tied with the performance of diffusion models. A common observation is that strong guidance promotes a tight alignment to the task-specific information, while reduces the diversity of the generated samples. In this paper, we provide the first theoretical study towards the influence of guidance on diffusion models in the context of Gaussian mixture models. Under mild conditions, we prove that incorporating diffusion guidance not only boosts prediction confidence but also diminishes distribution diversity, leading to a reduction in the differential entropy of the output distribution. Our analysis covers the widely used DDPM and DDIM sampling schemes, and leverages comparison inequalities in differential equations as well as the Fokker-Planck equation that characterizes the evolution of probability density function, which may be of independent theoretical interest.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CT7Q3RZ2/Wu et al. - 2024 - Theoretical insights for diffusion guidance A case study for Gaussian mixture models.pdf}
}

@article{wu_vdbgpdf_2025,
  title = {{{VDB-GPDF}}: {{Online Gaussian Process Distance Field With VDB Structure}}},
  shorttitle = {{{VDB-GPDF}}},
  author = {Wu, Lan and Le Gentil, Cedric and {Vidal-Calleja}, Teresa},
  year = {2025},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {1},
  pages = {374--381},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3505814},
  url = {https://ieeexplore.ieee.org/document/10766672/?arnumber=10766672},
  urldate = {2024-12-19},
  abstract = {Robots reason about the environment through dedicated representations. Popular choices for dense representations exploit Truncated Signed Distance Functions (TSDF) and Octree data structures. However, TSDF provides a projective or non-projective signed distance obtained directly from depth measurements that overestimate the Euclidean distance. Octrees, despite being memory efficient, require tree traversal and can lead to increased runtime in large scenarios. Other representations based on the Gaussian Process (GP) distance fields are appealing due to their probabilistic and continuous nature, but the computational complexity is a concern. In this letter, we present an online efficient mapping framework that seamlessly couples GP distance fields and the fast-access OpenVDB data structure. The key aspect is a latent Local GP Signed Distance Field (L-GPDF) contained in a local VDB structure that allows fast queries of the Euclidean distance, surface properties and their uncertainties for arbitrary points in the field of view. Probabilistic fusion is then performed by merging the inferred values of these points into a global VDB structure that is efficiently maintained over time. After fusion, the surface mesh is recovered, and a global GP Signed Distance Field (G-GPDF) is generated and made available for downstream applications to query accurate distance and gradients. A comparison with the state-of-the-art frameworks shows superior efficiency and accuracy of the inferred distance field and comparable reconstruction performance.},
  keywords = {Accuracy,Computational complexity,Euclidean distance,Euclidean distance field,Gaussian process distance field,gradient field,mapping,Memory management,Octrees,OpenVDB,Probabilistic logic,Scalability,Sensors,Uncertainty,Vegetation},
  file = {/Users/kshitijgoel/Zotero/storage/U9434ZLG/Wu et al. - 2025 - VDB-GPDF Online Gaussian Process Distance Field With VDB Structure.pdf;/Users/kshitijgoel/Zotero/storage/BHW9KRNJ/10766672.html}
}

@article{wynne_fundamental_2022,
  title = {Fundamental {{Science}} and {{Engineering Questions}} in {{Planetary Cave Exploration}}},
  author = {Wynne, J. Judson and Titus, Timothy N. and {Agha-Mohammadi}, Ali-akbar and {Azua-Bustos}, Armando and Boston, Penelope J. and {de Le{\'o}n}, Pablo and {Demirel-Floyd}, Cansu and De Waele, Jo and Jones, Heather and Malaska, Michael J. and Miller, Ana Z. and Sapers, Haley M. and Sauro, Francesco and Sonderegger, Derek L. and Uckert, Kyle and Wong, Uland Y. and Alexander Jr., E. Calvin and Chiao, Leroy and Cushing, Glen E. and DeDecker, John and Fair{\'e}n, Alberto G. and Frumkin, Amos and Harris, Gary L. and Kearney, Michelle L. and Kerber, Laura and L{\'e}veill{\'e}, Richard J. and Manyapu, Kavya and Massironi, Matteo and Mylroie, John E. and Onac, Bogdan P. and Parazynski, Scott E. and {Phillips-Lander}, Charity M. and Prettyman, Thomas H. and {Schulze-Makuch}, Dirk and Wagner, Robert V. and Whittaker, William L. and Williams, Kaj E.},
  year = {2022},
  journal = {Journal of Geophysical Research: Planets},
  volume = {127},
  number = {11},
  pages = {e2022JE007194},
  issn = {2169-9100},
  doi = {10.1029/2022JE007194},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2022JE007194},
  urldate = {2023-03-27},
  abstract = {Nearly half a century ago, two papers postulated the likelihood of lunar lava tube caves using mathematical models. Today, armed with an array of orbiting and fly-by satellites and survey instrumentation, we have now acquired cave data across our solar system---including the identification of potential cave entrances on the Moon, Mars, and at least nine other planetary bodies. These discoveries gave rise to the study of planetary caves. To help advance this field, we leveraged the expertise of an interdisciplinary group to identify a strategy to explore caves beyond Earth. Focusing primarily on astrobiology, the cave environment, geology, robotics, instrumentation, and human exploration, our goal was to produce a framework to guide this subdiscipline through at least the next decade. To do this, we first assembled a list of 198 science and engineering questions. Then, through a series of social surveys, 114 scientists and engineers winnowed down the list to the top 53 highest priority questions. This exercise resulted in identifying emerging and crucial research areas that require robust development to ultimately support a robotic mission to a planetary cave---principally the Moon and/or Mars. With the necessary financial investment and institutional support, the research and technological development required to achieve these necessary advancements over the next decade are attainable. Subsequently, we will be positioned to robotically examine lunar caves and search for evidence of life within Martian caves; in turn, this will set the stage for human exploration and potential habitation of both the lunar and Martian subsurface.},
  langid = {english},
  keywords = {horizon scan,human exploration,robotic exploration},
  file = {/Users/kshitijgoel/Zotero/storage/S4QF77JL/Wynne et al. - 2022 - Fundamental Science and Engineering Questions in P.pdf;/Users/kshitijgoel/Zotero/storage/FX5VCW9C/2022JE007194.html}
}

@article{wynne_planetary_2022,
  title = {Planetary {{Caves}}: {{A Solar System View}} of {{Processes}} and {{Products}}},
  shorttitle = {Planetary {{Caves}}},
  author = {Wynne, J. Judson and Mylroie, John E. and Titus, Timothy N. and Malaska, Michael J. and Buczkowski, Debra L. and Buhler, Peter B. and Byrne, Paul K. and Cushing, Glen E. and Davies, Ashley Gerard and Frumkin, Amos and Hansen-Koharcheck, Candice and Hiatt, Victoria and Hofgartner, Jason D. and Hoogenboom, Trudi and Horodyskyj, Ulyana and Hughson, Kynan and Kerber, Laura and Landis, Margaret and Leonard, Erin J. and Lesage, Elodie and Lucchetti, Alice and Massironi, Matteo and Mitchell, Karl L. and Penasa, Luca and Phillips, Cynthia B. and Pozzobon, Riccardo and Radebaugh, Jani and Sauro, Francesco and Wagner, Robert V. and Watters, Thomas R.},
  year = {2022},
  month = nov,
  journal = {Journal of Geophysical Research: Planets},
  volume = {127},
  number = {11},
  pages = {e2022JE007303},
  issn = {2169-9097, 2169-9100},
  doi = {10.1029/2022JE007303},
  url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022JE007303},
  urldate = {2024-02-01},
  abstract = {Abstract             We provide the first solar system wide compendium of speleogenic processes and products. An examination of 15 solar system bodies revealed that six cave-forming processes occur beyond Earth including volcanic (cryo and magmatic), fracturing (tectonic and impact melt), dissolution, sublimation, suffusion, and landslides. Although no caves (i.e., confirmed entrances with associated linear passages) have been confirmed, 3,545 SAPs (subsurface access points) have been identified on 11 planetary bodies and the potential for speleogenic processes (and thus SAPs) was observed on an additional four planetary bodies. The bulk of our knowledge on extraterrestrial SAPs is based on global databases for the Moon and Mars, which are bodies for which high-resolution imagery and other data are available. To further characterize most of the features beyond the Moon and Mars, acquisition (preferably global coverage) and subsequent analysis of high-resolution imagery will be required. The next few decades hold considerable promise for further identifying~and characterizing~caves across the solar system.           ,              Plain Language Summary             Until the last two decades, the potential for caves beyond Earth was principally theoretical. Today, databases of subsurface access points (SAPs) exist for the Moon and Mars. Across the solar system, 3,545 SAPs have been identified on 11 planetary bodies with speleogenic processes identified on another four bodies. Six cave-forming processes beyond Earth have been identified; these include volcanic (cryo and magmatic), fracturing (tectonic and impact melt), dissolution, sublimation, suffusion, and landslides. As more orbiter and fly by platforms with high-resolution instrumentation probe the solar system, our knowledge regarding caves beyond Earth will become more robust---culminating with the robotic and perhaps human exploration of caves on the Moon and Mars.           ,              Key Points                                                                Six speleogenic processes have been identified across the solar system                                                     Two speleogenic processes were documented---which are driven by different fluids than on Earth---cryovolcanism and methane-based dissolution                                                     At least 3,545 subsurface access points have been identified on 11 planetary bodies with speleogenic processes observed on an additional four bodies},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/RW7528JQ/Wynne et al. - 2022 - Planetary Caves A Solar System View of Processes .pdf}
}

@inproceedings{xanthidis_aquavis_2021,
  title = {{{AquaVis}}: {{A Perception-Aware Autonomous Navigation Framework}} for {{Underwater Vehicles}}},
  shorttitle = {{{AquaVis}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Xanthidis, Marios and Kalaitzakis, Michail and Karapetyan, Nare and Johnson, James and Vitzilaios, Nikolaos and O'Kane, Jason M. and Rekleitis, Ioannis},
  year = {2021},
  month = sep,
  pages = {5410--5417},
  issn = {2153-0866},
  doi = {10.1109/IROS51168.2021.9636124},
  abstract = {Visual monitoring operations underwater require both observing the objects of interest in close-proximity, and tracking the few feature-rich areas necessary for state estimation. This paper introduces the first navigation framework, called AquaVis, that produces on-line visibility-aware motion plans that enable Autonomous Underwater Vehicles (AUVs) to track multiple visual objectives with an arbitrary camera configuration in real-time. Using the proposed pipeline, AUVs can efficiently move in 3D, reach their goals while avoiding obstacles safely, and maximizing the visibility of multiple objectives along the path within a specified proximity. The method is sufficiently fast to be executed in real-time and is suitable for single or multiple camera configurations. Experimental results show the significant improvement on tracking multiple automatically-extracted points of interest, with low computational overhead and fast re-planning times.Accompanying short video: https://youtu.be/JKO bbrIZyU},
  keywords = {Autonomous underwater vehicles,Cameras,Pipelines,Three-dimensional displays,Tracking,Underwater structures,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/2BVAJNNC/Xanthidis et al. - 2021 - AquaVis A Perception-Aware Autonomous Navigation .pdf}
}

@inproceedings{xanthidis_mapping_2023,
  title = {Towards {{Mapping}} of~{{Underwater Structures}} by~a~{{Team}} of~{{Autonomous Underwater Vehicles}}},
  booktitle = {Robotics {{Research}}},
  author = {Xanthidis, Marios and Joshi, Bharat and Roznere, Monika and Wang, Weihan and Burgdorfer, Nathaniel and Li, Alberto Quattrini and Mordohai, Philippos and Nelakuditi, Srihari and Rekleitis, Ioannis},
  editor = {Billard, Aude and Asfour, Tamim and Khatib, Oussama},
  year = {2023},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {170--185},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-25555-7_12},
  abstract = {In this paper, we discuss how to effectively map an underwater structure with a team of robots considering the specific challenges posed by the underwater environment. The overarching goal of this work is to produce high-definition, accurate, photorealistic representation of underwater structures. Due to the many limitations of vision underwater, operating at a distance from the structure results in degraded images that lack details, while operating close to the structure increases the accumulated uncertainty due to the limited viewing area which causes drifting. We propose a multi-robot mapping framework that utilizes two types of robots: proximal observers which map close to the structure and distal observers which provide localization for proximal observers and bird's-eye-view situational awareness. The paper presents the fundamental components and related current results from real shipwrecks and simulations necessary to enable the proposed framework, including robust state estimation, real-time 3D mapping, and active perception navigation strategies for the two types of robots. Then, the paper outlines interesting research directions and plans to have a completely integrated framework that allows robots to map in harsh environments.},
  isbn = {978-3-031-25555-7},
  langid = {english},
  keywords = {Localization,Mapping,Multi-robot,Navigation,Underwater},
  file = {/Users/kshitijgoel/Zotero/storage/J834MGIJ/Xanthidis et al. - 2023 - Towards Mapping of Underwater Structures by a Team.pdf}
}

@article{xia_quadric_2023,
  title = {Quadric {{Representations}} for {{LiDAR Odometry}}, {{Mapping}} and {{Localization}}},
  author = {Xia, Chao and Xu, Chenfeng and Rim, Patrick and Ding, Mingyu and Zheng, Nanning and Keutzer, Kurt and Tomizuka, Masayoshi and Zhan, Wei},
  year = {2023},
  month = aug,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {8},
  pages = {5023--5030},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3290510},
  url = {https://ieeexplore.ieee.org/document/10167749/},
  urldate = {2024-03-13},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AHQR4NB2/Xia et al. - 2023 - Quadric Representations for LiDAR Odometry, Mappin.pdf}
}

@misc{xiang_structured_2024,
  title = {Structured {{3D Latents}} for {{Scalable}} and {{Versatile 3D Generation}}},
  author = {Xiang, Jianfeng and Lv, Zelong and Xu, Sicheng and Deng, Yu and Wang, Ruicheng and Zhang, Bowen and Chen, Dong and Tong, Xin and Yang, Jiaolong},
  year = {2024},
  month = dec,
  number = {arXiv:2412.01506},
  eprint = {2412.01506},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.01506},
  url = {http://arxiv.org/abs/2412.01506},
  urldate = {2024-12-23},
  abstract = {We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a sparsely-populated 3D grid with dense multiview visual features extracted from a powerful vision foundation model, comprehensively capturing both structural (geometry) and textural (appearance) information while maintaining flexibility during decoding. We employ rectified flow transformers tailored for SLAT as our 3D generation models and train models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. Our model generates high-quality results with text or image conditions, significantly surpassing existing methods, including recent ones at similar scales. We showcase flexible output format selection and local 3D editing capabilities which were not offered by previous models. Code, model, and data will be released.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/NGSHGRM4/Xiang et al. - 2024 - Structured 3D Latents for Scalable and Versatile 3D Generation.pdf;/Users/kshitijgoel/Zotero/storage/MW52HRWM/2412.html}
}

@misc{xiao_visionbased_2024,
  title = {Vision-Based {{Learning}} for {{Drones}}: {{A Survey}}},
  shorttitle = {Vision-Based {{Learning}} for {{Drones}}},
  author = {Xiao, Jiaping and Zhang, Rangya and Zhang, Yuhang and Feroskhan, Mir},
  year = {2024},
  month = jan,
  number = {arXiv:2312.05019},
  eprint = {2312.05019},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.05019},
  url = {http://arxiv.org/abs/2312.05019},
  urldate = {2024-12-17},
  abstract = {Drones as advanced cyber-physical systems are undergoing a transformative shift with the advent of vision-based learning, a field that is rapidly gaining prominence due to its profound impact on drone autonomy and functionality. Different from existing task-specific surveys, this review offers a comprehensive overview of vision-based learning in drones, emphasizing its pivotal role in enhancing their operational capabilities under various scenarios. We start by elucidating the fundamental principles of vision-based learning, highlighting how it significantly improves drones' visual perception and decision-making processes. We then categorize vision-based control methods into indirect, semi-direct, and end-to-end approaches from the perception-control perspective. We further explore various applications of vision-based drones with learning capabilities, ranging from single-agent systems to more complex multi-agent and heterogeneous system scenarios, and underscore the challenges and innovations characterizing each area. Finally, we explore open questions and potential solutions, paving the way for ongoing research and development in this dynamic and rapidly evolving field. With growing large language models (LLMs) and embodied intelligence, vision-based learning for drones provides a promising but challenging road towards artificial general intelligence (AGI) in 3D physical world.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/VCN8BH5M/Xiao et al. - 2024 - Vision-based Learning for Drones A Survey.pdf;/Users/kshitijgoel/Zotero/storage/KAU8WYDD/2312.html}
}

@phdthesis{xie_discovering_2021,
  title = {Discovering and {{Segmenting Unseen Objects}} for {{Robot Perception}}},
  author = {Xie, Christopher},
  year = {2021},
  address = {United States -- Washington},
  url = {https://www.proquest.com/docview/2592322074/abstract/370459849DD84610PQ/1},
  urldate = {2024-06-23},
  abstract = {Perception lies at the core of the ability of a robot to function in the real world. As robots become more ubiquitously deployed in unstructured environments such as homes and offices, it is inevitable that robots will en- counter objects that they have not observed before. Thus, in order to interact effectively with such environments, building a robust object recognition module of unseen objects is valuable. Additionally, it can facilitate down- stream tasks including grasping, re-arrangement, and sorting of unseen objects. This is a challenging perception task since the robot needs to learn the concept of ``objects'' and generalize it to unseen objects. In this thesis, we propose different methods for learning such perception systems by exploiting different visual cues and learning data without manual annotations. First, we investigate the use of motion cues for this problem. We develop a novel neural network architecture, PT-RNN, that leverages optical flow by casting the problem as object discovery via foreground motion clustering from videos. This network learns to produce pixel-trajectory embeddings such that clustering them results in segmenting the unseen objects into different instance masks. Next, we introduce UOIS-Net, which separately leverages RGB and depth for unseen object instance segmentation. UOIS-Net is able to learn from synthetic RGB-D data where the RGB is non-photorealistic, and provides state-of-the-art unseen object instance segmentation results in tabletop environments, which are common to robot manipulation. Lastly, we investigate the use of relational inductive biases in the form of graph neural networks in order to better segment unseen object instances. We introduce a novel framework, RICE, that refines a provided instance segmentation by utilizing a graph-based representation. We conclude with a discussion of the proposed work and future directions, which includes a vision of future research that leverages the proposed work to bootstrap a lifelong learning mechanism that renders unseen objects as no longer unseen.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9798480680386},
  langid = {english},
  school = {University of Washington},
  keywords = {Robot perception,Synthetic RGB-D data,Unseen objects},
  file = {/Users/kshitijgoel/Zotero/storage/WRAYIQ6P/Xie - 2021 - Discovering and Segmenting Unseen Objects for Robot Perception.pdf}
}

@misc{xie_gaussmi_2025,
  title = {{{GauSS-MI}}: {{Gaussian Splatting Shannon Mutual Information}} for {{Active 3D Reconstruction}}},
  shorttitle = {{{GauSS-MI}}},
  author = {Xie, Yuhan and Cai, Yixi and Zhang, Yinqiang and Yang, Lei and Pan, Jia},
  year = {2025},
  month = apr,
  number = {arXiv:2504.21067},
  eprint = {2504.21067},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.21067},
  url = {http://arxiv.org/abs/2504.21067},
  urldate = {2025-07-16},
  abstract = {This research tackles the challenge of real-time active view selection and uncertainty quantification on visual quality for active 3D reconstruction. Visual quality is a critical aspect of 3D reconstruction. Recent advancements such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have notably enhanced the image rendering quality of reconstruction models. Nonetheless, the efficient and effective acquisition of input images for reconstruction-specifically, the selection of the most informative viewpoint-remains an open challenge, which is crucial for active reconstruction. Existing studies have primarily focused on evaluating geometric completeness and exploring unobserved or unknown regions, without direct evaluation of the visual uncertainty within the reconstruction model. To address this gap, this paper introduces a probabilistic model that quantifies visual uncertainty for each Gaussian. Leveraging Shannon Mutual Information, we formulate a criterion, Gaussian Splatting Shannon Mutual Information (GauSS-MI), for real-time assessment of visual mutual information from novel viewpoints, facilitating the selection of next best view. GauSS-MI is implemented within an active reconstruction system integrated with a view and motion planner. Extensive experiments across various simulated and real-world scenes showcase the superior visual quality and reconstruction efficiency performance of the proposed system.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/48Q5SHXA/Xie et al. - 2025 - GauSS-MI Gaussian Splatting Shannon Mutual Information for Active 3D Reconstruction.pdf;/Users/kshitijgoel/Zotero/storage/P749A8CF/2504.html}
}

@misc{xing_stabilizing_2025,
  title = {Stabilizing {{Reinforcement Learning}} in {{Differentiable Multiphysics Simulation}}},
  author = {Xing, Eliot and Luk, Vernon and Oh, Jean},
  year = {2025},
  month = feb,
  number = {arXiv:2412.12089},
  eprint = {2412.12089},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.12089},
  url = {http://arxiv.org/abs/2412.12089},
  urldate = {2025-07-15},
  abstract = {Recent advances in GPU-based parallel simulation have enabled practitioners to collect large amounts of data and train complex control policies using deep reinforcement learning (RL), on commodity GPUs. However, such successes for RL in robotics have been limited to tasks sufficiently simulated by fast rigid-body dynamics. Simulation techniques for soft bodies are comparatively several orders of magnitude slower, thereby limiting the use of RL due to sample complexity requirements. To address this challenge, this paper presents both a novel RL algorithm and a simulation platform to enable scaling RL on tasks involving rigid bodies and deformables. We introduce Soft Analytic Policy Optimization (SAPO), a maximum entropy first-order model-based actor-critic RL algorithm, which uses first-order analytic gradients from differentiable simulation to train a stochastic actor to maximize expected return and entropy. Alongside our approach, we develop Rewarped, a parallel differentiable multiphysics simulation platform that supports simulating various materials beyond rigid bodies. We re-implement challenging manipulation and locomotion tasks in Rewarped, and show that SAPO outperforms baselines over a range of tasks that involve interaction between rigid bodies, articulations, and deformables. Additional details at https://rewarped.github.io/.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/6LRAY9AZ/Xing et al. - 2025 - Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation.pdf;/Users/kshitijgoel/Zotero/storage/I4B39M9M/2412.html}
}

@article{xu_autonomous_2021,
  title = {Autonomous {{UAV Exploration}} of {{Dynamic Environments Via Incremental Sampling}} and {{Probabilistic Roadmap}}},
  author = {Xu, Zhefan and Deng, Di and Shimada, Kenji},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {2729--2736},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3062008},
  abstract = {Autonomous exploration requires robots to generate informative trajectories iteratively. Although sampling-based methods are highly efficient in unmanned aerial vehicle exploration, many of these methods do not effectively utilize the sampled information from the previous planning iterations, leading to redundant computation and longer exploration time. Also, few have explicitly shown their exploration ability in dynamic environments even though they can run real-time. To overcome these limitations, we propose a novel dynamic exploration planner (DEP) for exploring unknown environments using incremental sampling and Probabilistic Roadmap (PRM). In our sampling strategy, nodes are added incrementally and distributed evenly in the explored region, yielding the best viewpoints. To further shortening exploration time and ensuring safety, our planner optimizes paths locally and refine them based on the Euclidean Signed Distance Function (ESDF) map. Meanwhile, as the multi-query planner, PRM allows the proposed planner to quickly search alternative paths to avoid dynamic obstacles for safe exploration. Simulation experiments show that our method safely explores dynamic environments and outperforms the benchmark planners in terms of exploration time, path length, and computational time.},
  keywords = {Collision avoidance,Mapping,motion and path planning,Planning,Robot sensing systems,Robots,search and rescue robots,Trajectory,unmanned aerial vehicle,Unmanned aerial vehicles,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/RVQ4DDUD/Xu et al. - 2021 - Autonomous UAV Exploration of Dynamic Environments.pdf;/Users/kshitijgoel/Zotero/storage/WSSFRL6H/9362184.html}
}

@article{xu_care_2023,
  title = {{{CARE}}: {{Confidence-rich Autonomous Robot Exploration}} Using {{Bayesian Kernel Inference}} and {{Optimization}}},
  shorttitle = {{{CARE}}},
  author = {Xu, Yang and Zheng, Ronghao and Zhang, Senlin and Liu, Meiqin and Huang, Shoudong},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3313054},
  abstract = {In this paper, we consider improving the efficiency of information-based autonomous robot exploration in unknown and complex environments. We first utilize Gaussian process (GP) regression to learn a surrogate model to infer the confidence-rich mutual information (CRMI) of querying control actions, then adopt an objective function consisting of predicted CRMI values and prediction uncertainties to conduct Bayesian optimization (BO), i.e., GP-based BO (GPBO). The trade-off between the best action with the highest CRMI value (exploitation) and the action with high prediction variance (exploration) can be realized. To further improve the efficiency of GPBO, we propose a novel lightweight information gain inference method based on Bayesian kernel inference and optimization (BKIO), achieving an approximate logarithmic complexity without the need for training. BKIO can also infer the CRMI and generate the best action using BO with bounded cumulative regret, which ensures its comparable accuracy to GPBO with much higher efficiency. Extensive numerical and real-world experiments show the desired efficiency of our proposed methods without losing exploration performance in different unstructured, cluttered environments. We also provide our open-source implementation code at https://github.com/Shepherd-Gregory/BKIO-Exploration.},
  keywords = {Bayes methods,Information theory,Kernel,Optimization,probabilistic inference,range sensing,reactive and sensor-based planning,Robot sensing systems,Robots,Uncertainty,View planning for SLAM},
  file = {/Users/kshitijgoel/Zotero/storage/HGNUMY6U/Xu et al. - 2023 - CARE Confidence-rich Autonomous Robot Exploration.pdf;/Users/kshitijgoel/Zotero/storage/U6BVYU9M/10243037.html}
}

@misc{xu_communication_2024,
  title = {Communication- and {{Computation-Efficient Distributed Decision-Making}} in {{Multi-Robot Networks}}},
  author = {Xu, Zirui and Garimella, Sandilya Sai and Tzoumas, Vasileios},
  year = {2024},
  month = jul,
  number = {arXiv:2407.10382},
  eprint = {2407.10382},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.10382},
  url = {http://arxiv.org/abs/2407.10382},
  urldate = {2024-12-11},
  abstract = {We provide a distributed coordination paradigm that enables scalable and near-optimal joint motion planning among multiple robots. Our coordination paradigm contrasts with current paradigms that are either near-optimal but impractical for replanning times or real-time but offer no near-optimality guarantees. We are motivated by the future of collaborative mobile autonomy, where distributed teams of robots will coordinate via vehicle-to-vehicle (v2v) communication to execute information-heavy tasks like mapping, surveillance, and target tracking. To enable rapid distributed coordination, we must curtail the explosion of information-sharing across the network, thus limiting robot coordination. However, this can lead to suboptimal plans, causing overlapping trajectories instead of complementary ones. We make theoretical and algorithmic contributions to balance the trade-off between decision speed and optimality. We introduce tools for distributed submodular optimization, a diminishing returns property in information-gathering tasks. Theoretically, we analyze how local network topology affects near-optimality at the global level. Algorithmically, we provide a communication- and computation-efficient coordination algorithm for agents to balance the trade-off. Our algorithm is up to two orders faster than competitive near-optimal algorithms. In simulations of surveillance tasks with up to 45 robots, it enables real-time planning at the order of 1 Hz with superior coverage performance. To enable the simulations, we provide a high-fidelity simulator that extends AirSim by integrating a collaborative autonomy pipeline and simulating v2v communication delays.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
  file = {/Users/kshitijgoel/Zotero/storage/XKII34KI/Xu et al. - 2024 - Communication- and Computation-Efficient Distributed Decision-Making in Multi-Robot Networks.pdf;/Users/kshitijgoel/Zotero/storage/WXH8RBJB/2407.html}
}

@article{xu_convergence_1996,
  title = {On {{Convergence Properties}} of the {{EM Algorithm}} for {{Gaussian Mixtures}}},
  author = {Xu, Lei and Jordan, Michael I.},
  year = {1996},
  month = jan,
  journal = {Neural Computation},
  volume = {8},
  number = {1},
  pages = {129--151},
  issn = {0899-7667},
  doi = {10.1162/neco.1996.8.1.129},
  url = {https://doi.org/10.1162/neco.1996.8.1.129},
  urldate = {2023-04-27},
  abstract = {We build up the mathematical connection between the ``Expectation-Maximization'' (EM) algorithm and gradient-based approaches for maximum likelihood learning of finite gaussian mixtures. We show that the EM step in parameter space is obtained from the gradient via a projection matrix P, and we provide an explicit expression for the matrix. We then analyze the convergence of EM in terms of special properties of P and provide new results analyzing the effect that P has on the likelihood surface. Based on these mathematical results, we present a comparative discussion of the advantages and disadvantages of EM and other algorithms for the learning of gaussian mixture models.},
  file = {/Users/kshitijgoel/Zotero/storage/5QHRRS22/Xu and Jordan - 1996 - On Convergence Properties of the EM Algorithm for .pdf}
}

@article{xu_d2slam_2024,
  title = {D{\textsuperscript{2}}{{SLAM}}: {{Decentralized}} and {{Distributed Collaborative Visual-Inertial SLAM System}} for {{Aerial Swarm}}},
  shorttitle = {D{\textsuperscript{2}}{{SLAM}}},
  author = {Xu, Hao and Liu, Peize and Chen, Xinyi and Shen, Shaojie},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {3445--3464},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3422003},
  url = {https://ieeexplore.ieee.org/document/10582478/?arnumber=10582478},
  urldate = {2024-11-14},
  abstract = {Collaborative simultaneous localization and mapping (CSLAM) is essential for autonomous aerial swarms, laying the foundation for downstream algorithms, such as planning and control. To address existing CSLAM systems' limitations in relative localization accuracy, crucial for close-range UAV collaboration, this article introduces D\textsuperscript{2}SLAM---a novel decentralized and distributed CSLAM system. D\textsuperscript{2}SLAM innovatively manages near-field estimation for precise relative state estimation in proximity and far-field estimation for consistent global trajectories. Its adaptable front-end supports both stereo and omnidirectional cameras, catering to various operational needs and overcoming field-of-view challenges in aerial swarms. Experiments demonstrate D\textsuperscript{2}SLAM's effectiveness in accurate ego-motion estimation, relative localization, and global consistency. Enhanced by distributed optimization algorithms, D\textsuperscript{2}SLAM exhibits remarkable scalability and resilience to network delays, making it well suited for a wide range of real-world aerial swarm applications. We believe the adaptability and proven performance of D\textsuperscript{2}SLAM signify a notable advancement in autonomous aerial swarm technology.},
  keywords = {Accuracy,Aerial systems: perception and autonomy,Location awareness,multirobot systems,Optimization,Robots,Simultaneous localization and mapping,simultaneous localization and mapping (SLAM),State estimation,swarms,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/QMPH26FA/Xu et al. - 2024 - D2SLAM Decentralized and Distributed Collaborative Visual-Inertial SLAM System for Aeria.pdf;/Users/kshitijgoel/Zotero/storage/ZRD8ZSYL/10582478.html}
}

@misc{xu_depthsplat_2025,
  title = {{{DepthSplat}}: {{Connecting Gaussian Splatting}} and {{Depth}}},
  shorttitle = {{{DepthSplat}}},
  author = {Xu, Haofei and Peng, Songyou and Wang, Fangjinhua and Blum, Hermann and Barath, Daniel and Geiger, Andreas and Pollefeys, Marc},
  year = {2025},
  month = mar,
  number = {arXiv:2410.13862},
  eprint = {2410.13862},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.13862},
  url = {http://arxiv.org/abs/2410.13862},
  urldate = {2025-06-03},
  abstract = {Gaussian splatting and single-view depth estimation are typically studied in isolation. In this paper, we present DepthSplat to connect Gaussian splatting and depth estimation and study their interactions. More specifically, we first contribute a robust multi-view depth model by leveraging pre-trained monocular depth features, leading to high-quality feed-forward 3D Gaussian splatting reconstructions. We also show that Gaussian splatting can serve as an unsupervised pre-training objective for learning powerful depth models from large-scale multi-view posed datasets. We validate the synergy between Gaussian splatting and depth estimation through extensive ablation and cross-task transfer experiments. Our DepthSplat achieves state-of-the-art performance on ScanNet, RealEstate10K and DL3DV datasets in terms of both depth estimation and novel view synthesis, demonstrating the mutual benefits of connecting both tasks. In addition, DepthSplat enables feed-forward reconstruction from 12 input views (512x960 resolutions) in 0.6 seconds.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/7XNYSSZ3/Xu et al. - 2025 - DepthSplat Connecting Gaussian Splatting and Depth.pdf;/Users/kshitijgoel/Zotero/storage/A9N2CNCC/2410.html}
}

@inproceedings{xu_game_2021,
  title = {{{GAME}}: {{Gaussian Mixture Model Mapping}} and {{Navigation Engine}} on {{Embedded FPGA}}},
  shorttitle = {{{GAME}}},
  booktitle = {2021 {{IEEE}} 29th {{Annual International Symposium}} on {{Field-Programmable Custom Computing Machines}} ({{FCCM}})},
  author = {Xu, Yuanfan and Zhang, Zhaoliang and Yu, Jincheng and Cao, Jianfei and Dong, Haolin and Huang, Zhengfeng and Wang, Yu and Yang, Huazhong},
  year = {2021},
  month = may,
  pages = {60--68},
  issn = {2576-2621},
  doi = {10.1109/FCCM51124.2021.00015},
  abstract = {3D mapping is a fundamental task in robot applications. The traditional mapping methods mainly rely on spatial discretization, in which the amount of data that needs to be stored is large, and the representation ability is limited. As a continuous probability model, the Gaussian Mixture Model (GMM) has a small memory footprint and high-fidelity representation ability. Thus the GMM map is superior to discrete map representations in basic robot tasks such as navigation and localization. The general method of building GMM maps is the iterative Expectation-Maximization (EM) algorithm with K-means initialization. The EM and K-means algorithms are computation-intensive, making it challenging to meet real-time 30 fps mapping requirements on the embedded robot systems. This paper proposes a Gaussian mixture model mapping and navigation engine (GAME) on embedded FPGA to accelerate the mapping process. To achieve fully pipelined with minimal hardware resource cost, we design a unified dataflow and hardware architecture for both K-means and EM for GMM. We analyze different quantization strategies for higher parallelism and find a low-bit quantization method with mixed 8/16-bit data representation, bringing negligible loss in accuracy. Combining the unified dataflow and the mixed-bit data quantization, GAME enables real-time GMM mapping and navigation on embedded robots. The experimental results on ZCU102 show that our proposed hardware-software co-optimization framework on FPGA can run over 60{\texttimes} faster than on a GeForce 1080Ti GPU and over 490{\texttimes} faster than on an Nvidia Jetson TX2, and achieves 59 fps.},
  keywords = {data quantization,FPGA accelerator,Games,Gaussian Mixture Model,Hardware,mapping and navigation,Navigation,Quantization (signal),Real-time systems,Robots,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/GWUND75D/Xu et al. - 2021 - GAME Gaussian Mixture Model Mapping and Navigatio.pdf}
}

@misc{xu_hgsplanner_2024,
  title = {{{HGS-Planner}}: {{Hierarchical Planning Framework}} for {{Active Scene Reconstruction Using 3D Gaussian Splatting}}},
  shorttitle = {{{HGS-Planner}}},
  author = {Xu, Zijun and Jin, Rui and Wu, Ke and Zhao, Yi and Zhang, Zhiwei and Zhao, Jieru and Gan, Zhongxue and Ding, Wenchao},
  year = {2024},
  month = sep,
  number = {arXiv:2409.17624},
  eprint = {2409.17624},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.17624},
  urldate = {2024-09-27},
  abstract = {In complex missions such as search and rescue, robots must make intelligent decisions in unknown environments, relying on their ability to perceive and understand their surroundings. High-quality and real-time reconstruction enhances situational awareness and is crucial for intelligent robotics. Traditional methods often struggle with poor scene representation or are too slow for real-time use. Inspired by the efficacy of 3D Gaussian Splatting (3DGS), we propose a hierarchical planning framework for fast and high-fidelity active reconstruction. Our method evaluates completion and quality gain to adaptively guide reconstruction, integrating global and local planning for efficiency. Experiments in simulated and realworld environments show our approach outperforms existing real-time methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/RLTE44XT/Xu et al. - 2024 - HGS-Planner Hierarchical Planning Framework for Active Scene Reconstruction Using 3D Gaussian Splat.pdf}
}

@misc{xu_intent_2024,
  title = {Intent {{Prediction-Driven Model Predictive Control}} for {{UAV Planning}} and {{Navigation}} in {{Dynamic Environments}}},
  author = {Xu, Zhefan and Jin, Hanyu and Han, Xinming and Shen, Haoyu and Shimada, Kenji},
  year = {2024},
  month = sep,
  number = {arXiv:2409.15633},
  eprint = {2409.15633},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.15633},
  url = {http://arxiv.org/abs/2409.15633},
  urldate = {2024-12-16},
  abstract = {The emergence of indoor aerial robots holds significant potential for enhancing construction site workers' productivity by autonomously performing inspection and mapping tasks. The key challenge to this application is ensuring navigation safety with human workers. While navigation in static environments has been extensively studied, navigating dynamic environments remains open due to challenges in perception and planning. Payload limitations of unmanned aerial vehicles limit them to using cameras with limited fields of view, resulting in unreliable perception and tracking during collision avoidance. Moreover, the unpredictable nature of the dynamic environments can quickly make the generated optimal trajectory outdated. To address these challenges, this paper presents a comprehensive navigation framework that incorporates both perception and planning, introducing the concept of dynamic obstacle intent prediction. Our perception module detects and tracks dynamic obstacles efficiently and handles tracking loss and occlusion during collision avoidance. The proposed intent prediction module employs a Markov Decision Process (MDP) to forecast potential actions of dynamic obstacles with the possible future trajectories. Finally, a novel intent-based planning algorithm, leveraging model predictive control (MPC), is applied to generate safe navigation trajectories. Simulation and physical experiments demonstrate that our method enables safe navigation in dynamic environments and achieves the fewest collisions compared to benchmarks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/Y2JG83ZY/Xu et al. - 2024 - Intent Prediction-Driven Model Predictive Control for UAV Planning and Navigation in Dynamic Environ.pdf;/Users/kshitijgoel/Zotero/storage/UEXCZ43F/2409.html}
}

@misc{xu_navrl_2024,
  title = {{{NavRL}}: {{Learning Safe Flight}} in {{Dynamic Environments}}},
  shorttitle = {{{NavRL}}},
  author = {Xu, Zhefan and Han, Xinming and Shen, Haoyu and Jin, Hanyu and Shimada, Kenji},
  year = {2024},
  month = sep,
  number = {arXiv:2409.15634},
  eprint = {2409.15634},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.15634},
  url = {http://arxiv.org/abs/2409.15634},
  urldate = {2024-12-16},
  abstract = {Safe flight in dynamic environments requires autonomous unmanned aerial vehicles (UAVs) to make effective decisions when navigating cluttered spaces with moving obstacles. Traditional approaches often decompose decision-making into hierarchical modules for prediction and planning. Although these handcrafted systems can perform well in specific settings, they might fail if environmental conditions change and often require careful parameter tuning. Additionally, their solutions could be suboptimal due to the use of inaccurate mathematical model assumptions and simplifications aimed at achieving computational efficiency. To overcome these limitations, this paper introduces the NavRL framework, a deep reinforcement learning-based navigation method built on the Proximal Policy Optimization (PPO) algorithm. NavRL utilizes our carefully designed state and action representations, allowing the learned policy to make safe decisions in the presence of both static and dynamic obstacles, with zero-shot transfer from simulation to real-world flight. Furthermore, the proposed method adopts a simple but effective safety shield for the trained policy, inspired by the concept of velocity obstacles, to mitigate potential failures associated with the black-box nature of neural networks. To accelerate the convergence, we implement the training pipeline using NVIDIA Isaac Sim, enabling parallel training with thousands of quadcopters. Simulation and physical experiments show that our method ensures safe navigation in dynamic environments and results in the fewest collisions compared to benchmarks in scenarios with dynamic obstacles.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/TQA8JHWB/Xu et al. - 2024 - NavRL Learning Safe Flight in Dynamic Environments.pdf;/Users/kshitijgoel/Zotero/storage/FZXRD47F/2409.html}
}

@article{xu_neural_2024,
  title = {Neural {{Feature Learning}} in {{Function Space}}},
  author = {Xu, Xiangxiang and Zheng, Lizhong},
  year = {2024},
  journal = {Journal of Machine Learning Research},
  volume = {25},
  number = {142},
  pages = {1--76},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v25/23-1202.html},
  urldate = {2024-10-15},
  abstract = {We present a novel framework for learning system design with neural feature extractors. First, we introduce the feature geometry, which unifies statistical dependence and feature representations in a function space equipped with inner products. This connection defines function-space concepts on statistical dependence, such as norms, orthogonal projection, and spectral decomposition, exhibiting clear operational meanings. In particular, we associate each learning setting with a dependence component and formulate learning tasks as finding corresponding feature approximations. We propose a nesting technique, which provides systematic algorithm designs for learning the optimal features from data samples with off-the-shelf network architectures and optimizers. We further demonstrate multivariate learning applications, including conditional inference and multimodal learning, where we present the optimal features and reveal their connections to classical approaches.},
  file = {/Users/kshitijgoel/Zotero/storage/DMGS53BU/Xu and Zheng - 2024 - Neural Feature Learning in Function Space.pdf;/Users/kshitijgoel/Zotero/storage/IAVZXG3P/NFE.html}
}

@article{xu_omniswarm_2022,
  title = {Omni-{{Swarm}}: {{A Decentralized Omnidirectional Visual}}--{{Inertial}}--{{UWB State Estimation System}} for {{Aerial Swarms}}},
  shorttitle = {Omni-{{Swarm}}},
  author = {Xu, Hao and Zhang, Yichen and Zhou, Boyu and Wang, Luqi and Yao, Xinjie and Meng, Guotao and Shen, Shaojie},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--21},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3182503},
  abstract = {Decentralized state estimation is one of the most fundamental components of autonomous aerial swarm systems in GPS-denied areas; yet, it remains a highly challenging research topic. Omni-swarm, a decentralized omnidirectional visual--inertial--ultrawideband (UWB) state estimation system for aerial swarms, is proposed in this article to address this research niche. To solve the issues of observability, complicated initialization, insufficient accuracy, and lack of global consistency, we introduce an omnidirectional perception front end in Omni-swarm. It consists of stereo wide-field-of-view cameras and UWB sensors, visual--inertial odometry, multidrone map-based localization, and visual drone tracking algorithms. The measurements from the front end are fused with graph-based optimization in the back end. The proposed method achieves centimeter-level relative state estimation accuracy while guaranteeing global consistency in the aerial swarm, as evidenced by the experimental results. Moreover, supported by Omni-swarm, interdrone collision avoidance can be accomplished without any external devices, demonstrating the potential of Omni-swarm as the foundation of autonomous aerial swarms.},
  keywords = {Aerial systems,Cameras,Drones,Estimation,Location awareness,multirobot systems,Observability,perception and autonomy,sensor fusion,State estimation,swarms,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/4SUINCZS/Xu et al. - 2022 - Omni-Swarm A Decentralized Omnidirectional Visual.pdf;/Users/kshitijgoel/Zotero/storage/G9DRAPQG/9813359.html}
}

@article{xu_onboard_2024,
  title = {Onboard {{Dynamic-Object Detection}} and {{Tracking}} for {{Autonomous Robot Navigation With RGB-D Camera}}},
  author = {Xu, Zhefan and Zhan, Xiaoyang and Xiu, Yumeng and Suzuki, Christopher and Shimada, Kenji},
  year = {2024},
  month = jan,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {1},
  pages = {651--658},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3334683},
  url = {https://ieeexplore.ieee.org/document/10323166/?arnumber=10323166},
  urldate = {2024-12-16},
  abstract = {Deploying autonomous robots in crowded indoor environments usually requires them to have accurate dynamic obstacle perception. Although plenty of previous works in the autonomous driving field have investigated the 3D object detection problem, the usage of dense point clouds from a heavy Light Detection and Ranging (LiDAR) sensor and their high computation cost for learning-based data processing make those methods not applicable to small robots, such as vision-based UAVs with small onboard computers. To address this issue, we propose a lightweight 3D dynamic obstacle detection and tracking (DODT) method based on an RGB-D camera, which is designed for low-power robots with limited computing power. Our method adopts a novel ensemble detection strategy, combining multiple computationally efficient but low-accuracy detectors to achieve real-time high-accuracy obstacle detection. Besides, we introduce a new feature-based data association and tracking method to prevent mismatches utilizing point clouds' statistical features. In addition, our system includes an optional and auxiliary learning-based module to enhance the obstacle detection range and dynamic obstacle identification. The proposed method is implemented in a small quadcopter, and the results show that our method can achieve the lowest position error (0.11 m) and a comparable velocity error (0.23 m/s) across the benchmarking algorithms running on the robot's onboard computer. The flight experiments prove that the tracking results from the proposed method can make the robot efficiently alter its trajectory for navigating dynamic environments. Our software is available on GitHub1 as an open-source ROS package.},
  keywords = {3D object detection,Cameras,collision avoidance,Detectors,Heuristic algorithms,Point cloud compression,RGB-D perception,Robot vision systems,Robots,Three-dimensional displays,vision-based navigation,visual tracking},
  file = {/Users/kshitijgoel/Zotero/storage/ENZVAXAQ/Xu et al. - 2024 - Onboard Dynamic-Object Detection and Tracking for Autonomous Robot Navigation With RGB-D Camera.pdf;/Users/kshitijgoel/Zotero/storage/GDRCF9ZT/10323166.html}
}

@misc{xu_quadcopter_2023,
  title = {Quadcopter {{Trajectory Time Minimization}} and {{Robust Collision Avoidance}} via {{Optimal Time Allocation}}},
  author = {Xu, Zhefan and Shimada, Kenji},
  year = {2023},
  month = sep,
  number = {arXiv:2309.08544},
  eprint = {2309.08544},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2309.08544},
  urldate = {2023-09-24},
  abstract = {Autonomous navigation requires robots to generate trajectories for collision avoidance efficiently. Although plenty of previous works have proven successful in generating smooth and spatially collision-free trajectories, their solutions often suffer from suboptimal time efficiency and potential unsafety, particularly when accounting for uncertainties in robot perception and control. To address this issue, this paper presents the Robust Optimal Time Allocation (ROTA) framework. This framework is designed to optimize the time progress of the trajectories temporally, serving as a post-processing tool to enhance trajectory time efficiency and safety under uncertainties. In this study, we begin by formulating a non-convex optimization problem aimed at minimizing trajectory execution time while incorporating constraints on collision probability as the robot approaches obstacles. Subsequently, we introduce the concept of the trajectory braking zone and adopt the chance-constrained formulation for robust collision avoidance in the braking zones. Finally, the non-convex optimization problem is reformulated into a second-order cone programming problem to achieve real-time performance. Through simulations and physical flight experiments, we demonstrate that the proposed approach effectively reduces trajectory execution time while enabling robust collision avoidance in complex environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/Y4H3TF6C/Xu and Shimada - 2023 - Quadcopter Trajectory Time Minimization and Robust.pdf;/Users/kshitijgoel/Zotero/storage/HI5PVA99/2309.html}
}

@inproceedings{xu_realtime_2023,
  title = {A Real-Time Dynamic Obstacle Tracking and Mapping System for {{UAV}} Navigation and Collision Avoidance with an {{RGB-D}} Camera},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Xu, Zhefan and Zhan, Xiaoyang and Chen, Baihan and Xiu, Yumeng and Yang, Chenhao and Shimada, Kenji},
  year = {2023},
  month = may,
  pages = {10645--10651},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10161194},
  url = {https://ieeexplore.ieee.org/document/10161194/},
  urldate = {2023-11-18},
  abstract = {{\DH} The real-time dynamic environment perception has become vital for autonomous robots in crowded spaces. Although the popular voxel-based mapping methods can efficiently represent 3D obstacles with arbitrarily complex shapes, they can hardly distinguish between static and dynamic obstacles, leading to the limited performance of obstacle avoidance. While plenty of sophisticated learning-based dynamic obstacle detection algorithms exist in autonomous driving, the quadcopter's limited computation resources cannot achieve real-time performance using those approaches. To address these issues, we propose a real-time dynamic obstacle tracking and mapping system for quadcopter obstacle avoidance using an RGB-D camera. The proposed system first utilizes a depth image with an occupancy voxel map to generate potential dynamic obstacle regions as proposals. With the obstacle region proposals, the Kalman filter and our continuity filter are applied to track each dynamic obstacle. Finally, the environment-aware trajectory prediction method is proposed based on the Markov chain using the states of tracked dynamic obstacles. We implemented the proposed system with our custom quadcopter and navigation planner. The simulation and physical experiments show that our methods can successfully track and represent obstacles in dynamic environments in real-time and safely avoid obstacles.},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/PS3MKMA6/Xu et al. - 2023 - A real-time dynamic obstacle tracking and mapping .pdf}
}

@article{xu_reproducing_2008,
  title = {A {{Reproducing Kernel Hilbert Space Framework}} for {{Information-Theoretic Learning}}},
  author = {Xu, Jian-Wu and Paiva, Antonio R. C. and Park, Il and Principe, Jose C.},
  year = {2008},
  month = dec,
  journal = {IEEE Transactions on Signal Processing},
  volume = {56},
  number = {12},
  pages = {5891--5902},
  issn = {1941-0476},
  doi = {10.1109/TSP.2008.2005085},
  url = {https://ieeexplore.ieee.org/document/4609923/?arnumber=4609923},
  urldate = {2025-02-27},
  abstract = {This paper provides a functional analysis perspective of information-theoretic learning (ITL) by defining bottom-up a reproducing kernel Hilbert space (RKHS) uniquely determined by the symmetric nonnegative definite kernel function known as the cross-information potential (CIP). The CIP as an integral of the product of two probability density functions characterizes similarity between two stochastic functions. We prove the existence of a one-to-one congruence mapping between the ITL RKHS and the Hilbert space spanned by square integrable probability density functions. Therefore, all the statistical descriptors in the original information-theoretic learning formulation can be rewritten as algebraic computations on deterministic functional vectors in the ITL RKHS, instead of limiting the functional view to the estimators as is commonly done in kernel methods. A connection between the ITL RKHS and kernel approaches interested in quantifying the statistics of the projected data is also established.},
  keywords = {Cross-information potential,Functional analysis,Hilbert space,information-theoretic learning (ITL),Kernel,kernel function,Least squares approximation,probability density function,Probability density function,Random variables,reproducing kernel Hilbert space (RKHS),Signal analysis,Signal detection,Stochastic processes,Surface fitting},
  file = {/Users/kshitijgoel/Zotero/storage/VK7EPHMN/Xu et al. - 2008 - A Reproducing Kernel Hilbert Space Framework for Information-Theoretic Learning.pdf;/Users/kshitijgoel/Zotero/storage/P8L8JKTG/4609923.html}
}

@inproceedings{xu_resourceaware_2022,
  title = {Resource-{{Aware Distributed Submodular Maximization}}: {{A Paradigm}} for {{Multi-Robot Decision-Making}}},
  shorttitle = {Resource-{{Aware Distributed Submodular Maximization}}},
  booktitle = {2022 {{IEEE}} 61st {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Xu, Zirui and Tzoumas, Vasileios},
  year = {2022},
  month = dec,
  pages = {5959--5966},
  issn = {2576-2370},
  doi = {10.1109/CDC51059.2022.9993308},
  abstract = {Multi-robot decision-making is the process where multiple robots coordinate actions. In this paper, we aim for efficient and effective multi-robot decision-making despite the robots' limited on-board resources and the often resource-demanding complexity of their tasks. We introduce the first algorithm enabling the robots to choose with which few other robots to coordinate and provably balance the trade-off of centralized vs. decentralized coordination. Particularly, centralization favors globally near-optimal decision-making but at the cost of increased on-board resource requirements; whereas, decentralization favors minimal resource requirements but at a global suboptimality cost. All robots can thus afford our algorithm, irrespective of their resources. We are motivated by the future of autonomy that involves multiple robots coordinating actions to complete resource-demanding tasks, such as target tracking, area covering, and monitoring. To provide closed-form guarantees, we focus on maximization problems involving monotone and "doubly" submodular functions. To capture the cost of decentralization, we introduce the notion of Centralization Of Information among non-Neighbors (COIN). We validate our algorithm in simulated scenarios of image covering.},
  keywords = {Complexity theory,Costs,Decision making,Memory management,Robot kinematics,Spread spectrum communication,Target tracking},
  file = {/Users/kshitijgoel/Zotero/storage/PCDJB738/Xu and Tzoumas - 2022 - Resource-Aware Distributed Submodular Maximization.pdf;/Users/kshitijgoel/Zotero/storage/SXMUPP5V/9993308.html}
}

@misc{xu_tracailer_2025,
  title = {Tracailer: {{An Efficient Trajectory Planner}} for {{Tractor-Trailer Vehicles}} in {{Unstructured Environments}}},
  shorttitle = {Tracailer},
  author = {Xu, Long and Chai, Kaixin and An, Boyuan and Gan, Jiaxiang and Wang, Qianhao and Zhou, Yuan and Li, Xiaoying and Lin, Junxiao and Han, Zhichao and Xu, Chao and Cao, Yanjun and Gao, Fei},
  year = {2025},
  month = feb,
  number = {arXiv:2502.19832},
  eprint = {2502.19832},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.19832},
  url = {http://arxiv.org/abs/2502.19832},
  urldate = {2025-03-03},
  abstract = {The tractor-trailer vehicle (robot) consists of a drivable tractor and one or more non-drivable trailers connected via hitches. Compared to typical car-like robots, the addition of trailers provides greater transportation capability. However, this also complicates motion planning due to the robot's complex kinematics, high-dimensional state space, and deformable structure. To efficiently plan safe, time-optimal trajectories that adhere to the kinematic constraints of the robot and address the challenges posed by its unique features, this paper introduces a lightweight, compact, and high-order smooth trajectory representation for tractor-trailer robots. Based on it, we design an efficiently solvable spatio-temporal trajectory optimization problem. To deal with deformable structures, which leads to difficulties in collision avoidance, we fully leverage the collision-free regions of the environment, directly applying deformations to trajectories in continuous space. This approach not requires constructing safe regions from the environment using convex approximations through collision-free seed points before each optimization, avoiding the loss of the solution space, thus reducing the dependency of the optimization on initial values. Moreover, a multi-terminal fast path search algorithm is proposed to generate the initial values for optimization. Extensive simulation experiments demonstrate that our approach achieves several-fold improvements in efficiency compared to existing algorithms, while also ensuring lower curvature and trajectory duration. Real-world experiments involving the transportation, loading and unloading of goods in both indoor and outdoor scenarios further validate the effectiveness of our method. The source code is accessible at https://github.com/ZJU-FAST-Lab/tracailer/.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/4JQPTV28/Xu et al. - 2025 - Tracailer An Efficient Trajectory Planner for Tractor-Trailer Vehicles in Unstructured Environments.pdf;/Users/kshitijgoel/Zotero/storage/NHC46MF7/2502.html}
}

@inproceedings{xu_vrexplorer_2024,
  title = {{{VRExplorer}}: {{An Efficient View-Region}} Based {{Autonomous Exploration Method}} in {{Unknown Environments}} for {{UAV}}},
  shorttitle = {{{VRExplorer}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Xu, Kai and Zheng, Lanxiang and Wei, Mingxin and Cheng, Hui},
  year = {2024},
  month = oct,
  pages = {8081--8087},
  issn = {2153-0866},
  doi = {10.1109/IROS58592.2024.10802710},
  url = {https://ieeexplore.ieee.org/document/10802710/?arnumber=10802710},
  urldate = {2024-12-31},
  abstract = {Autonomous exploration plays a crucial role in robotics applications like rescue and scene reconstruction. This work addresses the challenges of autonomous exploration in intricate unknown environments by presenting a novel UAV autonomous exploration method based on a new concept of the view-region. Our proposed approach leverages the view-region to replace the conventional viewpoint generation and selection process, streamlining the planning process for exploration. Simultaneously, we model the problem of maximizing frontier coverage within the field of view during exploration, and jointly optimize it with the exploration path optimization problem. This approach ensures exploration path safety and effectiveness while being aggressive. Additionally, a gimbal is incorporated beneath the camera, with an associated optimization problem designed to minimize UAV self-rotation and enhance exploration efficiency. Simulations and real-world experiments demonstrate that the proposed method outperforms existing state-of-the-art methods in terms of runtime and distance traveled.},
  keywords = {Autonomous aerial vehicles,Cameras,Intelligent robots,Optimization,Planning,Runtime,Safety},
  file = {/Users/kshitijgoel/Zotero/storage/JQW87IHD/Xu et al. - 2024 - VRExplorer An Efficient View-Region based Autonomous Exploration Method in Unknown Environments for.pdf;/Users/kshitijgoel/Zotero/storage/UCJHRX5A/10802710.html}
}

@inproceedings{xue_neural_2024,
  title = {Neural {{Visibility Field}} for {{Uncertainty-Driven Active Mapping}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Xue, Shangjie and Dill, Jesse and Mathur, Pranay and Dellaert, Frank and Tsiotra, Panagiotis and Xu, Danfei},
  year = {2024},
  pages = {18122--18132},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Neural_Visibility_Field_for_Uncertainty-Driven_Active_Mapping_CVPR_2024_paper.html},
  urldate = {2024-06-12},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/3927IPMW/Xue et al. - 2024 - Neural Visibility Field for Uncertainty-Driven Active Mapping.pdf}
}

@phdthesis{yamasaki_convergence_2024,
  type = {Doctoral Thesis},
  title = {Convergence {{Analysis}} of {{Mean Shift Type Algorithms}}},
  author = {Yamasaki, Ryoya},
  year = {2024},
  month = mar,
  doi = {10.14989/doctor.k25440},
  url = {https://repository.kulib.kyoto-u.ac.jp/dspace/handle/2433/288874},
  urldate = {2024-10-09},
  abstract = {京都大学},
  copyright = {Chapter 3 is based on "Ryoya Yamasaki and Toshiyuki Tanaka. Properties of Mean Shift. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 42(9): 2273-2286, 2020. doi: 10.1109/TPAMI.2019.2913640." with ?2020 IEEE and on "Ryoya Yamasaki and Toshiyuki Tanaka. Convergence Analysis of Mean Shift. arXiv preprint arXiv:2305.08463v3 [stat.ML], 2023. doi: 10.48550/arXiv.2305.08463." with CC-BY lisence. Chapter 4 is based on "Ryoya Yamasaki and Toshiyuki Tanaka. Kernel Selection for Modal Linear Regression: Optimal Kernel and IRLS Algorithm. In Proceedings of the 2019 18th IEEE International Conference on Machine Learning and Applications (ICMLA), pages 595-601, 2019. doi: 10.1109/ICMLA.2019.00110." with ?2019 IEEE. Chapter 5 is based on "Ryoya Yamasaki and Toshiyuki Tanaka. Convergence Analysis of Blurring Mean Shift. arXiv preprint arXiv:2402.15146v1 [cs.LG], 2024. doi: 10.48550/arXiv:2402.15146." with CC-BY lisence. In reference to IEEE copyrighted material which is used with permission in this thesis, the IEEE does not endorse any of [university/educational entity's name goes here]'s products or services. Internal or personal use of this material is permitted. If interested in reprinting/republishing IEEE copyrighted material for advertising or promotional purposes or for creating new collective works for resale or redistribution, please go to http://www.ieee.org/publications\_standards/publications/rights/rights\_link.html to learn how to obtain a License from RightsLink.},
  langid = {english},
  school = {Kyoto University},
  annotation = {Accepted: 2024-07-24T05:10:52Z},
  file = {/Users/kshitijgoel/Zotero/storage/4AEH2XQJ/Yamasaki - 2024 - Convergence Analysis of Mean Shift Type Algorithms.pdf}
}

@article{yamasaki_convergence_2024a,
  title = {Convergence {{Analysis}} of {{Mean Shift}}},
  author = {Yamasaki, Ryoya and Tanaka, Toshiyuki},
  year = {2024},
  month = oct,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {46},
  number = {10},
  pages = {6688--6698},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2024.3385920},
  url = {https://ieeexplore.ieee.org/document/10494563/?arnumber=10494563},
  urldate = {2024-10-09},
  abstract = {The mean shift (MS) algorithm seeks a mode of the kernel density estimate (KDE). This study presents a convergence guarantee of the mode estimate sequence generated by the MS algorithm and an evaluation of the convergence rate, under fairly mild conditions, with the help of the argument concerning the {\L}ojasiewicz inequality. Our findings extend existing ones covering analytic kernels and the Epanechnikov kernel. Those are significant in that they cover the biweight kernel, which is optimal among non-negative kernels in terms of the asymptotic statistical efficiency for the KDE-based mode estimation.},
  keywords = {Bandwidth,Biweight kernel,Clustering algorithms,convergence,Convergence,convergence rate,Estimation,Heuristic algorithms,Kernel,Lojasiewicz inequality,mean shift,Optimization},
  file = {/Users/kshitijgoel/Zotero/storage/6UXAY4IA/Yamasaki and Tanaka - 2024 - Convergence Analysis of Mean Shift.pdf;/Users/kshitijgoel/Zotero/storage/IRC39EGS/10494563.html}
}

@misc{yamasaki_convergence_2024b,
  title = {Convergence {{Analysis}} of {{Blurring Mean Shift}}},
  author = {Yamasaki, Ryoya and Tanaka, Toshiyuki},
  year = {2024},
  month = feb,
  number = {arXiv:2402.15146},
  eprint = {2402.15146},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2402.15146},
  urldate = {2024-06-03},
  abstract = {Blurring mean shift (BMS) algorithm, a variant of the mean shift algorithm, is a kernel-based iterative method for data clustering, where data points are clustered according to their convergent points via iterative blurring. In this paper, we analyze convergence properties of the BMS algorithm by leveraging its interpretation as an optimization procedure, which is known but has been underutilized in existing convergence studies. Whereas existing results on convergence properties applicable to multi-dimensional data only cover the case where all the blurred data point sequences converge to a single point, this study provides a convergence guarantee even when those sequences can converge to multiple points, yielding multiple clusters. This study also shows that the convergence of the BMS algorithm is fast by further leveraging geometrical characterization of the convergent points.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/kshitijgoel/Zotero/storage/8WXCXVW7/Yamasaki and Tanaka - 2024 - Convergence Analysis of Blurring Mean Shift.pdf}
}

@article{yamasaki_properties_2020,
  title = {Properties of {{Mean Shift}}},
  author = {Yamasaki, Ryoya and Tanaka, Toshiyuki},
  year = {2020},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {42},
  number = {9},
  pages = {2273--2286},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2019.2913640},
  url = {https://ieeexplore.ieee.org/abstract/document/8700249},
  urldate = {2024-03-29},
  abstract = {We study properties of the mean shift (MS)-type algorithms for estimating modes of probability density functions (PDFs), via regarding these algorithms as gradient ascent on estimated PDFs with adaptive step sizes. We rigorously prove convergence of mode estimate sequences generated by the MS-type algorithms, under the assumption that an analytic kernel function is used. Moreover, our analysis on the MS function finds several new properties of mode estimate sequences and corresponding density estimate sequences, including the result that in the MS-type algorithm using a Gaussian kernel the density estimate monotonically increases between two consecutive mode estimates. This implies that, in the one-dimensional case, the mode estimate sequence monotonically converges to the stationary point nearest to an initial point without jumping over any stationary point.},
  keywords = {Bandwidth,Clustering algorithms,conditional mean shift algorithm,Convergence,Estimation,Kernel,mean shift algorithm,mode clustering,Mode estimation,Probability density function,subspace constrained mean shift algorithm,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/CA3RFJMH/Yamasaki and Tanaka - 2020 - Properties of Mean Shift.pdf}
}

@inproceedings{yamauchi_frontierbased_1997,
  title = {A Frontier-Based Approach for Autonomous Exploration},
  booktitle = {Proceedings 1997 {{IEEE International Symposium}} on {{Computational Intelligence}} in {{Robotics}} and {{Automation CIRA}}'97. '{{Towards New Computational Principles}} for {{Robotics}} and {{Automation}}'},
  author = {Yamauchi, B.},
  year = {1997},
  month = jul,
  pages = {146--151},
  doi = {10.1109/CIRA.1997.613851},
  url = {https://ieeexplore.ieee.org/document/613851},
  urldate = {2023-10-28},
  abstract = {We introduce a new approach for exploration based on the concept of frontiers, regions on the boundary between open space and unexplored space. By moving to new frontiers, a mobile robot can extend its map into new territory until the entire environment has been explored. We describe a method for detecting frontiers in evidence grids and navigating to these frontiers. We also introduce a technique for minimizing specular reflections in evidence grids using laser-limited sonar. We have tested this approach with a real mobile robot, exploring real-world office environments cluttered with a variety of obstacles. An advantage of our approach is its ability to explore both large open spaces and narrow cluttered spaces, with walls and obstacles in arbitrary orientation.},
  file = {/Users/kshitijgoel/Zotero/storage/EMTGAQLH/Yamauchi - 1997 - A frontier-based approach for autonomous explorati.pdf;/Users/kshitijgoel/Zotero/storage/HQILK8LG/613851.html}
}

@inproceedings{yamauchi_frontierbased_1998,
  title = {Frontier-Based Exploration Using Multiple Robots},
  booktitle = {Proceedings of the Second International Conference on {{Autonomous}} Agents  - {{AGENTS}} '98},
  author = {Yamauchi, Brian},
  year = {1998},
  pages = {47--53},
  publisher = {ACM Press},
  address = {Minneapolis, Minnesota, United States},
  doi = {10.1145/280765.280773},
  url = {http://portal.acm.org/citation.cfm?doid=280765.280773},
  urldate = {2022-11-02},
  isbn = {978-0-89791-983-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/A9B2LVMJ/Yamauchi - 1998 - Frontier-based exploration using multiple robots.pdf}
}

@article{yan_active_2023,
  title = {Active {{Implicit Object Reconstruction Using Uncertainty-Guided Next-Best-View Optimization}}},
  author = {Yan, Dongyu and Liu, Jianheng and Quan, Fengyu and Chen, Haoyao and Fu, Mengmeng},
  year = {2023},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {10},
  pages = {6395--6402},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3306282},
  url = {https://ieeexplore.ieee.org/abstract/document/10223307},
  urldate = {2024-06-13},
  abstract = {Actively planning sensor views during object reconstruction is crucial for autonomous mobile robots. An effective method should be able to strike a balance between accuracy and efficiency. In this letter, we propose a seamless integration of the emerging implicit representation with the active reconstruction task. We build an implicit occupancy field as our geometry proxy. While training, the prior object bounding box is utilized as auxiliary information to generate clean and detailed reconstructions. To evaluate view uncertainty, we employ a sampling-based approach that directly extracts entropy from the reconstructed occupancy probability field as our measure of view information gain. This eliminates the need for additional uncertainty maps or learning. Unlike previous methods that compare view uncertainty within a finite set of candidates, we aim to find the next-best-view (NBV) on a continuous manifold. Leveraging the differentiability of the implicit representation, the NBV can be optimized directly by maximizing the view uncertainty using gradient descent. It significantly enhances the method's adaptability to different scenarios. Simulation and real-world experiments demonstrate that our approach effectively improves reconstruction accuracy and efficiency of view planning in active reconstruction tasks.},
  keywords = {active reconstruction,Geometry,Image reconstruction,Implicit representation,implicit uncertainty evaluation,next-best-view optimization,Optimization,Planning,Rendering (computer graphics),Robots,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/G3R9UHKD/Yan et al. - 2023 - Active Implicit Object Reconstruction Using Uncertainty-Guided Next-Best-View Optimization.pdf;/Users/kshitijgoel/Zotero/storage/TSLBB75Y/10223307.html}
}

@inproceedings{yan_active_2023a,
  title = {Active {{Neural Mapping}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Yan, Zike and Yang, Haoxiang and Zha, Hongbin},
  year = {2023},
  pages = {10981--10992},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Active_Neural_Mapping_ICCV_2023_paper.html},
  urldate = {2023-10-08},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/9KXBIN4E/Yan et al. - 2023 - Active Neural Mapping.pdf}
}

@article{yan_closedform_2015,
  title = {Closed-Form Characterization of the {{Minkowski}} Sum and Difference of Two Ellipsoids},
  author = {Yan, Yan and Chirikjian, Gregory S.},
  year = {2015},
  month = aug,
  journal = {Geometriae Dedicata},
  volume = {177},
  number = {1},
  pages = {103--128},
  issn = {1572-9168},
  doi = {10.1007/s10711-014-9981-3},
  url = {https://doi.org/10.1007/s10711-014-9981-3},
  urldate = {2024-01-19},
  abstract = {This paper makes three original contributions: (1) Explicit closed-form parametric formulas for the boundary of the Minkowski sum and difference of two arbitrarily oriented solid ellipsoids in n-dimensional Euclidean space are presented; (2) Based on this, new closed-form lower and upper bounds for the volume contained in these Minkowski sums and differences are derived in the 2D and 3D cases and these bounds are shown to be better than those in the existing literature; (3) A demonstration of how these ideas can be applied to problems in computational geometry and robotics is provided, and a relationship to the Principal Kinematic Formula from the fields of integral geometry and geometric probability is uncovered.},
  langid = {english},
  keywords = {65Dxx,Ellipsoid,Integral geometry,Mean curvature,Minkowski sum,Steiner's formula},
  file = {/Users/kshitijgoel/Zotero/storage/U48FCEHI/Yan and Chirikjian - 2015 - Closed-form characterization of the Minkowski sum .pdf}
}

@inproceedings{yan_gsslam_2024,
  title = {{{GS-SLAM}}: {{Dense Visual SLAM}} with {{3D Gaussian Splatting}}},
  shorttitle = {{{GS-SLAM}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Yan, Chi and Qu, Delin and Xu, Dan and Zhao, Bin and Wang, Zhigang and Wang, Dong and Li, Xuelong},
  year = {2024},
  pages = {19595--19604},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Yan_GS-SLAM_Dense_Visual_SLAM_with_3D_Gaussian_Splatting_CVPR_2024_paper.html},
  urldate = {2024-06-11},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/IARX5IJV/Yan et al. - 2024 - GS-SLAM Dense Visual SLAM with 3D Gaussian Splatting.pdf}
}

@article{yan_learning_2024,
  title = {Learning {{Gaussian}} Mixtures Using the {{Wasserstein}}--{{Fisher}}--{{Rao}} Gradient Flow},
  author = {Yan, Yuling and Wang, Kaizheng and Rigollet, Philippe},
  year = {2024},
  month = aug,
  journal = {The Annals of Statistics},
  volume = {52},
  number = {4},
  pages = {1774--1795},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/24-AOS2416},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-4/Learning-Gaussian-mixtures-using-the-WassersteinFisherRao-gradient-flow/10.1214/24-AOS2416.full},
  urldate = {2025-01-21},
  abstract = {Gaussian mixture models form a flexible and expressive parametric family of distributions that has found a variety of applications. Unfortunately, fitting these models to data is a notoriously hard problem from a computational perspective. Currently, only moment-based methods enjoy theoretical guarantees while likelihood-based methods are dominated by heuristics such as Expectation-Maximization that are known to fail in simple examples. In this work, we propose a new algorithm to compute the nonparametric maximum likelihood estimator (NPMLE) in a Gaussian mixture model. Our method is based on gradient descent over the space of probability measures equipped with the Wasserstein--Fisher--Rao geometry for which we establish convergence guarantees. In practice, it can be approximated using an interacting particle system where the weight and location of particles are updated alternately. We conduct extensive numerical experiments to confirm the effectiveness of the proposed algorithm compared not only to classical benchmarks but also to similar gradient descent algorithms with respect to simpler geometries. In particular, these simulations illustrate the benefit of updating both weight and location of the interacting particles.},
  keywords = {62G05,62H30,Gaussian mixture model,nonparametric MLE,Optimal transport,overparameterization,Wasserstein gradient flows,Wasserstein-Fisher-Rao geometry},
  file = {/Users/kshitijgoel/Zotero/storage/5P59W89N/Yan et al. - 2024 - Learning Gaussian mixtures using the Wasserstein–Fisher–Rao gradient flow.pdf}
}

@article{yan_muitare_2023,
  title = {{{MUI-TARE}}: {{Cooperative Multi-Agent Exploration With Unknown Initial Position}}},
  shorttitle = {{{MUI-TARE}}},
  author = {Yan, Jingtian and Lin, Xingqiao and Ren, Zhongqiang and Zhao, Shiqi and Yu, Jieqiong and Cao, Chao and Yin, Peng and Zhang, Ji and Scherer, Sebastian},
  year = {2023},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {7},
  pages = {4299--4306},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3281262},
  url = {https://ieeexplore.ieee.org/document/10138598},
  urldate = {2024-02-25},
  abstract = {Multi-agent exploration of a bounded 3D environment with the unknown initial poses of agents is a challenging problem. It requires both quickly exploring the environments and robustly merging the sub-maps built by the agents. Most existing exploration strategies directly merge two sub-maps built by different agents when a single frame observation is matched, which can lead to incorrect merging due to the false-positive detection of the overlap and is thus not robust. In the meanwhile, some recent place recognition methods use sequence matching for robust data association. However, naively applying these sequence matching methods to multi-agent exploration may require one agent to repeat a large amount of another agent's history trajectory so that a sequence of matched observation can be established, which reduces the overall exploration time efficiency. To intelligently balance the robustness of sub-map merging and exploration efficiency, we develop a new approach for lidar-based multi-agent exploration, which can direct one agent to repeat another agent's trajectory in an adaptive manner based on the quality indicator of the sub-map merging process. Additionally, our approach extends the recent single-agent hierarchical exploration strategy to multiple agents in a cooperative manner for agents whose sub-maps are merged, to improve exploration efficiency. Our experiments show that our approach is up to 50\% more efficient than the baselines while merging sub-maps robustly.},
  keywords = {Feature extraction,Merging,Multi-agent exploration,Planning,Point cloud compression,real-time map merging,Robustness,Servers,Three-dimensional displays,unknown initial pose},
  file = {/Users/kshitijgoel/Zotero/storage/DK4RDVUW/Yan et al. - 2023 - MUI-TARE Cooperative Multi-Agent Exploration With.pdf;/Users/kshitijgoel/Zotero/storage/P3NJSUEP/10138598.html}
}

@inproceedings{yan_online_2021,
  title = {Online {{Learning}} of a {{Probabilistic}} and {{Adaptive Scene Representation}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Yan, Zike and Wang, Xin and Zha, Hongbin},
  year = {2021},
  month = jun,
  pages = {13106--13116},
  issn = {2575-7075},
  doi = {10.1109/CVPR46437.2021.01291},
  url = {https://ieeexplore.ieee.org/document/9577619},
  urldate = {2024-11-15},
  abstract = {Constructing and maintaining a consistent scene model on-the-fly is the core task for online spatial perception, interpretation, and action. In this paper, we represent the scene with a Bayesian nonparametric mixture model, seamlessly describing per-point occupancy status with a continuous probability density function. Instead of following the conventional data fusion paradigm, we address the problem of online learning the process how sequential point cloud data are generated from the scene geometry. An incremental and parallel inference is performed to update the parameter space in real-time. We experimentally show that the proposed representation achieves state-of-the-art accuracy with promising efficiency. The consistent probabilistic formulation assures a generative model that is adaptive to different sensor characteristics, and the model complexity can be dynamically adjusted on-the-fly according to different data scales.},
  keywords = {Adaptation models,Computational modeling,Data models,Geometry,Mixture models,Probabilistic logic,Probability density function},
  file = {/Users/kshitijgoel/Zotero/storage/6S7FU38V/Yan et al. - 2021 - Online Learning of a Probabilistic and Adaptive Scene Representation.pdf;/Users/kshitijgoel/Zotero/storage/7KCTI3H8/9577619.html}
}

@inproceedings{yang_assisted_2020,
  title = {Assisted {{Mobile Robot Teleoperation}} with {{Intent-aligned Trajectories}} via {{Biased Incremental Action Sampling}}},
  booktitle = {2020 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Yang, Xuning and Michael, Nathan},
  year = {2020},
  month = oct,
  pages = {10998--11003},
  issn = {2153-0866},
  doi = {10.1109/IROS45743.2020.9341514},
  abstract = {We present a method to assist the operator in teleoperation of mobile robots by generating trajectories such that the vehicle completes the desired task with ease in unstructured environments. Traditional assisted teleoperation methods have focused on reactive methods to avoid collisions, but neglect the operator's intention in doing so. Instead, we generate long horizon, smooth trajectories that follow the operator's intended direction while circumventing obstacles for a seamless teleoperation experience. For mobile robot teleoperation, an explicit goal in the state space is often unclear in cases such as exploration or navigation. Therefore, we model the intent as a direction and encode it as a cost function. As trajectories of various lengths can satisfy the same directional objective, we iteratively construct a tree of sequential actions that form multiple trajectories along the intended direction. We show our algorithm on a real-time teleoperation task of a simulated hexarotor vehicle in a dense random forest environment. By doing so, our approach allows operator to achieve the navigation task while requiring less effort than reactive methods.},
  keywords = {Intelligent robots,Mobile robots,Navigation,Real-time systems,Task analysis,Trajectory,Vegetation},
  file = {/Users/kshitijgoel/Zotero/storage/CTLJXYIV/Yang and Michael - 2020 - Assisted Mobile Robot Teleoperation with Intent-al.pdf;/Users/kshitijgoel/Zotero/storage/IXEFYC3C/stamp.html}
}

@misc{yang_depth_2024,
  title = {Depth {{Anything V2}}},
  author = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  year = {2024},
  month = oct,
  number = {arXiv:2406.09414},
  eprint = {2406.09414},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.09414},
  url = {http://arxiv.org/abs/2406.09414},
  urldate = {2024-12-16},
  abstract = {This work presents Depth Anything V2. Without pursuing fancy techniques, we aim to reveal crucial findings to pave the way towards building a powerful monocular depth estimation model. Notably, compared with V1, this version produces much finer and more robust depth predictions through three key practices: 1) replacing all labeled real images with synthetic images, 2) scaling up the capacity of our teacher model, and 3) teaching student models via the bridge of large-scale pseudo-labeled real images. Compared with the latest models built on Stable Diffusion, our models are significantly more efficient (more than 10x faster) and more accurate. We offer models of different scales (ranging from 25M to 1.3B params) to support extensive scenarios. Benefiting from their strong generalization capability, we fine-tune them with metric depth labels to obtain our metric depth models. In addition to our models, considering the limited diversity and frequent noise in current test sets, we construct a versatile evaluation benchmark with precise annotations and diverse scenes to facilitate future research.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/TIAIJSXD/Yang et al. - 2024 - Depth Anything V2.pdf;/Users/kshitijgoel/Zotero/storage/P6B3SSN3/2406.html}
}

@inproceedings{yang_depth_2024a,
  title = {Depth {{Anything}}: {{Unleashing}} the {{Power}} of {{Large-Scale Unlabeled Data}}},
  shorttitle = {Depth {{Anything}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  year = {2024},
  pages = {10371--10381},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Depth_Anything_Unleashing_the_Power_of_Large-Scale_Unlabeled_Data_CVPR_2024_paper.html},
  urldate = {2024-12-16},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZT2UJEEX/Yang et al. - 2024 - Depth Anything Unleashing the Power of Large-Scale Unlabeled Data.pdf}
}

@inproceedings{yang_framework_2017,
  title = {A Framework for Efficient Teleoperation via Online Adaptation},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yang, Xuning and Sreenath, Koushil and Michael, Nathan},
  year = {2017},
  month = may,
  pages = {5948--5953},
  doi = {10.1109/ICRA.2017.7989701},
  url = {https://ieeexplore.ieee.org/document/7989701},
  urldate = {2024-11-15},
  abstract = {We propose a task-independent adaptive teleoperation methodology that seeks to improve operator performance and efficiency by concurrently modeling user intent and adapting the set of available actions according to the predicted intent. User input selects a robot motion from a finite set of dynamically feasible and safe motions, represented as a motion primitive library. User intent is modeled as a probabilistic distribution with respect to future actions that represents the likelihood of action selection given recent user input, which can be formulated independent of task, environment, or user. As the intent model becomes increasingly confident, the action set is adapted in order to reduce the error between the intended and actual performance. Experimental evaluation of teleoperating a quadrotor for nonaggressive, single-intent maneuvers such as following a racetrack and conducting a free-hand helix motion shows improved performance, validating that the approach provides efficient adaptation towards achieving the user intent.},
  keywords = {Adaptation models,Atmospheric modeling,Libraries,Multiprotocol label switching,Robots,Trajectory,Vehicle dynamics},
  file = {/Users/kshitijgoel/Zotero/storage/P8TQHII4/Yang et al. - 2017 - A framework for efficient teleoperation via online adaptation.pdf;/Users/kshitijgoel/Zotero/storage/AMHUKIPY/7989701.html}
}

@phdthesis{yang_humanintheloop_2022,
  title = {Human-in-the-Loop {{Planning}} of {{Mobile Robots}}},
  author = {Yang, Xuning},
  year = {2022},
  month = jan,
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/IKUNAT7N/_.pdf}
}

@inproceedings{yang_intention_2021,
  title = {An {{Intention Guided Hierarchical Framework}} for {{Trajectory-based Teleoperation}} of {{Mobile Robots}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yang, Xuning and Cheng, Jasmine and Michael, Nathan},
  year = {2021},
  month = may,
  pages = {482--488},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561798},
  abstract = {In human-in-the-loop navigation, the operator's intention is to locally avoid obstacles while planning long-horizon paths in order to complete the navigation task. We propose a hierarchical teleoperation framework that captures these characteristics of intention, and generates trajectories that are locally safe and follow the operator's global plan. The hierarchical teleoperation framework consists of 1) a global path which encapsulates the intended direction of the operator, 2) local trajectories that circumvent obstacles near the vehicle's vicinity while following the global path, and 3) safety monitoring to avoid possible imminent collisions. By removing the operator from providing dynamic-level control inputs and instead having inputs inform trajectory generation, we show a significant reduction of the operator's engagement while maintaining smooth performance.We showcase hierarchical teleoperation in navigation tasks in a random forest environment and a high-clutter warehouse characterized by narrow gaps and dense obstacles. With our method, we maintain consistent high speed throughout the task with smooth jerk profiles, decreased time to completion, and significantly reduced operator engagement.},
  keywords = {Automation,Conferences,Mobile robots,Navigation,Planning,Safety,Trajectory},
  file = {/Users/kshitijgoel/Zotero/storage/6D4JBQ2C/Yang et al. - 2021 - An Intention Guided Hierarchical Framework for Tra.pdf;/Users/kshitijgoel/Zotero/storage/Q5MVGJIF/stamp.html}
}

@misc{yang_learning_2022,
  title = {Learning {{Continuous Control Policies}} for {{Information-Theoretic Active Perception}}},
  author = {Yang, Pengzhi and Liu, Yuhan and Koga, Shumon and Asgharivaskasi, Arash and Atanasov, Nikolay},
  year = {2022},
  month = sep,
  number = {arXiv:2209.12427},
  eprint = {2209.12427},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2209.12427},
  urldate = {2022-10-01},
  abstract = {This paper proposes a method for learning continuous control policies for active landmark localization and exploration using an information-theoretic cost. We consider a mobile robot detecting landmarks within a limited sensing range, and tackle the problem of learning a control policy that maximizes the mutual information between the landmark states and the sensor observations. We employ a Kalman filter to convert the partially observable problem in the landmark state to Markov decision process (MDP), a differentiable field of view to shape the reward, and an attention-based neural network to represent the control policy. The approach is further unified with active volumetric mapping to promote exploration in addition to landmark localization. The performance is demonstrated in several simulated landmark localization tasks in comparison with benchmark methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/Q2EY8LJS/Yang et al. - 2022 - Learning Continuous Control Policies for Informati.pdf;/Users/kshitijgoel/Zotero/storage/F33IFLMX/2209.html}
}

@article{yang_multivisualinertial_2024,
  title = {Multi-Visual-Inertial System: {{Analysis}}, Calibration, and Estimation},
  shorttitle = {Multi-Visual-Inertial System},
  author = {Yang, Yulin and Geneva, Patrick and Huang, Guoquan},
  year = {2024},
  month = nov,
  journal = {The International Journal of Robotics Research},
  volume = {43},
  number = {13},
  pages = {1995--2026},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241245726},
  url = {https://doi.org/10.1177/02783649241245726},
  urldate = {2025-04-16},
  abstract = {In this paper, we study state estimation of multi-visual-inertial systems (MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrary number of asynchronous inertial measurement units (IMUs) or gyroscopes and global and/or rolling shutter cameras. We are especially interested in the full calibration of the associated visual-inertial sensors, including the IMU/camera intrinsics and the IMU-IMU/camera spatiotemporal extrinsics as well as the image readout time of rolling-shutter cameras (if used). To this end, we develop a new analytic combined IMU integration with inertial intrinsics---termed ACI3---to pre-integrate IMU measurements, which is leveraged to fuse auxiliary IMUs and/or gyroscopes alongside a base IMU. We model the multi-inertial measurements to include all the necessary inertial intrinsic and IMU-IMU spatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-body constraints to eliminate the necessity of auxiliary inertial poses and thus reducing computational complexity. By performing observability analysis of MVIS, we prove that the standard four unobservable directions remain---no matter how many inertial sensors are used, and also identify, for the first time, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliary inertial intrinsics. In addition to extensive simulations that validate our analysis and algorithms, we have built our own MVIS sensor rig and collected over 25 real-world datasets to experimentally verify the proposed calibration against the state-of-the-art calibration method Kalibr. We show that the proposed MVIS calibration is able to achieve competing accuracy with improved convergence and repeatability, which is open sourced to better benefit the community.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/E7DJSWRJ/Yang et al. - 2024 - Multi-visual-inertial system Analysis, calibration, and estimation.pdf}
}

@article{yang_online_2019,
  title = {Online Adaptive Teleoperation via Motion Primitives for Mobile Robots},
  author = {Yang, Xuning and Agrawal, Ayush and Sreenath, Koushil and Michael, Nathan},
  year = {2019},
  month = aug,
  journal = {Autonomous Robots},
  volume = {43},
  number = {6},
  pages = {1357--1373},
  issn = {1573-7527},
  doi = {10.1007/s10514-018-9753-2},
  url = {https://doi.org/10.1007/s10514-018-9753-2},
  urldate = {2023-02-09},
  abstract = {Assistive teleoperation aims to help operators control robotic systems with ease. In this work, we present a novel adaptive teleoperation approach that is amenable to mobile systems using motion primitives for long-duration teleoperation, such as exploration using mobile vehicles or walking for humanoid systems. We first describe teleoperation using motion primitives, which are dynamically feasible and safe local trajectories based on a kinematic or dynamic model. We take a predict-and-adapt approach to assistive teleoperation, whereby adaptation is based on the predicted user intent. By representing the operator as an optimizing controller, a probabilistic distribution can be constructed for the available future actions based on some reward function. Adaptation is provided in the form of subsampling, which tailors the set of available actions based on the likelihood of action selection. We describe the framework for general systems and delineate the extrapolation to ground, air, and legged mobile robots, and demonstrate generalizability of this framework on two systems via simulation and experimentation; namely, a quadrotor micro air vehicle, and a simulated 3D humanoid system. Both systems show provably better performance in teleoperation by measures of behavioral entropy.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/2B6CRVAH/Yang et al. - 2019 - Online adaptive teleoperation via motion primitive.pdf}
}

@phdthesis{yang_using_2004,
  title = {Using the {{Poisson}} Kernel in Model Building and Selection},
  author = {Yang, Ke},
  year = {2004},
  address = {United States -- Pennsylvania},
  url = {https://www.proquest.com/docview/305150132/abstract/6B9AE359CB7E4C81PQ/1},
  urldate = {2024-07-26},
  abstract = {The Poisson kernel originated from a famous Dirichlet problem. In this dissertation, we study the properties of Poisson kernel as a distance kernel, as a density function, and as a kernel for a statistical mixture model. After reviewing Cram{\'e}r-von Mises type statistics and the Karhunen-Lo{\`e}ve decomposition for the covariance kernel, we derive a quadratic distance for testing distributions. This quadratic distance can be written as a sum of asymptotically independent chi-square components. The Poisson kernel is specially chosen for this quadratic distance and its properties are studied. As a probability density function, the Poisson kernel can be used to describe the distribution of directional data. The simplest Poisson kernel distribution is the univariate Poisson kernel distribution on a circle, which is well known as the wrapped Cauchy distribution. Maximum likelihood estimation for the wrapped Cauchy distribution was studied by Kent and Tyler (1988). We extend their result to higher dimensions and construct an EM algorithm for the MLE. Then we consider a mixture model with the Poisson kernel used as the component density. We discuss the identifiability of the mixture model and its non-parametric MLE. This mixture model can be applied to directional data or normalized data, such as normalized microarray data.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780496068227},
  langid = {english},
  school = {The Pennsylvania State University},
  keywords = {Cauchy distribution,Poisson kernel,Pure sciences,Statistics},
  file = {/Users/kshitijgoel/Zotero/storage/N5USPV7T/Yang - Using the Poisson kernel in model building and selection.pdf}
}

@article{yang_video_2014,
  title = {Video {{Compressive Sensing Using Gaussian Mixture Models}}},
  author = {Yang, Jianbo and Yuan, Xin and Liao, Xuejun and Llull, Patrick and Brady, David J. and Sapiro, Guillermo and Carin, Lawrence},
  year = {2014},
  month = nov,
  journal = {IEEE Transactions on Image Processing},
  volume = {23},
  number = {11},
  pages = {4863--4878},
  issn = {1941-0042},
  doi = {10.1109/TIP.2014.2344294},
  url = {https://ieeexplore.ieee.org/document/6868277/?arnumber=6868277},
  urldate = {2024-12-19},
  abstract = {A Gaussian mixture model (GMM)-based algorithm is proposed for video reconstruction from temporally compressed video measurements. The GMM is used to model spatio-temporal video patches, and the reconstruction can be efficiently computed based on analytic expressions. The GMM-based inversion method benefits from online adaptive learning and parallel computation. We demonstrate the efficacy of the proposed inversion method with videos reconstructed from simulated compressive video measurements, and from a real compressive video camera. We also use the GMM as a tool to investigate adaptive video compressive sensing, i.e., adaptive rate of temporal compression.},
  keywords = {Algorithm design and analysis,blind compressive sensing,coded aperture compressive temporal imaging (CACTI),Compressed sensing,Compressive sensing,dictionary learning,Gaussian mixture model,Image coding,Image reconstruction,online learning,union-of-subspace model},
  file = {/Users/kshitijgoel/Zotero/storage/2PIHSBJ4/Yang et al. - 2014 - Video Compressive Sensing Using Gaussian Mixture Models.pdf;/Users/kshitijgoel/Zotero/storage/VN5GCQED/6868277.html}
}

@inproceedings{yang_voxfusion_2022,
  title = {Vox-{{Fusion}}: {{Dense Tracking}} and {{Mapping}} with {{Voxel-based Neural Implicit Representation}}},
  shorttitle = {Vox-{{Fusion}}},
  booktitle = {2022 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}})},
  author = {Yang, Xingrui and Li, Hai and Zhai, Hongjia and Ming, Yuhang and Liu, Yuqian and Zhang, Guofeng},
  year = {2022},
  month = oct,
  pages = {499--507},
  publisher = {IEEE Computer Society},
  issn = {1554-7868},
  doi = {10.1109/ISMAR55827.2022.00066},
  url = {https://www.computer.org/csdl/proceedings-article/ismar/2022/532500a499/1JrR9zO8aHK},
  urldate = {2023-09-14},
  abstract = {In this work, we present a dense tracking and mapping system named Vox-Fusion, which seamlessly fuses neural implicit representations with traditional volumetric fusion methods. Our approach is inspired by the recently developed implicit mapping and positioning system and further extends the idea so that it can be freely applied to practical scenarios. Specifically, we leverage a voxel-based neural implicit surface representation to encode and optimize the scene inside each voxel. Furthermore, we adopt an octree-based structure to divide the scene and support dynamic expansion, enabling our system to track and map arbitrary scenes without knowing the environment like in previous works. Moreover, we proposed a high-performance multi-process framework to speed up the method, thus supporting some applications that require real-time performance. The evaluation results show that our methods can achieve better accuracy and completeness than previous methods. We also show that our Vox-Fusion can be used in augmented reality and virtual reality applications. Our source code is publicly available at https://github.com/zju3dv/Vox-Fusion.},
  isbn = {978-1-6654-5325-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/K4UAI9W3/Yang et al. - 2022 - Vox-Fusion Dense Tracking and Mapping with Voxel-.pdf}
}

@phdthesis{yao_resourceconstrained_2020,
  title = {Resource-{{Constrained State Estimation}} with {{Multi-Modal Sensing}}},
  author = {Yao, John},
  year = {2020},
  month = apr,
  address = {Pittsburgh, PA, USA},
  school = {Carnegie Mellon University},
  file = {/Users/kshitijgoel/Zotero/storage/NIN82K3J/_.pdf}
}

@techreport{yao_vins_2020,
  title = {{{VINS Documentation}}},
  author = {Yao, John},
  year = {2020},
  month = may,
  file = {/Users/kshitijgoel/Zotero/storage/TZEC7FL7/Yao - 2020 - VINS Documentation.pdf}
}

@inproceedings{ye_grfgmm_2024,
  title = {{{GRF-GMM}}: {{A Trajectory Optimization Framework}} for~{{Obstacle Avoidance}} in~{{Learning}} from~{{Demonstration}}},
  shorttitle = {{{GRF-GMM}}},
  booktitle = {Neural {{Information Processing}}},
  author = {Ye, Bin and Yu, Peng and Hu, Cong and Qiu, Binbin and Tan, Ning},
  editor = {Luo, Biao and Cheng, Long and Wu, Zheng-Guang and Li, Hongyi and Li, Chaojie},
  year = {2024},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {18--30},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-99-8070-3_2},
  abstract = {Learning from demonstrations (LfD) provides a convenient pattern to teach robot to gain skills without mechanically programming. As an LfD approach, Gaussian mixture model/Gaussian mixture regression (GMM/GMR) has been widely used for its robustness and effectiveness. However, there still exist many problems of GMM when an obstacle, which is not presented in original demonstrations, appears in the workspace of robots. To address these problems, this paper presents a novel method based on Gaussian repulsive field-Gaussian mixture model (GRF-GMM) for obstacle avoidance by optimizing the model parameters. A Gaussian repulsive force is calculated through Gaussian functions and employed to work on Gaussian components to optimize the mixture distribution which is learnt from original demonstrations. Our approach allows the reproduced trajectory to keep a safe distance away from the obstacle. Finally, the feasibility and effectiveness of the proposed method are revealed through simulations and experiments.},
  isbn = {978-981-99-8070-3},
  langid = {english},
  keywords = {GMM/GMR,Obstacle avoidance,Potential field},
  file = {/Users/kshitijgoel/Zotero/storage/WQUREVVJ/Ye et al. - 2024 - GRF-GMM A Trajectory Optimization Framework for O.pdf}
}

@article{ye_uncertainty_2024,
  title = {Uncertainty {{Propagation}} on {{Unimodular Matrix Lie Groups}}},
  author = {Ye, Jikai and Jayaraman, Amitesh S. and Chirikjian, Gregory S.},
  year = {2024},
  journal = {IEEE Transactions on Automatic Control},
  pages = {1--16},
  issn = {1558-2523},
  doi = {10.1109/TAC.2024.3486652},
  url = {https://ieeexplore.ieee.org/ielx8/9/4601496/10735369.pdf?tp=&arnumber=10735369&isnumber=4601496&ref=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8=&tag=1},
  urldate = {2025-03-05},
  abstract = {This paper proposes a general method for uncertainty propagation on unimodular matrix Lie groups that have a surjective exponential map when the initial probability density function is concentrated. We derive the exact formula for the propagation of mean and covariance expressed in the form of expectation in a continuous-time setting from the governing Fokker-Planck equation. Two approximate propagation methods are discussed based on the exact formula. One uses numerical quadrature and another utilizes the expansion of moments. For the latter one, a closed-form second-order propagation formula is derived. We apply the general method to the joint attitude and angular momentum uncertainty propagation problem and numerical experiments demonstrate the two approximation methods. These results show that our new methods have high accuracy while being computationally efficient.},
  keywords = {Algebra,attitude estimation,Covariance matrices,Fokker-Planck equation,Jacobian matrices,Kalman filters,Lie groups,Manifolds,Mathematical models,matrix Lie group,Trajectory,Uncertainty,Uncertainty propagation,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/PTNLYZDA/Ye et al. - 2024 - Uncertainty Propagation on Unimodular Matrix Lie Groups.pdf;/Users/kshitijgoel/Zotero/storage/9Z884GPB/10735369.html}
}

@article{yin_automerge_2023,
  title = {{{AutoMerge}}: {{A Framework}} for {{Map Assembling}} and {{Smoothing}} in {{City-Scale Environments}}},
  shorttitle = {{{AutoMerge}}},
  author = {Yin, Peng and Zhao, Shiqi and Lai, Haowen and Ge, Ruohai and Zhang, Ji and Choset, Howie and Scherer, Sebastian},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {3686--3704},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3290448},
  url = {https://ieeexplore.ieee.org/document/10203034},
  urldate = {2023-10-17},
  abstract = {In the era of advancing autonomous driving and increasing reliance on geospatial information, high-precision mapping not only demands accuracy but also flexible construction. Current approaches mainly rely on expensive mapping devices, which are time consuming for city-scale map construction and vulnerable to erroneous data associations without accurate GPS assistance. In this article, we present AutoMerge, a novel framework for merging large-scale maps that surpasses these limitations, which: 1) provides robust place recognition performance despite differences in both translation and viewpoint; 2) is capable of identifying and discarding incorrect loop closures caused by perceptual aliasing; and 3) effectively associates and optimizes large-scale and numerous map segments in the real-world scenario. AutoMerge utilizes multiperspective fusion and adaptive loop closure detection for accurate data associations, and it uses incremental merging to assemble large maps from individual trajectory segments given in random order and with no initial estimations. Furthermore, AutoMerge performs pose graph optimization after assembling the segments to smooth the merged map globally. We demonstrate AutoMerge on both city-scale merging (120 km) and campus-scale repeated merging (4.5 km {\texttimes} 8). The experiments show that AutoMerge: 1) surpasses the second- and third-best methods by 0.9\% and 6.5\% recall in segment retrieval; 2) achieves comparable 3-D mapping accuracy for 120-km large-scale map assembly; and 3) and is robust to temporally spaced revisits. To our knowledge, AutoMerge is the first mapping approach to merge hundreds of kilometers of individual segments without using GPS.},
  file = {/Users/kshitijgoel/Zotero/storage/QNAHJ9Y8/Yin et al. - 2023 - AutoMerge A Framework for Map Assembling and Smoo.pdf}
}

@incollection{yoder_autonomous_2016,
  title = {Autonomous {{Exploration}} for {{Infrastructure Modeling}} with a {{Micro Aerial Vehicle}}},
  booktitle = {Field and {{Service Robotics}}: {{Results}} of the 10th {{International Conference}}},
  author = {Yoder, Luke and Scherer, Sebastian},
  editor = {Wettergreen, David S. and Barfoot, Timothy D.},
  year = {2016},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}},
  pages = {427--440},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-27702-8_28},
  url = {https://doi.org/10.1007/978-3-319-27702-8_28},
  urldate = {2023-05-11},
  abstract = {Micro aerial vehicles (MAVs) are an exciting technology for mobile sensing of infrastructure as they can easily position sensors in to hard to reach positions. Although MAVs equipped with 3D sensing are starting to be used in industry, they currently must be remotely controlled by a skilled pilot. In this paper we present an exploration path planning approach for MAVs equipped with 3D range sensors like lidar. The only user input that our approach requires is a 3D bounding box around the structure. Our method incrementally plans a path for a MAV to scan all surfaces of the structure up to a resolution and detects when exploration is finished. We demonstrate our method by modeling a train bridge and show that our method builds 3D models with the efficiency of a skilled pilot.},
  isbn = {978-3-319-27702-8},
  langid = {english},
  keywords = {Occupancy Grid,Path Cost,Path Planning Algorithm,Point Cloud,Visual Odometry},
  file = {/Users/kshitijgoel/Zotero/storage/5LSQ7KZH/Yoder and Scherer - 2016 - Autonomous Exploration for Infrastructure Modeling.pdf}
}

@inproceedings{yu_adaptaug_2024,
  title = {{{AdaptAUG}}: {{Adaptive Data Augmentation Framework}} for {{Multi-Agent Reinforcement Learning}}},
  shorttitle = {{{AdaptAUG}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yu, Xin and Tian, Yongkai and Wang, Li and Feng, Pu and Wu, Wenjun and Shi, Rongye},
  year = {2024},
  month = may,
  pages = {10814--10820},
  doi = {10.1109/ICRA57147.2024.10611035},
  url = {https://ieeexplore.ieee.org/document/10611035/?arnumber=10611035&tag=1},
  urldate = {2024-12-16},
  abstract = {Multi-agent reinforcement learning has emerged as a promising approach for the control of multi-robot systems. Nevertheless, the low sample efficiency of MARL poses a significant obstacle to its broader application in robotics. While data augmentation appears to be a straightforward solution for improving sample efficiency, it usually incurs training instability, making the sample efficiency worse. Moreover, manually choosing suitable augmentations for a variety of tasks is a tedious and time-consuming process. To mitigate these challenges, our research theoretically analyzes the implications of data augmentation on MARL algorithms. Guided by these insights, we present AdaptAUG, an adaptive framework designed to selectively identify beneficial data augmentations, thereby achieving superior sample efficiency and overall performance in multi-robot tasks. Extensive experiments in both simulated and real-world multi-robot scenarios validate the effectiveness of our proposed framework.},
  keywords = {Control systems,Data augmentation,Estimation,Multi-robot systems,Reinforcement learning,Sensitivity,Training},
  file = {/Users/kshitijgoel/Zotero/storage/EZZBHVML/Yu et al. - 2024 - AdaptAUG Adaptive Data Augmentation Framework for Multi-Agent Reinforcement Learning.pdf;/Users/kshitijgoel/Zotero/storage/E7AZK2GW/10611035.html}
}

@inproceedings{yu_avoidbench_2023,
  title = {{{AvoidBench}}: {{A}} High-Fidelity Vision-Based Obstacle Avoidance Benchmarking Suite for Multi-Rotors},
  shorttitle = {{{AvoidBench}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yu, Hang and De Croon, Guido C. H. E and De Wagter, Christophe},
  year = {2023},
  month = may,
  pages = {9183--9189},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10161097},
  url = {https://ieeexplore.ieee.org/document/10161097/},
  urldate = {2024-02-19},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/V78VDDAU/Yu et al. - 2023 - AvoidBench A high-fidelity vision-based obstacle .pdf}
}

@inproceedings{yu_cauchyschwarz_2023,
  title = {Cauchy-{{Schwarz Divergence Information Bottleneck}} for {{Regression}}},
  booktitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  author = {Yu, Shujian and Yu, Xi and L{\o}kse, Sigurd and Jenssen, Robert and Principe, Jose C.},
  year = {2023},
  month = oct,
  url = {https://openreview.net/forum?id=7wY67ZDQTE},
  urldate = {2024-04-28},
  abstract = {The information bottleneck (IB) approach is popular to improve the generalization, robustness and explainability of deep neural networks. Essentially, it aims to find a minimum sufficient representation \${\textbackslash}mathbf\{t\}\$ by striking a trade-off between a compression term \$I({\textbackslash}mathbf\{x\};{\textbackslash}mathbf\{t\})\$ and a prediction term \$I(y;{\textbackslash}mathbf\{t\})\$, where \$I({\textbackslash}cdot;{\textbackslash}cdot)\$ refers to the mutual information (MI). MI is for the IB for the most part expressed in terms of the Kullback-Leibler (KL) divergence, which in the regression case corresponds to prediction based on mean squared error (MSE) loss with Gaussian assumption and compression approximated by variational inference. In this paper, we study the IB principle for the regression problem and develop a new way to parameterize the IB with deep neural networks by exploiting favorable properties of the Cauchy-Schwarz (CS) divergence. By doing so, we move away from MSE-based regression and ease estimation by avoiding variational approximations or distributional assumptions. We investigate the improved generalization ability of our proposed CS-IB and demonstrate strong adversarial robustness guarantees. We demonstrate its superior performance on six real-world regression tasks over other popular deep IB approaches. We additionally observe that the solutions discovered by CS-IB always achieve the best trade-off between prediction accuracy and compression ratio in the information plane. The code is available at {\textbackslash}url\{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck\}.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/BBD5B9E9/Yu et al. - 2023 - Cauchy-Schwarz Divergence Information Bottleneck f.pdf}
}

@article{yu_conditional_2025,
  title = {The {{Conditional Cauchy-Schwarz Divergence With Applications}} to {{Time-Series Data}} and {{Sequential Decision Making}}},
  author = {Yu, Shujian and Li, Hongming and L{\o}kse, Sigurd and Jenssen, Robert and Pr{\'i}ncipe, Jos{\'e} C.},
  year = {2025},
  month = jul,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {47},
  number = {7},
  pages = {5901--5917},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2025.3552434},
  url = {https://ieeexplore.ieee.org/document/10930811/},
  urldate = {2025-06-07},
  abstract = {The Cauchy-Schwarz (CS) divergence was developed by Pr{\'i}ncipe et al. in 2000. In this paper, we extend the classic CS divergence to quantify the closeness between two conditional distributions and show that the developed conditional CS divergence can be elegantly estimated by a kernel density estimator from given samples. We illustrate the advantages (e.g., rigorous faithfulness guarantee, lower computational complexity, higher statistical power, and much more flexibility in a wide range of applications) of our conditional CS divergence over previous proposals, such as the conditional Kullback-Leibler divergence and the conditional maximum mean discrepancy. We also demonstrate the compelling performance of conditional CS divergence in two machine learning tasks related to time series data and sequential inference, namely time series clustering and uncertainty-guided exploration for sequential decision making.},
  keywords = {Conditional Cauchy-Schwarz divergence,Covariance matrices,Decision making,Estimation,Kernel,Machine learning,Matrix decomposition,Q measurement,sequential decision making,Symmetric matrices,Time series analysis,time series clustering,Vectors},
  file = {/Users/kshitijgoel/Zotero/storage/HZLVYZVI/Yu et al. - 2025 - The Conditional Cauchy-Schwarz Divergence With Applications to Time-Series Data and Sequential Decis.pdf}
}

@article{yu_densitypreserving_2019,
  title = {Density-{{Preserving Hierarchical EM Algorithm}}: {{Simplifying Gaussian Mixture Models}} for {{Approximate Inference}}},
  shorttitle = {Density-{{Preserving Hierarchical EM Algorithm}}},
  author = {Yu, Lei and Yang, Tianyu and Chan, Antoni B.},
  year = {2019},
  month = jun,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {41},
  number = {6},
  pages = {1323--1337},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2018.2845371},
  abstract = {We propose an algorithm for simplifying a finite mixture model into a reduced mixture model with fewer mixture components. The reduced model is obtained by maximizing a variational lower bound of the expected log-likelihood of a set of virtual samples. We develop three applications for our mixture simplification algorithm: recursive Bayesian filtering using Gaussian mixture model posteriors, KDE mixture reduction, and belief propagation without sampling. For recursive Bayesian filtering, we propose an efficient algorithm for approximating an arbitrary likelihood function as a sum of scaled Gaussian. Experiments on synthetic data, human location modeling, visual tracking, and vehicle self-localization show that our algorithm can be widely used for probabilistic data analysis, and is more accurate than other mixture simplification methods.},
  keywords = {Approximation algorithms,Bayes methods,Clustering algorithms,Density simplification,Gaussian mixture model,Inference algorithms,likelihood approximation,Mixture models,recursive Bayesian filtering},
  file = {/Users/kshitijgoel/Zotero/storage/NWKVJ2NG/Yu et al. - 2019 - Density-Preserving Hierarchical EM Algorithm Simp.pdf;/Users/kshitijgoel/Zotero/storage/8YHTZLBV/8375742.html}
}

@article{yu_hammer_2025,
  title = {{{HAMMER}}: {{Heterogeneous}}, {{Multi-Robot Semantic Gaussian Splatting}}},
  shorttitle = {{{HAMMER}}},
  author = {Yu, Javier and Chen, Timothy and Schwager, Mac},
  year = {2025},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {10},
  number = {7},
  pages = {7270--7277},
  issn = {2377-3766},
  doi = {10.1109/LRA.2025.3575235},
  url = {https://ieeexplore.ieee.org/document/11018364/},
  urldate = {2025-06-09},
  abstract = {3D Gaussian Splatting offers expressive scene reconstruction and can model a broad range of visual, geometric, and semantic information. However, efficient real-time map reconstruction with data streamed from multiple robots and devices remains a challenge. To that end, we propose HAMMER, a server-based multi-robot Gaussian Splatting method that leverages ROS communication infrastructure to generate 3D, metric-semantic maps from asynchronous robot data-streams. HAMMER consists of (i) a one-time frame alignment module that transforms local SLAM poses and image data into a global frame and requires no prior relative pose knowledge, and (ii) an online module for continually training semantic 3DGS maps from streaming data. HAMMER handles mixed perception modes, adjusts automatically for variations in image pre-processing among different devices, and distills CLIP semantic codes into the 3D scene for language queries. In real-world experiments, HAMMER creates better maps compared to baselines and is useful for downstream tasks, such as semantic navigation (e.g., ``go to the couch'').},
  keywords = {Image reconstruction,Mapping,multi-robot systems,Neural radiance field,Real-time systems,Robot kinematics,Robots,Semantics,Servers,Simultaneous localization and mapping,Streams,Training,visual learning},
  file = {/Users/kshitijgoel/Zotero/storage/G3FV7FE4/Yu et al. - 2025 - HAMMER Heterogeneous, Multi-Robot Semantic Gaussian Splatting.pdf}
}

@misc{yu_languageembedded_2024,
  title = {Language-{{Embedded Gaussian Splats}} ({{LEGS}}): {{Incrementally Building Room-Scale Representations}} with a {{Mobile Robot}}},
  shorttitle = {Language-{{Embedded Gaussian Splats}} ({{LEGS}})},
  author = {Yu, Justin and Hari, Kush and Srinivas, Kishore and {El-Refai}, Karim and Rashid, Adam and Kim, Chung Min and Kerr, Justin and Cheng, Richard and Irshad, Muhammad Zubair and Balakrishna, Ashwin and Kollar, Thomas and Goldberg, Ken},
  year = {2024},
  month = sep,
  number = {arXiv:2409.18108},
  eprint = {2409.18108},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.18108},
  urldate = {2024-11-10},
  abstract = {Building semantic 3D maps is valuable for searching for objects of interest in offices, warehouses, stores, and homes. We present a mapping system that incrementally builds a Language-Embedded Gaussian Splat (LEGS): a detailed 3D scene representation that encodes both appearance and semantics in a unified representation. LEGS is trained online as a robot traverses its environment to enable localization of open-vocabulary object queries. We evaluate LEGS on 4 room-scale scenes where we query for objects in the scene to assess how LEGS can capture semantic meaning. We compare LEGS to LERF and find that while both systems have comparable object query success rates, LEGS trains over 3.5x faster than LERF. Results suggest that a multi-camera setup and incremental bundle adjustment can boost visual reconstruction quality in constrained robot trajectories, and suggest LEGS can localize open-vocabulary and long-tail object queries with up to 66\% accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/6PZLE9GE/Yu et al. - 2024 - Language-Embedded Gaussian Splats (LEGS) Incrementally Building Room-Scale Representations with a M.pdf;/Users/kshitijgoel/Zotero/storage/YFL6B37E/2409.html}
}

@inproceedings{yu_learning_2020,
  title = {Learning {{Diverse}} and {{Discriminative Representations}} via the {{Principle}} of {{Maximal Coding Rate Reduction}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yu, Yaodong and Chan, Kwan Ho Ryan and You, Chong and Song, Chaobing and Ma, Yi},
  year = {2020},
  volume = {33},
  pages = {9422--9434},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html},
  urldate = {2024-03-29},
  file = {/Users/kshitijgoel/Zotero/storage/GI2VUXXI/Yu et al. - 2020 - Learning Diverse and Discriminative Representation.pdf}
}

@inproceedings{yu_plenoctrees_2021,
  title = {{{PlenOctrees}} for {{Real-Time Rendering}} of {{Neural Radiance Fields}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Yu, Alex and Li, Ruilong and Tancik, Matthew and Li, Hao and Ng, Ren and Kanazawa, Angjoo},
  year = {2021},
  pages = {5752--5761},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Yu_PlenOctrees_for_Real-Time_Rendering_of_Neural_Radiance_Fields_ICCV_2021_paper.html},
  urldate = {2022-06-14},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LADYKF6X/Yu et al. - 2021 - PlenOctrees for Real-Time Rendering of Neural Radi.pdf;/Users/kshitijgoel/Zotero/storage/8PEM4Y5L/Yu_PlenOctrees_for_Real-Time_Rendering_of_Neural_Radiance_Fields_ICCV_2021_paper.html}
}

@inproceedings{yu_principle_2022,
  title = {Principle of Relevant Information for Graph Sparsification},
  booktitle = {Proceedings of the {{Thirty-Eighth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Yu, Shujian and Alesiani, Francesco and Yin, Wenzhe and Jenssen, Robert and Principe, Jose C.},
  year = {2022},
  month = aug,
  pages = {2331--2341},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v180/yu22c.html},
  urldate = {2024-04-28},
  abstract = {Graph sparsification aims to reduce the number of edges of a graph while maintaining its structural properties. In this paper, we propose the first general and effective information-theoretic formulation of graph sparsification, by taking inspiration from the Principle of Relevant Information (PRI). To this end, we extend the PRI from a standard scalar random variable setting to structured data (i.e., graphs). Our Graph-PRI objective is achieved by operating on the graph Laplacian, made possible by expressing the graph Laplacian of a subgraph in terms of a sparse edge selection vector w. We provide both theoretical and empirical justifications on the validity of our Graph-PRI approach. We also analyze its analytical solutions in a few special cases. We finally present three representative real-world applications, namely graph sparsification, graph regularized multi-task learning, and medical imaging-derived brain network classification, to demonstrate the effectiveness, the versatility and the enhanced interpretability of our approach over prevalent sparsification techniques. Code of Graph-PRI is available at https://github.com/SJYuCNEL/PRI-Graphs.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/LKHCVDIV/Yu et al. - 2022 - Principle of relevant information for graph sparsi.pdf;/Users/kshitijgoel/Zotero/storage/Q28Y2ZCJ/Yu et al. - 2022 - Principle of relevant information for graph sparsi.pdf}
}

@inproceedings{yu_smmrexplore_2021,
  title = {{{SMMR-Explore}}: {{SubMap-based Multi-Robot Exploration System}} with {{Multi-robot Multi-target Potential Field Exploration Method}}},
  shorttitle = {{{SMMR-Explore}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Yu, Jincheng and Tong, Jianming and Xu, Yuanfan and Xu, Zhilin and Dong, Haolin and Yang, Tianxiang and Wang, Yu},
  year = {2021},
  month = may,
  pages = {8779--8785},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561328},
  abstract = {Collaborative exploration in an unknown environment without external positioning under limited communication is an essential task for multi-robot applications. For inter-robot positioning, various Distributed Simultaneous Localization and Mapping (DSLAM) systems share the Place Recognition (PR) descriptors and sensor data to estimate the relative pose between robots and merge robots' maps. As maps are constantly shared among robots in exploration, we design a map-based DSLAM framework, which only shares the submaps, eliminating the transfer of PR descriptors and sensor data. Our framework saves 30\% of total communication traffic. For exploration, each robot is assigned to get much unknown information about environments with paying little travel cost. As the number of sampled points increases, the goal would change back and forth among sampled frontiers, leading to the downgrade in exploration efficiency and the overlap of trajectories. We propose an exploration strategy based on Multi-robot Multi-target Potential Field (MMPF), which can eliminate goal's back-and-forth changes, boosting the exploration efficiency by 1.03 {\texttimes}{$\sim$}1.62 {\texttimes} with 3 \% {$\sim$} 40 \% travel cost saved. Our SubMap-based Multi-robot Exploration method (SMMR-Explore) is evaluated on both Gazebo simulator and real robots. The simulator and the exploration framework are published as an open-source ROS project at https://github.com/efc-robot/SMMR-Explore.},
  keywords = {Boosting,Collaboration,Conferences,Costs,Distributed databases,Robot sensing systems,Simultaneous localization and mapping},
  file = {/Users/kshitijgoel/Zotero/storage/V3AN7JCA/Yu et al. - 2021 - SMMR-Explore SubMap-based Multi-Robot Exploration.pdf}
}

@article{yu_whitebox_2023,
  title = {White-{{Box Transformers}} via {{Sparse Rate Reduction}}},
  author = {Yu, Yaodong and Buchanan, Sam and Pai, Druv and Chu, Tianzhe and Wu, Ziyang and Tong, Shengbang and Haeffele, Benjamin and Ma, Yi},
  year = {2023},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {9422--9457},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/1e118ba9ee76c20df728b42a35fb4704-Abstract-Conference.html},
  urldate = {2024-04-03},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AMF5P8BK/Yu et al. - 2023 - White-Box Transformers via Sparse Rate Reduction.pdf}
}

@article{yuan_efficient_2022,
  title = {Efficient and {{Probabilistic Adaptive Voxel Mapping}} for {{Accurate Online LiDAR Odometry}}},
  author = {Yuan, Chongjian and Xu, Wei and Liu, Xiyuan and Hong, Xiaoping and Zhang, Fu},
  year = {2022},
  month = jul,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {3},
  pages = {8518--8525},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3187250},
  abstract = {This letter proposes an efficient and probabilistic adaptive voxel mapping method for LiDAR odometry. The map is a collection of voxels; each contains one plane feature that enables the probabilistic representation of the environment and accurate registration of a new LiDAR scan. We further analyze the need for coarse-to-fine voxel mapping and then use a novel voxel map organized by a Hash table and octrees to build and update the map efficiently. We apply the proposed voxel map to an iterated extended Kalman filter and construct a maximum a posteriori probability problem for pose estimation. Experiments on the open KITTI dataset show the high accuracy and efficiency of our method compared to other state-of-the-art methods. Experiments on indoor and unstructured outdoor environments with solid-state LiDAR and non-repetitive scanning LiDAR further verify the adaptability of our mapping method to different environments and LiDAR scanning patterns (see our attached video1). Our codes and dataset are open-sourced on Github2},
  keywords = {Laser radar,Localization,Mapping,Measurement uncertainty,Noise measurement,Point cloud compression,Probabilistic logic,SLAM,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/K782QD2H/Yuan et al. - 2022 - Efficient and Probabilistic Adaptive Voxel Mapping.pdf;/Users/kshitijgoel/Zotero/storage/PCL97Q4P/9813516.html}
}

@misc{yugay_magicslam_2024,
  title = {{{MAGiC-SLAM}}: {{Multi-Agent Gaussian Globally Consistent SLAM}}},
  shorttitle = {{{MAGiC-SLAM}}},
  author = {Yugay, Vladimir and Gevers, Theo and Oswald, Martin R.},
  year = {2024},
  month = nov,
  number = {arXiv:2411.16785},
  eprint = {2411.16785},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.16785},
  url = {http://arxiv.org/abs/2411.16785},
  urldate = {2024-11-30},
  abstract = {Simultaneous localization and mapping (SLAM) systems with novel view synthesis capabilities are widely used in computer vision, with applications in augmented reality, robotics, and autonomous driving. However, existing approaches are limited to single-agent operation. Recent work has addressed this problem using a distributed neural scene representation. Unfortunately, existing methods are slow, cannot accurately render real-world data, are restricted to two agents, and have limited tracking accuracy. In contrast, we propose a rigidly deformable 3D Gaussian-based scene representation that dramatically speeds up the system. However, improving tracking accuracy and reconstructing a globally consistent map from multiple agents remains challenging due to trajectory drift and discrepancies across agents' observations. Therefore, we propose new tracking and map-merging mechanisms and integrate loop closure in the Gaussian-based SLAM pipeline. We evaluate MAGiC-SLAM on synthetic and real-world datasets and find it more accurate and faster than the state of the art.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/A5ZVBDT6/Yugay et al. - 2024 - MAGiC-SLAM Multi-Agent Gaussian Globally Consistent SLAM.pdf;/Users/kshitijgoel/Zotero/storage/8HVR6NJF/2411.html}
}

@inproceedings{zampieri_entropydriven_2024,
  title = {Entropy-Driven {{Progressive Compression}} of {{3D Point Clouds}}.},
  booktitle = {{{SGP}} 2024 - {{Eurographics Symposium}} on {{Geometry Processing}}},
  author = {Zampieri, Armand and Delarue, Guillaume and Bakr, Nachwa Abou and Alliez, Pierre},
  year = {2024},
  month = jun,
  volume = {43},
  url = {https://inria.hal.science/hal-04630545},
  urldate = {2024-07-16},
  abstract = {3D point clouds stand as one of the prevalent representations for 3D data, offering the advantage of closely aligning with sensing technologies and providing an unbiased representation of a measured physical scene. Progressive compression is required for real-world applications operating on networked infrastructures with restricted or variable bandwidth. We contribute a novel approach that leverages a recursive binary space partition, where the partitioning planes are not necessarily axis-aligned and optimized via an entropy criterion. The planes are encoded via a novel adaptive quantization method combined with prediction. The input 3D point cloud is encoded as an interlaced stream of partitioning planes and number of points in the cells of the partition. Compared to previous work, the added value is an improved rate-distortion performance, especially for very low bitrates. The latter are critical for interactive navigation of large 3D point clouds on heterogeneous networked infrastructures.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/4QT6QP2X/Zampieri et al. - 2024 - Entropy-driven Progressive Compression of 3D Point Clouds..pdf}
}

@inproceedings{zeng_efficient_2023,
  title = {Efficient {{View Path Planning}} for {{Autonomous Implicit Reconstruction}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zeng, Jing and Li, Yanxu and Ran, Yunlong and Li, Shuo and Gao, Fei and Li, Lincheng and He, Shibo and Chen, Jiming and Ye, Qi},
  year = {2023},
  month = may,
  pages = {4063--4069},
  publisher = {IEEE},
  address = {London, United Kingdom},
  doi = {10.1109/ICRA48891.2023.10160793},
  url = {https://ieeexplore.ieee.org/document/10160793/},
  urldate = {2023-09-24},
  abstract = {Implicit neural representations have shown promising potential for 3D scene reconstruction. Recent work applies it to autonomous 3D reconstruction by learning information gain for view path planning. Effective as it is, the computation of the information gain is expensive, and compared with that using volumetric representations, collision checking using the implicit representation for a 3D point is much slower. In the paper, we propose to 1) leverage a neural network as an implicit function approximator for the information gain field and 2) combine the implicit fine-grained representation with coarse volumetric representations to improve efficiency. Further with the improved efficiency, we propose a novel informative path planning based on a graph-based planner. Our method demonstrates significant improvements in the reconstruction quality and planning efficiency compared with autonomous reconstructions with implicit and explicit representations. We deploy the method on a real UAV and the results show that our method can plan informative views and reconstruct a scene with high quality.},
  isbn = {979-8-3503-2365-8},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VHVJNWK5/Zeng et al. - 2023 - Efficient View Path Planning for Autonomous Implic.pdf}
}

@misc{zeng_multirobot_2024,
  title = {Multi-Robot Autonomous {{3D}} Reconstruction Using {{Gaussian}} Splatting with {{Semantic}} Guidance},
  author = {Zeng, Jing and Ye, Qi and Liu, Tianle and Xu, Yang and Li, Jin and Xu, Jinming and Li, Liang and Chen, Jiming},
  year = {2024},
  month = dec,
  number = {arXiv:2412.02249},
  eprint = {2412.02249},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.02249},
  url = {http://arxiv.org/abs/2412.02249},
  urldate = {2024-12-08},
  abstract = {Implicit neural representations and 3D Gaussian splatting (3DGS) have shown great potential for scene reconstruction. Recent studies have expanded their applications in autonomous reconstruction through task assignment methods. However, these methods are mainly limited to single robot, and rapid reconstruction of large-scale scenes remains challenging. Additionally, task-driven planning based on surface uncertainty is prone to being trapped in local optima. To this end, we propose the first 3DGS-based centralized multi-robot autonomous 3D reconstruction framework. To further reduce time cost of task generation and improve reconstruction quality, we integrate online open-vocabulary semantic segmentation with surface uncertainty of 3DGS, focusing view sampling on regions with high instance uncertainty. Finally, we develop a multi-robot collaboration strategy with mode and task assignments improving reconstruction quality while ensuring planning efficiency. Our method demonstrates the highest reconstruction quality among all planning methods and superior planning efficiency compared to existing multi-robot methods. We deploy our method on multiple robots, and results show that it can effectively plan view paths and reconstruct scenes with high quality.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/SM9QWBFD/Zeng et al. - 2024 - Multi-robot autonomous 3D reconstruction using Gaussian splatting with Semantic guidance.pdf;/Users/kshitijgoel/Zotero/storage/ICMULAYM/2412.html}
}

@misc{zhang_back_2024,
  title = {Back to {{Newton}}'s {{Laws}}: {{Learning Vision-based Agile Flight}} via {{Differentiable Physics}}},
  shorttitle = {Back to {{Newton}}'s {{Laws}}},
  author = {Zhang, Yuang and Hu, Yu and Song, Yunlong and Zhou, Danping and Lin, Weiyao},
  year = {2024},
  month = jul,
  number = {arXiv:2407.10648},
  eprint = {2407.10648},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.10648},
  urldate = {2024-07-16},
  abstract = {Swarm navigation in cluttered environments is a grand challenge in robotics. This work combines deep learning with first-principle physics through differentiable simulation to enable autonomous navigation of multiple aerial robots through complex environments at high speed. Our approach optimizes a neural network control policy directly by backpropagating loss gradients through the robot simulation using a simple point-mass physics model and a depth rendering engine. Despite this simplicity, our method excels in challenging tasks for both multi-agent and single-agent applications with zeroshot sim-to-real transfer. In multi-agent scenarios, our system demonstrates self-organized behavior, enabling autonomous coordination without communication or centralized planning---an achievement not seen in existing traditional or learningbased methods. In single-agent scenarios, our system achieves a 90\% success rate in navigating through complex environments, significantly surpassing the 60\% success rate of the previous state-of-the-art approach. Our system can operate without state estimation and adapt to dynamic obstacles. In real-world forest environments, it navigates at speeds up to 20 m/s, doubling the speed of previous imitation learning-based solutions. Notably, all these capabilities are deployed on a budget-friendly \$21 computer, costing less than 5\% of a GPU-equipped board used in existing systems. Video demonstrations are available at https://youtu.be/LKg9hJqc2cc.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/7W85U5FG/Zhang et al. - 2024 - Back to Newton's Laws Learning Vision-based Agile Flight via Differentiable Physics.pdf}
}

@article{zhang_balancing_2022,
  title = {Balancing the {{Budget}}: {{Feature Selection}} and {{Tracking}} for {{Multi-Camera Visual-Inertial Odometry}}},
  shorttitle = {Balancing the {{Budget}}},
  author = {Zhang, Lintong and Wisth, David and Camurri, Marco and Fallon, Maurice},
  year = {2022},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {1182--1189},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3137910},
  abstract = {We present a multi-camera visual-inertial odometry system based on factor graph optimization which estimates motion by using all cameras simultaneously while retaining a fixed overall feature budget. We focus on motion tracking in challenging environments, such as narrow corridors, dark spaces with aggressive motions, and abrupt lighting changes. These scenarios cause traditional monocular or stereo odometry to fail. While tracking motion with extra cameras should theoretically prevent failures, it leads to additional complexity and computational burden. To overcome these challenges, we introduce two novel methods to improve multi-camera feature tracking. First, instead of tracking features separately in each camera, we track features continuously as they move from one camera to another. This increases accuracy and achieves a more compact factor graph representation. Second, we select a fixed budget of tracked features across the cameras to reduce back-end optimization time. We have found that using a smaller set of informative features can maintain the same tracking accuracy. Our proposed method was extensively tested using a hardware-synchronized device consisting of an IMU and four cameras (a front stereo pair and two lateral) in scenarios including: an underground mine, large open spaces, and building interiors with narrow stairs and corridors. Compared to stereo-only state-of-the-art visual-inertial odometry methods, our approach reduces the drift rate, relative pose error, by up to 80\% in translation and 39\% in rotation.},
  keywords = {Cameras,Estimation,Feature extraction,localization,omnidirectional vision,Optimization,Robot vision systems,Tracking,Visual-inertial SLAM,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/ZIFU36C7/Zhang et al. - 2022 - Balancing the Budget Feature Selection and Tracki.pdf;/Users/kshitijgoel/Zotero/storage/A4UJNC53/stamp.html}
}

@article{zhang_bsc_2023,
  title = {{{BSC}}: {{Belief Shift Clustering}}},
  shorttitle = {{{BSC}}},
  author = {Zhang, Zuo-Wei and Liu, Zhun-Ga and Martin, Arnaud and Zhou, Kuang},
  year = {2023},
  month = mar,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  volume = {53},
  number = {3},
  pages = {1748--1760},
  issn = {2168-2232},
  doi = {10.1109/TSMC.2022.3205365},
  url = {https://ieeexplore.ieee.org/abstract/document/9900368},
  urldate = {2024-06-23},
  abstract = {It is still a challenging problem to characterize uncertainty and imprecision between specific (singleton) clusters with arbitrary shapes and sizes. In order to solve such a problem, we propose a belief shift clustering (BSC) method for dealing with object data. The BSC method is considered as the evidential version of mean shift or mode seeking under the theory of belief functions. First, a new notion, called belief shift, is provided to preliminarily assign each query object as the noise, precise, or imprecise one. Second, a new evidential clustering rule is designed to partial credal redistribution for each imprecise object. To avoid the ``uniform effect'' and useless calculations, a specific dynamic framework with simulated cluster centers is established to reassign each imprecise object to a singleton cluster or related meta-cluster. Once an object is assigned to a meta-cluster, this object may be in the overlapping or intermediate areas of different singleton clusters. Consequently, the BSC can reasonably characterize the uncertainty and imprecision between singleton clusters. The effectiveness has been verified on several artificial, natural, and image segmentation/classification datasets by comparison with other related methods.},
  keywords = {Bandwidth,Belief shift,Clustering methods,Evidence theory,evidential clustering,Kernel,mean shift (or) mode seeking (MS),Probability density function,Shape,Task analysis,uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/LSMIQS39/Zhang et al. - 2023 - BSC Belief Shift Clustering.pdf}
}

@inproceedings{zhang_continuous_2023,
  title = {Continuous {{Implicit SDF Based Any-Shape Robot Trajectory Optimization}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Zhang, Tingrui and Wang, Jingping and Xu, Chao and Gao, Alan and Gao, Fei},
  year = {2023},
  month = oct,
  pages = {282--289},
  publisher = {IEEE},
  address = {Detroit, MI, USA},
  doi = {10.1109/IROS55552.2023.10342104},
  url = {https://ieeexplore.ieee.org/document/10342104/},
  urldate = {2024-01-18},
  abstract = {Optimization-based trajectory generation methods are widely used in whole-body planning for robots. However, existing work either oversimplifies the robot's geometry and environment representation, resulting in a conservative trajectory or suffers from a huge overhead in maintaining additional information such as the Signed Distance Field (SDF). To bridge the gap, we consider the robot as an implicit function, with its surface boundary represented by the zero-level set of its SDF. We further employ another implicit function to lazily compute the signed distance to the swept volume generated by the robot and its trajectory. The computation is efficient by exploiting continuity in space-time, and the implicit function guarantees continuous collision evaluation even for nonconvex robots with complex surfaces. We also propose a trajectory optimization pipeline applicable to the implicit SDF. Simulation and realworld experiments validate the high performance of our approach for arbitrarily shaped robot trajectory optimization.},
  isbn = {978-1-6654-9190-7},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/S9DIVFCN/Zhang et al. - 2023 - Continuous Implicit SDF Based Any-Shape Robot Traj.pdf}
}

@inproceedings{zhang_correspondencefree_2025,
  title = {Correspondence-{{Free SE}}(3) {{Point Cloud Registration}} in~{{RKHS}} via~{{Unsupervised Equivariant Learning}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2024},
  author = {Zhang, Ray and Zhou, Zheming and Sun, Min and Ghasemalizadeh, Omid and Kuo, Cheng-Hao and Eustice, Ryan M. and Ghaffari, Maani and Sen, Arnie},
  editor = {Leonardis, Ale{\v s} and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, G{\"u}l},
  year = {2025},
  pages = {68--86},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-73223-2_5},
  abstract = {This paper introduces a robust unsupervised SE(3) point cloud registration method that operates without requiring point correspondences. The method frames point clouds as functions in a reproducing kernel Hilbert space (RKHS), leveraging SE(3)-equivariant features for direct feature space registration. A novel RKHS distance metric is proposed, offering reliable performance amidst noise, outliers, and asymmetrical data. An unsupervised training approach is introduced to effectively handle limited ground truth data, facilitating adaptation to real datasets. The proposed method outperforms classical and supervised methods in terms of registration accuracy on both synthetic (ModelNet40) and real-world (ETH3D) noisy, outlier-rich datasets. To our best knowledge, this marks the first instance of successful real RGB-D odometry data registration using an equivariant method. The code is available at https://sites.google.com/view/eccv24-equivalign.},
  isbn = {978-3-031-73223-2},
  langid = {english},
  keywords = {Equivariant Learning,Kernel Method,Point Cloud Registration,Unsupervised Learning},
  file = {/Users/kshitijgoel/Zotero/storage/VHKCEBVE/Zhang et al. - 2025 - Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning.pdf}
}

@misc{zhang_darkgs_2024,
  title = {{{DarkGS}}: {{Learning Neural Illumination}} and {{3D Gaussians Relighting}} for {{Robotic Exploration}} in the {{Dark}}},
  shorttitle = {{{DarkGS}}},
  author = {Zhang, Tianyi and Huang, Kaining and Zhi, Weiming and {Johnson-Roberson}, Matthew},
  year = {2024},
  month = mar,
  number = {arXiv:2403.10814},
  eprint = {2403.10814},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2403.10814},
  urldate = {2024-05-28},
  abstract = {Humans have the remarkable ability to construct consistent mental models of an environment, even under limited or varying levels of illumination. We wish to endow robots with this same capability. In this paper, we tackle the challenge of constructing a photorealistic scene representation under poorly illuminated conditions and with a moving light source. We approach the task of modeling illumination as a learning problem, and utilize the developed illumination model to aid in scene reconstruction. We introduce an innovative framework that uses a data-driven approach, Neural Light Simulators (NeLiS), to model and calibrate the camera-light system. Furthermore, we present DarkGS, a method that applies NeLiS to create a relightable 3D Gaussian scene model capable of real-time, photorealistic rendering from novel viewpoints. We show the applicability and robustness of our proposed simulator and system in a variety of real-world environments.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/4VXWBGX9/Zhang et al. - 2024 - DarkGS Learning Neural Illumination and 3D Gaussians Relighting for Robotic Exploration in the Dark.pdf}
}

@article{zhang_distributed_2022,
  title = {Distributed {{Learning}} of {{Finite Gaussian Mixtures}}},
  author = {Zhang, Qiong and Chen, Jiahua},
  year = {2022},
  journal = {Journal of Machine Learning Research},
  volume = {23},
  number = {99},
  pages = {1--40},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v23/21-0093.html},
  urldate = {2022-09-27},
  abstract = {Advances in information technology have led to extremely large datasets that are often kept in different storage centers. Existing statistical methods must be adapted to overcome the resulting computational obstacles while retaining statistical validity and efficiency. In this situation, the split-and-conquer strategy is among the most effective solutions to many statistical problems, including quantile processes, regression analysis, principal eigenspaces, and exponential families. This paper applies this strategy to develop a distributed learning procedure of finite Gaussian mixtures. We recommend a reduction strategy and invent an effective majorization-minimization algorithm. The new estimator is consistent and retains root-n consistency under some general conditions. Experiments based on simulated and real-world datasets show that the proposed estimator has comparable statistical performance with the global estimator based on the full dataset, if the latter is feasible. It can even outperform the global estimator for the purpose of clustering if the model assumption does not fully match the real-world data. It also has better statistical and computational performance than some existing split-and-conquer approaches.},
  file = {/Users/kshitijgoel/Zotero/storage/U3DN3WQI/Zhang and Chen - 2022 - Distributed Learning of Finite Gaussian Mixtures.pdf;/Users/kshitijgoel/Zotero/storage/BDD6C24U/SCGMM.html}
}

@article{zhang_distributed_2023,
  title = {Distributed {{Information-Based Source Seeking}}},
  author = {Zhang, Tianpeng and Qin, Victor and Tang, Yujie and Li, Na},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  pages = {1--19},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3309099},
  url = {https://ieeexplore.ieee.org/document/10250987/},
  urldate = {2023-11-29},
  abstract = {In this article, we design an information-based multirobot source seeking algorithm where a group of mobile sensors localizes and moves close to a single source using only local rangebased measurements. In the algorithm, the mobile sensors perform source identification/localization to estimate the source location; meanwhile, they move to new locations to maximize the Fisher information about the source contained in the sensor measurements. In doing so, they improve the source location estimate and move closer to the source. Our algorithm is superior in convergence speed compared with traditional field climbing algorithms, is flexible in the measurement model and the choice of information metric, and is robust to measurement model errors. Moreover, we provide a fully distributed version of our algorithm, where each sensor decides its own actions and only shares information with its neighbors through a sparse communication network. We perform extensive simulation experiments to test our algorithms on large-scale systems and implement physical experiments on small ground vehicles with light sensors, demonstrating success in seeking a light source.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/HNHW47LE/Zhang et al. - 2023 - Distributed Information-Based Source Seeking.pdf}
}

@article{zhang_falco_2020,
  title = {Falco: {{Fast}} Likelihood-Based Collision Avoidance with Extension to Human-Guided Navigation},
  shorttitle = {Falco},
  author = {Zhang, Ji and Hu, Chen and Chadha, Rushat Gupta and Singh, Sanjiv},
  year = {2020},
  journal = {Journal of Field Robotics},
  volume = {37},
  number = {8},
  pages = {1300--1313},
  issn = {1556-4967},
  doi = {10.1002/rob.21952},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21952},
  urldate = {2022-07-17},
  abstract = {We propose a planning method to enable fast autonomous flight in cluttered environments. Typically, autonomous navigation through a complex environment requires a continuous search on a graph generated by a k-connected grid or a probabilistic scheme. As the vehicle travels, updating the graph with data from onboard sensors is expensive as is the search on the graph especially if the paths must be kinodynamically feasible. We propose to avoid the online search to reduce the computational complexity. Our method models the environment differently in two separate regions. Obstacles are considered to be deterministically known within the sensor range and probabilistically known beyond the sensor range. Instead of searching for the path with the lowest cost (typically the shortest path), the method maximizes the likelihood to reach the goal in determining the immediate next step for navigation. With such a problem formulation, the online method realized by a trajectory library can determine a path within 0.2--0.3 ms using a single central processing unit thread on a modem embedded computer. The method supports two configurations working with and without a prior map. Both configurations can be used to plan toward a goal point. Further, the later can allow human guidance for the navigation through a directional input. In experiments, it enables a lightweight unmanned aerial vehicle to fly at 10 m/s in a cluttered forest environment (see Figure 1 as an example).},
  langid = {english},
  keywords = {aerial robotics,obstacle avoidance,planning},
  file = {/Users/kshitijgoel/Zotero/storage/QKCI5U6F/Zhang et al. - 2020 - Falco Fast likelihood-based collision avoidance w.pdf;/Users/kshitijgoel/Zotero/storage/BFNPXJXK/rob.html}
}

@article{zhang_falcon_2024,
  title = {{{FALCON}}: {{Fast Autonomous Aerial Exploration Using Coverage Path Guidance}}},
  shorttitle = {{{FALCON}}},
  author = {Zhang, Yichen and Chen, Xinyi and Feng, Chen and Zhou, Boyu and Shen, Shaojie},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3522148},
  url = {https://ieeexplore.ieee.org/document/10816079/?arnumber=10816079},
  urldate = {2025-01-02},
  abstract = {This paper introduces FALCON, a novel Fast Autonomous expLoration framework using COverage path guidaNce, which aims at setting a new performance benchmark in the field of autonomous aerial exploration. Despite recent advancements in the domain, existing exploration planners often suffer from inefficiencies such as frequent revisitations of previously explored regions. FALCON effectively harnesses the full potential of online generated coverage paths in enhancing exploration efficiency. The framework begins with an incremental connectivity-aware space decomposition and connectivity graph construction, which facilitate efficient coverage path planning. Subsequently, a hierarchical planner generates a coverage path spanning the entire unexplored space, serving as a global guidance. Then, a local planner optimizes the frontier visitation order, minimizing traversal time while consciously incorporating the intention of the global guidance. Finally, minimum-time smooth and safe trajectories are produced to visit the frontier viewpoints. For fair and comprehensive benchmark experiments, we introduce a lightweight exploration planner evaluation environment that allows for comparing exploration planners across a variety of testing scenarios using an identical quadrotor simulator. Additionally, an in-depth analysis and evaluation is conducted to highlight the significant performance advantages of FALCON in comparison with the state-of-the-art exploration planners based on objective criteria. Extensive ablation studies demonstrate the effectiveness of each component in the proposed framework. Real-world experiments conducted fully onboard further validate FALCON's practical capability in complex and challenging environments. The source code of both the exploration planner FALCON and the exploration planner evaluation environment has been released to benefit the community},
  keywords = {aerial systems,Aerial systems,applications,autonomous exploration,Cameras,Laser radar,Lasers,Location awareness,motion and path planning,perception and autonomy,Planning,Quadrotors,Robot sensing systems,Robots,Three-dimensional displays,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/RRQ8FKCK/Zhang et al. - 2024 - FALCON Fast Autonomous Aerial Exploration Using Coverage Path Guidance.pdf;/Users/kshitijgoel/Zotero/storage/H39UQ7ZW/10816079.html}
}

@inproceedings{zhang_finding_2020,
  title = {Finding {{Plans Subject}} to {{Stipulations}} on {{What Information They Divulge}}},
  booktitle = {Algorithmic {{Foundations}} of {{Robotics XIII}}},
  author = {Zhang, Yulin and Shell, Dylan A. and O'Kane, Jason M.},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  series = {Springer {{Proceedings}} in {{Advanced Robotics}}},
  pages = {106--124},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-44051-0_7},
  abstract = {Motivated by applications where privacy is important, we study planning problems for robots acting in the presence of an observer. We first formulate and then solve planning problems subject to stipulations on the information divulged during plan execution---the appropriate solution concept being both a plan and an information disclosure policy. We pose this class of problem under a worst-case model within the framework of procrustean graphs, formulating the disclosure policy as a particular type of map on edge labels. We devise algorithms that, given a planning problem supplemented with an information stipulation, can find a plan, associated disclosure policy, or both jointly, if and only if some exists. The pair together, comprising the plan and associated disclosure policy, may depend subtly on additional information available to the observer, such as whether the observer knows the robot's plan (e.g., leaked via a side-channel). Our implementation finds a plan and a suitable disclosure policy, jointly, when any such pair exists, albeit for small problem instances.},
  isbn = {978-3-030-44051-0},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/L9RD56K8/Zhang et al. - 2020 - Finding Plans Subject to Stipulations on What Info.pdf}
}

@article{zhang_fsmi_2020,
  title = {{{FSMI}}: {{Fast}} Computation of {{Shannon}} Mutual Information for Information-Theoretic Mapping},
  shorttitle = {{{FSMI}}},
  author = {Zhang, Zhengdong and Henderson, Theia and Karaman, Sertac and Sze, Vivienne},
  year = {2020},
  month = aug,
  journal = {The International Journal of Robotics Research},
  volume = {39},
  number = {9},
  pages = {1155--1177},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/0278364920921941},
  url = {https://doi.org/10.1177/0278364920921941},
  urldate = {2022-05-20},
  abstract = {Exploration tasks are embedded in many robotics applications, such as search and rescue and space exploration. Information-based exploration algorithms aim to find the most informative trajectories by maximizing an information-theoretic metric, such as the mutual information between the map and potential future measurements. Unfortunately, most existing information-based exploration algorithms are plagued by the computational difficulty of evaluating the Shannon mutual information metric. In this article, we consider the fundamental problem of evaluating Shannon mutual information between the map and a range measurement. First, we consider 2D environments. We propose a novel algorithm, called the fast Shannon mutual information (FSMI). The key insight behind the algorithm is that a certain integral can be computed analytically, leading to substantial computational savings. Second, we consider 3D environments, represented by efficient data structures, e.g., an OctoMap, such that the measurements are compressed by run-length encoding (RLE). We propose a novel algorithm, called FSMI-RLE, that efficiently evaluates the Shannon mutual information when the measurements are compressed using RLE. For both the FSMI and the FSMI-RLE, we also propose variants that make different assumptions on the sensor noise distribution for the purpose of further computational savings. We evaluate the proposed algorithms in extensive experiments. In particular, we show that the proposed algorithms outperform existing algorithms that compute Shannon mutual information as well as other algorithms that compute the Cauchy?Schwarz quadratic mutual information (CSQMI). In addition, we demonstrate the computation of Shannon mutual information on a 3D map for the first time.},
  file = {/Users/kshitijgoel/Zotero/storage/DVI4PYST/Zhang et al. - 2020 - FSMI Fast computation of Shannon mutual informati.pdf}
}

@misc{zhang_fsmp_2025,
  title = {{{FSMP}}: {{A Frontier-Sampling-Mixed Planner}} for {{Fast Autonomous Exploration}} of {{Complex}} and {{Large}} 3-{{D Environments}}},
  shorttitle = {{{FSMP}}},
  author = {Zhang, Shiyong and Zhang, Xuebo and Dong, Qianli and Wang, Ziyu and Xi, Haobo and Yuan, Jing},
  year = {2025},
  month = feb,
  number = {arXiv:2502.20707},
  eprint = {2502.20707},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.20707},
  url = {http://arxiv.org/abs/2502.20707},
  urldate = {2025-03-03},
  abstract = {In this paper, we propose a systematic framework for fast exploration of complex and large 3-D environments using micro aerial vehicles (MAVs). The key insight is the organic integration of the frontier-based and sampling-based strategies that can achieve rapid global exploration of the environment. Specifically, a field-of-view-based (FOV) frontier detector with the guarantee of completeness and soundness is devised for identifying 3-D map frontiers. Different from random sampling-based methods, the deterministic sampling technique is employed to build and maintain an incremental road map based on the recorded sensor FOVs and newly detected frontiers. With the resulting road map, we propose a two-stage path planner. First, it quickly computes the global optimal exploration path on the road map using the lazy evaluation strategy. Then, the best exploration path is smoothed for further improving the exploration efficiency. We validate the proposed method both in simulation and real-world experiments. The comparative results demonstrate the promising performance of our planner in terms of exploration efficiency, computational time, and explored volume.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/CJEX8EV8/Zhang et al. - 2025 - FSMP A Frontier-Sampling-Mixed Planner for Fast Autonomous Exploration of Complex and Large 3-D Env.pdf;/Users/kshitijgoel/Zotero/storage/ATUN2DM6/2502.html}
}

@inproceedings{zhang_general_2023,
  title = {A General Class of Combinatorial Filters That Can Be Minimized Efficiently},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhang, Yulin and Shell, Dylan A.},
  year = {2023},
  month = may,
  pages = {1645--1651},
  doi = {10.1109/ICRA48891.2023.10160479},
  abstract = {State minimization of combinatorial filters is a fundamental problem that arises, for example, in building cheap, resource-efficient robots. But exact minimization is known to be NP-hard. This paper conducts a more nuanced analysis of this hardness than up till now, and uncovers two factors which contribute to this complexity. We show each factor is a distinct source of the problem's hardness and are able, thereby, to shed some light on the role played by (1) structure of the graph that encodes compatibility relationships, and (2) determinism-enforcing constraints. Just as a line of prior work has sought to introduce additional assumptions and identify sub-classes that lead to practical state reduction, we next use this new, sharper understanding to explore special cases for which exact minimization is efficient. We introduce a new algorithm for constraint repair that applies to a large sub-class of filters, subsuming three distinct special cases for which the possibility of optimal minimization in polynomial time was known earlier. While the efficiency in each of these three cases previously appeared to stem from seemingly dissimilar properties, when seen through the lens of the present work, their commonality now becomes clear. We also provide entirely new families of filters that are efficiently reducible.},
  keywords = {Automation,Buildings,Filtering algorithms,Maintenance engineering,Minimization,NP-hard problem,Robots},
  file = {/Users/kshitijgoel/Zotero/storage/PBNBAN4J/Zhang and Shell - 2023 - A general class of combinatorial filters that can .pdf;/Users/kshitijgoel/Zotero/storage/6KR6GDWQ/10160479.html}
}

@article{zhang_heterogeneous_2024,
  title = {Heterogeneous {{Targets Trapping With Swarm Robots}} by {{Using Adaptive Density-Based Interaction}}},
  author = {Zhang, Shuai and Lei, Xiaokang and Peng, Xingguang and Pan, Jia},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  pages = {1--20},
  issn = {1941-0468},
  doi = {10.1109/TRO.2024.3392078},
  url = {https://ieeexplore.ieee.org/document/10506641},
  urldate = {2024-05-06},
  abstract = {Homogeneous swarm robots are of significant research interest due to their robustness, flexibility, and scalability in completing complex tasks across various applications. This paper focuses on trapping heterogeneous targets using swarm robots, with emphasis on their different strengths. These targets consist of weak, strong, and group-moving individuals, where stronger targets exhibit larger body size, higher physical strength, and stronger resistance ability. Our goal is to develop an adaptive controller that enables swarm robots to self-organize and distribute themselves to trap targets, while adjusting encirclement thickness and robot group size based on target strength. We leverage local implicit information generated from density-based interaction to improve inter-robot and robot-target interactions through adaptive allocation and transformation mechanisms. The feasibility of our approach is validated through numerical simulations and experiments involving up to 50 physical robots and one human-controlled transformer.},
  keywords = {Distributed robot systems,heterogeneous targets trapping,multi-robot systems,Resource management,Robot kinematics,Robot sensing systems,Shape,swarm,Swarm robotics,Task analysis,Technological innovation},
  file = {/Users/kshitijgoel/Zotero/storage/PM7R6V6X/Zhang et al. - 2024 - Heterogeneous Targets Trapping With Swarm Robots by Using Adaptive Density-Based Interaction.pdf;/Users/kshitijgoel/Zotero/storage/VF2YHNW8/10506641.html}
}

@article{zhang_kernel_2021,
  title = {Kernel {{Smoothing}}, {{Mean Shift}}, and {{Their Learning Theory}} with {{Directional Data}}},
  author = {Zhang, Yikun and Chen, Yen-Chi},
  year = {2021},
  journal = {Journal of Machine Learning Research},
  volume = {22},
  number = {154},
  pages = {1--92},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v22/20-1194.html},
  urldate = {2024-06-24},
  abstract = {Directional data consist of observations distributed on a (hyper)sphere, and appear in many applied fields, such as astronomy, ecology, and environmental science. This paper studies both statistical and computational problems of kernel smoothing for directional data. We generalize the classical mean shift algorithm to directional data, which allows us to identify local modes of the directional kernel density estimator (KDE). The statistical convergence rates of the directional KDE and its derivatives are derived, and the problem of mode estimation is examined. We also prove the ascending property of the directional mean shift algorithm and investigate a general problem of gradient ascent on the unit hypersphere. To demonstrate the applicability of the algorithm, we evaluate it as a mode clustering method on both simulated and real-world data sets.},
  file = {/Users/kshitijgoel/Zotero/storage/5ANBTAQY/Zhang and Chen - 2021 - Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data.pdf;/Users/kshitijgoel/Zotero/storage/KMDCRQVJ/DirMS.html}
}

@article{zhang_learning_2025,
  title = {Learning Vision-Based Agile Flight via Differentiable Physics},
  author = {Zhang, Yuang and Hu, Yu and Song, Yunlong and Zou, Danping and Lin, Weiyao},
  year = {2025},
  month = jun,
  journal = {Nature Machine Intelligence},
  volume = {7},
  number = {6},
  pages = {954--966},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-025-01048-0},
  url = {https://www.nature.com/articles/s42256-025-01048-0},
  urldate = {2025-07-07},
  abstract = {Autonomous aerial robot swarms promise transformative applications, from planetary exploration to search and rescue in complex environments. However, navigating these swarms efficiently in unknown and cluttered spaces without bulky sensors, heavy computation or constant communication between robots remains a major research problem. This paper introduces an end-to-end approach that combines deep learning with first-principles physics through differentiable simulation to enable autonomous navigation by several aerial robots through complex environments at high speed. Our approach directly optimizes a neural network control policy by backpropagating loss gradients through the robot simulation using a simple point-mass physics model. Despite this simplicity, our method excels in both multi-agent and single-agent applications. In multi-agent scenarios, our system demonstrates self-organized behaviour, which enables autonomous coordination without communication or centralized planning. In single-agent scenarios, our system achieved a 90\% success rate in navigating through complex unknown environments and demonstrated enhanced robustness compared to previous state-of-the-art approaches. Our system can operate without state estimation and adapt to dynamic obstacles. In real-world forest environments, it navigates at speeds of up to 20\,m\,s-1, doubling the speed of previous imitation-learning-based solutions. Notably, all these capabilities are deployed on a budget-friendly US\$21 computer, which costs less than 5\% of the GPU-equipped board used in existing systems.},
  copyright = {2025 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Electrical and electronic engineering},
  file = {/Users/kshitijgoel/Zotero/storage/KGNPG9M5/Zhang et al. - 2025 - Learning vision-based agile flight via differentiable physics.pdf}
}

@article{zhang_leces_2024,
  title = {{{LECES}}: {{A Low-Bandwidth}} and {{Efficient Collaborative Exploration System With Distributed Multi-UAV}}},
  shorttitle = {{{LECES}}},
  author = {Zhang, Tong and Shen, Hao and Yin, Yingming and Xu, Jianyu and Yu, Jiajie and Pan, Yongzhou},
  year = {2024},
  month = sep,
  journal = {IEEE Robotics and Automation Letters},
  volume = {9},
  number = {9},
  pages = {7795--7802},
  issn = {2377-3766},
  doi = {10.1109/LRA.2024.3433200},
  url = {https://ieeexplore.ieee.org/document/10608399/?arnumber=10608399},
  urldate = {2024-12-11},
  abstract = {Collaborative exploration is a prevailing trend of autonomous exploration by unmanned aerial vehicles (UAVs). However, most collaborative exploration systems rely on excessively high communication bandwidth for precise map maintenance and efficient task allocation. This letter proposes a low-bandwidth and efficient collaborative exploration system with distributed multi-UAV. First, a lightweight map fusion method is proposed, based on Binary OctoMap with a sliding cube, to incrementally maintain a consistent global map for all UAVs with low bandwidth cost. Then, an efficient exploration strategy is proposed that decouples the multi-UAV task allocation problem into independent single-UAV Asymmetric Traveling Salesman Problems (ATSP) based on the consistent global map. By viewpoints clustering, assignment, and decision, it allows for efficient task allocation without iterative interactions. Experiments are conducted in both simulations and real-world environments. The experiment results demonstrate that our method achieves stable and efficient exploration with low communication bandwidth requirements.},
  keywords = {Aerial Systems: Applications,Autonomous aerial vehicles,Bandwidth,Collaboration,Iterative methods,Multi-Robot Systems,Resource management,Robots,Search and Rescue Robots,Task analysis},
  file = {/Users/kshitijgoel/Zotero/storage/P2IBFKNG/Zhang et al. - 2024 - LECES A Low-Bandwidth and Efficient Collaborative Exploration System With Distributed Multi-UAV.pdf;/Users/kshitijgoel/Zotero/storage/9DBD868L/10608399.html}
}

@article{zhang_linear_2023,
  title = {Linear Convergence of the Subspace Constrained Mean Shift Algorithm: From {{Euclidean}} to Directional Data},
  shorttitle = {Linear Convergence of the Subspace Constrained Mean Shift Algorithm},
  author = {Zhang, Yikun and Chen, Yen-Chi},
  year = {2023},
  month = mar,
  journal = {Information and Inference: A Journal of the IMA},
  volume = {12},
  number = {1},
  pages = {210--311},
  issn = {2049-8772},
  doi = {10.1093/imaiai/iaac005},
  url = {https://doi.org/10.1093/imaiai/iaac005},
  urldate = {2024-06-23},
  abstract = {This paper studies the linear convergence of the subspace constrained mean shift (SCMS) algorithm, a well-known algorithm for identifying a density ridge defined by a kernel density estimator. By arguing that the SCMS algorithm is a special variant of a subspace constrained gradient ascent (SCGA) algorithm with an adaptive step size, we derive the linear convergence of such SCGA algorithm. While the existing research focuses mainly on density ridges in the Euclidean space, we generalize density ridges and the SCMS algorithm to directional data. In particular, we establish the stability theorem of density ridges with directional data and prove the linear convergence of our proposed directional SCMS algorithm.},
  file = {/Users/kshitijgoel/Zotero/storage/AK6GBW5L/Zhang and Chen - 2023 - Linear convergence of the subspace constrained mean shift algorithm from Euclidean to directional d.pdf}
}

@article{zhang_mode_2025,
  title = {Mode and {{Ridge Estimation}} in {{Euclidean}} and {{Directional Product Spaces}}: {{A Mean Shift Approach}}},
  shorttitle = {Mode and {{Ridge Estimation}} in {{Euclidean}} and {{Directional Product Spaces}}},
  author = {Zhang, Yikun and Chen, Yen-Chi},
  year = {2025},
  month = jul,
  journal = {Journal of Computational and Graphical Statistics},
  eprint = {2110.08505},
  primaryclass = {stat},
  pages = {1--10},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2025.2505734},
  url = {http://arxiv.org/abs/2110.08505},
  urldate = {2025-07-31},
  abstract = {The set of local modes and density ridge lines are important summary characteristics of the data-generating distribution. In this work, we focus on estimating local modes and density ridges from point cloud data in a product space combining two or more Euclidean and/or directional metric spaces. Specifically, our approach extends the (subspace constrained) mean shift algorithm to such product spaces, addressing potential challenges in the generalization process. We establish the algorithmic convergence of the proposed methods, along with practical implementation guidelines. Experiments on simulated and real-world datasets demonstrate the effectiveness of our proposed methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/kshitijgoel/Zotero/storage/DNBA7AQ3/Zhang and Chen - 2025 - Mode and Ridge Estimation in Euclidean and Directional Product Spaces A Mean Shift Approach.pdf;/Users/kshitijgoel/Zotero/storage/TXLMAGKK/Supplement.pdf;/Users/kshitijgoel/Zotero/storage/XYR7VJL5/2110.html}
}

@article{zhang_mrtopomap_2022,
  title = {{{MR-TopoMap}}: {{Multi-Robot Exploration Based}} on {{Topological Map}} in {{Communication Restricted Environment}}},
  shorttitle = {{{MR-TopoMap}}},
  author = {Zhang, Zhaoliang and Yu, Jincheng and Tang, Jiahao and Xu, Yuanfan and Wang, Yu},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {10794--10801},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3192765},
  abstract = {Multi-robot exploration in unknown environments is a fundamental task for a multi-robot system, involving inter-robot communication through messages among the robots. However, in a restricted communication environment, the limited communication resources become the system's bottleneck due to a large amount of data in the occupancy grid map. Hence, to enhance multi-agent exploration in communication-constrained environments, this letter develops a method to build topological maps while the robot moves in the environment and an exploration strategy based on the created topological map. The latter map comprises a set of vertices and edges connecting the vertices, where each vertex represents a specific area embedded with a descriptor extracted by visually observing this area and recognizing it utilizing descriptors. Each robot has its local grid map stored for path planning, not shared between them. Considering the exploration task, a robot's ability to choose a proper direction depends on the other robot's locations and the unexplored areas. Our exploration framework is evaluated on the Gazebo simulator and real robots, increasing the exploration efficiency by 23\%\${\textbackslash}sim\$77\%. Compared with the occupancy grid map scheme, our method's data transfer is reduced by 84\%\${\textbackslash}sim\$90\%.},
  keywords = {Feature extraction,mapping,Merging,Multi-robot SLAM,multi-robot systems,Robot kinematics,Robots,Simultaneous localization and mapping,Task analysis,Visualization},
  file = {/Users/kshitijgoel/Zotero/storage/M2C54IDW/Zhang et al. - 2022 - MR-TopoMap Multi-Robot Exploration Based on Topol.pdf}
}

@inproceedings{zhang_multiuav_2022,
  title = {Multi-{{UAV Cooperative Short-Range Combat}} via {{Attention-Based Reinforcement Learning}} Using {{Individual Reward Shaping}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Zhang, Tianle and Qiu, Tenghai and Liu, Zhen and Pu, Zhiqiang and Yi, Jianqiang and Zhu, Jinying and Hu, Ruiguang},
  year = {2022},
  month = oct,
  pages = {13737--13744},
  issn = {2153-0866},
  doi = {10.1109/IROS47612.2022.9982096},
  url = {https://ieeexplore.ieee.org/abstract/document/9982096},
  urldate = {2025-08-08},
  abstract = {In this paper, we propose a novel distributed method based on attention-based deep reinforcement learning using individual reward shaping, for multiple unmanned aerial vehicles (UAVs) cooperative short-range combat mission. Specifically, a two-level attention distributed policy, composed of observation-level and communication-level attention networks, is designed to enable each UAV to selectively focus on important environmental features and messages, for enhancing the effectiveness of the cooperative policy. Moreover, due to the high complexity and stochasticity of the UAV combat mission, the learning of UAVs is tricky and low efficient. To embed knowledge to accelerate the policy learning, a potential-based individual reward function is constructed by implicitly translating the individual reward into the specific form of dynamic action potentials. In addition, an actor-critic training algorithm based on the centralized training and decentralized execution framework is adopted to train the policy network of UAV maneuver decision. We build a three-dimensional UAV simulation and training platform based on Unity for multi-UAV short-range combat missions. Simulation results demonstrate the effectiveness of the proposed method and the superiority of the attention policy and individual reward shaping.},
  keywords = {Action potentials,Autonomous aerial vehicles,Heuristic algorithms,Reinforcement learning,Simulation,Solid modeling,Training},
  file = {/Users/kshitijgoel/Zotero/storage/24ZXXMXC/Zhang et al. - 2022 - Multi-UAV Cooperative Short-Range Combat via Attention-Based Reinforcement Learning using Individual.pdf}
}

@inproceedings{zhang_perceptionaware_2018,
  title = {Perception-Aware {{Receding Horizon Navigation}} for {{MAVs}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhang, Zichao and Scaramuzza, Davide},
  year = {2018},
  month = may,
  pages = {2534--2541},
  publisher = {IEEE},
  address = {Brisbane, QLD},
  doi = {10.1109/ICRA.2018.8461133},
  url = {https://ieeexplore.ieee.org/document/8461133/},
  urldate = {2024-01-23},
  abstract = {To reach a given destination safely and accurately, a micro aerial vehicle needs to be able to avoid obstacles and minimize its state estimation uncertainty at the same time. To achieve this goal, we propose a perception-aware receding horizon approach. In our method, a single forwardlooking camera is used for state estimation and mapping. Using the information from the monocular state estimation and mapping system, we generate a library of candidate trajectories and evaluate them in terms of perception quality, collision probability, and distance to the goal. The best trajectory to execute is then selected as the one that maximizes a reward function based on these three metrics. To the best of our knowledge, this is the first work that integrates active vision within a receding horizon navigation framework for a goal reaching task. We demonstrate by simulation and real-world experiments on an actual quadrotor that our active approach leads to improved state estimation accuracy in a goal-reaching task when compared to a purely-reactive navigation system, especially in difficult scenes (e.g., weak texture).},
  isbn = {978-1-5386-3081-5},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AN48N97Y/Zhang and Scaramuzza - 2018 - Perception-aware Receding Horizon Navigation for M.pdf}
}

@article{zhang_probabilistic_2022,
  title = {Probabilistic {{Network Topology Prediction}} for {{Active Planning}}: {{An Adaptive Algorithm}} and {{Application}}},
  shorttitle = {Probabilistic {{Network Topology Prediction}} for {{Active Planning}}},
  author = {Zhang, Liang and Zhang, Zexu and Siegwart, Roland and Chung, Jen Jen},
  year = {2022},
  journal = {IEEE Transactions on Robotics},
  pages = {1--18},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3189223},
  abstract = {This article tackles the problem of active planning to achieve cooperative localization for multirobot systems under measurement uncertainty in GNSS-limited scenarios. Specifically, we address the issue of accurately predicting the probability of a future connection between two robots equipped with range-based measurement devices. Due to the limited range of the equipped sensors, edges in the network connection topology will be created or destroyed as the robots move with respect to one another. Accurately predicting the future existence of an edge, given imperfect state estimation and noisy actuation, is therefore a challenging task. An adaptive power series expansion (or APSE) algorithm is developed based on current estimates and control candidates. Such an algorithm applies the power series expansion formula of the quadratic positive form in a normal distribution. Finite-term approximation is made to realize the computational tractability. Further analyses are presented to show that the truncation error in the finite-term approximation can be theoretically reduced to a desired threshold by adaptively choosing the summation degree of the power series. Several sufficient conditions are rigorously derived as the selection principles. Finally, extensive simulation results and comparisons, with respect to both single and multirobot cases, validate that a formally computed and therefore more accurate probability of future topology can help improve the performance of active planning under uncertainty.},
  keywords = {Active planning under uncertainty,belief space,cooperative localization,disk communication model,Extraterrestrial measurements,GNSS-limited environment,Location awareness,Measurement uncertainty,Planning,probabilistic network topology,Robot sensing systems,Sensors,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/6KHGAZ6E/Zhang et al. - 2022 - Probabilistic Network Topology Prediction for Acti.pdf;/Users/kshitijgoel/Zotero/storage/B45CLW7N/9850388.html}
}

@inproceedings{zhang_smartcavedrone_2017,
  title = {{{SmartCaveDrone}}: {{3D}} Cave Mapping Using {{UAVs}} as Robotic Co-Archaeologists},
  shorttitle = {{{SmartCaveDrone}}},
  booktitle = {2017 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Zhang, Guoxiang and Shang, Bo and Chen, YangQuan and Moyes, Holley},
  year = {2017},
  month = jun,
  pages = {1052--1057},
  doi = {10.1109/ICUAS.2017.7991499},
  abstract = {This paper proposes the concept of drones capable of functioning as ``Co-Archaeologists'' that can map large caves and enter dangerous or hard-to-reach spaces. Using RGB-D data collected by drones, we will be able to produce accurate 3D models and semantic maps with proper lighting co-supervised by human archaeologists. This is going to be a major advance in archaeological practice, which can accelerate the speed of archaeological exploits by extending the archaeologists' sight and perception range. This will enable us to conduct 3D analyses so that we may answer new questions and create new insights into the archaeological record. The archaeologists will be able to visualize data collected by drones and instruct the drones' next step in real-time. These data will also be important in site management, data sharing and visualization. Human/drone interaction becomes important, not only for operating the equipment, but also for guiding drones to areas of interest to be mapped. Maps or real-time ``fly-throughs'' only make sense when they are organized by human interactions with the space. This human interaction is vital when visualizing and understanding a space and should be reflected in the imagery. We envision that this technology will be game changing in cave mapping and pertinent to anyone rendering interior spaces. It creates longer term impacts in archaeology and digital heritage and potentially creates a transformative way for further enhancing the performance of 3D mapping.},
  keywords = {Cameras,Drones,Lighting,Real-time systems,Sensors,Solid modeling,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/H77IFZGI/Zhang et al. - 2017 - SmartCaveDrone 3D cave mapping using UAVs as robo.pdf;/Users/kshitijgoel/Zotero/storage/M2LL8KVT/stamp.html}
}

@misc{zhang_soar_2024,
  title = {{{SOAR}}: {{Simultaneous Exploration}} and {{Photographing}} with {{Heterogeneous UAVs}} for {{Fast Autonomous Reconstruction}}},
  shorttitle = {{{SOAR}}},
  author = {Zhang, Mingjie and Feng, Chen and Li, Zengzhi and Zheng, Guiyong and Luo, Yiming and Wang, Zhu and Zhou, Jinni and Shen, Shaojie and Zhou, Boyu},
  year = {2024},
  month = sep,
  number = {arXiv:2409.02738},
  eprint = {2409.02738},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2409.02738},
  urldate = {2024-09-05},
  abstract = {Unmanned Aerial Vehicles (UAVs) have gained significant popularity in scene reconstruction. This paper presents SOAR, a LiDAR-Visual heterogeneous multi-UAV system specifically designed for fast autonomous reconstruction of complex environments. Our system comprises a LiDAR-equipped explorer with a large field-of-view (FoV), alongside photographers equipped with cameras. To ensure rapid acquisition of the scene's surface geometry, we employ a surface frontier-based exploration strategy for the explorer. As the surface is progressively explored, we identify the uncovered areas and generate viewpoints incrementally. These viewpoints are then assigned to photographers through solving a Consistent Multiple Depot Multiple Traveling Salesman Problem (Consistent-MDMTSP), which optimizes scanning efficiency while ensuring task consistency. Finally, photographers utilize the assigned viewpoints to determine optimal coverage paths for acquiring images. We present extensive benchmarks in the realistic simulator, which validates the performance of SOAR compared with classical and state-of-the-art methods. For more details, please see our project page at sysu-star.github.io/SOAR.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/76S3RYWK/Zhang et al. - 2024 - SOAR Simultaneous Exploration and Photographing with Heterogeneous UAVs for Fast Autonomous Reconst.pdf}
}

@article{zhang_submodular_2016,
  title = {Submodular {{Optimization}} with {{Routing Constraints}}},
  author = {Zhang, Haifeng and Vorobeychik, Yevgeniy},
  year = {2016},
  month = feb,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {30},
  number = {1},
  issn = {2374-3468},
  doi = {10.1609/aaai.v30i1.10066},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/10066},
  urldate = {2024-04-23},
  abstract = {Submodular optimization, particularly under cardinality or cost constraints, has received considerable attention, stemming from its breadth of application, ranging from sensor placement to targeted marketing. However, the constraints faced in many real domains are more complex. We investigate an important and very general class of problems of maximizing a submodular function subject to general cost constraints, especially focusing on costs coming from route planning. Canoni- cal problems that motivate our framework include mobile robotic sensing, and door-to-door marketing. We propose a generalized cost-benefit (GCB) greedy al- gorithm for our problem, and prove bi-criterion approximation guarantees under significantly weaker assumptions than those in related literature. Experimental evaluation on realistic mobile sensing and door-to-door marketing problems, as well as using simulated networks, show that our algorithm achieves significantly higher utility than state-of-the-art alternatives, and has either lower or competitive running time.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {Approximation Guarantees},
  file = {/Users/kshitijgoel/Zotero/storage/BS3L7UJ8/Zhang and Vorobeychik - 2016 - Submodular Optimization with Routing Constraints.pdf}
}

@misc{zhao_distributed_2024,
  title = {Distributed {{NeRF Learning}} for {{Collaborative Multi-Robot Perception}}},
  author = {Zhao, Hongrui and Ivanovic, Boris and Mehr, Negar},
  year = {2024},
  month = sep,
  number = {arXiv:2409.20289},
  eprint = {2409.20289},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.20289},
  url = {http://arxiv.org/abs/2409.20289},
  urldate = {2024-11-30},
  abstract = {Effective environment perception is crucial for enabling downstream robotic applications. Individual robotic agents often face occlusion and limited visibility issues, whereas multi-agent systems can offer a more comprehensive mapping of the environment, quicker coverage, and increased fault tolerance. In this paper, we propose a collaborative multi-agent perception system where agents collectively learn a neural radiance field (NeRF) from posed RGB images to represent a scene. Each agent processes its local sensory data and shares only its learned NeRF model with other agents, reducing communication overhead. Given NeRF's low memory footprint, this approach is well-suited for robotic systems with limited bandwidth, where transmitting all raw data is impractical. Our distributed learning framework ensures consistency across agents' local NeRF models, enabling convergence to a unified scene representation. We show the effectiveness of our method through an extensive set of experiments on datasets containing challenging real-world scenes, achieving performance comparable to centralized mapping of the environment where data is sent to a central server for processing. Additionally, we find that multi-agent learning provides regularization benefits, improving geometric consistency in scenarios with sparse input views. We show that in such scenarios, multi-agent mapping can even outperform centralized training.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/AGNVD3XA/Zhao et al. - 2024 - Distributed NeRF Learning for Collaborative Multi-Robot Perception.pdf;/Users/kshitijgoel/Zotero/storage/NRVYTES7/2409.html}
}

@inproceedings{zhao_learning_2023,
  title = {Learning {{Semi-supervised Gaussian Mixture Models}} for {{Generalized Category Discovery}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  author = {Zhao, Bingchen and Wen, Xin and Han, Kai},
  year = {2023},
  pages = {16623--16633},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.html},
  urldate = {2023-10-08},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/XDZCB2SS/Zhao et al. - 2023 - Learning Semi-supervised Gaussian Mixture Models f.pdf}
}

@misc{zhao_pseudo_2025,
  title = {Pseudo {{Depth Meets Gaussian}}: {{A Feed-forward RGB SLAM Baseline}}},
  shorttitle = {Pseudo {{Depth Meets Gaussian}}},
  author = {Zhao, Linqing and Xu, Xiuwei and Wang, Yirui and Wang, Hao and Zheng, Wenzhao and Tang, Yansong and Yan, Haibin and Lu, Jiwen},
  year = {2025},
  month = aug,
  number = {arXiv:2508.04597},
  eprint = {2508.04597},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2508.04597},
  url = {http://arxiv.org/abs/2508.04597},
  urldate = {2025-08-07},
  abstract = {Incrementally recovering real-sized 3D geometry from a pose-free RGB stream is a challenging task in 3D reconstruction, requiring minimal assumptions on input data. Existing methods can be broadly categorized into end-to-end and visual SLAM-based approaches, both of which either struggle with long sequences or depend on slow test-time optimization and depth sensors. To address this, we first integrate a depth estimator into an RGB-D SLAM system, but this approach is hindered by inaccurate geometric details in predicted depth. Through further investigation, we find that 3D Gaussian mapping can effectively solve this problem. Building on this, we propose an online 3D reconstruction method using 3D Gaussian-based SLAM, combined with a feed-forward recurrent prediction module to directly infer camera pose from optical flow. This approach replaces slow test-time optimization with fast network inference, significantly improving tracking speed. Additionally, we introduce a local graph rendering technique to enhance robustness in feed-forward pose prediction. Experimental results on the Replica and TUM-RGBD datasets, along with a real-world deployment demonstration, show that our method achieves performance on par with the state-of-the-art SplaTAM, while reducing tracking time by more than 90{\textbackslash}\%.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/YZ5T4XR8/Zhao et al. - 2025 - Pseudo Depth Meets Gaussian A Feed-forward RGB SLAM Baseline.pdf;/Users/kshitijgoel/Zotero/storage/24HR8M57/2508.html}
}

@misc{zhao_softsnap_2024,
  title = {{{SoftSnap}}: {{Rapid Prototyping}} of {{Untethered Soft Robots Using Snap-Together Modules}}},
  shorttitle = {{{SoftSnap}}},
  author = {Zhao, Luyang and Jiang, Yitao and She, Chun-Yi and Chen, Muhao and Balkcom, Devin},
  year = {2024},
  month = oct,
  number = {arXiv:2410.19169},
  eprint = {2410.19169},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2410.19169},
  urldate = {2024-10-28},
  abstract = {Soft robots offer adaptability and safe interaction with complex environments. Rapid prototyping kits that allow soft robots to be assembled easily will allow different geometries to be explored quickly to suit different environments or to mimic the motion of biological organisms. We introduce SoftSnap modules: snap-together components that enable the rapid assembly of a class of untethered soft robots. Each SoftSnap module includes embedded computation, motor-driven string actuation, and a flexible thermoplastic polyurethane (TPU) printed structure capable of deforming into various shapes based on the string configuration. These modules can be easily connected with other SoftSnap modules or customizable connectors. We demonstrate the versatility of the SoftSnap system through four configurations: a starfish-like robot, a brittle star robot, a snake robot, a 3D gripper, and a ring-shaped robot. These configurations highlight the ease of assembly, adaptability, and functional diversity of the SoftSnap modules. The SoftSnap modular system offers a scalable, snap-together approach to simplifying soft robot prototyping, making it easier for researchers to explore untethered soft robotic systems rapidly.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/XXI363RL/Zhao et al. - 2024 - SoftSnap Rapid Prototyping of Untethered Soft Robots Using Snap-Together Modules.pdf;/Users/kshitijgoel/Zotero/storage/Y6N8MI2E/2410.html}
}

@misc{zhao_ultrawideband_2024,
  title = {Ultra-Wideband {{Time Difference}} of {{Arrival Indoor Localization}}: {{From Sensor Placement}} to {{System Evaluation}}},
  shorttitle = {Ultra-Wideband {{Time Difference}} of {{Arrival Indoor Localization}}},
  author = {Zhao, Wenda and Goudar, Abhishek and Tang, Mingliang and Schoellig, Angela P.},
  year = {2024},
  month = dec,
  number = {arXiv:2412.12427},
  eprint = {2412.12427},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.12427},
  url = {http://arxiv.org/abs/2412.12427},
  urldate = {2024-12-18},
  abstract = {Wireless indoor localization has attracted significant research interest due to its high accuracy, low cost, lightweight design, and low power consumption. Specifically, ultra-wideband (UWB) time difference of arrival (TDOA)-based localization has emerged as a scalable positioning solution for mobile robots, consumer electronics, and wearable devices, featuring good accuracy and reliability. While UWB TDOA-based localization systems rely on the deployment of UWB radio sensors as positioning landmarks, existing works often assume these placements are predetermined or study the sensor placement problem alone without evaluating it in practical scenarios. In this article, we bridge this gap by approaching the UWB TDOA localization from a system-level perspective, integrating sensor placement as a key component and conducting practical evaluation in real-world scenarios. Through extensive real-world experiments, we demonstrate the accuracy and robustness of our localization system, comparing its performance to the theoretical lower bounds. Using a challenging multi-room environment as a case study, we illustrate the full system construction process, from sensor placement optimization to real-world deployment. Our evaluation, comprising a cumulative total of 39 minutes of real-world experiments involving up to five agents and covering 2608 meters across four distinct scenarios, provides valuable insights and guidelines for constructing UWB TDOA localization systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/462NJEIY/Zhao et al. - 2024 - Ultra-wideband Time Difference of Arrival Indoor Localization From Sensor Placement to System Evalu.pdf;/Users/kshitijgoel/Zotero/storage/VXUQQ998/2412.html}
}

@inproceedings{zhen_unified_2022,
  title = {Unified {{Representation}} of {{Geometric Primitives}} for {{Graph-SLAM Optimization Using Decomposed Quadrics}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhen, Weikun and Yu, Huai and Hu, Yaoyu and Scherer, Sebastian},
  year = {2022},
  month = may,
  pages = {5636--5642},
  doi = {10.1109/ICRA46639.2022.9812162},
  abstract = {In Simultaneous Localization And Mapping (SLAM) problems, high-level landmarks have the potential to build compact and informative maps compared to traditional point-based landmarks. In this work, we focus on the param-eterization of frequently used geometric primitives including points, lines, planes, ellipsoids, cylinders, and cones. We first present a unified representation based on quadrics, an algebraic representation of quadratic surfaces in 3D. Then we propose a decomposed model of quadrics that discloses the symmetry and degeneration properties of a primitive. Based on the decomposition, we develop geometrically meaningful quadrics factors for the graph-SLAM problem. Then in simulation, it is shown that the decomposed formulation has better efficiency and robustness to observation noises than baseline parame-terizations. Finally, in real-world experiments, the proposed back-end framework is demonstrated to be capable of building compact and regularized maps.},
  keywords = {Automation,Buildings,Ellipsoids,Optimization,Robustness,Simultaneous localization and mapping,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/AE8JUAN7/Zhen et al. - 2022 - Unified Representation of Geometric Primitives for.pdf;/Users/kshitijgoel/Zotero/storage/M77CNCUJ/9812162.html}
}

@misc{zheng_mapadapt_2024,
  title = {{{MAP-ADAPT}}: {{Real-Time Quality-Adaptive Semantic 3D Maps}}},
  shorttitle = {{{MAP-ADAPT}}},
  author = {Zheng, Jianhao and Barath, Daniel and Pollefeys, Marc and Armeni, Iro},
  year = {2024},
  month = jun,
  number = {arXiv:2406.05849},
  eprint = {2406.05849},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.05849},
  urldate = {2024-06-13},
  abstract = {Creating 3D semantic reconstructions of environments is fundamental to many applications, especially when related to autonomous agent operation (e.g., goal-oriented navigation or object interaction and manipulation). Commonly, 3D semantic reconstruction systems capture the entire scene in the same level of detail. However, certain tasks (e.g., object interaction) require a fine-grained and highresolution map, particularly if the objects to interact are of small size or intricate geometry. In recent practice, this leads to the entire map being in the same high-quality resolution, which results in increased computational and storage costs. To address this challenge, we propose MAPADAPT, a real-time method for quality-adaptive semantic 3D reconstruction using RGBD frames. MAP-ADAPT is the first adaptive semantic 3D mapping algorithm that, unlike prior work, generates directly a single map with regions of different quality based on both the semantic information and the geometric complexity of the scene. Leveraging a semantic SLAM pipeline for pose and semantic estimation, we achieve comparable or superior results to state-of-theart methods on synthetic and real-world data, while significantly reducing storage and computation requirements.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/BQSFC3FJ/Zheng et al. - 2024 - MAP-ADAPT Real-Time Quality-Adaptive Semantic 3D Maps.pdf}
}

@inproceedings{zheng_robust_2018,
  title = {A {{Robust Approach}} to {{Sequential Information Theoretic Planning}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Zheng, Sue and Pacheco, Jason and Fisher, John},
  year = {2018},
  month = jul,
  pages = {5941--5949},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/zheng18b.html},
  urldate = {2024-03-04},
  abstract = {In many sequential planning applications a natural approach to generating high quality plans is to maximize an information reward such as mutual information (MI). Unfortunately, MI lacks a closed form in all but trivial models, and so must be estimated. In applications where the cost of plan execution is expensive, one desires planning estimates which admit theoretical guarantees. Through the use of robust M-estimators we obtain bounds on absolute deviation of estimated MI. Moreover, we propose a sequential algorithm which integrates inference and planning by maximally reusing particles in each stage. We validate the utility of using robust estimators in the sequential approach on a Gaussian Markov Random Field wherein information measures have a closed form. Lastly, we demonstrate the benefits of our integrated approach in the context of sequential experiment design for inferring causal regulatory networks from gene expression levels. Our method shows improvements over a recent method which selects intervention experiments based on the same MI objective.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/Q9NSL2JF/Zheng et al. - 2018 - A Robust Approach to Sequential Information Theore.pdf}
}

@article{zheng_safe_2023,
  title = {Safe {{Navigation Using Density Functions}}},
  author = {Zheng, Andrew and Narayanan, Sriram S.K.S and Vaidya, Umesh},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  pages = {1--8},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2023.3311334},
  url = {https://ieeexplore.ieee.org/document/10238751/},
  urldate = {2023-09-29},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/B94CX8TY/Zheng et al. - 2023 - Safe Navigation Using Density Functions.pdf}
}

@article{zheng_uwbvio_2022,
  title = {{{UWB-VIO Fusion}} for {{Accurate}} and {{Robust Relative Localization}} of {{Round Robotic Teams}}},
  author = {Zheng, S. and Li, Z. and Liu, Y. and Zhang, H. and Zheng, P. and Liang, X. and Li, Y. and Bu, X. and Zou, X.},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {11950--11957},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3208354},
  abstract = {The relative pose estimation is one of the most fundamental components for multi-robot systems, while it still remains an open and challenging research topic in infrastructure-free environment. In this letter, we target improving the accuracy and robustness of relative pose estimation for ground robotic teams, and propose to fuse range and odometry measurements to estimate the relative pose using sliding window optimization. In the system, multiple UWB tags for ranging are equipped on each robot, and visual inertial odometry is applied for estimating the ego-motion pose for each robot. Aiming for simple and effective relative pose initialization, the triangulation uncertainty for multi-tag robots is analyzed, and an initialization method is designed. To cope with the complex environments such as continuous NLOS condition, a NLOS detection and range measurements filtering method is presented. We have conducted series of experiments to demonstrate the performance of the proposed approach.},
  keywords = {Location awareness,Multi-robot systems,Nonlinear optics,Optimization,Pollution measurement,Pose estimation,relative localization,Robot kinematics,Robots,sensor fusion},
  file = {/Users/kshitijgoel/Zotero/storage/7IT54QMT/Zheng et al. - 2022 - UWB-VIO Fusion for Accurate and Robust Relative Lo.pdf;/Users/kshitijgoel/Zotero/storage/VVLWEULE/9896952.html}
}

@article{zhitnikov_simplified_2024,
  title = {Simplified {{Continuous High-Dimensional Belief Space Planning With Adaptive Probabilistic Belief-Dependent Constraints}}},
  author = {Zhitnikov, Andrey and Indelman, Vadim},
  year = {2024},
  journal = {IEEE Transactions on Robotics},
  volume = {40},
  pages = {1684--1705},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3341625},
  url = {https://ieeexplore.ieee.org/document/10354386},
  urldate = {2024-06-05},
  abstract = {Online decision making under uncertainty in partially observable domains, also known as Belief Space Planning, is a fundamental problem in Robotics and Artificial Intelligence. Due to an abundance of plausible future unravelings, calculating an optimal course of action inflicts an enormous computational burden on the agent. Moreover, in many scenarios, e.g., Information gathering, it is required to introduce a belief-dependent constraint. Prompted by this demand, in this article, we consider a recently introduced probabilistic belief-dependent constrained partially observable Markov decision process (POMDP). We present a technique to adaptively accept or discard a candidate action sequence with respect to a probabilistic belief-dependent constraint, before expanding a complete set of sampled future observations episodes and without any loss in accuracy. Moreover, using our proposed framework, we contribute an adaptive method to find a maximal feasible return (e.g., Information Gain) in terms of Value at Risk and a corresponding action sequence, given a set of candidate action sequences, with substantial acceleration. On top of that, we introduce an adaptive simplification technique for a probabilistically constrained setting. Such an approach provably returns an identical-quality solution while dramatically accelerating the online decision making. Our universal framework applies to any belief-dependent constrained continuous POMDP with parameteric beliefs, as well as nonparameteric beliefs represented by particles. In the context of an information-theoretic constraint, our presented framework stochastically quantifies if a cumulative Information Gain along the planning horizon is sufficiently significant (for e.g., Information Gathering, active simultaneous localization and mapping (SLAM)). As a case study, we apply our method to two challenging problems of high dimensional belief space planning: active SLAM and sensor deployment. Extensive realistic simulations corroborate the superiority of our proposed ideas.},
  keywords = {Active simultaneous localization and mapping (SLAM),autonomous robotic exploration,belief space planning (BSP),belief-dependent probabilistic constraints,belief-dependent rewards,constrained belief-dependent partially observable Markov decision process (POMDP),Decision making,Planning,Probabilistic logic,Robots,Simultaneous localization and mapping,Task analysis,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/CAXI434R/Zhitnikov and Indelman - 2024 - Simplified Continuous High-Dimensional Belief Space Planning With Adaptive Probabilistic Belief-Depe.pdf;/Users/kshitijgoel/Zotero/storage/YI5LGJI5/10354386.html}
}

@inproceedings{zhong_shinemapping_2023,
  title = {{{SHINE-Mapping}}: {{Large-Scale 3D Mapping Using Sparse Hierarchical Implicit Neural Representations}}},
  shorttitle = {{{SHINE-Mapping}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhong, Xingguang and Pan, Yue and Behley, Jens and Stachniss, Cyrill},
  year = {2023},
  month = may,
  pages = {8371--8377},
  doi = {10.1109/ICRA48891.2023.10160907},
  abstract = {Accurate mapping of large-scale environments is an essential building block of most outdoor autonomous systems. Challenges of traditional mapping methods include the balance between memory consumption and mapping accuracy. This paper addresses the problem of achieving large-scale 3D reconstruction using implicit representations built from 3D LiDAR measurements. We learn and store implicit features through an octree-based, hierarchical structure, which is sparse and extensible. The implicit features can be turned into signed distance values through a shallow neural network. We leverage binary cross entropy loss to optimize the local features with the 3D measurements as supervision. Based on our implicit representation, we design an incremental mapping system with regularization to tackle the issue of forgetting in continual learning. Our experiments show that our 3D reconstructions are more accurate, complete, and memory-efficient than current state-of-the-art 3D mapping methods.},
  keywords = {Automation,Autonomous systems,Current measurement,Laser radar,Memory management,Neural networks,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/42PBWRPQ/Zhong et al. - 2023 - SHINE-Mapping Large-Scale 3D Mapping Using Sparse.pdf;/Users/kshitijgoel/Zotero/storage/HX27LN9B/10160907.html}
}

@inproceedings{zhou_assistive_2016,
  title = {Assistive Collision Avoidance for Quadrotor Swarm Teleoperation},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhou, Dingjiang and Schwager, Mac},
  year = {2016},
  month = may,
  pages = {1249--1254},
  doi = {10.1109/ICRA.2016.7487256},
  url = {https://ieeexplore.ieee.org/document/7487256/?arnumber=7487256&tag=1},
  urldate = {2024-12-19},
  abstract = {This paper presents a method for controlling quadrotor swarms in an environment with obstacles, with an intuitive human-swarm interface operated by a single human user. Our method allows for the quadrotor swarm to maintain a desired formation, while also keeping the quadrotors a safe distance from obstacles and from one another. We use a Virtual Rigid Body abstraction to provide a bridge between the single human user and the quadrotor swarm, so that a human user can fly an arbitrarily large quadrotor swarm from a single joystick. By applying multiple vector fields, collisions are automatically avoided within the swarm of quadrotors, and between the quadrotors and obstacles, while the Virtual Rigid Body is controlled by the human user. Our method is demonstrated in hardware experiments with groups of quadrotor micro aerial vehicles teleoperated by a single human operator in a motion capture system.},
  keywords = {Collision avoidance,Real-time systems,Robots,Standards,Trajectory,Vehicle dynamics,Vehicles},
  file = {/Users/kshitijgoel/Zotero/storage/HJPKZ73I/Zhou and Schwager - 2016 - Assistive collision avoidance for quadrotor swarm teleoperation.pdf;/Users/kshitijgoel/Zotero/storage/KUMZUZUR/7487256.html}
}

@inproceedings{zhou_controlbarrieraided_2024,
  title = {Control-{{Barrier-Aided Teleoperation}} with {{Visual-Inertial SLAM}} for {{Safe MAV Navigation}} in {{Complex Environments}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhou, Siqi and Papatheodorou, Sotiris and Leutenegger, Stefan and Schoellig, Angela P.},
  year = {2024},
  month = may,
  pages = {17836--17842},
  doi = {10.1109/ICRA57147.2024.10611280},
  url = {https://ieeexplore.ieee.org/document/10611280/?arnumber=10611280},
  urldate = {2024-12-09},
  abstract = {In this paper, we consider a Micro Aerial Vehicle (MAV) system teleoperated by a non-expert and introduce a perceptive safety filter that leverages Control Barrier Functions (CBFs) in conjunction with Visual-Inertial Simultaneous Localization and Mapping (VI-SLAM) and dense 3D occupancy mapping to guarantee safe navigation in complex and unstructured environments. Our system relies solely on onboard IMU measurements, stereo infrared images, and depth images and autonomously corrects teleoperated inputs when they are deemed unsafe. We define a point in 3D space as unsafe if it satisfies either of two conditions: (i) it is occupied by an obstacle, or (ii) it remains unmapped. At each time step, an occupancy map of the environment is updated by the VI-SLAM by fusing the onboard measurements, and a CBF is constructed to parameterize the (un)safe region in the 3D space. Given the CBF and state feedback from the VI-SLAM module, a safety filter computes a certified reference that best matches the teleoperation input while satisfying the safety constraint encoded by the CBF. In contrast to existing perception-based safe control frameworks, we directly close the perception-action loop and demonstrate the full capability of safe control in combination with real-time VI-SLAM without any external infrastructure or prior knowledge of the environment. We verify the efficacy of the perceptive safety filter in real-time MAV experiments using exclusively onboard sensing and computation and show that the teleoperated MAV is able to safely navigate through unknown environments despite arbitrary inputs sent by the teleoperator.},
  keywords = {Navigation,Real-time systems,Simultaneous localization and mapping,State feedback,Teleoperators,Three-dimensional displays,Time measurement},
  file = {/Users/kshitijgoel/Zotero/storage/B35Q3T68/Zhou et al. - 2024 - Control-Barrier-Aided Teleoperation with Visual-Inertial SLAM for Safe MAV Navigation in Complex Env.pdf;/Users/kshitijgoel/Zotero/storage/6RR2JVPX/10611280.html}
}

@article{zhou_dense_2013,
  title = {Dense Scene Reconstruction with Points of Interest},
  author = {Zhou, Qian-Yi and Koltun, Vladlen},
  year = {2013},
  month = jul,
  journal = {ACM Transactions on Graphics},
  volume = {32},
  number = {4},
  pages = {1--8},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2461912.2461919},
  url = {https://dl.acm.org/doi/10.1145/2461912.2461919},
  urldate = {2022-07-15},
  abstract = {We present an approach to detailed reconstruction of complex realworld scenes with a handheld commodity range sensor. The user moves the sensor freely through the environment and images the scene. An offline registration and integration pipeline produces a detailed scene model. To deal with the complex sensor trajectories required to produce detailed reconstructions with a consumer-grade sensor, our pipeline detects points of interest in the scene and preserves detailed geometry around them while a global optimization distributes residual registration errors through the environment. Our results demonstrate that detailed reconstructions of complex scenes can be obtained with a consumer-grade camera.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/97D9WRZF/Zhou and Koltun - 2013 - Dense scene reconstruction with points of interest.pdf}
}

@article{zhou_fuel_2021,
  title = {{{FUEL}}: {{Fast UAV Exploration Using Incremental Frontier Structure}} and {{Hierarchical Planning}}},
  shorttitle = {{{FUEL}}},
  author = {Zhou, Boyu and Zhang, Yichen and Chen, Xinyi and Shen, Shaojie},
  year = {2021},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {779--786},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3051563},
  url = {https://ieeexplore.ieee.org/document/9324988},
  urldate = {2024-11-15},
  abstract = {Autonomous exploration is a fundamental problem for various applications of unmanned aerial vehicles(UAVs). Existing methods, however, were demonstrated to insufficient exploration rate, due to the lack of efficient global coverage, conservative motion plans and low decision frequencies. In this letter, we propose FUEL, a hierarchical framework that can support Fast UAV ExpLoration in complex unknown environments. We maintain crucial information in the entire space required by exploration planning by a frontier information structure (FIS), which can be updated incrementally when the space is explored. Supported by the FIS, a hierarchical planner plans exploration motions in three steps, which find efficient global coverage paths, refine a local set of viewpoints and generate minimum-time trajectories in sequence. We present extensive benchmark and real-world tests, in which our method completes the exploration tasks with unprecedented efficiency (3-8 times faster) compared to state-of-the-art approaches. Our method will be made open source to benefit the community11To be released at https://github.com/HKUST-Aerial-Robotics/FUEL..},
  keywords = {Aerial systems: applications,aerial systems: perception and autonomy,Fuels,motion and path planning,Navigation,Planning,Robot sensing systems,Space exploration,Trajectory,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/IB45ZCAM/Zhou et al. - 2021 - FUEL Fast UAV Exploration Using Incremental Frontier Structure and Hierarchical Planning.pdf;/Users/kshitijgoel/Zotero/storage/RK9QH36K/9324988.html}
}

@article{zhou_online_2025,
  title = {Online {{Stable Streaming Feature Selection}} via {{Feature Aggregation}}},
  author = {Zhou, Peng and Wang, Qi and Zhang, Yunyun and Ling, Zhaolong and Zhao, Shu and Wu, Xindong},
  year = {2025},
  month = mar,
  journal = {ACM Trans. Knowl. Discov. Data},
  volume = {19},
  number = {3},
  pages = {65:1--65:23},
  issn = {1556-4681},
  doi = {10.1145/3715918},
  url = {https://dl.acm.org/doi/10.1145/3715918},
  urldate = {2025-07-31},
  abstract = {Feature selection is an essential pre-process component in data mining that aims to select the most relevant features from the target dataset. Datasets are always dynamic in real-world applications, and features may exist in stream mode. Then, online streaming feature selection methods are proposed, which deal with streaming features arriving continuously in real-time. However, most existing algorithms prioritize high accuracy and low time-consumption but overlook the stability of the selected features. Stable feature selection results are crucial for users in practice. For instance, in the medical field, unstable feature selection results can make it challenging for experts to identify the main causative factors of a disease. Motivated by this, this article proposes a new online stable streaming feature selection method via feature aggregation named OSSFS. Specifically, inspired by the cohesive MeanShift approach, OSSFS applies an incremental aggregation strategy to partition the streaming features into multiple hyperellipsoids. Then, we incrementally update and merge these hyperellipsoids with new streaming features. Finally, we select representative features from each hyperellipsoid as the final selected feature subset. Extensive experiments are conducted on several real-world datasets to compare our new method with state-of-the-art competing algorithms in cases of stability and predictive accuracy. Experimental results indicate that OSSFS achieves optimal stability without losing prediction accuracy.},
  file = {/Users/kshitijgoel/Zotero/storage/QK3RILWD/Zhou et al. - 2025 - Online Stable Streaming Feature Selection via Feature Aggregation.pdf}
}

@misc{zhou_open3d_2018,
  title = {{{Open3D}}: {{A Modern Library}} for {{3D Data Processing}}},
  shorttitle = {{{Open3D}}},
  author = {Zhou, Qian-Yi and Park, Jaesik and Koltun, Vladlen},
  year = {2018},
  month = jan,
  number = {arXiv:1801.09847},
  eprint = {1801.09847},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1801.09847},
  urldate = {2023-05-06},
  abstract = {Open3D is an open-source library that supports rapid development of software that deals with 3D data. The Open3D frontend exposes a set of carefully selected data structures and algorithms in both C++ and Python. The backend is highly optimized and is set up for parallelization. Open3D was developed from a clean slate with a small and carefully considered set of dependencies. It can be set up on different platforms and compiled from source with minimal effort. The code is clean, consistently styled, and maintained via a clear code review mechanism. Open3D has been used in a number of published research projects and is actively deployed in the cloud. We welcome contributions from the open-source community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/FMBDCRGW/Zhou et al. - 2018 - Open3D A Modern Library for 3D Data Processing.pdf;/Users/kshitijgoel/Zotero/storage/TGLUMD5F/1801.html}
}

@article{zhou_racer_2023,
  title = {{{RACER}}: {{Rapid Collaborative Exploration With}} a {{Decentralized Multi-UAV System}}},
  shorttitle = {{{RACER}}},
  author = {Zhou, Boyu and Xu, Hao and Shen, Shaojie},
  year = {2023},
  month = jun,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {3},
  pages = {1816--1835},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2023.3236945},
  url = {https://ieeexplore.ieee.org/document/10038280/},
  urldate = {2024-02-25},
  abstract = {Although the use of multiple unmanned aerial vehicles (UAVs) has great potential for fast autonomous exploration, it has received far too little attention. In this article, we present a RApid Collaborative ExploRation (RACER) approach using a fleet of decentralized UAVs. To effectively dispatch the UAVs, a pairwise interaction based on an online hgrid space decomposition is used. It ensures that all UAVs simultaneously explore distinct regions, using only asynchronous and limited communication. Furthermore, we optimize the coverage paths of unknown space and balance the workloads partitioned to each UAV with a capacitated vehicle routing problem formulation. Given the task allocation, each UAV constantly updates the coverage path and incrementally extracts crucial information to support the exploration planning. A hierarchical planner finds exploration paths, refines local viewpoints, and generates minimum-time trajectories in sequence to explore the unknown space agilely and safely. The proposed approach is evaluated extensively, showing high exploration efficiency, scalability, and robustness to limited communication. Furthermore, for the first time, we achieve fully decentralized collaborative exploration with multiple UAVs in the real world. We will release our implementation as an open-source package.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/AJXRD2C9/Zhou et al. - 2023 - RACER Rapid Collaborative Exploration With a Dece.pdf}
}

@article{zhou_raptor_2021,
  title = {{{RAPTOR}}: {{Robust}} and {{Perception-Aware Trajectory Replanning}} for {{Quadrotor Fast Flight}}},
  shorttitle = {{{RAPTOR}}},
  author = {Zhou, Boyu and Pan, Jie and Gao, Fei and Shen, Shaojie},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Robotics},
  volume = {37},
  number = {6},
  pages = {1992--2009},
  issn = {1941-0468},
  doi = {10.1109/TRO.2021.3071527},
  abstract = {Recent advances in trajectory replanning have enabled quadrotor to navigate autonomously in unknown environments. However, high-speed navigation still remains a significant challenge. Given very limited time, existing methods have no strong guarantee on the feasibility or quality of the solutions. Moreover, most methods do not consider environment perception, which is the key bottleneck to fast flight. In this article, we present RAPTOR, a robust and perception-aware replanning framework to support fast and safe flight, which addresses these issues systematically. A path-guided optimization approach that incorporates multiple topological paths is devised, to ensure finding feasible and high-quality trajectories in very limited time. We also introduce two perception-aware planning approaches to actively observe and avoid unknown obstacles. A risk-aware trajectory refinement ensures that unknown obstacles which may endanger the quadrotor can be observed earlier and avoid in time. The motion of yaw angle is planned to actively explore the surrounding space that is relevant for safe navigation. The proposed methods are tested extensively through benchmark comparisons and challenging indoor and outdoor aggressive flights. We release our implementation as an open-source package1 for the community.},
  keywords = {Aerial systems,collision avoidance,Collision avoidance,motion and path planning,Motion planning,Navigation,Optimization,Path planning,perception and autonomy,trajectory planning,Trajectory planning},
  file = {/Users/kshitijgoel/Zotero/storage/MQFFQY9U/Zhou et al. - 2021 - RAPTOR Robust and Perception-Aware Trajectory Rep.pdf;/Users/kshitijgoel/Zotero/storage/VFIGRM2Y/9422918.html}
}

@article{zhou_riskaware_2022,
  title = {Risk-{{Aware Submodular Optimization}} for {{Multirobot Coordination}}},
  author = {Zhou, Lifeng and Tokekar, Pratap},
  year = {2022},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {5},
  pages = {3064--3084},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3158227},
  abstract = {We study the problem of incorporating risk while making combinatorial decisions under uncertainty. We formulate a discrete submodular maximization problem for selecting a set using conditional value at risk (CVaR), a risk metric commonly used in financial analysis. While the CVaR has recently been used in the optimization of linear cost functions in robotics, we take the first step toward extending this to discrete submodular optimization and provide several positive results. Specifically, we propose the sequential greedy algorithm that provides an approximation guarantee on finding the maxima of the CVaR cost function under a matroid constraint. The approximation guarantee shows that the solution produced by our algorithm is within a constant factor of the optimal and an additive term that depends on the optimal. Our analysis uses the curvature of the submodular set function and proves that the algorithm runs in polynomial time. This formulates a number of combinatorial optimization problems that appear in robotics. We use two such problems, i.e., vehicle assignment under uncertainty for mobility on demand and sensor selection with failures for environmental monitoring, as case studies to demonstrate the efficacy of our formulation. We also study the problem of adaptive risk-aware submodular maximization. We design a heuristic solution that triggers the replanning only when certain conditions are satisfied, to eliminate unnecessary planning. In particular, for the online mobility-on-demand study, we propose an adaptive triggering assignment algorithm that triggers a new assignment only when it can potentially reduce the waiting time at demand locations. We verify the performance of the proposed algorithms through simulations.},
  keywords = {Conditional value at risk (CVaR),Greedy algorithms,Optimization,Portfolios,Reactive power,risk-aware decision making,Robot kinematics,Robot sensing systems,sequential greedy algorithm (SGA),submodular maximization,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/IMAR3CXC/Zhou and Tokekar - 2022 - Risk-Aware Submodular Optimization for Multirobot .pdf}
}

@article{zhou_swarm_2022,
  title = {Swarm of Micro Flying Robots in the Wild},
  author = {Zhou, Xin and Wen, Xiangyong and Wang, Zhepei and Gao, Yuman and Li, Haojia and Wang, Qianhao and Yang, Tiankai and Lu, Haojian and Cao, Yanjun and Xu, Chao and Gao, Fei},
  year = {2022},
  month = may,
  journal = {Science Robotics},
  volume = {7},
  number = {66},
  pages = {eabm5954},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.abm5954},
  url = {https://www.science.org/doi/10.1126/scirobotics.abm5954},
  urldate = {2024-02-25},
  abstract = {Aerial robots are widely deployed, but highly cluttered environments such as dense forests remain inaccessible to drones and even more so to swarms of drones. In these scenarios, previously unknown surroundings and narrow corridors combined with requirements of swarm coordination can create challenges. To enable swarm navigation in the wild, we develop miniature but fully autonomous drones with a trajectory planner that can function in a timely and accurate manner based on limited information from onboard sensors. The planning problem satisfies various task requirements including flight efficiency, obstacle avoidance, and inter-robot collision avoidance, dynamical feasibility, swarm coordination, and so on, thus realizing an extensible planner. Furthermore, the proposed planner deforms trajectory shapes and adjusts time allocation synchronously based on spatial-temporal joint optimization. A high-quality trajectory thus can be obtained after exhaustively exploiting the solution space within only a few milliseconds, even in the most constrained environment. The planner is finally integrated into the developed palm-sized swarm platform with onboard perception, localization, and control. Benchmark comparisons validate the superior performance of the planner in trajectory quality and computing time. Various real-world field experiments demonstrate the extensibility of our system. Our approach evolves aerial robotics in three aspects: capability of cluttered environment navigation, extensibility to diverse task requirements, and coordination as a swarm without external facilities.},
  file = {/Users/kshitijgoel/Zotero/storage/E4HPWSLL/Zhou et al. - 2022 - Swarm of micro flying robots in the wild.pdf}
}

@article{zhu_chanceconstrained_2019,
  title = {Chance-{{Constrained Collision Avoidance}} for {{MAVs}} in {{Dynamic Environments}}},
  author = {Zhu, Hai and {Alonso-Mora}, Javier},
  year = {2019},
  month = apr,
  journal = {IEEE Robotics and Automation Letters},
  volume = {4},
  number = {2},
  pages = {776--783},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2019.2893494},
  url = {https://ieeexplore.ieee.org/document/8613928/},
  urldate = {2023-10-13},
  abstract = {Safe autonomous navigation of microair vehicles in cluttered dynamic environments is challenging due to the uncertainties arising from robot localization, sensing, and motion disturbances. This letter presents a probabilistic collision avoidance method for navigation among other robots and moving obstacles, such as humans. The approach explicitly considers the collision probability between each robot and obstacle and formulates a chance constrained nonlinear model predictive control problem (CCNMPC). A tight bound for approximation of collision probability is developed, which makes the CCNMPC formulation tractable and solvable in real time. For multirobot coordination, we describe three approaches, one distributed without communication (constant velocity assumption), one distributed with communication (of previous plans), and one centralized (sequential planning). We evaluate the proposed method in experiments with two quadrotors sharing thespace with two humans and verify the multirobot coordination strategy in simulation with up to sixteen quadrotors.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/ZIXZNHL5/Zhu and Alonso-Mora - 2019 - Chance-Constrained Collision Avoidance for MAVs in.pdf}
}

@misc{zhu_loopsplat_2024,
  title = {{{LoopSplat}}: {{Loop Closure}} by {{Registering 3D Gaussian Splats}}},
  shorttitle = {{{LoopSplat}}},
  author = {Zhu, Liyuan and Li, Yue and Sandstr{\"o}m, Erik and Huang, Shengyu and Schindler, Konrad and Armeni, Iro},
  year = {2024},
  month = aug,
  number = {arXiv:2408.10154},
  eprint = {2408.10154},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.10154},
  url = {http://arxiv.org/abs/2408.10154},
  urldate = {2024-12-01},
  abstract = {Simultaneous Localization and Mapping (SLAM) based on 3D Gaussian Splats (3DGS) has recently shown promise towards more accurate, dense 3D scene maps. However, existing 3DGS-based methods fail to address the global consistency of the scene via loop closure and/or global bundle adjustment. To this end, we propose LoopSplat, which takes RGB-D images as input and performs dense mapping with 3DGS submaps and frame-to-model tracking. LoopSplat triggers loop closure online and computes relative loop edge constraints between submaps directly via 3DGS registration, leading to improvements in efficiency and accuracy over traditional global-to-local point cloud registration. It uses a robust pose graph optimization formulation and rigidly aligns the submaps to achieve global consistency. Evaluation on the synthetic Replica and real-world TUM-RGBD, ScanNet, and ScanNet++ datasets demonstrates competitive or superior tracking, mapping, and rendering compared to existing methods for dense RGB-D SLAM. Code is available at loopsplat.github.io.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/kshitijgoel/Zotero/storage/T2KGMI33/Zhu et al. - 2024 - LoopSplat Loop Closure by Registering 3D Gaussian Splats.pdf;/Users/kshitijgoel/Zotero/storage/UA3QMB29/2408.html}
}

@inproceedings{zhu_niceslam_2022,
  title = {{{NICE-SLAM}}: {{Neural Implicit Scalable Encoding}} for {{SLAM}}},
  shorttitle = {{{NICE-SLAM}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhu, Zihan and Peng, Songyou and Larsson, Viktor and Xu, Weiwei and Bao, Hujun and Cui, Zhaopeng and Oswald, Martin R. and Pollefeys, Marc},
  year = {2022},
  month = jun,
  pages = {12776--12786},
  publisher = {IEEE},
  address = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.01245},
  url = {https://ieeexplore.ieee.org/document/9878912/},
  urldate = {2024-11-18},
  abstract = {Neural implicit representations have recently shown encouraging results in various domains, including promising progress in simultaneous localization and mapping (SLAM). Nevertheless, existing methods produce oversmoothed scene reconstructions and have difficulty scaling up to large scenes. These limitations are mainly due to their simple fully-connected network architecture that does not incorporate local information in the observations. In this paper, we present NICE-SLAM, a dense SLAM system that incorporates multi-level local information by introducing a hierarchical scene representation. Optimizing this representation with pre-trained geometric priors enables detailed reconstruction on large indoor scenes. Compared to recent neural implicit SLAM systems, our approach is more scalable, efficient, and robust. Experiments on five challenging datasets demonstrate competitive results of NICESLAM in both mapping and tracking quality. Project page: https:// pengsongyou.github.io/ nice-slam.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-6654-6946-3},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/CE4SWMFR/Zhu et al. - 2022 - NICE-SLAM Neural Implicit Scalable Encoding for SLAM.pdf}
}

@inproceedings{zhu_unified_2022,
  title = {Unified {{Multivariate Gaussian Mixture}} for {{Efficient Neural Image Compression}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Zhu, Xiaosu and Song, Jingkuan and Gao, Lianli and Zheng, Feng and Shen, Heng Tao},
  year = {2022},
  pages = {17612--17621},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.html},
  urldate = {2022-09-02},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/M4PKZ6E4/Zhu et al. - 2022 - Unified Multivariate Gaussian Mixture for Efficien.pdf;/Users/kshitijgoel/Zotero/storage/PVTW6XG6/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_pape.html}
}

@article{zhuang_statistically_2024,
  title = {{{STATISTICALLY OPTIMAL K}} -{{MEANS CLUSTERING VIA NONNEGATIVE LOW-RANK SEMIDEFINITE PROGRAM-}}},
  author = {Zhuang, Yubo and Chen, Xiaohui and Yang, Yun and Zhang, Richard Y},
  year = {2024},
  abstract = {K-means clustering is a widely used machine learning method for identifying patterns in large datasets. Recently, semidefinite programming (SDP) relaxations have been proposed for solving the K-means optimization problem, which enjoy strong statistical optimality guarantees. However, the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. In contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm widely used by machine learning practitioners, but it lacks a solid statistical underpinning and theoretical guarantees. In this paper, we consider an NMF-like algorithm that solves a nonnegative low-rank restriction of the SDP-relaxed K-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is as simple and scalable as state-of-the-art NMF algorithms while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves significantly smaller mis-clustering errors compared to the existing state-of-the-art while maintaining scalability.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/VQ5SJQFV/Zhuang et al. - 2024 - STATISTICALLY OPTIMAL K -MEANS CLUSTERING VIA NONN.pdf}
}

@inproceedings{zienkiewicz_monocular_2016,
  title = {Monocular, {{Real-Time Surface Reconstruction Using Dynamic Level}} of {{Detail}}},
  booktitle = {2016 {{Fourth International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Zienkiewicz, Jacek and Tsiotsios, Akis and Davison, Andrew and Leutenegger, Stefan},
  year = {2016},
  month = oct,
  pages = {37--46},
  doi = {10.1109/3DV.2016.82},
  abstract = {We present a scalable, real-time capable method for robust surface reconstruction that explicitly handles multiple scales. As a monocular camera browses a scene, our algorithm processes images as they arrive and incrementally builds a detailed surface model.While most of the existing reconstruction approaches rely on volumetric or point-cloud representations of the environment, we perform depth-map and colour fusion directly into a multi-resolution triangular mesh that can be adaptively tessellated using the concept of Dynamic Level of Detail. Our method relies on least-squares optimisation, which enables a probabilistically sound and principled formulation of the fusion algorithm.We demonstrate that our method is capable of obtaining high quality, close-up reconstruction, as well as capturing overall scene geometry, while being memory and computationally efficient.},
  keywords = {Cameras,Heuristic algorithms,Image reconstruction,Real-time systems,Rendering (computer graphics),Surface reconstruction,Three-dimensional displays},
  file = {/Users/kshitijgoel/Zotero/storage/QRK7JXJB/Zienkiewicz et al. - 2016 - Monocular, Real-Time Surface Reconstruction Using .pdf;/Users/kshitijgoel/Zotero/storage/CSMI8VRA/stamp.html}
}

@inproceedings{zimmermann_differentiable_2022,
  title = {Differentiable {{Collision Avoidance Using Collision Primitives}}},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Zimmermann, Simon and Busenhart, Matthias and Huber, Simon and Poranne, Roi and Coros, Stelian},
  year = {2022},
  month = oct,
  pages = {8086--8093},
  publisher = {IEEE},
  address = {Kyoto, Japan},
  doi = {10.1109/IROS47612.2022.9981093},
  url = {https://ieeexplore.ieee.org/document/9981093/},
  urldate = {2024-01-30},
  abstract = {A central aspect of robotic motion planning is collision avoidance, where a multitude of different approaches are currently in use. Optimization-based motion planning is one method, that often heavily relies on distance computations between robots and obstacles. These computations can easily become a bottleneck, as they do not scale well with the complexity of the robots or the environment. To improve performance, many different methods suggested to use collision primitives, i.e. simple shapes that approximate the more complex rigid bodies, and that are simpler to compute distances to and from. However, each pair of primitives requires its own specialized code, and certain pairs are known to suffer from numerical issues. In this paper, we propose an easy-to-use, unified treatment of a wide variety of primitives. We formulate distance computation as a minimization problem, which we solve iteratively. We show how to take derivatives of this minimization problem, allowing it to be seamlessly integrated into a trajectory optimization method. We demonstrate that the resulting method can be used to plan smooth and collision-free paths based on a variety of single- and multi-robot scenarios with different obstacles.},
  isbn = {978-1-6654-7927-1},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/55LMB5UL/Zimmermann et al. - 2022 - Differentiable Collision Avoidance Using Collision.pdf}
}

@article{zitnick_stereo_2007,
  title = {Stereo for {{Image-Based Rendering}} Using {{Image Over-Segmentation}}},
  author = {Zitnick, C. Lawrence and Kang, Sing Bing},
  year = {2007},
  month = oct,
  journal = {International Journal of Computer Vision},
  volume = {75},
  number = {1},
  pages = {49--65},
  issn = {1573-1405},
  doi = {10.1007/s11263-006-0018-8},
  url = {https://doi.org/10.1007/s11263-006-0018-8},
  urldate = {2024-07-21},
  abstract = {In this paper, we propose a stereo method specifically designed for image-based rendering. For effective image-based rendering, the interpolated views need only be visually plausible. The implication is that the extracted depths do not need to be correct, as long as the recovered views appear to be correct. Our stereo algorithm relies on over-segmenting the source images. Computing match values over entire segments rather than single pixels provides robustness to noise and intensity bias. Color-based segmentation also helps to more precisely delineate object boundaries, which is important for reducing boundary artifacts in synthesized views. The depths of the segments for each image are computed using loopy belief propagation within a Markov Random Field framework. Neighboring MRFs are used for occlusion reasoning and ensuring that neighboring depth maps are consistent. We tested our stereo algorithm on several stereo pairs from the Middlebury data set, and show rendering results based on two of these data sets. We also show results for video-based rendering.},
  langid = {english},
  keywords = {image-based rendering,multi-view stereo,segmentation,stereo correspondence},
  file = {/Users/kshitijgoel/Zotero/storage/W7AFF4BW/Zitnick and Kang - 2007 - Stereo for Image-Based Rendering using Image Over-Segmentation.pdf}
}

@article{zlot_efficient_2014,
  title = {Efficient {{Large-scale Three-dimensional Mobile Mapping}} for {{Underground Mines}}},
  author = {Zlot, Robert and Bosse, Michael},
  year = {2014},
  journal = {Journal of Field Robotics},
  volume = {31},
  number = {5},
  pages = {758--779},
  issn = {1556-4967},
  doi = {10.1002/rob.21504},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21504},
  urldate = {2023-03-15},
  abstract = {Mapping large-scale underground environments, such as mines and tunnels, is typically a time-consuming and challenging endeavor. Existing methods based on terrestrial laser scanning are inefficient, and commercial mobile mapping systems are not suitable for underground use. Simultaneous Localization and Mapping (SLAM) solutions have the potential to efficiently survey underground environments while continuously moving, without relying on external positioning systems. However, no three-dimensional (3D) SLAM systems have thus far been demonstrated to be capable of mapping underground mines at kilometer scales. We have developed a solution that can accurately estimate, based on laser range and inertial measurements, the six-degrees-of-freedom trajectory of a sensor platform that continuously moves through an environment, as well as a 3D point cloud map of that environment. The key software components of the solution are continuous-time non-rigid registration, scalable place recognition, and robust pose graph optimization. A system consisting of a spinning 2D laser scanner and an industrial-grade inertial measurement unit mounted on a light vehicle was deployed at Northparkes Mine in Australia and used to map over 17 km of mine tunnel in 113 min while traveling at typical mine traffic speeds. Our processing software automatically produces a trajectory and point cloud of the mine in under half of the data acquisition time. The accuracy of the solution exceeds the raw sensor characteristics and matches closely to a surveyed map of the same environment.},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/5LKFYFLI/Zlot and Bosse - 2014 - Efficient Large-scale Three-dimensional Mobile Map.pdf}
}

@article{zobeidi_dense_2022,
  title = {Dense {{Incremental Metric-Semantic Mapping}} for {{Multiagent Systems}} via {{Sparse Gaussian Process Regression}}},
  author = {Zobeidi, Ehsan and Koppel, Alec and Atanasov, Nikolay},
  year = {2022},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {38},
  number = {5},
  pages = {3133--3153},
  issn = {1941-0468},
  doi = {10.1109/TRO.2022.3168733},
  url = {https://ieeexplore.ieee.org/document/9784107},
  urldate = {2024-11-15},
  abstract = {In this article, we develop an online probabilistic metric-semantic mapping approach for mobile robot teams relying on streaming RGB-D observations. The generated maps contain full continuous distributional information about the geometric surfaces and semantic labels (e.g., chair, table, and wall). Our approach is based on online Gaussian process (GP) training and inference and avoids the complexity of GP classification by regressing a truncated signed distance function (TSDF) of the regions occupied by different semantic classes. Online regression is enabled through a sparse pseudo-point approximation of the GP posterior. To scale to large environments, we further consider spatial domain partitioning via a hierarchical tree structure with overlapping leaves. An extension to a multirobot setting is developed by having each robot execute its own online measurement update and then combine its posterior parameters via local weighted geometric averaging with those of its neighbors. This yields a distributed information processing architecture, in which the GP map estimates of all the robots converge to a common map of the environment while relying only on local one-hop communication. Our experiments demonstrate the effectiveness of the probabilistic metric-semantic mapping technique in 2-D and 3-D environments in both the single- and multirobot settings and in comparison to a deep TSDF neural network approach.},
  keywords = {Distributed Gaussian process regression,Estimation,mapp- ing,multi-robot systems,Probabilistic logic,RGB-D perception,Robot sensing systems,Semantics,Sensors,Training,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/Y6H3S246/Zobeidi et al. - 2022 - Dense Incremental Metric-Semantic Mapping for Multiagent Systems via Sparse Gaussian Process Regress.pdf}
}

@article{zou_gaussian_2023,
  title = {Gaussian {{Process Mapping}} of {{Uncertain Building Models With GMM}} as {{Prior}}},
  author = {Zou, Qianqian and Brenner, Claus and Sester, Monika},
  year = {2023},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {10},
  pages = {6579--6586},
  issn = {2377-3766},
  doi = {10.1109/LRA.2023.3303694},
  url = {https://ieeexplore.ieee.org/abstract/document/10214122},
  urldate = {2024-03-13},
  abstract = {Mapping with uncertainty representation is required in many research domains, especially for localization. Although there are many investigations regarding the uncertainty of the pose estimation of an ego-robot with map information, the quality of the reference maps is often neglected. To avoid potential problems caused by the errors of maps and a lack of uncertainty quantification, an adequate uncertainty measure for the maps is required. In this letter, uncertain building models with abstract map surfaces using Gaussian Processes (GPs) are proposed to describe the map uncertainty in a probabilistic way. To reduce the redundant computation for simple planar objects, extracted facets from a Gaussian Mixture Model (GMM) are combined with an implicit GP map, also employing local GP-block techniques. The proposed method is evaluated on LiDAR point clouds of city buildings collected by a mobile mapping system. Compared to the performance of other methods such as OctoMap, GP Occupancy Map (GPOM), Bayesian Generalized Kernel OctoMap (BGKOctoMap), Local Automatic Relevance Determination-Hilbert Map (LARD-HM), and Gaussian Implicit Surface map (GPIS), our method achieves a higher Precision-Recall AUC for the evaluated buildings.},
  keywords = {Buildings,Kernel,laser-based,Location awareness,Mapping,Measurement uncertainty,Point cloud compression,Probabilistic logic,probability and statistical methods,Uncertainty,uncertainty representation},
  file = {/Users/kshitijgoel/Zotero/storage/S3TETSS3/Zou et al. - 2023 - Gaussian Process Mapping of Uncertain Building Mod.pdf}
}

@misc{zuo_fmgs_2024,
  title = {{{FMGS}}: {{Foundation Model Embedded 3D Gaussian Splatting}} for {{Holistic 3D Scene Understanding}}},
  shorttitle = {{{FMGS}}},
  author = {Zuo, Xingxing and Samangouei, Pouya and Zhou, Yunwen and Di, Yan and Li, Mingyang},
  year = {2024},
  month = may,
  number = {arXiv:2401.01970},
  eprint = {2401.01970},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.01970},
  url = {http://arxiv.org/abs/2401.01970},
  urldate = {2025-01-18},
  abstract = {Precisely perceiving the geometric and semantic properties of real-world 3D objects is crucial for the continued evolution of augmented reality and robotic applications. To this end, we present Foundation Model Embedded Gaussian Splatting (FMGS), which incorporates vision-language embeddings of foundation models into 3D Gaussian Splatting (GS). The key contribution of this work is an efficient method to reconstruct and represent 3D vision-language models. This is achieved by distilling feature maps generated from image-based foundation models into those rendered from our 3D model. To ensure high-quality rendering and fast training, we introduce a novel scene representation by integrating strengths from both GS and multi-resolution hash encodings (MHE). Our effective training procedure also introduces a pixel alignment loss that makes the rendered feature distance of the same semantic entities close, following the pixel-level semantic boundaries. Our results demonstrate remarkable multi-view semantic consistency, facilitating diverse downstream tasks, beating state-of-the-art methods by 10.2 percent on open-vocabulary language-based object detection, despite that we are 851X faster for inference. This research explores the intersection of vision, language, and 3D scene representation, paving the way for enhanced scene understanding in uncontrolled real-world environments. We plan to release the code on the project page.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/kshitijgoel/Zotero/storage/S7LZLDVX/Zuo et al. - 2024 - FMGS Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding.pdf;/Users/kshitijgoel/Zotero/storage/NPJK9MSW/2401.html}
}

@article{zurbrugg_embodied_2022,
  title = {Embodied {{Active Domain Adaptation}} for {{Semantic Segmentation}} via {{Informative Path Planning}}},
  author = {Zurbr{\"u}gg, Ren{\'e} and Blum, Hermann and Cadena, Cesar and Siegwart, Roland and Schmid, Lukas},
  year = {2022},
  month = oct,
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {4},
  pages = {8691--8698},
  issn = {2377-3766},
  doi = {10.1109/LRA.2022.3188901},
  abstract = {This work presents an embodied agent that can adapt its semantic segmentation network to new indoor environments in a fully autonomous way. Because semantic segmentation networks fail to generalize well to unseen environments, the agent collects images of the new environment which are then used for self-supervised domain adaptation. We formulate this as an informative path planning problem, and present a novel information gain that leverages uncertainty extracted from the semantic model to safely collect relevant data. As domain adaptation progresses, these uncertainties change over time and the rapid learning feedback of our system drives the agent to collect different data. Experiments show that our method adapts to new environments faster and with higher final performance compared to an exploration objective, and can successfully be deployed to real-world environments on physical robots.},
  keywords = {Image segmentation,integrated planning and learning,object detection,Perception-action coupling,Planning,Robots,segmentation and categorization,Semantics,Three-dimensional displays,Training,Uncertainty},
  file = {/Users/kshitijgoel/Zotero/storage/277ACJ7R/Zurbrügg et al. - 2022 - Embodied Active Domain Adaptation for Semantic Seg.pdf}
}

@inproceedings{zwicker_ewa_2001,
  title = {{{EWA}} Volume Splatting},
  booktitle = {Proceedings {{Visualization}}, 2001. {{VIS}} '01.},
  author = {Zwicker, M. and Pfister, H. and Van Baar, J. and Gross, M.},
  year = {2001},
  pages = {29--538},
  publisher = {IEEE},
  address = {San Diego, CA, USA},
  doi = {10.1109/VISUAL.2001.964490},
  url = {http://ieeexplore.ieee.org/document/964490/},
  urldate = {2023-11-11},
  abstract = {In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.},
  isbn = {978-0-7803-7200-9},
  langid = {english},
  file = {/Users/kshitijgoel/Zotero/storage/SGVJHHLE/Zwicker et al. - 2001 - EWA volume splatting.pdf}
}
